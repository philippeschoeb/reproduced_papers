{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KD vs RKD vs QRKD (mini MNIST)\n",
    "\n",
    "This walkthrough trains small teacher/student CNNs on a **10k subset of MNIST** for a few epochs to contrast classical distillation flavors:\n",
    "\n",
    "- **KD**: match teacher logits (soft targets).\n",
    "- **RKD**: match relational geometry (pairwise distances/angles) of teacher features.\n",
    "- **QRKD**: extend RKD with a quantum-inspired fidelity kernel on normalized features (see `QRKD.txt` and the paper *Quantum Relational Knowledge Distillation*, arXiv:2508.13054, for the conceptual background: map features to a Hilbert space and align quantum kernels \\|\\u27e8\\u03c6(x\\_i)\\|\\u03c6(x\\_j)\\u27e9\\|^2 to transfer richer relations).\n",
    "\n",
    "We keep everything classical here; the \"quantum\" part is the fidelity kernel regularizer over feature vectors. Runs are short (3 epochs) for quick comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add project to path when running from repo root\n",
    "import sys\n",
    "ROOT = Path(\".\").resolve()\n",
    "if str(ROOT / \"QRKD\") not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT / \"QRKD\"))\n",
    "\n",
    "from lib.models import TeacherCNN, StudentCNN\n",
    "from lib.losses import DistillationLoss\n",
    "from lib.train import TrainConfig, train_teacher, train_student\n",
    "from lib.utils import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for the quick demo\n",
    "SEED = 1337\n",
    "SUBSET_SIZE = 10_000  # use 10k samples from MNIST train split\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 3\n",
    "LR = 1e-3\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: 10k MNIST subset for training, full 10k test for evaluation\n",
    "tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "train_full = datasets.MNIST(\"data\", train=True, download=True, transform=tfm)\n",
    "indices = torch.randperm(len(train_full))[:SUBSET_SIZE]\n",
    "train_subset = Subset(train_full, indices)\n",
    "test_set = datasets.MNIST(\"data\", train=False, download=True, transform=tfm)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "len(train_subset), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: train teacher\n",
    "def run_teacher():\n",
    "    teacher = TeacherCNN().to(DEVICE)\n",
    "    cfg = TrainConfig(epochs=EPOCHS, lr=LR, device=str(DEVICE), verbose=True)\n",
    "    teacher, hist = train_teacher(teacher, train_loader, cfg, test_loader)\n",
    "    return teacher, hist\n",
    "\n",
    "teacher, hist_teacher = run_teacher()\n",
    "hist_teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student variants\n",
    "def run_student(student_name: str, weights: DistillationLoss, teacher_model=None):\n",
    "    student = StudentCNN().to(DEVICE)\n",
    "    cfg = TrainConfig(epochs=EPOCHS, lr=LR, device=str(DEVICE), verbose=True)\n",
    "    result = train_student(student, teacher_model, train_loader, test_loader, cfg, weights, student_name=student_name)\n",
    "    return result[\"history\"], result[\"test_acc\"]\n",
    "\n",
    "histories = {}\n",
    "test_accs = {}\n",
    "\n",
    "# Scratch\n",
    "scratch_hist, scratch_acc = run_student(\"student_scratch\", DistillationLoss(kd=0.0, dr=0.0, ar=0.0, qk=0.0), teacher_model=None)\n",
    "histories[\"Scratch\"] = scratch_hist\n",
    "test_accs[\"Scratch\"] = scratch_acc\n",
    "\n",
    "# KD\n",
    "kd_weights = DistillationLoss(kd=0.5, dr=0.0, ar=0.0, qk=0.0, temperature=4.0, kd_alpha=0.5)\n",
    "kd_hist, kd_acc = run_student(\"student_kd\", kd_weights, teacher_model=teacher)\n",
    "histories[\"KD\"] = kd_hist\n",
    "test_accs[\"KD\"] = kd_acc\n",
    "\n",
    "# RKD\n",
    "rkd_weights = DistillationLoss(kd=0.0, dr=0.1, ar=0.1, qk=0.0, temperature=4.0, kd_alpha=0.5)\n",
    "rkd_hist, rkd_acc = run_student(\"student_rkd\", rkd_weights, teacher_model=teacher)\n",
    "histories[\"RKD\"] = rkd_hist\n",
    "test_accs[\"RKD\"] = rkd_acc\n",
    "\n",
    "# QRKD (simple fidelity kernel on features)\n",
    "qrkd_weights = DistillationLoss(\n",
    "    kd=0.5,\n",
    "    dr=0.1,\n",
    "    ar=0.1,\n",
    "    qk=0.1,\n",
    "    qk_backend=\"merlin\",  # use Merl√Øn fidelity kernel backend for the \"quantum\" relational term\n",
    "    qk_n_modes=10,\n",
    "    qk_n_photons=5,\n",
    "    temperature=4.0,\n",
    "    kd_alpha=0.5,\n",
    ")\n",
    "qrkd_hist, qrkd_acc = run_student(\"student_qrkd\", qrkd_weights, teacher_model=teacher)\n",
    "histories[\"QRKD\"] = qrkd_hist\n",
    "test_accs[\"QRKD\"] = qrkd_acc\n",
    "\n",
    "test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize final accuracy\n",
    "from pprint import pprint\n",
    "\n",
    "summary = {\n",
    "    \"Teacher train\": hist_teacher[\"train_acc\"][-1],\n",
    "    \"Teacher test\": hist_teacher[\"test_acc\"][-1],\n",
    "}\n",
    "for name in [\"Scratch\", \"KD\", \"RKD\", \"QRKD\"]:\n",
    "    h = histories[name]\n",
    "    summary[f\"{name} train\"] = h[\"train_acc\"][-1]\n",
    "    summary[f\"{name} test\"] = h[\"test_acc\"][-1]\n",
    "\n",
    "pprint(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy curves\n",
    "plt.figure(figsize=(8, 5))\n",
    "epochs = range(1, EPOCHS + 1)\n",
    "plt.plot(epochs, hist_teacher[\"train_acc\"], label=\"Teacher train\", marker=\"o\")\n",
    "plt.plot(epochs, hist_teacher[\"test_acc\"], label=\"Teacher test\", marker=\"x\", linestyle=\"--\")\n",
    "for name, style in zip([\"Scratch\", \"KD\", \"RKD\", \"QRKD\"], [\"-\", \"--\", \"-.\", \":\"]):\n",
    "    train = histories[name][\"train_acc\"]\n",
    "    test = histories[name][\"test_acc\"]\n",
    "    plt.plot(epochs, train, label=f\"{name} train\", marker=\"o\", linestyle=style)\n",
    "    plt.plot(epochs, test, label=f\"{name} test\", marker=\"x\", linestyle=style)\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"KD vs RKD vs QRKD on 10k MNIST subset\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
