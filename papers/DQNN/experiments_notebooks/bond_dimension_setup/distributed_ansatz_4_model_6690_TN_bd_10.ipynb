{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1637.5\" height=\"593.75\" viewBox=\"-30.0 0 1310.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.615968</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.176858</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.491779</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.270334</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.18105</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.780972</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.839758</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.129596</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.516667</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.908748</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.131645</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.251263</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.747513</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.919496</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.348707</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.971089</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.125304</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.546382</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.938062</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.014583</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.435556</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.624612</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.29591</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.824777</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.332312</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.605712</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.727727</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.098243</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.755074</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.1277</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.637946</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.498587</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.84915</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.224791</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.972742</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.221953</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.664839</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.966107</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.885312</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.351013</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.321069</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.233929</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.182461</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.34901</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.45401</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.345373</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.156457</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.734499</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.173532</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.019966</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.801444</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.917521</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.302358</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.174632</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.81159</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.341672</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.668798</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.619817</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.347688</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.516094</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.879582</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.837221</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.008616</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.115833</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.743963</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.012085</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.803604</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.279518</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.773759</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.241897</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.498742</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.16995</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.627421</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.312893</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.003923</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.807581</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.988504</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.473282</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.991777</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.334076</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.091967</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.410589</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.214939</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.096916</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.365572</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.076026</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.675424</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.824672</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.62746</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.727703</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.106833</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.212508</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.608588</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.353697</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.737658</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.043084</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25.0 L1240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,125.0 L1240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,175.0 L1240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,225.0 L1240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,275.0 L1240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,325.0 L1240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,375.0 L1240,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,425.0 L1240,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1250\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1250\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1250\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1250\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1250\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1250\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1250\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1250\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1250\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7c49b2b403d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m=9, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.85549</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.110444</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.969731</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.037339</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.698961</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.671986</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.687041</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.038529</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.674513</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.150659</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.755375</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.819354</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.951681</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.629848</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.087593</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.97672</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.585868</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.93097</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.820522</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.587921</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.915681</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.253397</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.361071</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.526343</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.564045</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.926508</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.676014</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.666648</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.232176</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.970302</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.222139</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.414231</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.441453</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.461236</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.219568</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.022935</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.641648</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.278828</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.713285</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.367264</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.537207</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.797495</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.313493</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.170189</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.379654</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.308025</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.072954</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.387941</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.424925</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.208033</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.333881</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.219331</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.111879</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.499367</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.253052</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.990143</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.82627</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.820866</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.054269</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.936741</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.69925</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.250843</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.442553</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.621534</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.919186</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.952669</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.836693</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.921938</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.681296</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.125749</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.162962</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.317035</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.324861</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.220479</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.358161</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7c49b2ad49d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m=8, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        #     super(CNNModel, self).__init__()\n",
    "        #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "        #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "        #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "        #     self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "        # def forward(self, x):\n",
    "        #     x = self.pool(self.conv1(x))\n",
    "        #     x = self.pool(self.conv2(x))\n",
    "        #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        #     x = self.fc1(x)\n",
    "        #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 73.67%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    # class MappingModel(nn.Module):\n",
    "    #     def __init__(self, input_size, hidden_sizes, output_size):\n",
    "    #         super().__init__()\n",
    "    #         # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "    #         self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "    #         self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "    #         self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    #     def forward(self, X):\n",
    "    #         # Ensure the input tensor is the same type as the weights\n",
    "    #         X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "    #         # Input layer with ReLU activation\n",
    "    #         X = self.input_layer(X)\n",
    "\n",
    "    #         # Hidden layers with ReLU activation\n",
    "    #         for hidden in self.hidden_layers:\n",
    "    #             X = hidden(X)\n",
    "\n",
    "    #         # Output layer with linear activation\n",
    "    #         output = self.output_layer(X)\n",
    "    #         # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "    #         return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "        # self.MappingNetwork = self.MappingModel(n_qubit+1, [8], 1).to(device)\n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit + 1, output_dim=1, bond_dim=10)\n",
    "\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        # self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[\n",
    "            :108\n",
    "        ]  # nn.Parameter(q_delta * torch.randn(135)).to(device)\n",
    "        self.q_params_2 = qnn_parameters[108:]\n",
    "        device = x.device\n",
    "\n",
    "        res_1 = bs_1.run(parameters=self.q_params_1, samples=100000)\n",
    "        trans_res_1 = bs_1.translate_results(res=res_1)\n",
    "        trans_res_1 = trans_res_1 / torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)\n",
    "\n",
    "        res_2 = bs_2.run(parameters=self.q_params_2, samples=100000)\n",
    "        trans_res_2 = bs_2.translate_results(res=res_2)\n",
    "        trans_res_2 = trans_res_2 / torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)\n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(126 * 70, 1)\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[: len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  3100\n",
      "# of trainable parameter in QNN model:  192\n",
      "# of trainable parameter in full model:  3292\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108 + 84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\n",
    "    \"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters\n",
    ")\n",
    "print(\n",
    "    \"# of trainable parameter in full model: \",\n",
    "    num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.2889, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.1664, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 1.8582, batch time: 0.10, accuracy:  35.94%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 1.8236, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 1.5374, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 1.2615, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 0.9694, batch time: 0.04, accuracy:  71.09%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 0.8718, batch time: 0.11, accuracy:  70.31%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 0.7756, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 0.9743, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 0.7541704177856445, accuracy: 74.5 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 0.794323205947876, accuracy: 73.3 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 0.734567403793335, accuracy: 75.7 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 0.7252063751220703, accuracy: 76.8 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 0.7106390595436096, accuracy: 77.6 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 0.7678558230400085, accuracy: 74.8 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 0.7171351909637451, accuracy: 77.3 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 0.6811805367469788, accuracy: 78.2 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 0.6880494356155396, accuracy: 77.4 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 0.6797682046890259, accuracy: 78.0 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 0.7034, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 0.6907, batch time: 0.11, accuracy:  73.44%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 0.5555, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 0.5605, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 0.4691, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 0.4671, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 0.4822, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 0.2763, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 0.4524, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 0.4424, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 0.4205152690410614, accuracy: 87.7 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 0.41259077191352844, accuracy: 87.6 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 0.4337678849697113, accuracy: 87.7 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 0.398016095161438, accuracy: 88.6 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 0.43555834889411926, accuracy: 87.4 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 0.4082975685596466, accuracy: 87.5 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 0.4362231194972992, accuracy: 86.9 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 0.3692764639854431, accuracy: 89.3 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 0.3663763105869293, accuracy: 89.6 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 0.3759998083114624, accuracy: 88.7 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 0.3689, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 0.3494, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 0.4039, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 0.4388, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 0.4161, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 0.4478, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 0.4398, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 0.4207, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 0.4602, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 0.4695, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 0.3321089744567871, accuracy: 89.7 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 1.980019450187683, accuracy: 54.0 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 0.35162946581840515, accuracy: 89.7 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 0.30905938148498535, accuracy: 89.7 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 0.34093356132507324, accuracy: 90.1 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 0.33717218041419983, accuracy: 89.6 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 0.30621328949928284, accuracy: 90.3 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 0.32586243748664856, accuracy: 90.1 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 0.33069026470184326, accuracy: 90.1 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 0.3524404764175415, accuracy: 89.0 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 0.4010, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 0.2806, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 0.3964, batch time: 0.09, accuracy:  92.19%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 0.2443, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 0.3023, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 0.4577, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 0.3566, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 0.2198, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 0.2154, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 0.3306, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 0.29146796464920044, accuracy: 91.5 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 0.2924882769584656, accuracy: 91.0 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 0.27384278178215027, accuracy: 92.1 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 0.2645733058452606, accuracy: 92.0 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 0.3300710916519165, accuracy: 89.9 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 0.2770051658153534, accuracy: 91.8 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 0.26096123456954956, accuracy: 92.5 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 0.261111319065094, accuracy: 92.7 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 0.2586897313594818, accuracy: 92.7 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 0.2583087980747223, accuracy: 92.5 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 0.2464, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 0.2897, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 0.2994, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 0.3596, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 0.2810, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 0.3231, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 0.1143, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 0.2351, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 0.3601, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 0.2188, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 0.23577295243740082, accuracy: 93.5 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 1.200610637664795, accuracy: 70.3 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 0.2233884632587433, accuracy: 93.9 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 0.21938888728618622, accuracy: 93.6 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 0.21285545825958252, accuracy: 93.3 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 0.2135152369737625, accuracy: 93.5 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 0.2140190750360489, accuracy: 93.5 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 0.2753952443599701, accuracy: 92.5 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 0.2516290545463562, accuracy: 91.8 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 0.226037859916687, accuracy: 93.3 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 0.2803, batch time: 0.09, accuracy:  91.41%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 0.4739, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 0.1498, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 0.3002, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 0.2732, batch time: 0.08, accuracy:  90.62%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 0.2635, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 0.3635, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 0.2147, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 0.1678, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 0.2938, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 0.24220921099185944, accuracy: 92.7 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 0.2654135227203369, accuracy: 90.6 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 0.25435513257980347, accuracy: 92.1 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 0.24977591633796692, accuracy: 92.4 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 0.24008136987686157, accuracy: 93.0 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 0.23001910746097565, accuracy: 93.0 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 0.23755693435668945, accuracy: 93.3 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 0.3121371865272522, accuracy: 89.6 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 0.22456401586532593, accuracy: 93.0 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 0.22475703060626984, accuracy: 93.3 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 0.2200, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 0.1829, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 0.3707, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 0.2346, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 0.1392, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 0.2168, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 0.1601, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 0.2750, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 0.3000, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 0.1748, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 0.2096526324748993, accuracy: 94.1 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 0.20583391189575195, accuracy: 94.1 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 0.19969086349010468, accuracy: 94.5 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 0.19728590548038483, accuracy: 94.6 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 0.20097045600414276, accuracy: 93.7 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 0.18811126053333282, accuracy: 94.0 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 0.21967430412769318, accuracy: 93.4 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 0.18179652094841003, accuracy: 94.8 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 0.17999958992004395, accuracy: 94.4 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 0.1798252910375595, accuracy: 94.5 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 0.1996, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 0.1947, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 0.1813, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 0.1327, batch time: 0.07, accuracy:  96.09%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 0.1553, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 0.1600, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 0.1589, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 0.2115, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 0.2066, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 0.2751, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 0.2064630389213562, accuracy: 93.9 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 0.20039238035678864, accuracy: 94.9 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 0.19318607449531555, accuracy: 95.2 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 0.1925574243068695, accuracy: 95.7 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 0.20192024111747742, accuracy: 94.6 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 0.19003668427467346, accuracy: 95.1 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 0.34164196252822876, accuracy: 90.0 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 0.20183302462100983, accuracy: 94.9 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 0.18769799172878265, accuracy: 95.0 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 0.18610848486423492, accuracy: 94.7 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 0.2334, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 0.0484, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 0.2068, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 0.3205, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 0.1941, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 0.1988, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 0.2761, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 0.1336, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 0.2207, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 0.3084, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 0.20722617208957672, accuracy: 93.2 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 0.2187928557395935, accuracy: 93.2 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 0.201897993683815, accuracy: 93.4 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 0.19365669786930084, accuracy: 93.5 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 0.18598151206970215, accuracy: 93.4 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 0.20850202441215515, accuracy: 93.0 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 0.1776786893606186, accuracy: 93.9 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 0.17351047694683075, accuracy: 94.0 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 0.17017336189746857, accuracy: 94.1 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 0.16794845461845398, accuracy: 94.4 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 0.1894, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 0.2011, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 0.1556, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 0.1783, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 0.1835, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 0.1331, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 0.2253, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 0.2385, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 0.1710, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 0.1863, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 0.1679271161556244, accuracy: 94.1 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 0.17373110353946686, accuracy: 93.8 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 0.16420695185661316, accuracy: 95.6 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 0.14331771433353424, accuracy: 95.7 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 0.15368641912937164, accuracy: 96.0 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 0.15425045788288116, accuracy: 95.4 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 0.140749990940094, accuracy: 96.1 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 0.14161242544651031, accuracy: 96.1 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 0.13752993941307068, accuracy: 96.3 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 0.13749195635318756, accuracy: 96.4 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 0.1756, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 0.2686, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 0.0728, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 0.1556, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 0.1315, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 0.2755, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 0.1206, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 0.1236, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 0.1920, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 0.0636, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 0.22354833781719208, accuracy: 93.6 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 0.24461862444877625, accuracy: 92.8 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 0.19780631363391876, accuracy: 93.9 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 0.19117312133312225, accuracy: 94.5 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 0.20428554713726044, accuracy: 93.9 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 0.18656153976917267, accuracy: 94.4 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 0.20171032845973969, accuracy: 94.4 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 0.17533162236213684, accuracy: 94.8 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 0.18541531264781952, accuracy: 94.8 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 0.1753946989774704, accuracy: 95.1 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 0.2792, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 0.1166, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 0.1794, batch time: 0.09, accuracy:  93.75%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 0.2850, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 0.2902, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 0.2458, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 0.1878, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 0.1464, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 0.1379, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 0.1616, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 0.18459804356098175, accuracy: 93.2 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 0.20033897459506989, accuracy: 93.0 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 0.1657957285642624, accuracy: 94.0 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 0.16366930305957794, accuracy: 94.2 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 0.1599206179380417, accuracy: 93.9 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 0.1695970594882965, accuracy: 94.4 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 0.15199239552021027, accuracy: 94.5 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 0.14516524970531464, accuracy: 94.8 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 0.16365130245685577, accuracy: 94.3 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 0.16212007403373718, accuracy: 94.5 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 0.1710, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 0.2152, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 0.1335, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 0.0891, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 0.0724, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 0.1582, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 0.1423, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 0.1094, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 0.1489, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 0.1922, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 0.1533256620168686, accuracy: 94.2 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 0.15147767961025238, accuracy: 94.7 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 0.3174099326133728, accuracy: 90.0 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 0.19422511756420135, accuracy: 93.0 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 0.12917622923851013, accuracy: 95.8 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 0.1299276053905487, accuracy: 95.3 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 0.12192452698945999, accuracy: 96.0 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 0.1247437447309494, accuracy: 95.4 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 0.12380712479352951, accuracy: 95.9 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 0.11795678734779358, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 0.1110, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 0.1849, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 0.1174, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 0.1228, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 0.2299, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 0.1465, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 0.0957, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 0.2136, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 0.1251, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 0.2573, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 0.1276969611644745, accuracy: 95.9 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 0.1256648153066635, accuracy: 96.2 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 0.13352316617965698, accuracy: 96.1 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 0.12322089821100235, accuracy: 96.1 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 0.11971797794103622, accuracy: 96.9 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 0.12235411256551743, accuracy: 96.8 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 0.11549395322799683, accuracy: 96.5 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 0.11503137648105621, accuracy: 96.5 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 0.10928194969892502, accuracy: 96.6 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 0.10720951110124588, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 0.2330, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 0.1161, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 0.1896, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 0.1377, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 0.2579, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 0.1034, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 0.1237, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 0.1218, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 0.0917, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 0.0957, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 0.11192233860492706, accuracy: 96.4 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 0.11737196147441864, accuracy: 95.8 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 0.10109568387269974, accuracy: 97.1 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 0.09981769323348999, accuracy: 97.0 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 0.10286460816860199, accuracy: 96.9 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 0.11694414168596268, accuracy: 96.3 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 0.11907432228326797, accuracy: 96.5 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 0.09279651939868927, accuracy: 97.6 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 0.09162475168704987, accuracy: 97.6 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 0.09090828150510788, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 0.1924, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 0.1748, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 0.2287, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 0.1488, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 0.2074, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 0.1578, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 0.1301, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 0.1745, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 0.0942, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 0.1007, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 0.11046946793794632, accuracy: 97.3 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 0.14133280515670776, accuracy: 95.1 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 0.11483630537986755, accuracy: 96.5 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 0.10156210511922836, accuracy: 97.3 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 0.10725521296262741, accuracy: 97.3 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 0.10771821439266205, accuracy: 96.1 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 0.09134337306022644, accuracy: 97.4 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 0.08812478184700012, accuracy: 97.5 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 0.08698451519012451, accuracy: 97.4 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 0.08574721217155457, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 0.1864, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 0.1766, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 0.1407, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 0.1559, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 0.1233, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 0.1964, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 0.1490, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 0.1300, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 0.0894, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 0.1519, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 0.15262745320796967, accuracy: 96.1 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 0.14644134044647217, accuracy: 96.0 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 0.13692790269851685, accuracy: 96.7 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 0.12804628908634186, accuracy: 96.9 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 0.1305103898048401, accuracy: 96.3 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 0.14506258070468903, accuracy: 96.1 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 0.14349022507667542, accuracy: 95.4 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 0.15109220147132874, accuracy: 95.9 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 0.1296079307794571, accuracy: 96.6 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 0.12434111535549164, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 0.1509, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 0.0848, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 0.1227, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 0.1120, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 0.1447, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 0.0436, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 0.0769, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 0.1248, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 0.0469, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 0.1201, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 0.11315105110406876, accuracy: 96.2 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 0.12876619398593903, accuracy: 95.8 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 0.10383480042219162, accuracy: 96.9 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 0.09835775196552277, accuracy: 97.3 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 0.09695494174957275, accuracy: 97.3 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 0.1287441998720169, accuracy: 95.6 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 0.10254694521427155, accuracy: 96.9 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 0.0959370881319046, accuracy: 97.3 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 0.14936523139476776, accuracy: 94.9 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 0.09931164979934692, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 0.1138, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 0.0569, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 0.0831, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 0.1571, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 0.0781, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 0.1428, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 0.1823, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 0.1099, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 0.1167, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 0.0878, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 0.13032178580760956, accuracy: 95.5 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 0.14371289312839508, accuracy: 94.6 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 0.13490261137485504, accuracy: 94.9 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 0.1170254647731781, accuracy: 95.7 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 0.11512809991836548, accuracy: 96.1 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 0.10808522254228592, accuracy: 95.9 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 0.10814572870731354, accuracy: 96.0 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 0.11622243374586105, accuracy: 95.5 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 0.1077897772192955, accuracy: 96.5 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 0.1048584058880806, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 0.2873, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 0.2024, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 0.1146, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 0.1246, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 0.1081, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 0.0742, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 0.0847, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 0.1360, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 0.2142, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 0.0697, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 0.11973580718040466, accuracy: 95.6 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 0.11285277456045151, accuracy: 96.4 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 0.12130017578601837, accuracy: 95.8 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 0.10043910145759583, accuracy: 97.0 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 0.10774486511945724, accuracy: 96.2 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 0.11018030345439911, accuracy: 96.2 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 0.10728532075881958, accuracy: 96.6 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 0.13138648867607117, accuracy: 95.9 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 0.10359504818916321, accuracy: 96.5 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 0.09427858144044876, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 0.1642, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 0.0803, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 0.1270, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 0.0845, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 0.0737, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 0.0873, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 0.1048, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 0.1071, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 0.0818, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 0.0975, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 0.10881957411766052, accuracy: 96.3 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 0.15976330637931824, accuracy: 94.6 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 0.11373903602361679, accuracy: 96.8 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 0.10178941488265991, accuracy: 96.7 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 0.09718697518110275, accuracy: 97.1 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 0.11143433302640915, accuracy: 96.6 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 0.09282075613737106, accuracy: 97.2 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 0.11778533458709717, accuracy: 95.8 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 0.11980563402175903, accuracy: 95.8 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 0.09375469386577606, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 0.0778, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 0.0949, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 0.0320, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 0.0754, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 0.1010, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 0.1535, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 0.1207, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 0.0947, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 0.0478, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 0.0606, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 0.11961875855922699, accuracy: 95.8 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 0.11719357967376709, accuracy: 95.9 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 0.10757342725992203, accuracy: 96.4 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 0.11401355266571045, accuracy: 96.3 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 0.10856299102306366, accuracy: 96.6 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 0.0874260663986206, accuracy: 97.0 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 0.09492220729589462, accuracy: 97.2 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 0.08485548198223114, accuracy: 97.5 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 0.08375390619039536, accuracy: 97.6 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 0.08141089230775833, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 0.2016, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 0.1734, batch time: 0.08, accuracy:  92.19%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 0.1353, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 0.2218, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 0.0731, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 0.1128, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 0.1549, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 0.2076, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 0.0650, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 0.0856, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 0.09805136173963547, accuracy: 96.9 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 0.13339310884475708, accuracy: 96.3 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 0.12440412491559982, accuracy: 96.1 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 0.11333570629358292, accuracy: 96.2 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 0.086087666451931, accuracy: 97.4 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 0.08011549711227417, accuracy: 97.6 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 0.07933539897203445, accuracy: 97.6 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 0.07825212180614471, accuracy: 97.9 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 0.0778723880648613, accuracy: 98.0 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 0.07765840739011765, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 0.1176, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 0.0932, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 0.1555, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 0.1678, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 0.0630, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 0.1755, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 0.0498, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 0.1009, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 0.1060, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 0.0814, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 0.09567967057228088, accuracy: 96.9 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 0.11713434755802155, accuracy: 95.1 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 0.1338547319173813, accuracy: 95.2 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 0.08511092513799667, accuracy: 97.4 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 0.08413880318403244, accuracy: 97.4 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 0.10543005913496017, accuracy: 96.7 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 0.11832574754953384, accuracy: 95.6 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 0.0794154480099678, accuracy: 97.7 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 0.07644755393266678, accuracy: 97.6 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 0.07387235015630722, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 0.0479, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 0.0821, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 0.1018, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 0.1405, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 0.0698, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 0.0849, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 0.0364, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 0.1197, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 0.0594, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 0.1053, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 0.13837699592113495, accuracy: 95.4 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 0.15074217319488525, accuracy: 95.5 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 0.1310892552137375, accuracy: 95.4 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 0.13514481484889984, accuracy: 95.5 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 0.13444499671459198, accuracy: 95.3 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 0.11756131052970886, accuracy: 95.6 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 0.12204951047897339, accuracy: 95.7 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 0.10515189915895462, accuracy: 96.7 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 0.10352803021669388, accuracy: 96.3 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 0.10279583185911179, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 0.0451, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 0.1179, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 0.2630, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 0.1612, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 0.1417, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 0.0937, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 0.1470, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 0.0616, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 0.0584, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 0.0620, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 0.09233398735523224, accuracy: 96.7 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 0.11444797366857529, accuracy: 96.0 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 0.10135193169116974, accuracy: 96.4 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 0.08001939952373505, accuracy: 97.4 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 0.09482262283563614, accuracy: 96.5 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 0.0833248719573021, accuracy: 96.9 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 0.06975805759429932, accuracy: 97.7 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 0.0694170817732811, accuracy: 98.0 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 0.06855137646198273, accuracy: 97.8 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 0.06781048327684402, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 0.1135, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 0.3232, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 0.1204, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 0.0594, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 0.1111, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 0.2712, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 0.0637, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 0.1570, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 0.0491, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 0.0689, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 0.10716726630926132, accuracy: 96.3 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 0.11346732825040817, accuracy: 96.2 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 0.10281194001436234, accuracy: 96.8 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 0.09642066061496735, accuracy: 97.0 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 0.11316738277673721, accuracy: 96.3 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 0.10074091702699661, accuracy: 96.6 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 0.08897463977336884, accuracy: 97.0 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 0.09540503472089767, accuracy: 97.2 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 0.08401840925216675, accuracy: 97.4 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 0.09228366613388062, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 0.0909, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 0.1243, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 0.1567, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 0.1512, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 0.0531, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 0.1013, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 0.0944, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 0.1352, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 0.0908, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 0.0819, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 0.1152634471654892, accuracy: 96.0 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 0.1832653135061264, accuracy: 94.5 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 0.10603367537260056, accuracy: 96.4 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 0.09567002207040787, accuracy: 96.6 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 0.11964310705661774, accuracy: 95.7 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 0.11039253324270248, accuracy: 96.6 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 0.10892289131879807, accuracy: 96.3 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 0.08179033547639847, accuracy: 97.0 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 0.0823609009385109, accuracy: 96.9 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 0.0757598727941513, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 0.0482, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 0.2172, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 0.1330, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 0.0737, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 0.0742, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 0.0931, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 0.1623, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 0.2145, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 0.2174, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 0.0950, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 0.12209317088127136, accuracy: 96.3 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 0.1332705169916153, accuracy: 95.0 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 0.12173910439014435, accuracy: 95.1 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 0.09254812449216843, accuracy: 97.4 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 0.1101662814617157, accuracy: 96.1 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 0.09415186196565628, accuracy: 97.2 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 0.1249200776219368, accuracy: 95.5 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 0.07770209014415741, accuracy: 97.8 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 0.07667004317045212, accuracy: 97.9 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 0.07566781342029572, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 0.1740, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 0.1665, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 0.0965, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 0.0599, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 0.2416, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 0.0883, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 0.1321, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 0.0354, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 0.0925, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 0.0891, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 0.06965355575084686, accuracy: 97.7 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 0.08792322874069214, accuracy: 97.4 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 0.06109882518649101, accuracy: 98.2 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 0.05938059464097023, accuracy: 98.3 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 0.06215709447860718, accuracy: 98.2 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 0.05850936844944954, accuracy: 98.2 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 0.0763636976480484, accuracy: 97.4 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 0.05836993828415871, accuracy: 98.4 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 0.05228135734796524, accuracy: 98.5 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 0.05242067202925682, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 0.0766, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 0.0958, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 0.0611, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 0.1446, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 0.0774, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 0.0627, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 0.0834, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 0.1908, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 0.1221, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 0.1928, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 0.09336203336715698, accuracy: 96.7 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 0.21303047239780426, accuracy: 93.1 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 0.0875638797879219, accuracy: 96.9 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 0.08049050718545914, accuracy: 96.8 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 0.08972664177417755, accuracy: 96.9 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 0.07557663321495056, accuracy: 97.2 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 0.07567069679498672, accuracy: 97.3 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 0.09051354229450226, accuracy: 96.9 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 0.08873789012432098, accuracy: 97.1 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 0.07313326746225357, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 0.0559, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 0.1122, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 0.1822, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 0.0720, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 0.1131, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 0.0785, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 0.0803, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 0.0794, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 0.0670, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 0.0660, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 0.06416864693164825, accuracy: 98.4 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 0.06394728273153305, accuracy: 97.9 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 0.05674494057893753, accuracy: 98.2 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 0.04954078793525696, accuracy: 98.3 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 0.06701099127531052, accuracy: 98.0 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 0.046392038464546204, accuracy: 98.8 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 0.04590054228901863, accuracy: 98.7 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 0.04490222781896591, accuracy: 98.8 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 0.04422784224152565, accuracy: 98.6 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 0.04376831278204918, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 0.1355, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 0.0818, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 0.1057, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 0.1456, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 0.1205, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 0.1181, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 0.1444, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 0.0712, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 0.0936, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 0.1270, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 0.09987985342741013, accuracy: 96.6 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 0.15967251360416412, accuracy: 95.0 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 0.10644729435443878, accuracy: 96.7 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 0.09628802537918091, accuracy: 96.3 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 0.0828617513179779, accuracy: 96.8 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 0.08484922349452972, accuracy: 96.9 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 0.07816198468208313, accuracy: 97.2 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 0.08104623109102249, accuracy: 97.3 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 0.07709865272045135, accuracy: 97.0 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 0.08298998326063156, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 0.0758, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 0.1469, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 0.2037, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 0.1120, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 0.0689, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 0.0817, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 0.1255, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 0.0766, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 0.1810, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 0.0918, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 0.1081739291548729, accuracy: 96.1 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 0.10861581563949585, accuracy: 96.1 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 0.10759266465902328, accuracy: 97.1 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 0.08894606679677963, accuracy: 97.1 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 0.08919385075569153, accuracy: 96.9 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 0.09465672075748444, accuracy: 96.9 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 0.09255234897136688, accuracy: 97.1 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 0.09164783358573914, accuracy: 97.1 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 0.07900900393724442, accuracy: 97.5 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 0.07662907987833023, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 0.1445, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 0.1383, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 0.0417, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 0.0733, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 0.1035, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 0.1368, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 0.1036, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 0.0479, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 0.0662, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 0.0795, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 0.08003514260053635, accuracy: 97.2 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 0.13327404856681824, accuracy: 95.5 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 0.08088400959968567, accuracy: 96.9 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 0.12656836211681366, accuracy: 95.7 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 0.0727255642414093, accuracy: 97.2 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 0.0696270763874054, accuracy: 97.7 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 0.06895908713340759, accuracy: 97.6 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 0.07247985154390335, accuracy: 97.9 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 0.06881281733512878, accuracy: 97.5 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 0.06793353706598282, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 0.0819, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 0.0846, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 0.0595, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 0.1591, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 0.0606, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 0.1472, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 0.0808, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 0.0537, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 0.0875, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 0.0931, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 0.0718388631939888, accuracy: 97.7 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 0.13697709143161774, accuracy: 94.9 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 0.13787052035331726, accuracy: 94.8 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 0.0887172520160675, accuracy: 96.9 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 0.06181059777736664, accuracy: 98.3 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 0.04995650798082352, accuracy: 98.7 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 0.0495416522026062, accuracy: 98.7 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 0.04632660374045372, accuracy: 98.8 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 0.044282399117946625, accuracy: 98.9 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 0.048283472657203674, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 0.1007, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 0.1053, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 0.1000, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 0.1172, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 0.0736, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 0.0568, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 0.0787, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 0.0596, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 0.0415, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 0.1358, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 0.0730762630701065, accuracy: 97.8 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 0.07916194200515747, accuracy: 97.6 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 0.06451476365327835, accuracy: 97.8 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 0.06414967030286789, accuracy: 97.8 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 0.15702679753303528, accuracy: 93.9 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 0.0657358169555664, accuracy: 97.7 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 0.08483149856328964, accuracy: 97.1 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 0.05821281298995018, accuracy: 98.1 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 0.05699996277689934, accuracy: 97.7 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 0.057313308119773865, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 0.0369, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 0.1514, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 0.0872, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 0.1203, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 0.1021, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 0.0987, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 0.1299, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 0.1522, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 0.3412, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 0.1257, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 0.06461481750011444, accuracy: 97.8 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 0.10750619322061539, accuracy: 96.2 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 0.06440352648496628, accuracy: 97.6 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 0.058358222246170044, accuracy: 98.0 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 0.0616404227912426, accuracy: 97.9 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 0.07068862020969391, accuracy: 97.5 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 0.05931762605905533, accuracy: 98.0 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 0.07498843222856522, accuracy: 97.0 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 0.0697636753320694, accuracy: 97.7 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 0.057501357048749924, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 0.0535, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 0.0732, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 0.0590, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 0.0686, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 0.0254, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 0.1109, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 0.0738, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 0.1988, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 0.0485, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 0.1096, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 0.07711211591959, accuracy: 98.0 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 0.33979740738868713, accuracy: 88.9 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 0.07619491219520569, accuracy: 97.9 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 0.07134813815355301, accuracy: 97.8 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 0.07029407471418381, accuracy: 97.9 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 0.07522092759609222, accuracy: 98.1 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 0.07950527966022491, accuracy: 98.1 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 0.06480036675930023, accuracy: 98.2 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 0.06393091380596161, accuracy: 98.6 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 0.06353306770324707, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 0.0886, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 0.1243, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 0.0199, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 0.0479, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 0.1852, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 0.0866, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 0.0438, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 0.0634, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 0.0360, batch time: 0.22, accuracy:  97.66%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 0.1052, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 0.08152292668819427, accuracy: 96.7 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 0.6162044405937195, accuracy: 83.4 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 0.07651031017303467, accuracy: 97.3 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 0.07494351267814636, accuracy: 97.9 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 0.0825648382306099, accuracy: 96.8 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 0.07567877322435379, accuracy: 97.3 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 0.08788823336362839, accuracy: 97.0 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 0.071120485663414, accuracy: 97.9 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 0.07054338604211807, accuracy: 97.8 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 0.06938914209604263, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 0.0354, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 0.0634, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 0.0653, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 0.0713, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 0.1220, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 0.2866, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 0.0255, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 0.1523, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 0.1404, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 0.0733, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 0.10419032722711563, accuracy: 95.4 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 0.3747979998588562, accuracy: 89.0 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 0.5178700685501099, accuracy: 86.1 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 0.23007093369960785, accuracy: 93.1 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 0.0725572258234024, accuracy: 97.0 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 0.06865529716014862, accuracy: 97.4 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 0.06457372009754181, accuracy: 97.6 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 0.06294398754835129, accuracy: 97.6 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 0.06075788289308548, accuracy: 97.8 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 0.05986763909459114, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 0.1051, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 0.0946, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 0.1004, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 0.0791, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 0.1358, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 0.1011, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 0.0766, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 0.1351, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 0.0874, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 0.0511, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 0.06588749587535858, accuracy: 97.8 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 0.09554293751716614, accuracy: 96.4 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 0.062398143112659454, accuracy: 97.7 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 0.0821613147854805, accuracy: 97.5 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 0.059520263224840164, accuracy: 98.0 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 0.05755001679062843, accuracy: 98.0 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 0.05464257299900055, accuracy: 98.0 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 0.05281425639986992, accuracy: 98.3 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 0.05350106209516525, accuracy: 98.4 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 0.052642688155174255, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 0.1479, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 0.0621, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 0.0255, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 0.0826, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 0.1353, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 0.0673, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 0.1326, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 0.1542, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 0.0857, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 0.1037, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 0.06538411974906921, accuracy: 98.0 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 0.13422130048274994, accuracy: 95.5 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 0.05080144479870796, accuracy: 98.5 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 0.050331149250268936, accuracy: 98.4 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 0.05319933593273163, accuracy: 98.5 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 0.05699857324361801, accuracy: 98.4 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 0.04596363380551338, accuracy: 98.7 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 0.044729456305503845, accuracy: 98.4 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 0.04353068396449089, accuracy: 98.8 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 0.0442475825548172, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 0.1140, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 0.0568, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 0.1143, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 0.1209, batch time: 0.07, accuracy:  94.53%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 0.0412, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 0.0374, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 0.1191, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 0.1023, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 0.1775, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 0.0624, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 0.07692742347717285, accuracy: 97.5 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 0.18532876670360565, accuracy: 94.1 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 0.13318826258182526, accuracy: 95.2 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 0.06780803203582764, accuracy: 97.8 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 0.06797630339860916, accuracy: 98.2 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 0.06786603480577469, accuracy: 97.8 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 0.06347325444221497, accuracy: 98.5 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 0.06291715055704117, accuracy: 98.5 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 0.07627570629119873, accuracy: 97.1 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 0.06551730632781982, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 0.1475, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 0.1552, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 0.0935, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 0.1060, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 0.0646, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 0.0971, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 0.0667, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 0.0646, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 0.0383, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 0.1032, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 0.0809619277715683, accuracy: 97.2 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 1.1283475160598755, accuracy: 71.8 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 0.07397778332233429, accuracy: 97.4 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 0.0717741996049881, accuracy: 97.3 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 0.07297064363956451, accuracy: 97.4 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 0.07366513460874557, accuracy: 97.3 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 0.06988315284252167, accuracy: 97.8 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 0.06691402941942215, accuracy: 97.5 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 0.059521786868572235, accuracy: 98.5 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 0.05788629129528999, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 0.0595, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 0.1349, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 0.0407, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 0.1132, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 0.0445, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 0.1113, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 0.0475, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 0.0493, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 0.0319, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 0.0562, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 0.10028079897165298, accuracy: 96.8 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 0.21780087053775787, accuracy: 93.7 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 0.07642509043216705, accuracy: 97.3 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 0.06810080260038376, accuracy: 97.6 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 0.06578254699707031, accuracy: 97.9 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 0.08811094611883163, accuracy: 96.8 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 0.0703926682472229, accuracy: 97.5 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 0.0642518624663353, accuracy: 98.4 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 0.05731085687875748, accuracy: 98.4 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 0.0668892115354538, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 0.1201, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 0.1106, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 0.1259, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 0.0833, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 0.0769, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 0.0496, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 0.0841, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 0.0437, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 0.0463, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 0.1040, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 0.07408607006072998, accuracy: 97.2 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 0.384071946144104, accuracy: 88.4 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 0.07115600258111954, accuracy: 97.3 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 0.06291333585977554, accuracy: 97.6 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 0.06574437022209167, accuracy: 97.8 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 0.07728926092386246, accuracy: 97.1 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 0.06346817314624786, accuracy: 97.7 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 0.06503904610872269, accuracy: 97.6 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 0.06454337388277054, accuracy: 97.4 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 0.05824393033981323, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 0.0771, batch time: 0.07, accuracy:  96.09%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 0.1039, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 0.0274, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 0.0534, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 0.0839, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 0.1017, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 0.0841, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 0.1028, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 0.0379, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 0.0559, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 0.06918935477733612, accuracy: 97.5 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 0.8447896838188171, accuracy: 81.3 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 0.07153388857841492, accuracy: 97.4 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 0.06378906220197678, accuracy: 97.4 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 0.08785246312618256, accuracy: 96.9 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 0.05513850599527359, accuracy: 98.1 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 0.06004185229539871, accuracy: 97.9 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 0.06036532670259476, accuracy: 97.8 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 0.05396988242864609, accuracy: 98.2 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 0.053222838789224625, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 0.1078, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 0.1933, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 0.0374, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 0.0428, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 0.0644, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 0.1203, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 0.0972, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 0.1439, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 0.2168, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 0.0741, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 0.07973845303058624, accuracy: 97.2 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 0.10368722677230835, accuracy: 96.8 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 0.07520875334739685, accuracy: 96.8 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 0.0711882933974266, accuracy: 97.5 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 0.07075464725494385, accuracy: 97.2 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 0.0697430819272995, accuracy: 97.2 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 0.07367917895317078, accuracy: 97.3 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 0.06796522438526154, accuracy: 97.6 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 0.06782260537147522, accuracy: 97.6 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 0.06923060864210129, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 0.1105, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 0.0411, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 0.0646, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 0.0276, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 0.0497, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 0.1329, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 0.0383, batch time: 0.08, accuracy:  98.44%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 0.0646, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 0.1387, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 0.0759, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 0.047997623682022095, accuracy: 98.4 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 0.33257320523262024, accuracy: 90.8 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 0.055482953786849976, accuracy: 98.1 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 0.044235993176698685, accuracy: 98.6 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 0.04923225939273834, accuracy: 98.3 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 0.0453886054456234, accuracy: 98.6 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 0.04739886522293091, accuracy: 98.4 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 0.03912733122706413, accuracy: 98.8 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 0.035981252789497375, accuracy: 98.8 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 0.03519169241189957, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 0.0407, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 0.0973, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 0.0272, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 0.1241, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 0.0456, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 0.1088, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 0.0231, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 0.0499, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 0.0132, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 0.1546, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 0.06136714294552803, accuracy: 97.9 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 0.5516469478607178, accuracy: 87.0 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 0.052430249750614166, accuracy: 98.8 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 0.04925213009119034, accuracy: 98.6 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 0.20491668581962585, accuracy: 93.1 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 0.04132432863116264, accuracy: 98.2 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 0.04059416428208351, accuracy: 98.6 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 0.04088827967643738, accuracy: 98.5 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 0.04151270166039467, accuracy: 98.9 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 0.04019702225923538, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 0.0693, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 0.0899, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 0.0268, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 0.0693, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 0.0373, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 0.0274, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 0.0334, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 0.0431, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 0.0576, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 0.1018, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 0.10055730491876602, accuracy: 96.4 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 0.21891054511070251, accuracy: 93.0 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 0.09174040704965591, accuracy: 97.1 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 0.0781068280339241, accuracy: 97.4 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 0.07346131652593613, accuracy: 97.8 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 0.06997247040271759, accuracy: 97.3 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 0.07552605867385864, accuracy: 97.2 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 0.07785985618829727, accuracy: 97.6 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 0.0822792574763298, accuracy: 97.0 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 0.07030235230922699, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 0.1378, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 0.0738, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 0.0504, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 0.0651, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 0.1033, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 0.0607, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 0.0892, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 0.0767, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 0.1420, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 0.0523, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 0.057882681488990784, accuracy: 98.2 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 0.21964561939239502, accuracy: 94.0 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 0.053940027952194214, accuracy: 98.0 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 0.06912887841463089, accuracy: 97.4 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 0.05253895744681358, accuracy: 98.5 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 0.056720979511737823, accuracy: 98.3 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 0.06392082571983337, accuracy: 98.2 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 0.051799140870571136, accuracy: 98.3 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 0.06170753389596939, accuracy: 98.0 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 0.04715330898761749, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 0.0945, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 0.0276, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 0.0161, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 0.0603, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 0.0849, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 0.0296, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 0.0384, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 0.0561, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 0.1704, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 0.1623, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 0.06508182734251022, accuracy: 97.4 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 0.33912283182144165, accuracy: 90.7 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 0.05757889524102211, accuracy: 97.9 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 0.059567276388406754, accuracy: 97.8 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 0.046929676085710526, accuracy: 98.7 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 0.04941004887223244, accuracy: 98.1 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 0.04218686372041702, accuracy: 98.6 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 0.054160814732313156, accuracy: 98.2 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 0.03748166933655739, accuracy: 98.8 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 0.035355910658836365, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 0.0583, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 0.0614, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 0.0474, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 0.0996, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 0.2193, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 0.0229, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 0.0499, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 0.1220, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 0.0483, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 0.1378, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 0.06656619906425476, accuracy: 98.0 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 0.07030881196260452, accuracy: 98.2 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 0.07478317618370056, accuracy: 97.9 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 0.0648374930024147, accuracy: 98.2 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 0.06424584984779358, accuracy: 98.2 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 0.06306494027376175, accuracy: 98.2 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 0.06270080804824829, accuracy: 98.8 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 0.061861854046583176, accuracy: 98.4 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 0.06468722969293594, accuracy: 98.2 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 0.06103743612766266, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 0.1270, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 0.0481, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 0.0580, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 0.1077, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 0.0245, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 0.0583, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 0.0192, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 0.0543, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 0.1047, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 0.0905, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 0.038143206387758255, accuracy: 98.9 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 0.4726942479610443, accuracy: 89.0 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 0.10572071373462677, accuracy: 96.3 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 0.06128382310271263, accuracy: 97.6 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 0.029358064755797386, accuracy: 98.8 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 0.024987557902932167, accuracy: 99.3 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 0.026633720844984055, accuracy: 99.3 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 0.02537958137691021, accuracy: 99.3 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 0.023592153564095497, accuracy: 99.3 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 0.02463783323764801, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 0.0319, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 0.0360, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 0.0278, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 0.1481, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 0.0379, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 0.0784, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 0.0706, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 0.1322, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 0.0612, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 0.1634, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 0.04304221644997597, accuracy: 98.3 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 0.05222272127866745, accuracy: 97.9 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 0.04112613573670387, accuracy: 98.6 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 0.03884352371096611, accuracy: 99.1 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 0.03949401527643204, accuracy: 98.5 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 0.036097053438425064, accuracy: 99.2 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 0.04096348583698273, accuracy: 98.6 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 0.038438230752944946, accuracy: 98.6 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 0.03598974645137787, accuracy: 98.8 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 0.04388035833835602, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 0.0223, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 0.0762, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 0.0373, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 0.0330, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 0.0516, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 0.1045, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 0.0928, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 0.0950, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 0.0336, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 0.0550, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 0.03976612910628319, accuracy: 98.4 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 0.24785776436328888, accuracy: 94.3 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 0.030056387186050415, accuracy: 99.2 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 0.031439464539289474, accuracy: 99.0 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 0.02631751261651516, accuracy: 99.0 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 0.030657541006803513, accuracy: 99.0 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 0.03973925858736038, accuracy: 98.3 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 0.02693694457411766, accuracy: 99.0 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 0.023985544219613075, accuracy: 99.4 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 0.023660052567720413, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 0.1197, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 0.0472, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 0.0930, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 0.0940, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 0.0502, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 0.0355, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 0.0763, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 0.0759, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 0.0566, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 0.0682, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 0.059584133327007294, accuracy: 98.1 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 0.43936318159103394, accuracy: 89.0 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 0.05164407193660736, accuracy: 98.5 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 0.04668714478611946, accuracy: 98.3 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 0.04505143314599991, accuracy: 98.7 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 0.05548688396811485, accuracy: 98.2 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 0.045448124408721924, accuracy: 98.7 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 0.04427296668291092, accuracy: 98.9 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 0.04058549925684929, accuracy: 98.9 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 0.03946780413389206, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 0.0334, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 0.0308, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 0.1543, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 0.0678, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 0.0961, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 0.1561, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 0.1060, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 0.0767, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 0.0760, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 0.1187, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 0.04249705374240875, accuracy: 98.3 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 0.052600789815187454, accuracy: 98.2 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 0.038448672741651535, accuracy: 98.8 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 0.03422302380204201, accuracy: 99.1 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 0.03708374500274658, accuracy: 98.6 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 0.03182463347911835, accuracy: 99.0 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 0.03414619341492653, accuracy: 99.0 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 0.04036359116435051, accuracy: 98.7 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 0.0360502228140831, accuracy: 98.9 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 0.031087493523955345, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 0.0506, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 0.0318, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 0.0243, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 0.0765, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 0.0304, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 0.0874, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 0.0525, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 0.1337, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 0.0981, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 0.0830, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 0.045388296246528625, accuracy: 98.5 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 0.06096914783120155, accuracy: 98.3 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 0.04229862615466118, accuracy: 98.6 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 0.05894572287797928, accuracy: 98.0 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 0.03979570046067238, accuracy: 98.7 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 0.038017213344573975, accuracy: 99.1 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 0.03752127289772034, accuracy: 99.0 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 0.03682928904891014, accuracy: 98.9 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 0.03600657358765602, accuracy: 99.0 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 0.03522539138793945, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 0.0879, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 0.0834, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 0.0513, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 0.0919, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 0.0463, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 0.0834, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 0.1348, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 0.0778, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 0.0292, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 0.0509, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 0.05900690332055092, accuracy: 97.9 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 0.07097630202770233, accuracy: 97.6 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 0.05215781554579735, accuracy: 98.1 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 0.047883257269859314, accuracy: 98.3 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 0.058677949011325836, accuracy: 97.9 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 0.05128241330385208, accuracy: 97.8 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 0.050219230353832245, accuracy: 98.3 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 0.048449013382196426, accuracy: 98.1 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 0.044350843876600266, accuracy: 98.1 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 0.0426299087703228, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 0.1520, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 0.0507, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 0.0675, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 0.1450, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 0.0688, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 0.0498, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 0.0711, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 0.0215, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 0.0296, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 0.0590, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 0.0396600179374218, accuracy: 98.6 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 0.052123021334409714, accuracy: 97.9 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 0.10418378561735153, accuracy: 96.0 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 0.052530720829963684, accuracy: 97.7 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 0.03196791931986809, accuracy: 98.8 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 0.028295965865254402, accuracy: 99.4 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 0.02885350212454796, accuracy: 99.3 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 0.02705388516187668, accuracy: 99.5 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 0.029405483976006508, accuracy: 99.3 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 0.027039937674999237, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 0.0430, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 0.0812, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 0.1273, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 0.0143, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 0.0682, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 0.0389, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 0.0759, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 0.0331, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 0.0307, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 0.0317, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 0.05618349090218544, accuracy: 97.7 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 0.06905322521924973, accuracy: 97.3 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 0.05311690270900726, accuracy: 97.8 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 0.062416426837444305, accuracy: 97.7 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 0.04894560948014259, accuracy: 98.2 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 0.06144615262746811, accuracy: 97.5 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 0.04677363112568855, accuracy: 98.2 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 0.038393136113882065, accuracy: 98.4 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 0.03629119321703911, accuracy: 98.6 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 0.036166075617074966, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 0.0237, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 0.0438, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 0.0544, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 0.0428, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 0.0708, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 0.0254, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 0.1265, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 0.0949, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 0.0276, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 0.0133, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 0.05069589614868164, accuracy: 98.1 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 0.06373187899589539, accuracy: 97.3 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 0.04637616127729416, accuracy: 98.2 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 0.03835458680987358, accuracy: 98.5 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 0.05822177231311798, accuracy: 97.8 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 0.04819890111684799, accuracy: 98.3 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 0.0383039228618145, accuracy: 98.7 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 0.03503865748643875, accuracy: 98.5 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 0.034005504101514816, accuracy: 98.7 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 0.032730087637901306, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 0.0428, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 0.0495, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 0.0670, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 0.0358, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 0.0448, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 0.1439, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 0.0140, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 0.1169, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 0.0492, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 0.0930, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 0.06086838245391846, accuracy: 98.1 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 0.05933874845504761, accuracy: 97.9 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 0.040248606353998184, accuracy: 98.6 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 0.03827349469065666, accuracy: 98.6 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 0.04344460368156433, accuracy: 98.6 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 0.04644932970404625, accuracy: 98.1 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 0.05061136186122894, accuracy: 98.4 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 0.03149314597249031, accuracy: 99.1 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 0.032757896929979324, accuracy: 99.0 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 0.03036070242524147, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 0.0413, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 0.0273, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 0.0664, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 0.0876, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 0.0168, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 0.0647, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 0.0467, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 0.0840, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 0.0303, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 0.0378, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 0.05064231902360916, accuracy: 97.9 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 0.057596106082201004, accuracy: 97.8 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 0.0571778267621994, accuracy: 98.1 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 0.0379304401576519, accuracy: 98.4 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 0.041135888546705246, accuracy: 98.4 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 0.04800386354327202, accuracy: 97.6 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 0.027867937460541725, accuracy: 98.7 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 0.02513141743838787, accuracy: 98.9 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 0.022778969258069992, accuracy: 99.0 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 0.021816490218043327, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 0.0341, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 0.0816, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 0.0599, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 0.0247, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 0.0435, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 0.1220, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 0.0774, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 0.0534, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 0.0801, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 0.0665, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 0.04623771086335182, accuracy: 98.5 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 0.06388954818248749, accuracy: 97.8 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 0.04643125832080841, accuracy: 98.6 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 0.040585506707429886, accuracy: 99.0 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 0.04233503341674805, accuracy: 98.5 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 0.04714372754096985, accuracy: 98.7 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 0.03987030312418938, accuracy: 99.1 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 0.04883785918354988, accuracy: 98.8 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 0.04661193862557411, accuracy: 98.5 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 0.04130219668149948, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 0.0868, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 0.0482, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 0.0378, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 0.0370, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 0.0226, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 0.0236, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 0.1132, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 0.0638, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 0.0364, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 0.0541, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 0.0675353929400444, accuracy: 97.2 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 0.09599508345127106, accuracy: 96.5 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 0.051403556019067764, accuracy: 98.1 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 0.043915439397096634, accuracy: 98.5 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 0.03814972937107086, accuracy: 98.7 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 0.0373825803399086, accuracy: 98.8 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 0.03694356605410576, accuracy: 98.7 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 0.04416133090853691, accuracy: 98.4 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 0.05443916842341423, accuracy: 97.9 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 0.032905563712120056, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 0.1461, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 0.0314, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 0.0553, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 0.0398, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 0.0539, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 0.0325, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 0.0719, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 0.0287, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 0.0176, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 0.0176, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 0.07446280121803284, accuracy: 97.5 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 0.7105996608734131, accuracy: 83.2 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 0.07966471463441849, accuracy: 97.2 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 0.07045947015285492, accuracy: 97.6 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 0.0609334297478199, accuracy: 97.8 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 0.0634065791964531, accuracy: 97.7 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 0.055697932839393616, accuracy: 98.2 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 0.05869985371828079, accuracy: 97.7 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 0.046862322837114334, accuracy: 98.6 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 0.04455854371190071, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 0.0517, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 0.0561, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 0.0423, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 0.0561, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 0.0260, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 0.0768, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 0.0268, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 0.0241, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 0.0451, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 0.0572, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 0.029627446085214615, accuracy: 99.0 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 0.03764427825808525, accuracy: 98.6 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 0.029073193669319153, accuracy: 99.2 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 0.020910872146487236, accuracy: 99.3 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 0.019582854583859444, accuracy: 99.4 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 0.028606893494725227, accuracy: 98.6 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 0.03503386676311493, accuracy: 98.8 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 0.01652204804122448, accuracy: 99.7 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 0.016017749905586243, accuracy: 99.8 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 0.0158140379935503, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 0.1980, batch time: 0.08, accuracy:  93.75%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 0.0742, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 0.0448, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 0.0698, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 0.0665, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 0.0561, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 0.0348, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 0.0628, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 0.0398, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 0.0862, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 0.0438295342028141, accuracy: 98.5 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 0.052600882947444916, accuracy: 98.0 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 0.035010334104299545, accuracy: 99.0 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 0.031524937599897385, accuracy: 98.9 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 0.02870376594364643, accuracy: 99.1 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 0.02876095473766327, accuracy: 99.2 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 0.03408556431531906, accuracy: 99.0 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 0.02681945078074932, accuracy: 99.2 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 0.0282960943877697, accuracy: 99.2 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 0.02762441709637642, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 0.0965, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 0.0676, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 0.0617, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 0.0627, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 0.0343, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 0.0613, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 0.0839, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 0.0084, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 0.0663, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 0.1622, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 0.034615110605955124, accuracy: 98.9 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 0.03357921540737152, accuracy: 98.9 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 0.033935192972421646, accuracy: 99.0 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 0.0301965344697237, accuracy: 99.0 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 0.03308039531111717, accuracy: 99.0 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 0.03351055830717087, accuracy: 98.9 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 0.031530607491731644, accuracy: 99.1 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 0.038224734365940094, accuracy: 99.1 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 0.03450823947787285, accuracy: 98.9 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 0.03488212451338768, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 0.0786, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 0.1917, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 0.0486, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 0.0600, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 0.0932, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 0.1050, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 0.0431, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 0.0202, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 0.0193, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 0.1220, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 0.033004119992256165, accuracy: 98.8 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 0.03334760293364525, accuracy: 99.0 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 0.034152425825595856, accuracy: 99.0 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 0.022560669109225273, accuracy: 99.3 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 0.024286258965730667, accuracy: 99.4 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 0.02508780173957348, accuracy: 99.2 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 0.026394998654723167, accuracy: 99.2 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 0.02244720049202442, accuracy: 99.5 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 0.020463556051254272, accuracy: 99.5 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 0.023800307884812355, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 0.0499, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 0.0250, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 0.0277, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 0.1261, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 0.0588, batch time: 0.34, accuracy:  98.44%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 0.0423, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 0.0451, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 0.0435, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 0.0516, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 0.0548, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 0.05547889322042465, accuracy: 98.0 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 0.2106311023235321, accuracy: 94.2 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 0.044166889041662216, accuracy: 98.8 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 0.03952820971608162, accuracy: 98.8 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 0.04698461666703224, accuracy: 98.3 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 0.04409538209438324, accuracy: 98.1 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 0.03878921642899513, accuracy: 98.8 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 0.03363630175590515, accuracy: 99.0 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 0.03270065784454346, accuracy: 98.9 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 0.031734809279441833, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 0.0419, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 0.0186, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 0.0514, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 0.0356, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 0.0765, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 0.0553, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 0.0413, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 0.0882, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 0.0797, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 0.0233, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 0.039818402379751205, accuracy: 98.6 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 0.04486313834786415, accuracy: 98.5 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 0.035842880606651306, accuracy: 98.8 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 0.03395828977227211, accuracy: 98.9 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 0.03501467406749725, accuracy: 98.9 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 0.03624281287193298, accuracy: 98.8 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 0.034098684787750244, accuracy: 98.6 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 0.03828327730298042, accuracy: 98.6 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 0.03742687776684761, accuracy: 98.7 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 0.033160533756017685, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 0.0829, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 0.0558, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 0.0595, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 0.0978, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 0.0221, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 0.0283, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 0.0205, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 0.0729, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 0.0633, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 0.0225, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 0.050040069967508316, accuracy: 97.8 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 0.1678544580936432, accuracy: 94.9 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 0.052345190197229385, accuracy: 98.0 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 0.04319868981838226, accuracy: 98.0 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 0.047002632170915604, accuracy: 97.7 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 0.04033955931663513, accuracy: 98.9 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 0.03754359111189842, accuracy: 98.8 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 0.04089995101094246, accuracy: 98.4 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 0.03531031683087349, accuracy: 98.7 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 0.035090312361717224, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 0.0289, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 0.1150, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 0.0695, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 0.0827, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 0.0398, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 0.0604, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 0.0205, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 0.0818, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 0.0685, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 0.0084, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 0.021030033007264137, accuracy: 99.4 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 0.16486498713493347, accuracy: 95.4 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 0.026598723605275154, accuracy: 99.0 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 0.013073839247226715, accuracy: 99.6 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 0.014293141663074493, accuracy: 99.5 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 0.014864595606923103, accuracy: 99.5 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 0.013815130107104778, accuracy: 99.6 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 0.023906366899609566, accuracy: 99.2 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 0.010601233690977097, accuracy: 99.7 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 0.06793212890625, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 0.0503, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 0.0431, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 0.0281, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 0.0669, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 0.0499, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 0.0342, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 0.0476, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 0.0232, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 0.0569, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 0.0247, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 0.03397778049111366, accuracy: 98.8 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 0.04488160088658333, accuracy: 98.4 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 0.03866160288453102, accuracy: 98.4 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 0.02883795276284218, accuracy: 99.1 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 0.032384030520915985, accuracy: 98.7 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 0.04412847384810448, accuracy: 98.3 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 0.025913408026099205, accuracy: 98.9 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 0.02659318782389164, accuracy: 99.1 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 0.024769876152276993, accuracy: 99.3 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 0.022459985688328743, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 0.0596, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 0.0825, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 0.0603, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 0.0562, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 0.0073, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 0.0601, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 0.0259, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 0.1330, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 0.0682, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 0.0306, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 0.032228268682956696, accuracy: 98.9 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 0.287659227848053, accuracy: 91.6 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 0.3308185338973999, accuracy: 92.1 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 0.018885402008891106, accuracy: 99.5 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 0.016742950305342674, accuracy: 99.7 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 0.017363496124744415, accuracy: 99.8 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 0.026210740208625793, accuracy: 99.3 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 0.017984041944146156, accuracy: 99.6 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 0.02668459340929985, accuracy: 99.0 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 0.014630261808633804, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 0.0452, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 0.1140, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 0.0738, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 0.0488, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 0.0823, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 0.0441, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 0.0471, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 0.0786, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 0.0364, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 0.0501, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 0.041656725108623505, accuracy: 98.8 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 0.04179048165678978, accuracy: 98.8 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 0.04072588309645653, accuracy: 99.1 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 0.03467917814850807, accuracy: 99.2 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 0.03289704769849777, accuracy: 99.3 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 0.04034411534667015, accuracy: 99.0 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 0.0321393720805645, accuracy: 99.1 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 0.035675693303346634, accuracy: 99.3 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 0.03422941640019417, accuracy: 99.5 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 0.03518347442150116, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 0.0282, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 0.0368, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 0.0231, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 0.0304, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 0.0213, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 0.0550, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 0.0449, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 0.0901, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 0.0488, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 0.0211, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 0.05081992596387863, accuracy: 98.4 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 0.05345769226551056, accuracy: 98.4 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 0.05734938383102417, accuracy: 98.2 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 0.04142842814326286, accuracy: 98.8 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 0.039676353335380554, accuracy: 98.8 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 0.0564241036772728, accuracy: 98.3 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 0.03922538459300995, accuracy: 98.9 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 0.032911330461502075, accuracy: 99.0 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 0.031579747796058655, accuracy: 98.9 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 0.03121412731707096, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 0.0172, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 0.0724, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 0.0407, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 0.0570, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 0.1030, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 0.0542, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 0.1103, batch time: 0.09, accuracy:  96.09%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 0.0541, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 0.0515, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 0.0064, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 0.07303018867969513, accuracy: 97.4 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 0.09858185052871704, accuracy: 97.0 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 0.054628241807222366, accuracy: 98.0 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 0.04931117221713066, accuracy: 98.2 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 0.04842052981257439, accuracy: 98.2 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 0.05325010046362877, accuracy: 98.2 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 0.042255498468875885, accuracy: 98.6 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 0.06611345708370209, accuracy: 97.5 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 0.04497745260596275, accuracy: 98.4 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 0.057812027633190155, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 0.0351, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 0.0326, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 0.0780, batch time: 0.09, accuracy:  98.44%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 0.0675, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 0.0604, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 0.1050, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 0.0042, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 0.0693, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 0.0398, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 0.0919, batch time: 0.25, accuracy:  96.88%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 0.036445558071136475, accuracy: 98.6 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 0.056530460715293884, accuracy: 98.1 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 0.03385430574417114, accuracy: 98.7 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 0.03149457275867462, accuracy: 98.6 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 0.034653063863515854, accuracy: 98.5 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 0.032447364181280136, accuracy: 98.7 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 0.03485114872455597, accuracy: 98.6 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 0.028298474848270416, accuracy: 98.9 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 0.027962228283286095, accuracy: 99.0 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 0.0276188887655735, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 0.0604, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 0.0442, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 0.0823, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 0.1332, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 0.0716, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 0.0429, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 0.0435, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 0.0390, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 0.0601, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 0.1045, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 0.03164070099592209, accuracy: 98.7 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 0.03557220846414566, accuracy: 98.7 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 0.027878405526280403, accuracy: 99.0 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 0.025561219081282616, accuracy: 99.3 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 0.029768425971269608, accuracy: 99.1 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 0.03197655826807022, accuracy: 98.8 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 0.04379619285464287, accuracy: 98.5 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 0.02040775865316391, accuracy: 99.6 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 0.01963154785335064, accuracy: 99.7 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 0.019074996933341026, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 0.0253, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 0.0677, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 0.0095, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 0.0249, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 0.0577, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 0.0342, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 0.0255, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 0.1497, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 0.0145, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 0.0998, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 0.049836479127407074, accuracy: 98.1 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 0.11924665421247482, accuracy: 96.0 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 0.048432301729917526, accuracy: 98.8 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 0.03850878030061722, accuracy: 98.9 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 0.043506696820259094, accuracy: 98.3 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 0.04585942253470421, accuracy: 98.4 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 0.03845918923616409, accuracy: 98.7 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 0.04650946706533432, accuracy: 98.5 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 0.03504246473312378, accuracy: 99.0 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 0.04729947820305824, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 0.0460, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 0.0892, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 0.0438, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 0.0724, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 0.0477, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 0.1167, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 0.0161, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 0.0698, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 0.0868, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 0.0843, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 0.027768637984991074, accuracy: 99.2 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 0.043408945202827454, accuracy: 98.5 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 0.03826121240854263, accuracy: 98.8 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 0.028325408697128296, accuracy: 99.0 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 0.025614488869905472, accuracy: 99.2 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 0.02049165591597557, accuracy: 99.5 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 0.01950691267848015, accuracy: 99.5 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 0.019389087334275246, accuracy: 99.5 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 0.018406275659799576, accuracy: 99.6 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 0.01827075146138668, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 0.0535, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 0.0294, batch time: 0.09, accuracy:  98.44%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 0.0212, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 0.0787, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 0.0286, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 0.0149, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 0.0739, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 0.0403, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 0.0287, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 0.0159, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 0.046683184802532196, accuracy: 98.6 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 0.06617779284715652, accuracy: 98.1 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 0.04062214493751526, accuracy: 98.3 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 0.03277914971113205, accuracy: 98.7 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 0.03979559615254402, accuracy: 98.1 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 0.026899848133325577, accuracy: 98.9 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 0.025557300075888634, accuracy: 98.9 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 0.024542251601815224, accuracy: 98.9 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 0.022408798336982727, accuracy: 99.0 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 0.02195197343826294, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 0.0675, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 0.0649, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 0.0486, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 0.0819, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 0.0297, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 0.0093, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 0.0383, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 0.0578, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 0.0482, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 0.0163, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 0.04384686052799225, accuracy: 98.4 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 0.25498896837234497, accuracy: 93.2 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 0.038823895156383514, accuracy: 98.7 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 0.03903215751051903, accuracy: 98.7 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 0.042136725038290024, accuracy: 98.2 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 0.0518031120300293, accuracy: 97.9 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 0.032127492129802704, accuracy: 98.6 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 0.030225805938243866, accuracy: 98.9 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 0.028663750737905502, accuracy: 99.2 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 0.027042042464017868, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 0.0725, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 0.0182, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 0.0414, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 0.0323, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 0.0741, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 0.0351, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 0.0812, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 0.0120, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 0.0740, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 0.0407, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 0.04020019993185997, accuracy: 98.5 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 0.04363135248422623, accuracy: 98.5 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 0.036742184311151505, accuracy: 98.7 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 0.052677080035209656, accuracy: 98.0 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 0.032089658081531525, accuracy: 98.8 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 0.022130310535430908, accuracy: 99.3 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 0.020029013976454735, accuracy: 99.7 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 0.020957019180059433, accuracy: 99.3 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 0.018106330186128616, accuracy: 99.8 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 0.01726371794939041, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 0.0248, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 0.0122, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 0.0848, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 0.0195, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 0.0608, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 0.0343, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 0.0530, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 0.0591, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 0.0616, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 0.1530, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 0.03226511552929878, accuracy: 99.2 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 0.042888931930065155, accuracy: 98.7 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 0.027478909119963646, accuracy: 99.4 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 0.028272001072764397, accuracy: 99.1 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 0.026377197355031967, accuracy: 99.2 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 0.029864365234971046, accuracy: 99.3 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 0.050827573984861374, accuracy: 98.0 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 0.0222004447132349, accuracy: 99.5 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 0.021646447479724884, accuracy: 99.5 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 0.021582409739494324, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 0.0698, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 0.0892, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 0.0226, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 0.1247, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 0.0639, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 0.0592, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 0.0244, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 0.0603, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 0.0217, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 0.0581, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 0.07262787222862244, accuracy: 97.2 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 0.608313798904419, accuracy: 85.3 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 0.052550308406353, accuracy: 98.4 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 0.051101017743349075, accuracy: 98.5 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 0.04932296648621559, accuracy: 98.8 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 0.05013347417116165, accuracy: 98.8 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 0.04901670664548874, accuracy: 98.6 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 0.04100939258933067, accuracy: 98.8 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 0.04102589190006256, accuracy: 98.8 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 0.03994656726717949, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 0.0597, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 0.0299, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 0.0215, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 0.0171, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 0.0131, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 0.0565, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 0.0309, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 0.0661, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 0.0461, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 0.0306, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 0.0406484492123127, accuracy: 98.4 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 0.04293712601065636, accuracy: 98.3 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 0.04454362019896507, accuracy: 98.6 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 0.036484263837337494, accuracy: 98.6 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 0.06268720328807831, accuracy: 97.6 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 0.031518254429101944, accuracy: 98.8 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 0.02934248559176922, accuracy: 99.1 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 0.027509870007634163, accuracy: 99.3 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 0.026757510378956795, accuracy: 99.3 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 0.025893544778227806, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 0.0596, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 0.0323, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 0.0430, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 0.0077, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 0.0644, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 0.0635, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 0.0151, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 0.0335, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 0.0598, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 0.0510, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 0.032830990850925446, accuracy: 98.9 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 0.03786735609173775, accuracy: 98.7 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 0.02860899642109871, accuracy: 99.2 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 0.02354404516518116, accuracy: 99.4 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 0.024046536535024643, accuracy: 99.3 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 0.03315221145749092, accuracy: 98.9 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 0.024087438359856606, accuracy: 99.3 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 0.019541699439287186, accuracy: 99.5 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 0.019040793180465698, accuracy: 99.5 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 0.017699789255857468, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 0.0761, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 0.0412, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 0.1045, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 0.0296, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 0.0337, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 0.0432, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 0.0404, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 0.0584, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 0.0142, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 0.0692, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 0.04269692674279213, accuracy: 98.3 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 0.04826059192419052, accuracy: 98.4 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 0.04061951860785484, accuracy: 98.2 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 0.03625936061143875, accuracy: 98.7 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 0.06483526527881622, accuracy: 97.5 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 0.0386488102376461, accuracy: 98.5 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 0.028555793687701225, accuracy: 99.1 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 0.026178251951932907, accuracy: 99.3 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 0.04520537704229355, accuracy: 98.0 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 0.03321489319205284, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 0.1762, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 0.0410, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 0.0173, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 0.0366, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 0.0359, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 0.0436, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 0.0281, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 0.0285, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 0.0286, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 0.0585, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 0.03759046643972397, accuracy: 98.5 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 0.03129960224032402, accuracy: 98.7 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 0.029352618381381035, accuracy: 98.7 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 0.029352618381381035, accuracy: 98.7 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 0.039285801351070404, accuracy: 98.4 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 0.03420298919081688, accuracy: 98.4 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 0.03441493958234787, accuracy: 98.4 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 0.02209859900176525, accuracy: 99.2 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 0.02076856419444084, accuracy: 99.1 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 0.020110640674829483, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 0.0412, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 0.0291, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 0.0236, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 0.0376, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 0.0246, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 0.0778, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 0.0716, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 0.0216, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 0.0291, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 0.0487, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 0.02522984892129898, accuracy: 99.5 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 0.02253667451441288, accuracy: 99.7 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 0.06021466106176376, accuracy: 97.6 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 0.028200911357998848, accuracy: 99.2 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 0.017910480499267578, accuracy: 99.5 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 0.017002079635858536, accuracy: 99.7 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 0.01693977415561676, accuracy: 99.7 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 0.016351841390132904, accuracy: 99.8 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 0.01603642664849758, accuracy: 99.8 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 0.01674715429544449, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 0.0400, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 0.0556, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 0.0729, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 0.0762, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 0.0173, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 0.0754, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 0.0200, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 0.0455, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 0.0338, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 0.0219, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 0.06412239372730255, accuracy: 98.4 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 0.05309376120567322, accuracy: 98.3 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 0.04966961219906807, accuracy: 98.2 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 0.14941023290157318, accuracy: 95.6 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 0.03809252381324768, accuracy: 99.1 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 0.03664896637201309, accuracy: 99.1 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 0.03912331908941269, accuracy: 99.1 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 0.03471269831061363, accuracy: 99.1 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 0.03577771782875061, accuracy: 99.0 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 0.03508586436510086, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 0.1540, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 0.0628, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 0.0820, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 0.0459, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 0.0278, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 0.0486, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 0.0283, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 0.0587, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 0.0253, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 0.0408, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 0.04636813700199127, accuracy: 99.0 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 0.04398725554347038, accuracy: 98.9 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 0.0345737524330616, accuracy: 98.8 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 0.03345894441008568, accuracy: 99.1 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 0.05012304708361626, accuracy: 98.1 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 0.030335592105984688, accuracy: 99.2 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 0.033925727009773254, accuracy: 99.1 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 0.04085791856050491, accuracy: 98.6 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 0.032459404319524765, accuracy: 99.0 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 0.026905426755547523, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 0.0476, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 0.0772, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 0.0580, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 0.0380, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 0.0977, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 0.0697, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 0.0105, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 0.0229, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 0.0446, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 0.0401, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 0.051571547985076904, accuracy: 98.8 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 0.05530819296836853, accuracy: 98.8 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 0.046970535069704056, accuracy: 98.8 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 0.046623341739177704, accuracy: 98.7 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 0.04486429691314697, accuracy: 99.0 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 0.04608303681015968, accuracy: 98.7 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 0.04285731166601181, accuracy: 99.2 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 0.045528337359428406, accuracy: 98.7 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 0.042297184467315674, accuracy: 99.0 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 0.04010879248380661, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 0.0319, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 0.0502, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 0.0990, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 0.0421, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 0.0662, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 0.0106, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 0.0664, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 0.0599, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 0.0200, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 0.1512, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 0.03824630752205849, accuracy: 98.6 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 0.03720012679696083, accuracy: 98.8 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 0.029197853058576584, accuracy: 99.1 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 0.0259705837816, accuracy: 98.9 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 0.025806520134210587, accuracy: 99.1 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 0.030065437778830528, accuracy: 99.0 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 0.03431077301502228, accuracy: 98.6 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 0.02538171410560608, accuracy: 99.4 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 0.025773968547582626, accuracy: 99.2 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 0.028836799785494804, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 0.0470, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 0.1158, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 0.0412, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 0.0928, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 0.0218, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 0.0044, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 0.0182, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 0.0167, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 0.0945, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 0.0429, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 0.03628164529800415, accuracy: 98.7 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 0.04321630299091339, accuracy: 98.4 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 0.02810630202293396, accuracy: 98.9 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 0.035143010318279266, accuracy: 98.4 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 0.023291269317269325, accuracy: 99.4 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 0.01895516738295555, accuracy: 99.5 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 0.01854170858860016, accuracy: 99.7 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 0.017783494666218758, accuracy: 99.5 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 0.01721351034939289, accuracy: 99.4 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 0.01664683409035206, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 0.0776, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 0.1053, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 0.0222, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 0.0480, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 0.0545, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 0.0704, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 0.0143, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 0.0892, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 0.0033, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 0.0322, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 0.03317183256149292, accuracy: 98.9 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 0.04415897652506828, accuracy: 98.4 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 0.024882987141609192, accuracy: 99.4 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 0.0229543074965477, accuracy: 99.5 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 0.026793306693434715, accuracy: 99.0 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 0.022675445303320885, accuracy: 99.4 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 0.023542208597064018, accuracy: 99.4 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 0.01996891014277935, accuracy: 99.6 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 0.019464004784822464, accuracy: 99.6 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 0.01842108555138111, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 0.0252, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 0.0715, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 0.0374, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 0.0748, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 0.0150, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 0.0331, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 0.1346, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 0.0127, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 0.0197, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 0.0591, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 0.028622670099139214, accuracy: 99.0 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 0.027883442118763924, accuracy: 98.7 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 0.023961734026670456, accuracy: 99.1 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 0.021318906918168068, accuracy: 99.3 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 0.020996857434511185, accuracy: 99.3 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 0.01976250670850277, accuracy: 99.6 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 0.021027246490120888, accuracy: 99.3 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 0.01793696917593479, accuracy: 99.6 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 0.017478985711932182, accuracy: 99.6 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 0.020821087062358856, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 0.0080, batch time: 0.06, accuracy:  100.00%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 0.0302, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 0.0429, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 0.0954, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 0.0259, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 0.1913, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 0.0288, batch time: 0.39, accuracy:  98.44%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 0.0312, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 0.0321, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 0.0358, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 0.04322993382811546, accuracy: 98.4 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 0.055164940655231476, accuracy: 98.0 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 0.031164683401584625, accuracy: 99.3 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 0.026348643004894257, accuracy: 99.2 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 0.028156733140349388, accuracy: 99.3 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 0.024498412385582924, accuracy: 99.6 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 0.021451426669955254, accuracy: 99.6 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 0.03283347561955452, accuracy: 98.7 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 0.020084179937839508, accuracy: 99.7 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 0.01917903684079647, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 0.0395, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 0.0477, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 0.0735, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 0.0630, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 0.0333, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 0.0314, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 0.0635, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 0.0855, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 0.0177, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 0.0325, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 0.037249669432640076, accuracy: 98.6 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 0.039801351726055145, accuracy: 98.7 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 0.03368966281414032, accuracy: 98.9 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 0.029282154515385628, accuracy: 99.0 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 0.029612326994538307, accuracy: 99.1 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 0.024663403630256653, accuracy: 99.4 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 0.02602621354162693, accuracy: 99.4 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 0.026363443583250046, accuracy: 99.0 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 0.025141237303614616, accuracy: 99.2 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 0.020573146641254425, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 0.0226, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 0.0238, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 0.0649, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 0.0855, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 0.0045, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 0.0452, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 0.0234, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 0.0208, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 0.0879, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 0.1041, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 0.0381796732544899, accuracy: 98.6 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 0.05666862055659294, accuracy: 98.0 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 0.029376192018389702, accuracy: 98.7 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 0.029051851481199265, accuracy: 99.0 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 0.03573146089911461, accuracy: 98.5 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 0.030634891241788864, accuracy: 99.0 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 0.024130553007125854, accuracy: 99.1 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 0.025463756173849106, accuracy: 99.2 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 0.022056736052036285, accuracy: 99.5 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 0.031974270939826965, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 0.1013, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 0.1084, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 0.0158, batch time: 0.08, accuracy:  99.22%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 0.0387, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 0.0282, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 0.0939, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 0.0047, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 0.0610, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 0.0080, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 0.1574, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 0.057328127324581146, accuracy: 98.4 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 0.24788770079612732, accuracy: 92.4 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 0.11391256004571915, accuracy: 95.9 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 0.0482645109295845, accuracy: 98.4 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 0.035830430686473846, accuracy: 99.1 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 0.04276524856686592, accuracy: 98.7 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 0.0446222759783268, accuracy: 98.5 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 0.030708083882927895, accuracy: 99.2 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 0.03179214894771576, accuracy: 99.5 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 0.03220505639910698, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 0.0703, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 0.0706, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 0.0503, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 0.1216, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 0.0177, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 0.1367, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 0.0392, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 0.0983, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 0.0383, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 0.0159, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 0.044178660959005356, accuracy: 99.0 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 0.16491243243217468, accuracy: 95.3 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 0.034065164625644684, accuracy: 98.6 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 0.032639335840940475, accuracy: 98.8 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 0.026336612179875374, accuracy: 99.2 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 0.027292294427752495, accuracy: 98.7 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 0.026080066338181496, accuracy: 99.0 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 0.02943403087556362, accuracy: 98.6 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 0.0276310034096241, accuracy: 99.0 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 0.021560361608862877, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 0.0391, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 0.1515, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 0.0734, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 0.0509, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 0.0380, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 0.0770, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 0.0374, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 0.0413, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 0.0445, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 0.0841, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 0.07581902295351028, accuracy: 97.7 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 0.14879083633422852, accuracy: 95.3 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 0.13232402503490448, accuracy: 96.4 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 0.06522707641124725, accuracy: 98.1 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 0.062680184841156, accuracy: 97.8 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 0.07682366669178009, accuracy: 97.4 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 0.05878129228949547, accuracy: 97.8 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 0.06318390369415283, accuracy: 97.7 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 0.056873030960559845, accuracy: 98.1 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 0.05532538518309593, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 0.0656, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 0.1086, batch time: 0.08, accuracy:  93.75%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 0.0952, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 0.0113, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 0.0062, batch time: 0.06, accuracy:  100.00%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 0.0463, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 0.0587, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 0.0113, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 0.0681, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 0.0373, batch time: 0.06, accuracy:  99.22%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 0.03461860120296478, accuracy: 98.7 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 0.035209476947784424, accuracy: 98.8 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 0.03312045335769653, accuracy: 98.7 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 0.026850871741771698, accuracy: 98.9 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 0.02673509158194065, accuracy: 98.9 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 0.022435400635004044, accuracy: 99.3 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 0.022246696054935455, accuracy: 99.2 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 0.02039409428834915, accuracy: 99.4 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 0.030021853744983673, accuracy: 99.0 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 0.026537002995610237, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 0.0182, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 0.0591, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 0.0696, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 0.0536, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 0.1089, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 0.0622, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 0.0782, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 0.0917, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 0.0677, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 0.1209, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 0.03500397875905037, accuracy: 98.7 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 0.032620787620544434, accuracy: 98.7 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 0.021014627069234848, accuracy: 99.5 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 0.02831350266933441, accuracy: 99.1 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 0.02124539390206337, accuracy: 99.5 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 0.024445632472634315, accuracy: 98.8 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 0.020793786272406578, accuracy: 99.3 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 0.03355397284030914, accuracy: 98.7 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 0.02236146293580532, accuracy: 99.2 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 0.02509346976876259, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 0.0493, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 0.0265, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 0.0509, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 0.0389, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 0.0800, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 0.0345, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 0.0163, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 0.0504, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 0.0093, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 0.0775, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 0.047703199088573456, accuracy: 98.2 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 0.04880395531654358, accuracy: 98.2 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 0.22881761193275452, accuracy: 92.0 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 0.042857106775045395, accuracy: 98.6 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 0.034300416707992554, accuracy: 99.0 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 0.03373338282108307, accuracy: 99.0 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 0.029248593375086784, accuracy: 99.4 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 0.02945224568247795, accuracy: 99.7 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 0.03037256747484207, accuracy: 99.2 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 0.0293913371860981, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 0.0689, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 0.1196, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 0.0407, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 0.0799, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 0.1510, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 0.0588, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 0.0147, batch time: 0.08, accuracy:  100.00%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 0.1375, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 0.0863, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 0.0247, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 0.062320467084646225, accuracy: 97.8 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 0.19118571281433105, accuracy: 94.7 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 0.05266629159450531, accuracy: 97.9 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 0.04716021195054054, accuracy: 98.3 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 0.04199427738785744, accuracy: 98.7 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 0.03801202401518822, accuracy: 99.0 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 0.04005033150315285, accuracy: 98.5 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 0.035970889031887054, accuracy: 98.9 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 0.03555256873369217, accuracy: 98.8 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 0.03333178162574768, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 0.0542, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 0.0521, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 0.0586, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 0.1078, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 0.0326, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 0.0787, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 0.0751, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 0.0362, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 0.0289, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 0.0354, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 0.033850960433483124, accuracy: 98.9 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 0.05435945838689804, accuracy: 97.8 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 0.02660820633172989, accuracy: 98.9 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 0.025642456486821175, accuracy: 99.0 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 0.022371085360646248, accuracy: 99.3 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 0.02771752141416073, accuracy: 98.9 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 0.022732749581336975, accuracy: 99.4 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 0.023451026529073715, accuracy: 99.6 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 0.023230690509080887, accuracy: 99.2 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 0.023606836795806885, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 0.1371, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 0.0501, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 0.0166, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 0.0391, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 0.0473, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 0.0841, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 0.0139, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 0.0337, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 0.0510, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 0.0315, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 0.01734352298080921, accuracy: 99.7 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 0.03929987549781799, accuracy: 99.0 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 0.01351492665708065, accuracy: 99.9 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 0.012048237025737762, accuracy: 99.8 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 0.0155185516923666, accuracy: 99.7 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 0.00998556800186634, accuracy: 99.9 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 0.009935468435287476, accuracy: 99.9 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 0.02211669832468033, accuracy: 99.3 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 0.009039826691150665, accuracy: 100.0 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 0.008209441788494587, accuracy: 100.0 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 0.0738, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 0.0593, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 0.0234, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 0.0438, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 0.0755, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 0.0761, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 0.0199, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 0.1379, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 0.0569, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 0.0197, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 0.02624169923365116, accuracy: 99.1 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 0.027610071003437042, accuracy: 98.9 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 0.035571396350860596, accuracy: 98.8 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 0.028163569048047066, accuracy: 99.2 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 0.04219140112400055, accuracy: 98.4 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 0.01996001787483692, accuracy: 99.4 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 0.018220016732811928, accuracy: 99.7 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 0.01702975668013096, accuracy: 99.8 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 0.017100872471928596, accuracy: 99.9 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 0.0166334118694067, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 0.0095, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 0.0497, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 0.0260, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 0.0697, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 0.1013, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 0.0571, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 0.0618, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 0.0508, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 0.0614, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 0.0754, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 0.05837894231081009, accuracy: 98.0 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 0.08480259031057358, accuracy: 97.0 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 0.05613822117447853, accuracy: 98.1 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 0.04903667792677879, accuracy: 98.4 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 0.04683639481663704, accuracy: 98.5 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 0.040783967822790146, accuracy: 98.6 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 0.04265688359737396, accuracy: 98.7 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 0.042445577681064606, accuracy: 98.8 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 0.03784461319446564, accuracy: 98.7 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 0.035329632461071014, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 0.0638, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 0.0125, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 0.0063, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 0.0095, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 0.0163, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 0.0155, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 0.1150, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 0.0519, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 0.0175, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 0.0828, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 0.04203598201274872, accuracy: 98.8 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 0.525657057762146, accuracy: 88.2 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 0.03972826525568962, accuracy: 98.1 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 0.027863943949341774, accuracy: 99.2 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 0.03324207291007042, accuracy: 98.8 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 0.02612443082034588, accuracy: 99.5 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 0.029455188661813736, accuracy: 98.8 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 0.021411534398794174, accuracy: 99.7 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 0.020928695797920227, accuracy: 99.7 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 0.020366307348012924, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 0.0717, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 0.0507, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 0.0649, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 0.0195, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 0.0089, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 0.1579, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 0.0518, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 0.0712, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 0.0473, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 0.0444, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 0.025760052725672722, accuracy: 98.9 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 0.28399521112442017, accuracy: 91.4 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 0.02316831611096859, accuracy: 99.3 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 0.02196590043604374, accuracy: 99.5 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 0.025816140696406364, accuracy: 99.5 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 0.019951745867729187, accuracy: 99.3 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 0.019419096410274506, accuracy: 99.4 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 0.018905531615018845, accuracy: 99.5 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 0.021108316257596016, accuracy: 99.4 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 0.018119852989912033, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 0.0237, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 0.0497, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 0.0202, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 0.0973, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 0.0760, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 0.0443, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 0.0052, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 0.0889, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 0.0331, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 0.0339, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 0.06010875105857849, accuracy: 98.0 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 0.5883501768112183, accuracy: 87.4 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 0.04897373542189598, accuracy: 98.4 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 0.04600927233695984, accuracy: 98.8 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 0.043211549520492554, accuracy: 98.8 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 0.04419805482029915, accuracy: 98.7 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 0.044652875512838364, accuracy: 98.4 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 0.07782963663339615, accuracy: 97.1 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 0.03707217797636986, accuracy: 98.7 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 0.03596171364188194, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 0.1773, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 0.0472, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 0.1136, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 0.0630, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 0.0442, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 0.0517, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 0.0303, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 0.0926, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 0.0153, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 0.0410, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 0.021271120756864548, accuracy: 99.7 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 0.0884786918759346, accuracy: 97.0 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 0.019242241978645325, accuracy: 99.6 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 0.01856103166937828, accuracy: 99.6 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 0.015265131369233131, accuracy: 99.8 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 0.016841648146510124, accuracy: 99.9 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 0.013292710296809673, accuracy: 99.9 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 0.01154818944633007, accuracy: 99.8 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 0.01111005712300539, accuracy: 99.8 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 0.010536449030041695, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 0.0793, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 0.0648, batch time: 0.40, accuracy:  96.88%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 0.1143, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 0.0409, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 0.0749, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 0.0303, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 0.0262, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 0.0232, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 0.0282, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 0.0875, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 0.04631568118929863, accuracy: 97.8 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 0.4517103433609009, accuracy: 86.4 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 0.05397842079401016, accuracy: 98.5 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 0.03236912935972214, accuracy: 99.0 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 0.0291262399405241, accuracy: 99.2 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 0.02566065825521946, accuracy: 99.5 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 0.02559690736234188, accuracy: 99.6 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 0.02815668098628521, accuracy: 99.8 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 0.024365516379475594, accuracy: 99.6 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 0.023421714082360268, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 0.0579, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 0.0313, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 0.0109, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 0.0111, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 0.0272, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 0.0288, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 0.0514, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 0.0635, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 0.0123, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 0.0311, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 0.027746252715587616, accuracy: 98.9 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 0.029561864212155342, accuracy: 98.8 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 0.029759762808680534, accuracy: 99.0 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 0.021280331537127495, accuracy: 99.3 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 0.026866862550377846, accuracy: 99.2 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 0.019637513905763626, accuracy: 99.4 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 0.02106565795838833, accuracy: 99.3 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 0.018812645226716995, accuracy: 99.6 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 0.03290301561355591, accuracy: 98.4 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 0.017505958676338196, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 0.0290, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 0.0168, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 0.0868, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 0.0634, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 0.0437, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 0.0297, batch time: 0.07, accuracy:  99.22%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 0.0488, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 0.0190, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 0.0687, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 0.0645, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 0.03720933571457863, accuracy: 98.8 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 0.04300664737820625, accuracy: 98.5 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 0.02948659285902977, accuracy: 98.9 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 0.02510722354054451, accuracy: 98.9 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 0.02237018197774887, accuracy: 99.0 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 0.02291208505630493, accuracy: 99.1 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 0.020196307450532913, accuracy: 99.2 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 0.019741754978895187, accuracy: 99.3 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 0.019136153161525726, accuracy: 99.3 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 0.018519526347517967, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 0.0177, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 0.0757, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 0.0055, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 0.0369, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 0.0141, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 0.0386, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 0.0596, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 0.0470, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 0.0389, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 0.0326, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 0.018919687718153, accuracy: 99.2 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 0.02201140858232975, accuracy: 98.9 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 0.015812300145626068, accuracy: 99.6 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 0.015189061872661114, accuracy: 99.5 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 0.014576015993952751, accuracy: 99.5 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 0.014266381040215492, accuracy: 99.5 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 0.014300735667347908, accuracy: 99.4 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 0.011265242472290993, accuracy: 99.7 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 0.011005440726876259, accuracy: 99.7 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 0.010562627576291561, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 0.0549, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 0.0554, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 0.0390, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 0.0794, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 0.0186, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 0.0258, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 0.1113, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 0.0753, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 0.0225, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 0.0121, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 0.041527774184942245, accuracy: 98.3 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 0.05286170169711113, accuracy: 98.0 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 0.04339321702718735, accuracy: 98.7 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 0.02962428331375122, accuracy: 99.2 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 0.028715074062347412, accuracy: 99.2 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 0.04941140115261078, accuracy: 98.4 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 0.027414174750447273, accuracy: 99.1 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 0.02570335939526558, accuracy: 99.4 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 0.0242629274725914, accuracy: 99.6 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 0.024023618549108505, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 0.0277, batch time: 0.41, accuracy:  99.22%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 0.0253, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 0.0273, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 0.0314, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 0.0723, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 0.0219, batch time: 0.08, accuracy:  98.44%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 0.0231, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 0.0607, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 0.0322, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 0.0932, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 0.037612609565258026, accuracy: 98.8 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 0.09969206154346466, accuracy: 96.9 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 0.030738674104213715, accuracy: 99.5 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 0.03416987136006355, accuracy: 99.1 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 0.029805172234773636, accuracy: 99.1 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 0.027581116184592247, accuracy: 99.6 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 0.027157697826623917, accuracy: 99.6 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 0.026281841099262238, accuracy: 99.5 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 0.026234209537506104, accuracy: 99.6 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 0.02600572071969509, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 0.0659, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 0.1253, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 0.0472, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 0.0073, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 0.1494, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 0.0421, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 0.0415, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 0.0512, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 0.1129, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 0.0829, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 0.04057345539331436, accuracy: 98.5 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 0.04824236407876015, accuracy: 98.2 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 0.03540627658367157, accuracy: 98.6 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 0.030531493946909904, accuracy: 99.3 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 0.030920669436454773, accuracy: 98.9 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 0.02737720124423504, accuracy: 99.2 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 0.04450083523988724, accuracy: 98.5 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 0.03270997479557991, accuracy: 99.3 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 0.02785547263920307, accuracy: 99.3 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 0.026471473276615143, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 0.0696, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 0.0382, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 0.0485, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 0.1070, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 0.0432, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 0.0718, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 0.0723, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 0.0371, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 0.0942, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 0.0449, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 0.029922867193818092, accuracy: 99.2 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 0.03285522013902664, accuracy: 98.8 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 0.028582176193594933, accuracy: 98.9 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 0.024813024327158928, accuracy: 99.1 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 0.02376578003168106, accuracy: 99.2 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 0.022084616124629974, accuracy: 99.3 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 0.021959828212857246, accuracy: 99.3 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 0.02193479612469673, accuracy: 99.2 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 0.021809598430991173, accuracy: 99.3 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 0.02179195173084736, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 0.0650, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 0.0559, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 0.0175, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 0.0571, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 0.0380, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 0.0936, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 0.0489, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 0.0449, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 0.0692, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 0.0517, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 0.03417797386646271, accuracy: 98.7 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 0.04571333900094032, accuracy: 98.1 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 0.02676388807594776, accuracy: 99.1 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 0.02163090929389, accuracy: 99.1 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 0.025717997923493385, accuracy: 99.3 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 0.018459182232618332, accuracy: 99.4 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 0.01706545241177082, accuracy: 99.5 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 0.016626251861453056, accuracy: 99.5 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 0.016412341967225075, accuracy: 99.5 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 0.01582983508706093, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 0.0209, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 0.1516, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 0.0876, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 0.0919, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 0.0637, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 0.0454, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 0.0875, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 0.0292, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 0.0734, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 0.0387, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 0.04828270524740219, accuracy: 98.1 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 0.04793476313352585, accuracy: 98.4 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 0.04505208879709244, accuracy: 98.9 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 0.03851718828082085, accuracy: 98.9 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 0.041354693472385406, accuracy: 98.9 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 0.03638434782624245, accuracy: 99.2 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 0.03529511019587517, accuracy: 99.1 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 0.03471117839217186, accuracy: 99.2 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 0.034422218799591064, accuracy: 99.4 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 0.033513788133859634, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 0.0322, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 0.0847, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 0.0492, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 0.0633, batch time: 0.09, accuracy:  99.22%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 0.0279, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 0.0447, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 0.0466, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 0.0690, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 0.1171, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 0.0294, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 0.05696211755275726, accuracy: 98.2 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 0.1131807342171669, accuracy: 96.7 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 0.05045222491025925, accuracy: 97.9 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 0.05377403274178505, accuracy: 97.9 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 0.052864085882902145, accuracy: 98.2 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 0.05768735334277153, accuracy: 98.1 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 0.0448940210044384, accuracy: 98.5 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 0.042534731328487396, accuracy: 98.6 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 0.04148188605904579, accuracy: 99.0 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 0.04026718810200691, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 0.0361, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 0.1224, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 0.0078, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 0.0944, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 0.0239, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 0.0763, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 0.0152, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 0.0537, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 0.0403, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 0.0067, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 0.023772260174155235, accuracy: 99.2 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 0.020983759313821793, accuracy: 99.4 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 0.02015107497572899, accuracy: 99.3 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 0.016888882964849472, accuracy: 99.7 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 0.016228312626481056, accuracy: 99.7 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 0.015417493879795074, accuracy: 99.7 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 0.014387785457074642, accuracy: 99.6 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 0.01382676512002945, accuracy: 99.8 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 0.013518186286091805, accuracy: 99.9 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 0.012995322234928608, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 0.0463, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 0.0385, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 0.0519, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 0.0607, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 0.0211, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 0.0278, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 0.0421, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 0.0884, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 0.0911, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 0.0087, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 0.045539066195487976, accuracy: 98.7 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 0.1332777738571167, accuracy: 95.8 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 0.046950098127126694, accuracy: 98.6 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 0.0410604290664196, accuracy: 98.8 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 0.04786841943860054, accuracy: 98.2 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 0.031882479786872864, accuracy: 98.9 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 0.03413020819425583, accuracy: 98.8 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 0.02976914495229721, accuracy: 99.0 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 0.03474579006433487, accuracy: 98.7 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 0.028706008568406105, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 0.1009, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 0.0322, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 0.0326, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 0.0390, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 0.0625, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 0.0827, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 0.0797, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 0.1448, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 0.1179, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 0.0273, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 0.026858214288949966, accuracy: 99.0 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 0.032876934856176376, accuracy: 99.0 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 0.022015580907464027, accuracy: 99.0 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 0.017312776297330856, accuracy: 99.4 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 0.019818220287561417, accuracy: 99.1 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 0.022731833159923553, accuracy: 99.3 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 0.019972385838627815, accuracy: 99.4 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 0.013633967377245426, accuracy: 99.8 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 0.01288965530693531, accuracy: 99.9 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 0.012314178049564362, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 0.0637, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 0.0463, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 0.0095, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 0.0186, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 0.0160, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 0.0229, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 0.0187, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 0.0776, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 0.0203, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 0.0265, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 0.04020005464553833, accuracy: 98.7 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 0.04247802868485451, accuracy: 98.5 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 0.03400344029068947, accuracy: 99.2 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 0.03687587007880211, accuracy: 98.7 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 0.03101428411900997, accuracy: 99.2 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 0.02788727916777134, accuracy: 99.4 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 0.02717197872698307, accuracy: 99.2 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 0.026676977053284645, accuracy: 99.5 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 0.026820899918675423, accuracy: 99.2 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 0.02554032765328884, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 0.0179, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 0.0384, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 0.0339, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 0.0915, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 0.0775, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 0.0519, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 0.0261, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 0.0583, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 0.0395, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 0.0536, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 0.030071791261434555, accuracy: 98.9 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 0.22378124296665192, accuracy: 92.8 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 0.03246772661805153, accuracy: 99.0 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 0.025070136412978172, accuracy: 99.2 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 0.02770368941128254, accuracy: 99.1 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 0.02226053923368454, accuracy: 99.5 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 0.025173960253596306, accuracy: 99.3 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 0.02424471080303192, accuracy: 99.2 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 0.018498588353395462, accuracy: 99.6 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 0.017637353390455246, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 0.0487, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 0.0400, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 0.0289, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 0.0845, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 0.0038, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 0.0608, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 0.0439, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 0.0633, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 0.0607, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 0.0391, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 0.02605465240776539, accuracy: 98.6 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 0.02742541767656803, accuracy: 98.8 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 0.021189266815781593, accuracy: 99.2 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 0.016387557610869408, accuracy: 99.5 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 0.018510159105062485, accuracy: 99.3 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 0.014931851997971535, accuracy: 99.7 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 0.015223102644085884, accuracy: 99.4 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 0.020774057134985924, accuracy: 99.4 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 0.012642237357795238, accuracy: 99.6 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 0.01260099932551384, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 0.0816, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 0.0526, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 0.0932, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 0.0263, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 0.0707, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 0.0998, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 0.0504, batch time: 0.08, accuracy:  98.44%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 0.0154, batch time: 0.08, accuracy:  99.22%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 0.0612, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 0.0739, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 0.053931109607219696, accuracy: 98.0 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 0.34023240208625793, accuracy: 90.0 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 0.03928934782743454, accuracy: 98.3 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 0.035285480320453644, accuracy: 98.8 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 0.03446104750037193, accuracy: 98.5 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 0.031619567424058914, accuracy: 99.0 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 0.02942691557109356, accuracy: 98.9 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 0.03328963741660118, accuracy: 99.2 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 0.02586887963116169, accuracy: 99.3 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 0.026300935074687004, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 0.0151, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 0.1194, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 0.0313, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 0.0235, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 0.0465, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 0.0886, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 0.0167, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 0.0172, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 0.0184, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 0.0697, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 0.026843613013625145, accuracy: 98.7 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 0.024936826899647713, accuracy: 99.2 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 0.02386041358113289, accuracy: 99.2 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 0.01891259476542473, accuracy: 99.5 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 0.019179493188858032, accuracy: 99.5 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 0.026396965608000755, accuracy: 98.9 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 0.03479064628481865, accuracy: 98.8 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 0.016206061467528343, accuracy: 99.7 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 0.01684926450252533, accuracy: 99.4 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 0.01406179554760456, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 0.0561, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 0.0185, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 0.0316, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 0.0365, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 0.0444, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 0.0450, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 0.0306, batch time: 0.42, accuracy:  99.22%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 0.0395, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 0.0761, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 0.0139, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 0.02972254902124405, accuracy: 99.2 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 0.032443802803754807, accuracy: 98.7 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 0.024442046880722046, accuracy: 99.4 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 0.022369354963302612, accuracy: 99.5 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 0.02317609265446663, accuracy: 99.5 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 0.020331265404820442, accuracy: 99.7 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 0.02062462642788887, accuracy: 99.8 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 0.025981895625591278, accuracy: 99.2 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 0.020509185269474983, accuracy: 99.6 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 0.01871132291853428, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 0.0185, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 0.0670, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 0.0417, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 0.0742, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 0.0599, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 0.0692, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 0.0380, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 0.0309, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 0.0447, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 0.0482, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 0.05687694996595383, accuracy: 98.1 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 0.05682240054011345, accuracy: 98.0 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 0.050199683755636215, accuracy: 98.2 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 0.040995437651872635, accuracy: 98.4 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 0.039579473435878754, accuracy: 98.2 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 0.03678717836737633, accuracy: 98.4 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 0.03931237757205963, accuracy: 98.0 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 0.0405329130589962, accuracy: 98.0 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 0.034194156527519226, accuracy: 98.6 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 0.03324447572231293, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 0.0242, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 0.0796, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 0.1267, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 0.0421, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 0.0274, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 0.0206, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 0.0609, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 0.0436, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 0.0717, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 0.0453, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 0.0502832792699337, accuracy: 98.2 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 0.17080149054527283, accuracy: 94.2 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 0.03865928575396538, accuracy: 98.7 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 0.04309440404176712, accuracy: 98.5 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 0.033333759754896164, accuracy: 98.9 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 0.03590448200702667, accuracy: 98.8 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 0.028766872361302376, accuracy: 99.3 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 0.029942039400339127, accuracy: 98.9 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 0.02801857702434063, accuracy: 99.3 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 0.031089233234524727, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 0.0433, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 0.0045, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 0.0471, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 0.0240, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 0.0642, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 0.0292, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 0.0019, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 0.1300, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 0.0197, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 0.0428, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 0.07638682425022125, accuracy: 97.6 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 0.06898469477891922, accuracy: 98.1 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 0.06525981426239014, accuracy: 97.9 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 0.05981644615530968, accuracy: 98.2 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 0.05827432870864868, accuracy: 98.3 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 0.04934092238545418, accuracy: 98.6 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 0.052123092114925385, accuracy: 98.3 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 0.042502790689468384, accuracy: 98.8 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 0.044328466057777405, accuracy: 98.5 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 0.041416700929403305, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 0.0215, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 0.0065, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 0.0416, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 0.0802, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 0.0610, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 0.0591, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 0.0171, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 0.0640, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 0.0082, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 0.0450, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 0.03701566532254219, accuracy: 98.6 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 0.03564278781414032, accuracy: 98.8 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 0.05596404895186424, accuracy: 97.9 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 0.02691464312374592, accuracy: 99.2 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 0.027561044320464134, accuracy: 99.2 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 0.03428821638226509, accuracy: 98.6 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 0.027678394690155983, accuracy: 99.1 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 0.030774034559726715, accuracy: 98.6 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 0.022846847772598267, accuracy: 99.4 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 0.022267337888479233, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 0.0504, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 0.0818, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 0.0295, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 0.0565, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 0.0335, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 0.0343, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 0.0547, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 0.0598, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 0.0053, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 0.0256, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 0.06337665021419525, accuracy: 97.8 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 0.06417661160230637, accuracy: 97.8 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 0.0514659509062767, accuracy: 98.1 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 0.04550330713391304, accuracy: 98.6 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 0.044772252440452576, accuracy: 98.6 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 0.04084741324186325, accuracy: 98.6 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 0.04063175246119499, accuracy: 98.9 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 0.03922880440950394, accuracy: 98.7 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 0.03966113552451134, accuracy: 98.5 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 0.04168231785297394, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 0.0366, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 0.0245, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 0.0386, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 0.0530, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 0.0584, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 0.0305, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 0.0255, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 0.0167, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 0.0151, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 0.0397, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 0.021937398239970207, accuracy: 99.0 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 0.024299204349517822, accuracy: 99.2 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 0.02087009698152542, accuracy: 99.4 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 0.015714038163423538, accuracy: 99.5 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 0.014932100661098957, accuracy: 99.5 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 0.013212242163717747, accuracy: 99.8 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 0.021457429975271225, accuracy: 99.1 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 0.012626704759895802, accuracy: 99.8 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 0.012873424217104912, accuracy: 99.7 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 0.012227124534547329, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 0.0690, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 0.0354, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 0.0515, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 0.0931, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 0.0973, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 0.0667, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 0.0549, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 0.0368, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 0.0361, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 0.0869, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 0.026789216324687004, accuracy: 98.7 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 0.10559466481208801, accuracy: 95.7 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 0.017382221296429634, accuracy: 99.5 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 0.020838607102632523, accuracy: 99.2 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 0.01554102636873722, accuracy: 99.6 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 0.01504120510071516, accuracy: 99.8 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 0.012746313586831093, accuracy: 99.9 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 0.018374111503362656, accuracy: 99.6 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 0.014012027531862259, accuracy: 99.5 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 0.02026382088661194, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 0.0585, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 0.0519, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 0.0318, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 0.0628, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 0.0375, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 0.0350, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 0.0526, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 0.0152, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 0.1222, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 0.0466, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 0.03334854543209076, accuracy: 98.7 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 0.03510254994034767, accuracy: 98.8 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 0.02904677391052246, accuracy: 98.4 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 0.023291125893592834, accuracy: 99.1 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 0.023527629673480988, accuracy: 99.4 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 0.02088075503706932, accuracy: 99.2 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 0.028094854205846786, accuracy: 98.9 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 0.020347679033875465, accuracy: 99.4 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 0.019836261868476868, accuracy: 99.7 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 0.021735308691859245, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 0.0089, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 0.0447, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 0.0381, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 0.0233, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 0.1299, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 0.0308, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 0.0058, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 0.0394, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 0.0601, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 0.0460, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 0.03525758162140846, accuracy: 99.2 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 0.03715451806783676, accuracy: 98.9 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 0.033141911029815674, accuracy: 99.1 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 0.031826335936784744, accuracy: 99.1 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 0.030818171799182892, accuracy: 99.2 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 0.02773175947368145, accuracy: 99.4 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 0.02698294073343277, accuracy: 99.3 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 0.03195400536060333, accuracy: 99.0 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 0.02668609283864498, accuracy: 99.5 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 0.025242088362574577, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 0.0226, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 0.0651, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 0.2067, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 0.0445, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 0.0168, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 0.0700, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 0.0321, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 0.0284, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 0.0567, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 0.0373, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 0.03832462430000305, accuracy: 98.8 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 0.11040240526199341, accuracy: 96.5 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 0.03451910614967346, accuracy: 99.1 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 0.029259374365210533, accuracy: 99.1 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 0.025939904153347015, accuracy: 99.0 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 0.023646853864192963, accuracy: 99.3 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 0.021680094301700592, accuracy: 99.5 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 0.022481190040707588, accuracy: 99.5 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 0.019371574744582176, accuracy: 99.5 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 0.024480795487761497, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 0.0910, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 0.0377, batch time: 0.09, accuracy:  99.22%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 0.0402, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 0.0123, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 0.0359, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 0.0382, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 0.0433, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 0.0796, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 0.0182, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 0.0024, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 0.042991384863853455, accuracy: 98.2 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 0.09566270560026169, accuracy: 96.3 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 0.033373091369867325, accuracy: 99.0 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 0.03185310587286949, accuracy: 98.8 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 0.02794555574655533, accuracy: 99.2 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 0.03335259482264519, accuracy: 98.8 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 0.03002195619046688, accuracy: 98.9 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 0.02690635435283184, accuracy: 99.3 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 0.025375282391905785, accuracy: 99.3 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 0.02466151863336563, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 0.0528, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 0.0166, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 0.1088, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 0.0202, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 0.1120, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 0.0425, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 0.0897, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 0.0605, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 0.0329, batch time: 0.06, accuracy:  99.22%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 0.0230, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 0.03908926993608475, accuracy: 98.3 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 0.07277011126279831, accuracy: 97.2 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 0.028924962505698204, accuracy: 98.9 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 0.02558089606463909, accuracy: 99.0 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 0.037027955055236816, accuracy: 98.4 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 0.026237942278385162, accuracy: 98.9 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 0.02365097589790821, accuracy: 99.1 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 0.026292817667126656, accuracy: 98.9 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 0.022340692579746246, accuracy: 99.2 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 0.029333891347050667, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 0.0456, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 0.0444, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 0.0189, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 0.0141, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 0.0150, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 0.0095, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 0.0325, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 0.0556, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 0.0160, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 0.0686, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 0.029573237523436546, accuracy: 99.2 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 0.0315975584089756, accuracy: 99.1 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 0.03555676341056824, accuracy: 98.8 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 0.024053018540143967, accuracy: 99.3 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 0.02509591355919838, accuracy: 99.3 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 0.0221530981361866, accuracy: 99.3 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 0.020747993141412735, accuracy: 99.3 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 0.020024556666612625, accuracy: 99.7 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 0.020838338881731033, accuracy: 99.5 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 0.019731029868125916, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 0.1052, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 0.0838, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 0.0605, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 0.0509, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 0.0607, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 0.0513, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 0.0666, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 0.0278, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 0.0885, batch time: 0.34, accuracy:  96.88%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 0.0129, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 0.024067742750048637, accuracy: 99.0 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 0.08513317257165909, accuracy: 97.4 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 0.019160542637109756, accuracy: 99.0 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 0.01686267927289009, accuracy: 99.6 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 0.014749689027667046, accuracy: 99.8 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 0.0233573317527771, accuracy: 99.5 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 0.014062155969440937, accuracy: 99.6 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 0.012130716815590858, accuracy: 99.6 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 0.012694460339844227, accuracy: 99.4 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 0.012762520462274551, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 0.0080, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 0.1308, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 0.0786, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 0.0139, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 0.0510, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 0.0420, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 0.0422, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 0.0750, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 0.0693, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 0.0531, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 0.025705335661768913, accuracy: 99.3 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 0.02475442737340927, accuracy: 99.3 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 0.02381218411028385, accuracy: 99.3 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 0.02263871394097805, accuracy: 99.5 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 0.024631474167108536, accuracy: 99.5 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 0.020256919786334038, accuracy: 99.6 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 0.020310990512371063, accuracy: 99.6 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 0.025650963187217712, accuracy: 99.2 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 0.020385347306728363, accuracy: 99.3 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 0.020691240206360817, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 0.0150, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 0.0748, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 0.0086, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 0.0373, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 0.1301, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 0.0272, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 0.0394, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 0.0218, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 0.1026, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 0.0383, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 0.01586303487420082, accuracy: 99.3 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 0.014986150898039341, accuracy: 99.4 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 0.013307061977684498, accuracy: 99.6 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 0.012796640396118164, accuracy: 99.5 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 0.014870552346110344, accuracy: 99.4 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 0.01224609650671482, accuracy: 99.6 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 0.020634887740015984, accuracy: 99.3 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 0.00852690078318119, accuracy: 100.0 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 0.00821505207568407, accuracy: 100.0 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 0.007377518340945244, accuracy: 100.0 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 0.0015, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 0.0646, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 0.0111, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 0.0647, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 0.0526, batch time: 0.06, accuracy:  98.44%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 0.0521, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 0.0571, batch time: 0.08, accuracy:  98.44%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 0.0243, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 0.0451, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 0.1168, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 0.03544119372963905, accuracy: 98.8 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 0.039708465337753296, accuracy: 98.4 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 0.024541255086660385, accuracy: 99.5 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 0.022740719839930534, accuracy: 99.2 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 0.027469532564282417, accuracy: 99.3 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 0.023280799388885498, accuracy: 99.3 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 0.02567354217171669, accuracy: 99.3 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 0.016751648858189583, accuracy: 99.7 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 0.02322285808622837, accuracy: 99.3 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 0.01666403003036976, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 0.0305, batch time: 0.06, accuracy:  99.22%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 0.0176, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 0.0406, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 0.0741, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 0.0532, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 0.0563, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 0.0180, batch time: 0.09, accuracy:  100.00%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 0.0617, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 0.0566, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 0.0331, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 0.03558456525206566, accuracy: 98.5 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 0.0339149571955204, accuracy: 98.7 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 0.023228226229548454, accuracy: 99.5 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 0.020784057676792145, accuracy: 99.5 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 0.022605573758482933, accuracy: 99.5 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 0.032602209597826004, accuracy: 98.8 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 0.02236456610262394, accuracy: 99.4 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 0.020496640354394913, accuracy: 99.6 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 0.017834646627306938, accuracy: 99.7 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 0.016888685524463654, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 0.0320, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 0.0475, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 0.0543, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 0.0708, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 0.0578, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 0.0343, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 0.0331, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 0.0444, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 0.0189, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 0.0611, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 0.03767498582601547, accuracy: 98.8 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 0.051935404539108276, accuracy: 98.5 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 0.033833038061857224, accuracy: 99.0 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 0.03281160071492195, accuracy: 98.9 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 0.03155054524540901, accuracy: 98.9 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 0.031553320586681366, accuracy: 99.0 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 0.029059864580631256, accuracy: 99.1 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 0.030743887647986412, accuracy: 99.2 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 0.028423083946108818, accuracy: 99.2 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 0.030194899067282677, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 0.0409, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 0.0490, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 0.0588, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 0.0720, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 0.0365, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 0.0517, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 0.0521, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 0.1181, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 0.0206, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 0.0718, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 0.03270465508103371, accuracy: 99.1 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 0.15359638631343842, accuracy: 95.7 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 0.030726514756679535, accuracy: 99.0 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 0.025834621861577034, accuracy: 99.4 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 0.024558063596487045, accuracy: 99.3 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 0.023225916549563408, accuracy: 99.4 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 0.02721114084124565, accuracy: 99.2 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 0.020860543474555016, accuracy: 99.5 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 0.022591494023799896, accuracy: 99.5 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 0.030077550560235977, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 0.0756, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 0.0362, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 0.0320, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 0.0275, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 0.0459, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 0.2091, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 0.0335, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 0.1365, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 0.0202, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 0.0122, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 0.027627713978290558, accuracy: 99.2 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 0.059030529111623764, accuracy: 98.3 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 0.024538572877645493, accuracy: 99.4 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 0.02147752232849598, accuracy: 99.2 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 0.019300933927297592, accuracy: 99.4 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 0.01827147603034973, accuracy: 99.3 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 0.019402150064706802, accuracy: 99.2 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 0.020528092980384827, accuracy: 99.1 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 0.020526956766843796, accuracy: 99.6 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 0.016836578026413918, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 0.1059, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 0.0625, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 0.0374, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 0.0850, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 0.0273, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 0.0459, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 0.0222, batch time: 0.06, accuracy:  100.00%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 0.0287, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 0.0788, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 0.0342, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 0.03796716406941414, accuracy: 98.9 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 0.08846842497587204, accuracy: 97.2 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 0.07497667521238327, accuracy: 97.2 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 0.028146114200353622, accuracy: 99.1 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 0.02155574969947338, accuracy: 99.5 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 0.02197345159947872, accuracy: 99.2 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 0.020326893776655197, accuracy: 99.3 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 0.023491254076361656, accuracy: 99.5 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 0.020010357722640038, accuracy: 99.7 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 0.018983827903866768, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 0.0120, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 0.1007, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 0.0150, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 0.0113, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 0.0340, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 0.0528, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 0.0546, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 0.0312, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 0.0271, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 0.0590, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 0.040127549320459366, accuracy: 98.6 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 0.04313814640045166, accuracy: 98.4 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 0.030514320358633995, accuracy: 99.2 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 0.025396086275577545, accuracy: 99.4 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 0.027097688987851143, accuracy: 99.1 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 0.024260569363832474, accuracy: 99.3 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 0.02305375412106514, accuracy: 99.4 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 0.024837113916873932, accuracy: 99.3 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 0.02291017957031727, accuracy: 99.5 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 0.02048644982278347, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 0.1915, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 0.0868, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 0.0121, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 0.0296, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 0.0886, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 0.1597, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 0.0209, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 0.0576, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 0.0388, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 0.0095, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 0.02477310784161091, accuracy: 99.1 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 0.15043911337852478, accuracy: 95.8 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 0.7602853178977966, accuracy: 86.9 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 0.012326007708907127, accuracy: 99.6 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 0.011033887974917889, accuracy: 99.8 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 0.015048579312860966, accuracy: 99.3 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 0.0103364959359169, accuracy: 99.9 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 0.008399485610425472, accuracy: 99.9 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 0.009572125039994717, accuracy: 99.9 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 0.011485818773508072, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 0.0535, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 0.0366, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 0.0068, batch time: 0.07, accuracy:  100.00%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 0.0645, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 0.0102, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 0.0892, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 0.0294, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 0.0366, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 0.0577, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 0.0221, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 0.018849972635507584, accuracy: 99.4 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 0.020461605861783028, accuracy: 99.4 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 0.014657624997198582, accuracy: 99.4 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 0.012371130287647247, accuracy: 99.7 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 0.013074848800897598, accuracy: 99.8 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 0.011386791244149208, accuracy: 99.8 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 0.010965387336909771, accuracy: 99.9 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 0.010217376053333282, accuracy: 99.8 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 0.010046822018921375, accuracy: 99.8 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 0.009788659401237965, accuracy: 99.9 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 0.0487, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 0.0599, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 0.0328, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 0.0231, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 0.0156, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 0.0212, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 0.0412, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 0.0664, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 0.0555, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 0.0488, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 0.028628921136260033, accuracy: 99.0 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 0.13565786182880402, accuracy: 95.9 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 0.025388726964592934, accuracy: 99.3 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 0.022362420335412025, accuracy: 99.3 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 0.025880176573991776, accuracy: 99.3 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 0.02037397213280201, accuracy: 99.5 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 0.018678274005651474, accuracy: 99.5 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 0.021496694535017014, accuracy: 99.3 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 0.025156352669000626, accuracy: 99.0 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 0.017498910427093506, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 0.0568, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 0.0343, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 0.1592, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 0.0758, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 0.0543, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 0.0299, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 0.0409, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 0.0252, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 0.0145, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 0.1613, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 0.1035655066370964, accuracy: 96.8 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 0.10554750263690948, accuracy: 97.3 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 0.09138958901166916, accuracy: 97.6 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 0.08974386006593704, accuracy: 97.5 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 0.08519676327705383, accuracy: 97.3 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 0.0849732905626297, accuracy: 97.5 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 0.08460968732833862, accuracy: 97.8 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 0.08645221590995789, accuracy: 97.1 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 0.078646220266819, accuracy: 97.8 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 0.07681389153003693, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 0.0305, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 0.0129, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 0.0598, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 0.0176, batch time: 0.36, accuracy:  99.22%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 0.0520, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 0.0919, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 0.0487, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 0.0489, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 0.0373, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 0.0387, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 0.02160455845296383, accuracy: 99.3 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 0.05791895091533661, accuracy: 97.6 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 0.0218702033162117, accuracy: 99.2 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 0.016195474192500114, accuracy: 99.5 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 0.01634383387863636, accuracy: 99.5 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 0.019416747614741325, accuracy: 99.5 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 0.017405685037374496, accuracy: 99.6 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 0.015260715037584305, accuracy: 99.6 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 0.014535276219248772, accuracy: 99.7 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 0.014474179595708847, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 0.0425, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 0.1046, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 0.0240, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 0.0391, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 0.1019, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 0.0710, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 0.0320, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 0.0239, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 0.0223, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 0.0594, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 0.029817024245858192, accuracy: 98.8 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 0.042712029069662094, accuracy: 98.4 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 0.05017319321632385, accuracy: 98.2 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 0.023846328258514404, accuracy: 99.1 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 0.021085217595100403, accuracy: 99.2 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 0.020232120528817177, accuracy: 99.5 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 0.021642571315169334, accuracy: 99.5 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 0.017816806212067604, accuracy: 99.6 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 0.019962644204497337, accuracy: 99.6 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 0.02420380711555481, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 0.1393, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 0.0539, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 0.0514, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 0.0361, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 0.0101, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 0.1571, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 0.0043, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 0.0268, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 0.0429, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 0.0670, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 0.04642796888947487, accuracy: 98.4 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 0.08959601819515228, accuracy: 96.9 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 0.04051535949110985, accuracy: 98.7 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 0.03344997391104698, accuracy: 99.2 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 0.03161481022834778, accuracy: 98.9 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 0.029001880437135696, accuracy: 99.2 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 0.027490921318531036, accuracy: 99.0 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 0.029972214251756668, accuracy: 99.2 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 0.027303317561745644, accuracy: 99.4 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 0.02784980647265911, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 0.1497, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 0.0295, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 0.0161, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 0.0607, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 0.0319, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 0.1030, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 0.0190, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 0.0574, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 0.0310, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 0.0203, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 0.02533460035920143, accuracy: 99.4 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 0.026369228959083557, accuracy: 99.3 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 0.0261069368571043, accuracy: 99.1 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 0.017423611134290695, accuracy: 99.3 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 0.017128512263298035, accuracy: 99.5 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 0.01619553379714489, accuracy: 99.3 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 0.018496854230761528, accuracy: 99.1 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 0.01671857014298439, accuracy: 99.4 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 0.014224995858967304, accuracy: 99.6 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 0.01715082861483097, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 0.0148, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 0.0240, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 0.0233, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 0.0398, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 0.0339, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 0.0156, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 0.0990, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 0.0506, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 0.0647, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 0.0521, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 0.03251229599118233, accuracy: 98.8 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 0.032627884298563004, accuracy: 98.7 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 0.028148533776402473, accuracy: 99.0 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 0.022856298834085464, accuracy: 99.3 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 0.02225583977997303, accuracy: 99.5 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 0.019630514085292816, accuracy: 99.6 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 0.02484182082116604, accuracy: 99.2 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 0.0198302511125803, accuracy: 99.3 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 0.021255021914839745, accuracy: 99.2 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 0.016639528796076775, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 0.0203, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 0.0226, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 0.0258, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 0.0683, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 0.0723, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 0.0601, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 0.0922, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 0.0406, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 0.0393, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 0.0134, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 0.03271760046482086, accuracy: 99.1 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 0.5667047500610352, accuracy: 89.5 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 0.0252961628139019, accuracy: 98.9 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 0.02408536709845066, accuracy: 99.0 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 0.022503063082695007, accuracy: 99.2 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 0.02214665524661541, accuracy: 99.3 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 0.026166660711169243, accuracy: 99.2 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 0.021692847833037376, accuracy: 99.1 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 0.027226721867918968, accuracy: 98.8 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 0.02058633416891098, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 0.0278, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 0.1541, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 0.1463, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 0.0333, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 0.0400, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 0.0658, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 0.0472, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 0.0668, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 0.0374, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 0.0459, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 0.07596806436777115, accuracy: 97.7 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 0.0995466560125351, accuracy: 97.5 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 0.05144023150205612, accuracy: 98.3 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 0.04911308363080025, accuracy: 98.4 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 0.046806324273347855, accuracy: 98.4 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 0.04715575650334358, accuracy: 98.6 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 0.04468053951859474, accuracy: 98.7 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 0.043589405715465546, accuracy: 98.9 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 0.04401428997516632, accuracy: 98.5 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 0.041724178940057755, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 0.0844, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 0.0336, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 0.0530, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 0.0373, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 0.0507, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 0.0164, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 0.0113, batch time: 0.06, accuracy:  100.00%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 0.0750, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 0.0871, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 0.0519, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 0.032127972692251205, accuracy: 98.8 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 0.052331723272800446, accuracy: 98.3 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 0.026248447597026825, accuracy: 99.4 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 0.024529602378606796, accuracy: 99.6 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 0.031710054725408554, accuracy: 99.0 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 0.02399343065917492, accuracy: 99.5 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 0.025274153798818588, accuracy: 99.2 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 0.023554544895887375, accuracy: 99.8 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 0.023926198482513428, accuracy: 99.5 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 0.02259543538093567, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 0.0073, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 0.0674, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 0.0232, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 0.0110, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 0.0496, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 0.0410, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 0.0263, batch time: 0.09, accuracy:  99.22%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 0.0627, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 0.1058, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 0.0803, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 0.02344285510480404, accuracy: 99.1 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 0.023573921993374825, accuracy: 99.0 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 0.02115941233932972, accuracy: 99.2 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 0.020531825721263885, accuracy: 99.3 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 0.02088775299489498, accuracy: 99.2 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 0.039466723799705505, accuracy: 98.3 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 0.01809277944266796, accuracy: 99.6 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 0.016622377559542656, accuracy: 99.5 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 0.016324399039149284, accuracy: 99.5 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 0.01607338711619377, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 0.0093, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 0.0574, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 0.0225, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 0.0372, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 0.0133, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 0.0632, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 0.0606, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 0.0271, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 0.0308, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 0.0246, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 0.0336664579808712, accuracy: 99.2 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 0.03196139633655548, accuracy: 99.1 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 0.02968808263540268, accuracy: 99.3 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 0.028772175312042236, accuracy: 99.2 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 0.028529543429613113, accuracy: 99.4 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 0.030127035453915596, accuracy: 99.3 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 0.02824055403470993, accuracy: 99.3 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 0.026254460215568542, accuracy: 99.3 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 0.03245154023170471, accuracy: 98.9 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 0.031874626874923706, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 0.0119, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 0.0338, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 0.0134, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 0.0706, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 0.0380, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 0.0847, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 0.0921, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 0.0757, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 0.0786, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 0.0388, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 0.028200248256325722, accuracy: 98.7 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 0.0696144849061966, accuracy: 97.4 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 0.022748319432139397, accuracy: 99.4 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 0.023095089942216873, accuracy: 99.3 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 0.026750925928354263, accuracy: 98.9 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 0.023330140858888626, accuracy: 99.4 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 0.02132895216345787, accuracy: 99.5 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 0.019789133220911026, accuracy: 99.8 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 0.018351363018155098, accuracy: 99.7 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 0.02048427239060402, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 0.0567, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 0.0761, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 0.0301, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 0.0423, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 0.0538, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 0.0944, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 0.0817, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 0.0562, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 0.0321, batch time: 0.09, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 0.0433, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 0.019165311008691788, accuracy: 99.5 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 0.08528579771518707, accuracy: 97.2 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 0.019255220890045166, accuracy: 99.5 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 0.017878331243991852, accuracy: 99.5 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 0.01850922219455242, accuracy: 99.6 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 0.01578008383512497, accuracy: 99.6 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 0.016092505306005478, accuracy: 99.4 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 0.014969882555305958, accuracy: 99.7 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 0.015439372509717941, accuracy: 99.6 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 0.014145230874419212, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 0.0640, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 0.0320, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 0.0225, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 0.0240, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 0.0378, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 0.0213, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 0.0677, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 0.0656, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 0.0202, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 0.0558, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 0.02224695309996605, accuracy: 99.3 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 0.024861019104719162, accuracy: 99.3 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 0.022016232833266258, accuracy: 99.4 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 0.019120337441563606, accuracy: 99.6 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 0.01945842057466507, accuracy: 99.7 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 0.019926877692341805, accuracy: 99.5 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 0.020234350115060806, accuracy: 99.2 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 0.01921055279672146, accuracy: 99.3 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 0.019794119521975517, accuracy: 99.5 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 0.01624273508787155, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 0.0499, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 0.0182, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 0.0387, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 0.0447, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 0.0378, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 0.0169, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 0.0422, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 0.1051, batch time: 0.06, accuracy:  95.31%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 0.0104, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 0.0181, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 0.027262654155492783, accuracy: 98.8 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 0.022023331373929977, accuracy: 99.3 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 0.0228533074259758, accuracy: 99.3 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 0.02047884091734886, accuracy: 99.4 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 0.021604564040899277, accuracy: 99.3 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 0.017398854717612267, accuracy: 99.8 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 0.018530461937189102, accuracy: 99.7 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 0.025465937331318855, accuracy: 99.3 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 0.01603095792233944, accuracy: 99.6 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 0.015551097691059113, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 0.0220, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 0.0106, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 0.0522, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 0.0610, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 0.0126, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 0.0498, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 0.1259, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 0.1177, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 0.0095, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 0.0554, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 0.05283987894654274, accuracy: 98.3 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 0.06173329055309296, accuracy: 97.6 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 0.04172968491911888, accuracy: 98.2 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 0.03515299782156944, accuracy: 98.7 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 0.03537271171808243, accuracy: 98.9 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 0.031433962285518646, accuracy: 98.8 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 0.03108871728181839, accuracy: 98.9 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 0.03083464689552784, accuracy: 98.9 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 0.02985742874443531, accuracy: 98.9 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 0.02905287966132164, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 0.0329, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 0.0902, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 0.1239, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 0.0100, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 0.0837, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 0.0164, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 0.0597, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 0.0220, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 0.0042, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 0.0049, batch time: 0.09, accuracy:  100.00%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 0.031293127685785294, accuracy: 98.8 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 0.04653197154402733, accuracy: 98.4 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 0.027537396177649498, accuracy: 99.0 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 0.024258483201265335, accuracy: 99.1 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 0.026780785992741585, accuracy: 98.9 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 0.031407810747623444, accuracy: 98.7 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 0.02490854263305664, accuracy: 98.9 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 0.03765159845352173, accuracy: 98.9 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 0.02221769280731678, accuracy: 99.2 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 0.019806936383247375, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 0.0077, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 0.0597, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 0.0592, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 0.0486, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 0.0581, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 0.0778, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 0.0139, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 0.0358, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 0.0277, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 0.1441, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 0.05973305553197861, accuracy: 98.3 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 0.1725274622440338, accuracy: 95.7 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 0.03293576464056969, accuracy: 98.9 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 0.026294736191630363, accuracy: 98.7 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 0.019345397129654884, accuracy: 99.1 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 0.020188335329294205, accuracy: 99.3 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 0.021192381158471107, accuracy: 99.4 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 0.020488813519477844, accuracy: 98.9 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 0.014546474441885948, accuracy: 99.7 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 0.016282755881547928, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 0.0411, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 0.0936, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 0.1283, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 0.0308, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 0.0871, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 0.0387, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 0.0408, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 0.0462, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 0.0303, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 0.0130, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 0.022591691464185715, accuracy: 99.3 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 0.08778736740350723, accuracy: 97.3 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 0.0207297932356596, accuracy: 99.2 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 0.018958576023578644, accuracy: 99.4 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 0.01916935294866562, accuracy: 99.5 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 0.01882767304778099, accuracy: 99.4 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 0.020127510651946068, accuracy: 99.2 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 0.01506129465997219, accuracy: 99.6 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 0.019983703270554543, accuracy: 99.3 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 0.01350063644349575, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 0.0340, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 0.0250, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 0.0088, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 0.0513, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 0.0599, batch time: 0.09, accuracy:  98.44%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 0.0760, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 0.0094, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 0.0650, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 0.0465, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 0.0543, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 0.03360021486878395, accuracy: 99.0 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 0.07912963628768921, accuracy: 97.3 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 0.030131839215755463, accuracy: 98.5 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 0.02855079621076584, accuracy: 98.7 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 0.025129277259111404, accuracy: 99.3 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 0.02287643402814865, accuracy: 99.3 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 0.024615710601210594, accuracy: 99.3 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 0.026125434786081314, accuracy: 99.3 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 0.021678682416677475, accuracy: 99.3 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 0.020625656470656395, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 0.0502, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 0.0420, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 0.0241, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 0.0230, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 0.0532, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 0.0640, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 0.0781, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 0.0037, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 0.0951, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 0.0362, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 0.028102263808250427, accuracy: 99.2 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 0.024379193782806396, accuracy: 98.9 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 0.015602313913404942, accuracy: 99.5 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 0.014955447986721992, accuracy: 99.6 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 0.015740856528282166, accuracy: 99.6 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 0.012671149335801601, accuracy: 99.5 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 0.01082502119243145, accuracy: 99.8 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 0.015757771208882332, accuracy: 99.4 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 0.01002455409616232, accuracy: 99.9 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 0.00944685097783804, accuracy: 99.9 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 0.0247, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 0.1506, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 0.0433, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 0.0424, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 0.0552, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 0.0345, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 0.0241, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 0.0600, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 0.0165, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 0.0494, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 0.04720466211438179, accuracy: 98.5 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 0.07054973393678665, accuracy: 98.1 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 0.041881855577230453, accuracy: 98.7 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 0.040267568081617355, accuracy: 98.7 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 0.038635529577732086, accuracy: 98.9 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 0.0364108681678772, accuracy: 99.1 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 0.036886073648929596, accuracy: 99.1 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 0.03446227312088013, accuracy: 99.1 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 0.03360983729362488, accuracy: 99.0 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 0.04149046912789345, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 0.0423, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 0.0258, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 0.0830, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 0.0359, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 0.0554, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 0.0363, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 0.0199, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 0.0639, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 0.0209, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 0.0947, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 0.030555710196495056, accuracy: 99.1 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 0.0695081427693367, accuracy: 97.5 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 0.02384859323501587, accuracy: 99.3 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 0.02104738913476467, accuracy: 99.2 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 0.020935337990522385, accuracy: 99.2 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 0.02404053509235382, accuracy: 99.2 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 0.01701924204826355, accuracy: 99.6 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 0.016685515642166138, accuracy: 99.7 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 0.015402556397020817, accuracy: 99.6 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 0.015259095467627048, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 0.0291, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 0.0597, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 0.0246, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 0.0449, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 0.0406, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 0.0924, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 0.1000, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 0.0265, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 0.1234, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 0.0702, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 0.020631859079003334, accuracy: 99.2 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 0.032795485109090805, accuracy: 98.8 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 0.018456531688570976, accuracy: 99.4 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 0.01600589044392109, accuracy: 99.6 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 0.016428977251052856, accuracy: 99.6 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 0.015399999916553497, accuracy: 99.5 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 0.01600910723209381, accuracy: 99.5 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 0.014810503460466862, accuracy: 99.7 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 0.013857895508408546, accuracy: 99.8 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 0.013461739756166935, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 0.0176, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 0.0611, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 0.0527, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 0.0470, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 0.0403, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 0.1197, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 0.0145, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 0.0568, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 0.0186, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 0.0241, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 0.026158003136515617, accuracy: 98.9 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 0.043579112738370895, accuracy: 98.2 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 0.025179492309689522, accuracy: 99.1 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 0.024029633030295372, accuracy: 99.0 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 0.02836785279214382, accuracy: 99.1 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 0.05312288552522659, accuracy: 98.3 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 0.03669336810708046, accuracy: 98.7 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 0.028707437217235565, accuracy: 99.0 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 0.014401399530470371, accuracy: 99.8 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 0.013958374969661236, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 0.0662, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 0.0620, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 0.0446, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 0.0240, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 0.0575, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 0.0515, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 0.0235, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 0.0221, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 0.0070, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 0.0256, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 0.046361107379198074, accuracy: 98.8 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 0.07725860923528671, accuracy: 97.1 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 0.03586798906326294, accuracy: 99.0 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 0.032187171280384064, accuracy: 99.1 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 0.03210095688700676, accuracy: 99.0 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 0.02930155023932457, accuracy: 99.5 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 0.028993427753448486, accuracy: 99.4 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 0.027712825685739517, accuracy: 99.4 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 0.02665259875357151, accuracy: 99.4 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 0.026398058980703354, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 0.0166, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 0.0510, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 0.0440, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 0.0145, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 0.0457, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 0.0146, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 0.0581, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 0.0329, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 0.1603, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 0.0581, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 0.05703895166516304, accuracy: 98.3 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 0.11891060322523117, accuracy: 96.4 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 0.04588231071829796, accuracy: 98.4 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 0.04300105571746826, accuracy: 98.7 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 0.04337814450263977, accuracy: 98.7 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 0.03973183408379555, accuracy: 98.8 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 0.039034511893987656, accuracy: 99.2 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 0.04022230952978134, accuracy: 98.6 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 0.036624763160943985, accuracy: 98.9 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 0.034440841525793076, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 0.0699, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 0.0368, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 0.0059, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 0.0644, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 0.0263, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 0.0848, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 0.0207, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 0.0290, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 0.0284, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 0.0658, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 0.015617256052792072, accuracy: 99.8 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 0.0161418616771698, accuracy: 99.7 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 0.013393230736255646, accuracy: 99.7 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 0.012690332718193531, accuracy: 99.7 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 0.01362021453678608, accuracy: 99.7 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 0.011750230565667152, accuracy: 99.9 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 0.012743623927235603, accuracy: 99.9 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 0.011096189729869366, accuracy: 99.8 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 0.013746675103902817, accuracy: 99.8 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 0.010829583741724491, accuracy: 100.0 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 0.0499, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 0.0731, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 0.0456, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 0.0740, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 0.0579, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 0.0959, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 0.1151, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 0.0620, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 0.0339, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 0.0078, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 0.025225521996617317, accuracy: 99.2 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 0.040279511362314224, accuracy: 98.7 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 0.01991119794547558, accuracy: 99.5 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 0.01864590123295784, accuracy: 99.5 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 0.01772393099963665, accuracy: 99.4 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 0.018323520198464394, accuracy: 99.5 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 0.01687912456691265, accuracy: 99.7 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 0.01573614403605461, accuracy: 99.7 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 0.014768043532967567, accuracy: 99.7 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 0.015133429318666458, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 0.0501, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 0.0951, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 0.0803, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 0.0289, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 0.0730, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 0.0521, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 0.0282, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 0.0515, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 0.0208, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 0.1078, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 0.04786711931228638, accuracy: 98.1 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 0.07532263547182083, accuracy: 96.9 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 0.11034940183162689, accuracy: 95.9 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 0.05026739463210106, accuracy: 98.2 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 0.03212055563926697, accuracy: 99.0 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 0.03022998571395874, accuracy: 98.9 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 0.029631314799189568, accuracy: 99.3 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 0.02785344049334526, accuracy: 99.2 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 0.0313338004052639, accuracy: 99.0 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 0.02787969820201397, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 0.0209, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 0.0426, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 0.0499, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 0.0553, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 0.0354, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 0.0876, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 0.0313, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 0.0309, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 0.0765, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 0.0708, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 0.02459735982120037, accuracy: 99.5 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 0.07887183874845505, accuracy: 97.8 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 0.08103921264410019, accuracy: 97.6 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 0.018231481313705444, accuracy: 99.7 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 0.0164671391248703, accuracy: 99.7 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 0.018640408292412758, accuracy: 99.6 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 0.014876600354909897, accuracy: 99.7 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 0.014350363984704018, accuracy: 99.7 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 0.01397816650569439, accuracy: 99.6 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 0.012902509421110153, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 0.0600, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 0.0293, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 0.0568, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 0.0172, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 0.0264, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 0.0834, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 0.0394, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 0.1583, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 0.0303, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 0.0313, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 0.030871938914060593, accuracy: 98.6 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 0.08008617162704468, accuracy: 97.0 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 0.03967780992388725, accuracy: 98.3 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 0.0245855450630188, accuracy: 99.2 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 0.01783647947013378, accuracy: 99.5 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 0.0183116402477026, accuracy: 99.4 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 0.018533023074269295, accuracy: 99.5 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 0.0181079413741827, accuracy: 99.4 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 0.023354222998023033, accuracy: 99.2 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 0.016121739521622658, accuracy: 99.6 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "loss_list_epoch = []\n",
    "acc_list_epoch = []\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0\n",
    "\n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter)\n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "\n",
    "            qnn_train_step += 1\n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\"\n",
    "                )\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA\n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(\n",
    "            qnn_minimize_loss,\n",
    "            init_param,\n",
    "            method=\"COBYLA\",\n",
    "            options={\"maxiter\": 1000, \"adaptive\": True},\n",
    "        )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB210lEQVR4nO2deZwcZZ3/P313z31ljkwmJyEhJCSQkBCQQwgEZAEvjMgKAoKyoGjQH8YV8NglrC7I6iIoiuCBsLqIq2IUAgExgUBCgEDIRS6SuZO5Z/qs3x/Vz1NPVd8zPVOZ9Of9es0rmZ7q7uqu7no+9fleDk3TNBBCCCGE2ITT7h0ghBBCSGFDMUIIIYQQW6EYIYQQQoitUIwQQgghxFYoRgghhBBiKxQjhBBCCLEVihFCCCGE2ArFCCGEEEJsxW33DmRDLBbDoUOHUFpaCofDYffuEEIIISQLNE1Db28vJk6cCKcztf8xLsTIoUOH0NTUZPduEEIIIWQYHDhwAJMmTUr593EhRkpLSwHoL6asrMzmvSGEEEJINvT09KCpqUmu46kYF2JEhGbKysooRgghhJBxRqYUCyawEkIIIcRWKEYIIYQQYisUI4QQQgixFYoRQgghhNgKxQghhBBCbIVihBBCCCG2QjFCCCGEEFuhGCGEEEKIrVCMEEIIIcRWKEYIIYQQYisUI4QQQgixFYoRQgghhNjKuBiUN1r89O/v4f0jg7hi8WTMqk8/UZAQQggho0NBOyN/fqsZj6zfi32d/XbvCiGEEFKwFLQYcTv1kcYxTbN5TwghhJDCpaDFiNOhi5FIjGKEEEIIsYuCFiNuly5GohQjhBBCiG0UtBhxOfWXTzFCCCGE2EdhixHdGGGYhhBCCLGRwhYjcWckRjFCCCGE2EaBixH9XzojhBBCiH0UtBhxM2eEEEIIsZ1hiZH7778fU6dOhd/vx5IlS7Bx48a02993332YNWsWAoEAmpqa8OUvfxlDQ0PD2uF84nKymoYQQgixm5zFyBNPPIGVK1fizjvvxObNmzF//nwsX74cbW1tSbd/7LHH8LWvfQ133nkntm3bhp/97Gd44okn8PWvf33EOz9SKEYIIYQQ+8lZjNx77724/vrrcc0112DOnDl48MEHUVRUhIcffjjp9uvXr8cZZ5yBT33qU5g6dSouuOACXHHFFRndlLFAihF2YCWEEEJsIycxEgqFsGnTJixbtsx4AKcTy5Ytw4YNG5Le5/TTT8emTZuk+Hjvvffw9NNP40Mf+lDK5wkGg+jp6TH9jAZuOiOEEEKI7eQ0tbejowPRaBR1dXWm2+vq6vDuu+8mvc+nPvUpdHR04AMf+AA0TUMkEsHnP//5tGGa1atX41vf+lYuuzYsnHExEolSjBBCCCF2MerVNOvWrcNdd92FH/3oR9i8eTOefPJJ/PnPf8Z3vvOdlPdZtWoVuru75c+BAwdGZd/cDNMQQgghtpOTM1JTUwOXy4XW1lbT7a2traivr096n9tvvx2f/vSn8dnPfhYAMG/ePPT39+OGG27Av/7rv8LpTNRDPp8PPp8vl10bFmJQXjQWG/XnIoQQQkhycnJGvF4vFi5ciLVr18rbYrEY1q5di6VLlya9z8DAQILgcLlcAADNZkdCOCNsekYIIYTYR07OCACsXLkSV199NRYtWoTFixfjvvvuQ39/P6655hoAwFVXXYXGxkasXr0aAHDJJZfg3nvvxcknn4wlS5Zg165duP3223HJJZdIUWIXrvhwGraDJ4QQQuwjZzGyYsUKtLe344477kBLSwsWLFiANWvWyKTW/fv3m5yQb3zjG3A4HPjGN76BgwcPYsKECbjkkkvw7//+7/l7FcPE5aAzQgghhNiNQ7M7VpIFPT09KC8vR3d3N8rKyvL2uPf+bTt+8NwuXL10Cr512dy8PS4hhBBCsl+/C3o2jZM5I4QQQojtFLQYYdMzQgghxH4KWoy4OLWXEEIIsZ0CFyP6vxQjhBBCiH0UuBiJOyNHfw4vIYQQcsxS0GKETc8IIYQQ+yloMSKqaaIclEcIIYTYRkGLEQ7KI4QQQuynoMWIy8HSXkIIIcRuCluMMGeEEEIIsZ2CFiNuDsojhBBCbKegxYhTDsqL2bwnhBBCSOFS0GJEJLBSixBCCCH2UdBixMgZoRohhBBC7IJiBKymIYQQQuyEYgTsM0IIIYTYCcUIgAg7sBJCCCG2QTEChmkIIYQQOyloMeLm1F5CCCHEdgpajLjir57OCCGEEGIfBS5G4s4IxQghhBBiG4UtRjgojxBCCLGdwhYjHJRHCCGE2E5BixEOyiOEEELsp6DFiDEoj2KEEEIIsYuCFiNu9hkhhBBCbKegxQibnhFCCCH2QzECihFCCCHETgpajLg5KI8QQgixnYIWI07FGdEoSAghhBBbKGgxIpwRgKEaQgghxC4KWoy4VDFCZ4QQQgixBYqROHRGCCGEEHugGIlDMUIIIYTYQ0GLEbfTePkUI4QQQog9FLQYUYwRtoQnhBBCbKKgxYjD4ZChGg7LI4QQQuyhoMUIALg4LI8QQgixFYoRtoQnhBBCbKXgxQgn9xJCCCH2UvBiRLSEZ5iGEEIIsYeCFyPCGYmxAyshhBBiCwUvRkTOSCRKMUIIIYTYAcUIc0YIIYQQW6EYEWKEYRpCCCHEFihGpDMSs3lPCCGEkMKEYoQ5I4QQQoitFLwYcTNMQwghhNhKwYsRp4MJrIQQQoidFLwYcbsoRgghhBA7KXgx4qIzQgghhNgKxQjbwRNCCCG2UvBixO3U34IYxQghhBBiCwUvRuJahM4IIYQQYhMFL0akM8LSXkIIIcQWCl6MsOkZIYQQYi8UIxyURwghhNgKxQg7sBJCCCG2QjHiYGkvIYQQYicUI6IDa5RTewkhhBA7KHgxYgzKs3lHCCGEkAKl4MWI0Q6ezgghhBBiBxQjsprG5h0hhBBCCpSCFyPG1F6qEUIIIcQOCl6MOFlNQwghhNhKwYsRkcDKQXmEEEKIPRS8GHE66YwQQgghdlLwYsTNdvCEEEKIrRS8GHHFp/ZSjBBCCCH2QDESfwcYpiGEEELsYVhi5P7778fUqVPh9/uxZMkSbNy4Me32XV1duOmmm9DQ0ACfz4fjjz8eTz/99LB2ON8IZyTGQXmEEEKILbhzvcMTTzyBlStX4sEHH8SSJUtw3333Yfny5di+fTtqa2sTtg+FQjj//PNRW1uL3/3ud2hsbMS+fftQUVGRj/0fMRyURwghhNhLzmLk3nvvxfXXX49rrrkGAPDggw/iz3/+Mx5++GF87WtfS9j+4YcfxuHDh7F+/Xp4PB4AwNSpU0e213lENj3jcBpCCCHEFnIK04RCIWzatAnLli0zHsDpxLJly7Bhw4ak9/m///s/LF26FDfddBPq6uowd+5c3HXXXYhGoymfJxgMoqenx/QzWsh28AzTEEIIIbaQkxjp6OhANBpFXV2d6fa6ujq0tLQkvc97772H3/3ud4hGo3j66adx++2345577sG//du/pXye1atXo7y8XP40NTXlsps5YQzKoxghhBBC7GDUq2lisRhqa2vxk5/8BAsXLsSKFSvwr//6r3jwwQdT3mfVqlXo7u6WPwcOHBi1/XOx6RkhhBBiKznljNTU1MDlcqG1tdV0e2trK+rr65Pep6GhAR6PBy6XS952wgknoKWlBaFQCF6vN+E+Pp8PPp8vl10bNiJnhO3gCSGEEHvIyRnxer1YuHAh1q5dK2+LxWJYu3Ytli5dmvQ+Z5xxBnbt2oWYMhV3x44daGhoSCpExhpjUB6n9hJCCCF2kHOYZuXKlXjooYfw6KOPYtu2bbjxxhvR398vq2uuuuoqrFq1Sm5/44034vDhw7jllluwY8cO/PnPf8Zdd92Fm266KX+vYgQY7eBt3hFCCCGkQMm5tHfFihVob2/HHXfcgZaWFixYsABr1qyRSa379++H02lonKamJvz1r3/Fl7/8ZZx00klobGzELbfcgttuuy1/r2IEOKUYoRohhBBC7MChaUd/TWtPTw/Ky8vR3d2NsrKyvD72k5vfx8r/eQNnzqzBL69bktfHJoQQQgqZbNdvzqaJOyNsB08IIYTYA8WIKO1lB1ZCCCHEFgpejLjpjBBCCCG2UvBiREztZdMzQgghxB4oRuLvANvBE0IIIfZAMRJ3RihGCCGEEHugGOGgPEIIIcRWKEY4KI8QQgixlYIXIxyURwghhNhLwYsRY1AexQghhBBiBwUvRoxBeRQjhBBCiB0UvBhxUYwQQgghtkIxwgRWQgghxFYKXoywHTwhhBBiLwUvRpxyUF7M5j0hhBBCCpOCFyNMYCWEEELspeDFiExgZZiGEEIIsQWKETojhBBCiK1QjFCMEEIIIbZCMeIQ1TRsCU8IIYTYQcGLEbfTeAuYN0IIIYSMPQUvRlzxQXkAQzWEEEKIHVCMOChGCCGEEDuhGHEaYoQt4QkhhJCxp+DFiFsRI0xgJYQQQsaeghcjTjojhBBCiK0UvBgBOCyPEEIIsROKESjD8uiMEEIIIWMOxQiUYXlRihFCCCFkrKEYAYflEUIIIXZCMQJ1Pk3M5j0hhBBCCg+KEShhGmoRQgghZMyhGAHgdIgEVqoRQgghZKyhGIHqjDBnhBBCCBlrKEZgDMujGCGEEELGHooRGMPyKEYIIYSQsYdiBEY1DZueEUIIIWMPxQgAt1N/GzgojxBCCBl7KEbAdvCEEEKInVCMQKmmYQdWQgghZMyhGIHhjHA2DSGEEDL2UIzAcEYYpiGEEELGHooRGNU0MYZpCCGEkDGHYgRGnxE6I4QQQsjYQzECwO3i1F5CCCHELihGYIRpOLWXEEIIGXsoRqC2g6caIYQQQsYaihHQGSGEEELshGIEqhihGiGEEELGGooRcFAeIYQQYicUI1DawVOMEEIIIWMOxQiUdvAUI4QQQsiYQzECDsojhBBC7IRiBEoCKwflEUIIIWMOxQiYwEoIIYTYCcUIALdTfxuSDcrrHgjjpZ0diFGoEEIIIaMCxQgAZ5pBed/609v455+9gnU72sZ6twghhJCCgGIE6qC8RDFyqGsQALCnY2BM94kQQggpFChGoHZgTRQjg2G9K2vXQGhM94kQQggpFChGYAzKiyQZTjMUigIAugbCY7pPhBBCSKFAMQKgyOcCAPTHhYfKYFi/7QidEUIIIWRUoBgBUOb3AAB6hxLdDyFG6IwQQgghowPFCIBSvxsA0DMYSfibCNPQGSGEEEJGB4oRAGUB3RnpoTNCCCGEjDkUI1DDNGZnJByNyd4jrKYhhBBCRgeKEQBlIkxjcUaEKwLoya2hSGK1DSGEEEJGBsUIjDBN71AEmtISfshSXUN3hBBCCMk/FCMwElijMQ0DigBRnREA6Bpk3gghhBCSbyhGAAQ8LrjjXVjVUI1VjBzppzNCCCGE5BuKEQAOh8MUqhEMWsI0R1hRQwghhOSdYYmR+++/H1OnToXf78eSJUuwcePGrO73+OOPw+Fw4MMf/vBwnnZUMXqNKM4Ic0YIIYSQUSdnMfLEE09g5cqVuPPOO7F582bMnz8fy5cvR1tbW9r77d27F1/5yldw5plnDntnR5Nk5b0JYRo6I4QQQkjeyVmM3Hvvvbj++utxzTXXYM6cOXjwwQdRVFSEhx9+OOV9otEorrzySnzrW9/C9OnTR7TDo0VpkvLexARWOiOEEEJIvslJjIRCIWzatAnLli0zHsDpxLJly7Bhw4aU9/v2t7+N2tpaXHfddVk9TzAYRE9Pj+lntBHOSNowTT+dEUIIISTf5CRGOjo6EI1GUVdXZ7q9rq4OLS0tSe/z0ksv4Wc/+xkeeuihrJ9n9erVKC8vlz9NTU257OawKAsIZ8QI0wwlhGnojBBCCCH5ZlSraXp7e/HpT38aDz30EGpqarK+36pVq9Dd3S1/Dhw4MIp7qVPqT5xPI8I0Xrf+NnE+DSGEEJJ/3LlsXFNTA5fLhdbWVtPtra2tqK+vT9h+9+7d2Lt3Ly655BJ5Wyymt1R3u93Yvn07ZsyYkXA/n88Hn8+Xy66NGCNMo5b26vvaUO7Hvs4B5owQQggho0BOzojX68XChQuxdu1aeVssFsPatWuxdOnShO1nz56Nt956C1u2bJE/l156KT74wQ9iy5YtYxJ+yRYRpulN4oxMLA8AYDUNIYQQMhrk5IwAwMqVK3H11Vdj0aJFWLx4Me677z709/fjmmuuAQBcddVVaGxsxOrVq+H3+zF37lzT/SsqKgAg4Xa7McI0iTkjDRV+AHqfEU3T4HA4xn4HCSGEkGOUnMXIihUr0N7ejjvuuAMtLS1YsGAB1qxZI5Na9+/fD6dz/DV2FZN7Tc5IvJqmoVwXI+Gohv5QFCW+nN82QgghhKRgWKvqzTffjJtvvjnp39atW5f2vo888shwnnLUKU1W2ht3RiqLvPC6nQhFYugaCFGMEEIIIXlk/FkYo0Sy0l4hRoq8blQW6WKFFTWEEEJIfqEYiWO0gzfEhsgZCXidqAh4AbDXCCGEEJJvKEbiCDEyFI4hFNFLekXOSMDjQkXcGWFFDSGEEJJfKEbilPiNPBDhjogwjd/jQmWR7ox00xkhhBBC8grFSByX04FSnzlvRIiRgMeFymI6I4QQQshoQDGiICf3xitqhkSYxutCOXNGCCGEkFGBYkShLCCSWBOdEZEz0j1IZ4QQQgjJJxQjCtIZSZIz4osPyxPJrYQQQgjJDxQjCmVK47NYTMNQWBceAa8LHpf+VoWjFCOEEEJIPqEYUVDDNEHFAQl4XPBKMaLZsm+EEELIsQrFiIIaphEhGkAP03jc+nA8OiOEEEJIfqEYUTC6sEakGPG6nXA5HXA7GaYhhBBCRgOKEQU5n2YwbOq+CkDJGWGYhhBCCMknFCMKcnLvUNiYSxMXI954mCZCZ4QQQgjJKxQjCrKaRgnTBLy6GBFhmhCdEUIIISSvUIwoqB1YRZjGnxCmoTNCCCGE5BOKEYUJpT4AQEvPkNJ9VX+LvKymIYQQQkYFihGFpqoiAEDXQBjtvUEAQJFXd0tEmCbCMA0hhBCSVyhGFEp8blTGZ9DsbO0FkBimCdEZIYQQQvIKxYgF4Y7saO0DYCSwMkxDCCGEjA4UIxaaKnUxsrNNd0ZEzohwRhimIYQQQvILxYiFSVUBAEBHXwiA0WfEzTANIYQQMipQjFgQzojA7xU5IwzTEEIIIaMBxYgFkTMikB1Y486IpgHRGEM1hBBCSL6gGLHQVBkw/W4N0wB0RwghhJB8QjFiobEyAIfD+D1gCdMAzBshhBBC8gnFiAWf24W6Ur/8XfYZcSrOSIRihBBCCMkXFCNJaKoyQjUiTON0OuByxif3MmeEEEIIyRsUI0lQK2qEGAGMUE2IzgghhBCSNyhGkjBJqagROSMAJ/cSQgghowHFSBLUihq/4oyI8l6GaQghhJD8QTGSBLXXiBqmcTNMQwghhOQdipEkTGaYhhBCCBkzKEaSUFfmR4nPDacDqAh45O0M0xBCCCH5x233DhyNuJwO/PTqRegaCKOy2CtvF2Ea9hkhhBBC8gfFSApOm16dcJuHk3sJIYSQvMMwTQ4YOSMM0xBCCCH5gmIkB0TTswidEUIIISRvUIzkgDVM8/ed7fjlhr027hEhhBAy/mHOSA5YwzS3/e5NHOoewpkzJ2BqTTEAIBrT5AwbQgghhGSGzkgOCDEiwjRdg2EAwOGBEADgnUM9mP+tv+HBF3bbs4OEEELIOIRiJAdEzohoehaMl/gOBKMAgE37j6AvGMGLO9rt2UFCCCFkHEIxkgNGzoiGcDSGaLz5WX8oAgAYCOr/dg2E7dlBQgghZBxCMZIDapgmqDQ+G4iLkf6Q7pB0D1KMEEIIIdlCMZIDapgmGI7K2wfiIqQ/7oxQjBBCCCHZQzGSA2qYZkh1RuI5I8Ih6QtGOEyPEEIIyRKKkRxQp/aqzki/FCHGbT10RwghhJCsoBjJAbUD61BYzRmJOyPxMA1glP0SQgghJD0UIzmgNj0LRhRnJCgSWBUxwooaQgghJCsoRnJAbQefzBnpZ5iGEEIIyRmKkRzwuI0wTUZnZDA0tjtHCCGEjFMoRnLA41TDNMlyRgyBwjANIYQQkh0UIzkgElj1ME1iNU2/ksDKXiOEEEJIdlCM5IDHnaIDazAKTdOYwEoIIYQMA4qRHDCFaSzOyFA4hvioGgB0RgghhJBsoRjJAZHAGk6YTRM1uSKAIUYGQ1Ec7Bocu50khBBCxhkUIzkgS3sjZjHSH4yYklcBoGtAr6a54Zev4cz/eA4HDg+M3Y4SQggh4wiKkRxwx8M0kZhmSmANRmLoGTKHZboGw9A0DZv2HUFMA/Z09I/pvhJCCCHjBYqRHPCmCNMAQHtv0PR7z2AYnf0ho+zXEsYhhBBCiA7FSA6oYRrVGQEMMVJV7AWgV9Ps6zRCM32WMA4hhBBCdChGckCIkUhMQzBsdkbaeocAAI0VAbnNtuYe+Xe1BwkhhBBCDChGckA0PQtHYxiKpHZGvPF+JFsPdsu/91GMEEIIIUmhGMkBObU3EktwRtr7dDFS4nOjPOABALz5viFG6IwQQgghyaEYyQEpRmKaaVAeALT16GKk2OdCRVyM7GjtlX+nGCGEEEKSQzGSA6YwTQpnpMjrRkWRLkYiSkvW/hATWAkhhJBkUIzkgClMk8YZEWEaFTojhBBCSHIoRnJAipGoJp2RMr8bADAYL/Ut9rlRHvAm3JcJrCPj/SMDCQKQEELIsQHFSA64RZgmZlTTVJf4TNsUK2EaFTojw2dXWy8+8B/P45bfbLF7VwghhIwCFCM54I07I5qmD8ADgEqL8CjymsM0JT7dOeln07Nh8/YhvV/Lex19Nu8JIYSQ0YBiJAdEmAYA+oZ0p6Oq2OyMlPjMzsjs+lJ9ezojw6ajTx86aG3BTwgh5NiAYiQHTGIkJMSIxRlR+owAwAkNZQA4m2YkdMQrlawt+AkhhBwbDEuM3H///Zg6dSr8fj+WLFmCjRs3ptz2oYcewplnnonKykpUVlZi2bJlabc/mhGlvYAeqgESnZFiS5hGiBGGaYZPZ1yM0BkhhJBjk5zFyBNPPIGVK1fizjvvxObNmzF//nwsX74cbW1tSbdft24drrjiCjz//PPYsGEDmpqacMEFF+DgwYMj3vmxxuFwwO10mG6zOiPFPjcqioxqmjkTdTESisYQ4mI6LESYhs4IIYQcm+QsRu69915cf/31uOaaazBnzhw8+OCDKCoqwsMPP5x0+1//+tf4l3/5FyxYsACzZ8/GT3/6U8RiMaxdu3bEO28HaqgGACqLzGW8xV63TGp1OIBZdaXyb6yoGR4dijOiaVqGrQkhhIw33LlsHAqFsGnTJqxatUre5nQ6sWzZMmzYsCGrxxgYGEA4HEZVVVXKbYLBIILBoPy9p6cn5bZjjdvlAMLG79UlZjFS5HOhutiLj57ciMbKAAJeF3xuJ4KRGPqCEVQWJ/YgIenpiA8h1DS9x4vX7chwD0IIIeOJnJyRjo4ORKNR1NXVmW6vq6tDS0tLVo9x2223YeLEiVi2bFnKbVavXo3y8nL509TUlMtujipexRlxOR0o85vDNCU+NxwOB+5dsQC3XjBL3gYA/SmSWHe19eLxjfsRi/Gq34qmaTJMAyBhWjIhhJDxz5hW09x99914/PHH8fvf/x5+vz/ldqtWrUJ3d7f8OXDgwBjuZXrUMI3f7UTA65K/Ox2Az534lhb59G1SJbHe8Ye38bUn38KG9zrzvLfjn95gBKGokWtjnZZMCCFk/JNTmKampgYulwutra2m21tbW1FfX5/2vv/5n/+Ju+++G88++yxOOumktNv6fD74fL6029iFW6mo8XlcKPYab2GxV3dFrIhtUuWMdMav/Pd1DuCM4/K5t+MfEaIRMImVEEKOPXJyRrxeLxYuXGhKPhXJqEuXLk15v+9+97v4zne+gzVr1mDRokXD39ujAK/FGRGuB6BX0iTD6MKaXIyIuTZtvUP52s1jBjVEA7C8lxBCjkVyckYAYOXKlbj66quxaNEiLF68GPfddx/6+/txzTXXAACuuuoqNDY2YvXq1QCA//iP/8Add9yBxx57DFOnTpW5JSUlJSgpKcnjSxkb1DCN1RlRhYmKECmpurAaYiSY9O+FjKikEdAZIYSQY4+cxciKFSvQ3t6OO+64Ay0tLViwYAHWrFkjk1r3798Pp9NYsB944AGEQiF8/OMfNz3OnXfeiW9+85sj23sb8CiVHD63EwGP4ox4h+eMDMXn3LT1UIxYsYoROiOEEHLskbMYAYCbb74ZN998c9K/rVu3zvT73r17h/MURy1up9kZcTodKPK6MBCKojiFM1IUT3LtDyW/qhcVIu0M0ySQEKahM0IIIcccnE2TI2rOiKicKYo7IqmckeI0zkg4GkM4qpf0ZhOm2XqwG+ff+wLWbM2ulHq8Q2eEEEKOfShGckQN0/jjIRrhiAwngVXNgWjvDWbsNfLCjnbsbOvDU6+Pv3b6w8FaTRNknxFCCDnmoBjJEVOYxuqMZExgTVxIBxUxEolpODIQSthGRQialp7CCOkkJrDSGSGEkGMNipEcMTU9E85IPCekKGUCq2h6luiMWJt4ZQrVDMTzTloLRozo4qwiPu9nPDkjWw92Y/2uDrt3gxBCjnooRnLEa6mmAYAin3BGMuSMJGkHP2hJyMwkRgZDRhlwtADax3fGnZHGigCA8eWMXPvIq/j0wxvRzpJtQghJC8VIjiQL0whnpNibqpomdZ+RQUuFTaaFayAuXqIxLSGEcawxGIrKCiQhRsaLMxKLaVIw7unot3t3CCHkqIZiJEeShWnOnV2LmhIvTptenfQ+IoF1IEPOCJC5C+ug4q60dI99qGZXWx9+/o89CEdH36EQYsvndsrpyOPFGVGrft4/MmDjnhQmWw504YF1uwvCPSTkWGBYfUYKmWRhmssXNeHjCyclnUsDGImtyZwRa0fRTI3PBhQnpaVnCPOz2+28cdfT2/Dcu22oKfHhkvkTR/W52uNipKbEB59bfw/HizOiisyDRwZt3JPC5Dt/egeb9h3BSZPKccZxNXbvDiEkA3RGciSZMwIgpRABlNLeJDkjVjGSMUyjiBE7kliFc7OtuWfUn0uU9daU+uDz6O/7eJnaq4qR9ylGxhzhqmWqTiOEHB1QjORIspyRTKRrepZ7mMbYvtmGME3vkP4adrX15f2xtx7sxo7WXvl7Z7++kEwo8cIfd0aGxoszohyng10UI2ON+JwmC40SQo4+KEZyJFnTs0wIMRKOaglhhsGQfqUvSlczlvaGDUHTmicx8vz2Nvx9Z3tW20ox0p5fMTIQiuDyBzdgxY83yDi/dEZKxp8zMmRyRpgzMpZomobeoTAA/XNFCDn6oRjJkWTt4DOhVtn0W67UxKI1paoIgJ4zommpk+7UK718ND7rGQrjhl+8hht+sQmRDEmp6kl+X+cAQnlszX64P4TBcBRHBsIyt+Zw3GKvLFadkfEhRlTH61DXUMbOuiR/BCPGiIVU86BIana29uKff/oKXtt72O5dIQUExUiOmAflZff2uV1OKVysoRqxaDXFxchgOJo00VVgTWAdKQcODyAc1TAYjmY8cQ+FjZN8NKZhX2f+SlbV1yVef8+g/m+Z36M4I+NjcVFfTygak8m4ZPQR7h2QWDpPMvOnN5vx0q4O/G7T+3bvCikgKEZyxBSmcWcXpgFSJ7EKZ6S62Cu3SRWqicU00xV3S/dQWhclG5q7DEGTydIWroggn3kjqgATzyP+LQu4x58zYlkEmcQ6dqif02RJ4yQ94oKJrtLoE4nG0MUkawAUIzljCtNk6YwAqZNYxaLl97pQW+oDkLq815q8ORCKojeNi5INh7qNRXIgw8mnZ8j8XDvzKEbU8JO4shX/lo5DZ8RaJcW8kbFDFbZ0RjJz7zM7sPrpbfJ30VhxYITnFpKZz/1yExbftbZgxnukg2IkR9zO4TkjqYblCYER8LgwQYiRFBU1qlgojT/eSJNYD6nOSIbKg9F0RtQrWOmMBPV/S/1upc/IOHFGLGKEFTVjhxqm4dV9eobCUfxg7U78+MX35BW6ECGZLk7IyHl172GEIjHsHoXqxPEGxUiOeNzDc0ZSDcsT1TR+jwu1ZX4AqXuNSBfF40RDhb7tSPNGDnWpzkimMI3573kVI6YwjTVnxA1//L22Og5HKwzT2IcqmgcZpknLYJJcLSFCWIk0uvQHI9JtpvCjGMkZj6maJntnJNV8GrG4BjxKmCaFGBEf2CKvG3Vx4TLSXiMmMZJhoRciQTg473X05a1KRL2C7ZFhGuGMeOR7nc8KntFEOCPCSWMX1rFDFc08yadH/c6L90p8dvnejS7NSojc6qQWIhQjOeI1dWDNxRkR82mSV9OYxEgKt0NcqQQ8LjSU62JkOGGaHuXKURUz2YZpTpxYBq/LiaFwLG/hhwFLAqteRixyRsafMyL2c2pNMYDCyxkJRqJ4cUe7LceLYZrsUZ2R/gRn5Nh775q7B3Gk/+hIGFVD5MxtohjJGbdLnU2TS86Ivu3eTvOiJE7WPo8TtWXpnZFB6Yy4UF82vDDNLzbsxUnf/BuefqsZ0Zhmun8mW1aImIqAB9Pii2y+QjXWMM1QOIZI3HUpU5yRcZMzEj9WM2tLAOg5IyOtfBpPPPKPvbjq4Y146MX3xvy5zaW9DDWkQ10EhfgwRMmx9d71ByM4/94X8eEf/cPuXQFgHnRKZ4RiJGc8w6ymWTJNn+j7yPq9+NXL++TtZmdEFxiZwzQu1AlnJEcxsmV/FwDg2W2taOsdMk01zXQlpFa3HBdfZHe29aa7S9aoV7C9Q2EpfFxOB4q8rgRnZM3WZnz20VezKouLxTRs2ndkTK8+xHGdPqEYDofeo+XwUXJFNha8skdvmLUnj71osqUvqJT2sh18WtRFUIgQcdux5io1dw+hLxjBvs6BjA0ex4JcKhkLAYqRHPEOM2fko6c04nNnTQcAfOOprfjjG4cAGFcmAW8WYZqwkTNSP8ycEVEK/Nb73aZ8ESB7MVIWcGNmnS5G/rGrM6fnT4XVGREhoRKfGw6HI8EZ+dlLe/Dstjb88c3mjI/917db8LEH1uPuv2zLuG2+ECf0Mr8HdXGRWUhJrFsPdgOALZa4yRnhFWdaVPfDGp4JRWJHxaKdL9TwdKb8uLGg2RSmObZcqOFAMZIjapgml5wRh8OBr100G/982mQAukMCWBNY9UWrZyiSNNYuPrBFXhfqy4cnRvqU2TLWEEumL0SPklB62YJGuJwOvLCjHZv2jbxttNkZMbLMS/16ro3oYBuJaYhEYzgyoO/LO4e6Mz62eJ357IuSCXlcvS40VgYAFI4YaesZku7e4YFwhq3zjylnhL0y0qKeZ2Q1jfKeHQ2Ldr7oGVQdM/s/F4eYwGqCYiRH1DCN6pJkg8PhwCUnTQRgXDEOhY3S3rKAG974opusvFdYzgGvS7aPP9wfyumLJU44mgY8806b+fGzDtO4Ma2mGJcvnAQA+O6a7SPOh7AmsKohIcA8lDAYiaE7fmJ5+1BPxscWM246lJbsmqaZQlT5xijDNoRjponMxwpbFYFohzOiXgEHI7FRPc7jnQFTzkgEmqaZK2yOoTCXWaTa/7rUnBGGaShGckaIEZ/bCYfDkWHrRCqLvQCAI/EFUihiv8cFh8OhlPcmLlyDMkzjQpnfg/KAvlAfyKFSQ+3BICb1ij5umcM0hjMCAF88bya8Lide2XMYL+3qyHofktFnCdOIq5gyizMC6Fdz3fEr7ndbehHOYCV3xbft7DMWxlse34Klq9eaFq58ouYCVcePeaHkjLz1viEQj9jQ6tpaPn+sJWLmE3POSBTBSAzqdcWx9N6ZwjRHwetqZgKrCYqRHPHEwzTqlXouVMQFRPdg2DRrJhCf7JuuJfyADNPoC/TkuDuyvzN7MaKeqEX+hXicbJueidDJxIoA/vm0KQCAH67dlfU+JGPAEqaxOiNOp0M6UV2DYYTiAiQUiWWs6BEi4PBASMbAn3u3DW29QexszU8CrhWZC+RxobJIFyOdhSJGDhrOSO9QJKNYzDfW5nyjnbj8/pEB/HDtznE5Y2TQ4oxYXdZj6YpdNFEE7HdGeobCHFtggWIkR2pL/XA4IPt85Ep5kb64xjRdkIgmXgGPECOpK2oGQmbh0lSl5yIcyCEXwXqiBiArYzLPpjG7FQDwiVP1UM32ES7q6kmwZyhsDMlTnku4I9YKokyhGnF1rmnAkYEw+oMRYzJwkvdDcKhrEC/uaM/hVRioIrO6JO6GFYgYeduSxzPW7oh1bMFoV4U8sG437nlmB365YV/mjY8yTH1GQtGEc8AxJUaOImekxZLrdyy9z8OFYiRH6sv9+N3nl+KhqxYN6/4+twtFcTGh9vgQybBGr5EkYRpR2usRYkR3NA4czs4ZCUViSft0zIiLkUzq3OpWAEBNib6/PUPhEWXeq7Np+oIRmRNSqoqR+Ou25tNYFz8raniksz9oEnp9acTIl57Ygqse3igrQ3JBFSNVxYXjjHT0BdHcPQSHA/JzfqR/bJNYrcd0tBcecTGwrSVz/tLRhjk/JJIQLhDfy/96didu/Z83xnWvHDWB1RrKG2uslYwM01CMDIuFU6qkEBgOIlSjqmMxdC99mMbijFTmJkZU90E8DwAcN0EXI+nGrVs7olpfixZ3eoaLmiinaYZQU4VPSmfkYAZnRBEBHb0h0/2TOUWCffEeGcPpnipmDgU8hhgphJwRIdym1xTLxN2xdEaiMU06IeJzOtoWuOiCvL1ldEJ+o0kmZ2QwFIWmabj/+V34383vJzRtPJrYuOcw9nak7mvTk4cxAQe7BhOct+Eg8kXEuAiGaShGbKE8nkMgPpA+txPO+IcymzCNNWckXQLrUDgq58eIq4GAx4UFTRUAgGKlTDjdF2IwHJVVCWWKQHC7nDKUcmSYZZyapiUIIXHlUBZQnREhRvT3Rkwufqe5J+WMnKFw1GTTd/YHTWJEbZBl3SdxRd81jNc1ZEpg1YVfIYmRuY3lqCoa+/CU6oqI+U2jHaYRwnlv5wCCkfG1qFhzRqzjKvqDEQyEojJHqyfHC46xGgfQ3D2IFT/ZgGsffTXlNqqIGE5p777Ofpzzvedx82OvD2sfVZrj57fJ1fo5nM4IxYgtGM6I/oEUTgcATEjTEn4wbPQZAdQwTfJW4wcOD+Cs7z6PTz70MgC1T4gbJ00qB6AnoQpxk84ZEQ6C6IiqYq0QypWhcAxCSwj3Q8xtUJ0R4R4JMbFgcgV8bif6ghHsT+EOWYVEe2/QFOZJ5Yz0KyfgrhxPwJpmTkyuLNZfw5GB0DFfZro17lLNayyXn4vDY+iM9MbFpc/tlNVmo9lQaigclY5gNKbhvfbR6Tg7EIpg074jeRtMKbBW0yTLGVEdz3ROopV3DvXgpG/+DV96/PW877eV948MQtOAvR39Kb9jqpAajjOy5UAXwlENL+3qGHHoT1yITq/JLkReCFCM2IBYnMQH0q90chXhk/YkOSNqO3gAaKwIwOHQTygdfeYTfjSm4db/eQNtvUG8uvcwojFNXjWW+N04Z1YtHA5g0dRK+XjpvhDWjqim11M0sjCEKoKMacS6UDPnjOgfVxHCqir2YnZ9KQBzbwsV6z519mcXplGv5nMNP4WjRg8Tv1JNo2kYlxUXubAvLgpn1JagMp6sPRxnabiooUTxuR7NyglryHDHKFVn3fX0NnzsgfV4ZltrXh9XFSMDoUhCkzOrGMmlFH7TvsMIRWN4assh3PfsjpHvbBpEqX9MS31R1DPCZniiaWE0puGt93PPI1MR5/4ZtfqML7sTao8GKEZsoDygL07C3jU5I3Ex0tkfSkgIHbSEabxuJxrii7fVGfjJi+9h4169M6rI5xBhmlKfG3Mby7HpG+fj3z88D8Xxx0t3tWDtiKoiciKGu9CKE0OR1yXDMuGoFn++RGdEJPdWBDyYM1F3eFJV1FhPTB29QRnmAdKIEeV+uS6m6gk+4HHB4zKu0u3ou5FvDnYN4vvP7DA1kRN0x19fZZHXcEbGMEyjJlkLMTKSLqK/2bgfi/7tmZRJzNaqiNESI7vbdMdlR57zUsxTe6MJYZqBUMQsRnIQ5uoF0g+e2yVHYIwGqnuZ7HMJWDqwDmPxVzsov36gK+f7q4juqzOEM8IwDcWIHVQUWZwRpWdJdbEPTocuIKxuhzWBFTBCNWqS5Y7WXtz7zHbTfQ/3h6QYKYkLiqpiL5xOh3y8gVA0pZ3aI6tbPAl/E6/n8DCrJsSVa5HXjVKf+fGTOSNCTJQHjIF9qcI01sW/sz9kqlRKlTNy2OSM5LaYiji5y+mQfWlE47POvtFdmN8/MoBVT76JXXkaYJiMB9ftxn+t3YnHXtmf8DexcJUHPCPOGRlOdVavEoqUInsElRNrtragoy+Ex19NfK1A4tTsHa3ZjxwYCCUf+5AMsdimGqI5XBKckTyGacR3SHz27/jD1lGrxlH3saM3lTOihGmG4Zap59jN+47kfH+BpmlyLs30CbozMhSOjXoo62iHYsQGrNU06owbl9Mhy2Wt5b3WMA2QvPHZLzbsRTiq4dzZtfLvXQMheSIp8ZndjWKf8XhDKRLwklXSCMSiM2xnJCT2y5Xw+Mn6jMghdAGPHBjYmmJGj1gIRZv9jr6gqVJpVJwRpeGZCGkNp6Lmfze9j2ffyc2W/83G/fjNxgN4+B97c7pfLuxu1xfc5m5zeWI4GpPJohUBz4hyRn7+jz2Y+82/4rW9uc09koLb5zaJ7OEijtdLO5N3GBZhGhFezdYZCUViuOSHL+G8e17IKulVfLeSjYkYCQOWahrrFXqCM5JDmKazX9/XG+IDQo8MhOWgznzTrXzGkjkjoUhMjt4A8uOMpBJW/cFI2tywnsGIMtW7RN5e6O4IxYgNiBwCtbpFRfYasZT3qoPyBE2WippgJIo/vqFPsr32jGlKcmlYOVGb3Qc1ZyVVfF1O7E0iRkZqxxthGneC86JW7li73lYUeVFfrr9X1itUgXBrZsS/9J19IUs1TfKTkury5Jozorb4F+Taa6S9N4hbf/sGvvCb13NKehWJv9mWew+HfXHh2265AlVt8LKAR37Oh1Nl9Y9dHRgKx2SoMVvUcGKxT4Qfh78AdsYXtr2dA0nfU+HSnTlzAgDdocsmGfH57W3Y3d6Pg12DpumtqRDiON/zjVRnJhSJyWPoUEZE9AzTGRHObmNlQJ6z8uEMJhMB3RnCNNZy3FwFaiym4aAiRtp7g0kHX3YNhHDa6rX4zM83pnysjn6jGlBcmAIUIxQjNiC6sAoSxEiS8l51gFUgmTMSP1Gu3daG7sEwGsr9WDqjWiYRHukPmSxsFafTIfch1YnU6IiaGKYZyaIDGCeGEp87Yd+S9RkRlAc8MuG1rSeY9CQlTuIz4+Gclp6hhAnByVBDC8PNGQl4jf3N1RkRrsNgOCqvMLNBuG3Wpkr5IhiJyni3db9EKKHU54bL6UBVsfHZyxXxnnfn+N6r85PEZ3q4zoimaSbxuH53ojsiRPCJE8tQVeyFpiHjeAIA+P3mg/L/mUIvQ+GovKrPd5jGKtTa4wu5cDv7g9Fh54wIIVdV7FU+/yPb/+t/8Ro+9IOXZOdqgZoz0p5EjFg7Lefa9Ky9L4hQNAaX04ETJ5YBSJ43sq25F71DEbzy3uGUYRd5YRfwwOl0SGe80CtqKEZsQFXDAOD3WsVIYphmKGwMsBIJrIDSEv6wvkA8ufl9AMCHT27UFwQpFEKymiZZqEWEagbCyb+kacM0xebkzGfeacXHH1if9dW5ODEU+Vwm58WtfFGBRGekPOCRwi0UjSUVQ2LxF2LE6jJkE6bJ1RkZkp1yjdeSqxhR7fjW7uxP4ML1OdiVvNx7pOhl5Pr/rVegMl8kLoArR5AzIhaXbBN+D3YNYigcNSrGfG7jMz3Mk/xAKGrqWPz3JKEaER6sK/Pj+Dr9M5YpVNM1EMLad43wWya3QxXDbb3JRfdwsS6Aws0QIwwGw8MP04jPek2JD9Xx0PNInJFgJIpn3mnFtuYe7O00l1Bnyhmxiqhcc0ZEvkh9mR+nTq0CkDxvRBzLUDQmHZBU+yLOpeJ8TmeEjDkirCFQwySAKkaMD7N6BaM6KSJM09w9iAOHB7Buuz5L5WOn6DNjKoqMuH2vEk+3EshQBmmd2KtSYVl0frFhL17bdwS/eiW7WR0iwbDYEqYp9ZvLiK3OSEWRB163UybIWSsbAGMxU61iwMjTSdVNUV0E+4K5DXuTYRpvYpgmWzGiHvtUISgrmqbJpOihcHJxNlL2KYuA9aSvJq8ChhjpDUYSrmQzIRbgbFypt97vxgf+4zmsevItUzgx4B1ZmMZ6rNbv7ky42hXHpr7ch+Pr9DLzTGLkj282y2oxIHm3ZRX1s6iHUvKXd2FdAIUIFlV9Cc5IlmGaiHJxUF3szcvkalXIWEuq1c9JMifRKqJyzRkRIZmmqgBOnlwBILkzol5EpAq/9Vhc5pE6eMcKFCM2YHVGVDsfACYooQeB+KD63E64nMYCPaHEh4DHhZgGnPW95xGJaZjfVCGrTIRr0dUfNvUZsSIqD1JZhdmU9oqTpggZvfxedvF+ETYptiSwWoVPMmcEMHqTWE9QgHHyqyz2ysRgAJgWL6kLRmJJF0rrSTMXe1pWPSmujrjSHJYzkqUY6RkyzxYZjVDNPiVRejAcNS30IqQijktZwAPxUe3KoSJJ0zRZwZRNw7lX9nRC04C/bG2Wbk2p34PiESawihDNhFIfir0uHO4P4Z1mo4Rc0zT5HdWdEV2MZBoa+fu4eyn2L1lYQSWhcV9ffvJGwtGYFEVCqIvPnfiuDLe0VyQtOxz6xUo+5jOpTlyrRcD1ZMwZ0T+novIv18+EECOTKotwyuRKAMA7h7oTqqHUi4hU3z8jTKOf64xE68LuNUIxYgNlVjGSkDOinwj2dvbLKzGxyBRbXA2Hw4FbLzgetaU+aZ9fcWqT/HuFGqbJxhlJ8YVI74zEBc9gGOFoTH4Jtx7szmqOQ6oEVrUVPJA8ZwSAbGefzEEQbk1VkVcKAsAoqVOf33w/837n0oVV5oyYEliN/jHZMBwxYt0uWYLdSNlnscdVd8TqjLicDsU1y03MiUUymwqtPfF5JEPhmKx6KVGang1bjMQXtfoyP06bXg1AT6wVHBkIyy69taV+nNCgi5F30kyR3tfZj837u+B0AJcv0r+nmZwR63uQaftsUYWrEB8ip0OMMBhuae9h5Xvncjry4oyYxYjFGckyTCOq76w5I+29QVz63y/h0fV7kz63CDlPqgxgUmUApX43wlEtIRTdpuzXwRRiROyLcEbE53SsWucfrVCM2IDf4zItVFYxsqCpAn6PE7va+vDfz+8CoF5tm7cFgM+eOR2vfP08PHfr2Xjs+iVYoYiRyiRiJFkS6kicEbXD6PaWXrmQRGMaXtubuR5/QHFGVNfG2nPEp4SzfG6ndErSOiPxE3mVxRlprDDCNslOsNZchVySWIeSJBpXFeWWwKeKkWThp2RYtxsNZ8Q6KE29qheLVoWSoF0pe9BkvwipC4v6vm892J0ghvR9Mm4ToUi9A2vmZn7pEMKxqtiLM46rAaCHagTi/a4p8cLrdmJ2fRkcDv3qOFUJ7rvxpmVzG8tlImSmnBFruC1fSawit8npMI6ZiELVlOqf1+F2YO205J7kY1ik+p6qi77upJnDNNa8GrHfDfELl1AkZgq9vrCjHW++341HN+xN+tyqM+JwONBYoefqWQWH6tg0p/jeWvPv/AzTAKAYsY1K5YTtswiMujI//u3D8wAA3392B17aacxCsM6FETgcDkyfUILTZ9SY8iyMuShho89IEkGRqSdDugRWj8spb3/j/S7T3za815mwvRUhkoot1TTW51KTWcsVd6kuXgptFSODIaMKQQ/TGM5IbalPOkS9wTCauwdx2f3/wG9fO6APyRsQyXf6fXJpfCYEnam0VwnTZJOAqC5QrVkuPlZnKNWV2UgQITgRfulMIkZU569yGD1o1G27BsPxoYUhfPRH63HFT15O2H5Pknkwpg6sI8wZqS72yqTF1/cb82GMHiP6Alfsc2Naje64vZ1iPIF4bdXFXtTGRXSm3iHWEFe+ynvVC5xir/m7poZp1BBIXzCSVXOuDqWSRv03VXfUbFCbQKqCrM/S1yMc1RKSzkWeTX15QN6mnuvE53pf50DSsK1IYJ1Uqd9fiJFDlrwQ9dikuhiQOSMBszPCahpiC2JyL5Dc7fj4wkm4YnETNA340hOvS5s7lRhJhVrRkKrpmfq4qU7cvUOJC02y53nzgH4SFnktL2chRsRzFnvdpmoaa0hIdUbUq29hvVqdASEoPC4Hir3G9FwAqC3zS7HTOxTB8++2440DXfjFhn3xhFX95Da1Wl9ccqmoSRamETZ1OKplVVaoOg6pGrpZEdsJLWo9GWqaNqLZOJFoTNrSs+v1q3p1geiy5IwASNv4bOvBbpx211r8YctB0+1qOW8oEsNgOIr9hwcQisZwqHvIFPobCkdxKMn7k4+mZ4cVZ2R2Qyn8Hid6hiJ4r0Mv3TWSV/3yPnMa9PdFzS1RES5HZbE3aaJ6MpINe8wHRgm629T4ENBz0QA99KU+v6YBfVmIOynk4o9jhIHy44yoFx7iu+l1GxdFVtEjBEBNiVd2RVbPdeJzHY1p2H/YLG5jMU0KeyFGJkoxYv6OZZMzklhNExcjDNMQO1CTWAMpBMadl5yI2lIfOvpCeCkeq061bSrklelg2DTszopqaQ+Govi/Nw6ZYpjpmp4BxqIjnJEPztKbQG092J3R2u0LGvkw1moaFV8qZ6RchGnMJyCZvFrkhcPhMDkjdaU+lMSfq28oIk9uu9r6pMXs9zjlQpNLmCaZGPF7XPKkk+mErGmaOUyTZc6I2G5WPJFSdUaiMQ03PbYZp3znGazb3iZv39fZn3XpbXP3ECIxDV63E3MbhRhJdEbUY5OuJfzTbzWjpWcIv7a0lbfm53QNhFOGrURCbanfjQVNFfL2sjy0gxefg6oSLzwuJ06apD/+5n1dAIwFUYQJAeDELGclVRZ5ZcXK4f5Q2mot8d4JAZ6vMI0xXsJpahcAwBTSjMRdByFys0liFe9dTXEewzQpEljFd7Mi4JEiytqQzzh/eYwp5crnQh0nYe0T09YbRDiqweV0yAufiUnCNEPhqCnkm0wkW/cFYJhGQDFiE+qVfTJnBNA/pEtn6IlzL8QXEOtJI9vnicY02TMhWailSElg/dlL7+GLv3kd9z6jT9oMRWJpE1gBI+y0M/5FXjS1CtNqihHTgI0ZqmqM0l5zNY3VhVGdEXXBq0+RM3JEyRcBjKs0QF9AhLDqDYblfQfDUbwVH4pWVeSVz5NTzkiSGULqfmRKYu0LRkytq7sHw1klt4nXsHCKnu2vXpnd/ZdtePqtFsQ04Dt/egeRaAyvvNeJ8+55AZ9++JUsXpWRmzG5qkiGJlQxIhapioAh+ozuvInvn4jDv/l+l2kOjfW97hoImxZgNRYvklen1xTjnLgABhIH5aULjQ2EIvjly/sSwh+dMplTfw2iimLzfj0PSrzf9SYxEndGUokRKZD12T3uuIOYLnwhxJmo1slXAqv4TBV5Ep2RymKjEgpAPAlV//5kU1os3juRuK1+9ofbJ6VDzRnpHZKP06OIYCGiEpwRGUJ0yyomtY1BOjEiQjQN5X64XfqS2ViZKEbEcRGirb03mLTV/0jDNJqm4S9vNcvP/rECxYhNVChhGjUXwoqIVQuVnaszol6RC6wVOYBRZjgYikqL+a9vt0DTNLy69zBimn61NEFZ0FXEFbCI3U6uKpIVCJnyRkRpb5HPjYDHJUM8VhfGnDOiuBzxxaCzP2T68qvOCGC+2qstM3JGVGcEAF6NtyCvLPZKMTecMI21FFlWFGRo/CQW3pL4+wFkV1HTYhEjHX0hDIWjeOyV/Xjo73sA6Ce+3e39+Pk/9uLW376BSEzD24d6suoDIpJXp1YXycREtfeDyG0whWlEpVWSMI04yQ+FYzKxU30c+ftAKKUzIk7IU2uKcdbxhhgp8btRFD++mhbvu5JkEjYA/Prl/bj9qa347+d2mW43ckb0z80p8f4SQoyI/RAjCQBDjOzp6E8ajhNhmooifUilnEOVRmCI9044XvnOGfF7XQkXOUVet+m28oBHVrdlUyFnTWAV/4YiMVMH5FxQnZFwVJPvZZeSOC0Sb1OFacr8Hvm5EJWDg6Go6fO125KDJHuMVBbJ2xor9HOOKvjFcZlUGZCVf8mSz635d7L7dZZhms37j+DGX2/Gl5/YktX26dje0msaAGgnFCM2oToj1kVLZfG0KtPvRWm2TUWlJT/F40o87AElTCOs732dA9jT0Y+123RX5tzZE+BUL5fU57A0cmuqLMIH4hUIa7e1pr0a6pclx/pgOfElTQjTpHBGKuPNzwDzSf1Iv9kZmRg/gVQVe1HkdUsx0jMUQYtyv1fiTk5VsVde5ecmRvQFzyoCs53hI06MtaU+mZybTUWN2Ob4ulIpLt9t6cW3//Q2AODW84/HV5fPAgD8+9Pb5ElW07KrvNkvnZFiuYgmq6bJNmck1Uh2awv4rsGwqbeG6ozsFWKkuhjzJ1Xg7OMn4Pw5dSj2mivW3j7UjcV3PYsvPv56wn5siT+3tRRaDdMAwClxkbejtQ/dg2GZvFirOCPVJT7plGxr7kEsppkW764Bs0CWc6jShF7Eois6vOYrTDMonRGX/LwIirzmi5jygEe6otk0PhPunwiNFnnd8mIikxhPRYfldQuB3p2VM2K0YJczi+LOyAHLYpzKGRFuCGCEaVq6h+QFmDgudaX+lAmu+r5Ymp5lqGS08vr+LgDGwMrh8ty7rbjov17Exx/YMKwJ2fmGYsQmTDkjaQTGcRNKTJU3uSawAkZFDZC8kgZQ2sGHIqYJwM+92yZbV587uy71c1jm7UyuKsI5sybA53Zib+dAyoQ+8ZyAEYIyxIglTKM4I6qYczgcctFWrxoPy2RBfdsp1cX4zofn4p5PzDc9fl8wYioVFE2rKk1hmtyraazHNdswjWw8VeozypYzLEChSEwmk9aX++XJ8oF1uzAUjmF2fSluPvc4XLlkipxn5HDoc2SA7HqSSGekpijpST9dzohVgA2Fo6ZF9XWltXbSMI0iFlt6jH3dExdI02qK4XI68Oi1i/HQVYvgcDjgUsYJPP1WC8JRDZuStPDeFv9sWhcwtZoG0J018d5976/vYntrL1xOh3QsBHPi7siW/V248qevYOF3npXfqSOWz2Sy0Q9WxPsxM/48vUORvPSkEIM3A16XdAsAvVLK53aazjVlAY90KrPLGTGHaQDDYcpl1pIgGIlKETRR5oiZxUiZKkasQxyVuVzFSkgaMCaei+/C7vY+U8WQEL8TlUTl2lI/XE4HIjEjv0tWV5X5Uia4AonOSK79cEQIsHcoIoWupmk5VY1tb+nFFx57HTFNd1RfzaIFw2hDMWITlaYwTWqB4XQ6sGiq4Y4EcswZsT5XaZIQDWAsnAe7hkxjvn/58j7s6xyA1+XEB2bWpH4OxRkp9btRXqRfgYg4/l/eakl5XxG7FQmHwg6dpFyJAOa2+eWWfBKjoiaJM6K8/k+fNgUfnFULwBBmh/tCSQVCVbFXzlnJpelZsj4jgLGoZZq3orbklmIkgzMiFjOPS59HJK7i/vq2LiQ/sagJDocDXrcT37x0DlxOB75w7kwsnKpf7WeyaiPRmDwJTq4qkle8wj1Qh7mpgyCnVOvH8t2WXpNDYD1Jq86INUxzZCBkcmCSOSOipNaKELiiWZmejKiMkg9GpKBRQ04DIaObbZXy2RYhsF+9rCfdfu6s6XLhEYhQzT3PbMeG9zoRisawJZ7YbXVGRBJrqgoZtQJqclWRdADzUVEzqOQ2qc5IkVcfw5AYptGP63DCNOr/hzOfRghtj8shRZkQqEYCqzelM5I8gVV//SJfZMn0aridDgyEoqakcZmorIgRNZlV5I20SUfTL/uZWD/n0Zgmz6/i/TTCNMnFxOb9R/CjdbukA6Ne2Invwt1r3sX8b/0NWw8mLylXOdIfwnWPvor+UFSGxJ95pzXDvUYfihGbUE/YmfJAliihGqudmg2qGEnljIgv6I547F6c9ETIZsn0qqRVOAJ1wVdjqx+a1wBAr5zQNA13/GErPvbAehlPj8Y0pbus/tru+cR8/OLaxbJ6QZCqmgYwrHL1JCL+r+bnqIgrvVR2Z2WRVzpY+cgZEVeJmXotiJPahBJf2u6yKmrPC6fTYVogvS4nPnJyo/z93Nl1ePc7F2Ll+cdLwWe1qq383xuHcLBrEBVFHiyaWiVP+t2D4YTR86rgPa62BNNrihGKxPDcu0YVj3BixAl9T4dR1SMWF3FC7x5MXk3TF4zI92pqSjGiHwPhdmmaeSF/t6XXNPhPhBPFgul1OU2fe5E3AuhJs188b2bCcwoxoiYht/UMxfvXxJ0RKUYSJ3Sr9AUjspqlssiblZOSLQNK1ZeaRybeM2uYRjojGcI0wUhULrg1ijMykooaEaKpLvYlJKybwzSJOSORaMxo+BjwmFxgwBAjMyYUS/GshmpE5U5dqSFGALXXSFyM9BgXEdIZsVxE9CnvncwZyZDAeucf3sZ312zHn97UKxzVfRNC6IXt7QhHNZnvlo7HNu7H+0cGMaW6CKs/ovez+ts7LaMyWDMXKEZsItswDWAksQK5J7AC5hBKKkFR5DMnUc2fVC6/mACw7ITUIRrAvOALKxsAzjuhDl63E+919OMrv30Tv9iwD5v2HcHfd+gD/VRrUZwQG8oDpmREgbq4lxcld0ZEuKW9N4gX4kMDRazfingvdsXFSH2ZX/YgAHQrXTxPLqPsU4VpRKJjqgFaApkzUuaTi0+mBFbhCIkFvFERI+efWJeQ0yPyhoRwTBemiURj+MHanQCAG86ajhKfG+UBj6wE6ewPGla532PKK3I4HLhoXj0AszsmxM+JE8tka36RuyEeS/R4OdIfSlpNI1yRqmJvgjgVJAtrqs6KepUZjBiLltpjRG0iqH6W7v7YSUldTVHeC5grvXqGjOZcIswoxUVPEDtbe/HJn2ww9eYRwszndiLgdZm2HylyurQlgVWKEZ/qjLhljkMmZ0S8d26nwzTSYSTzaYS4mKDkUbX2CjFilD7XlArBbx50KSj1u+V5RjgjosdIU1WRnOmlXqAk6ycDGDloUoz0igsCX8LfBCJc5HM7ZQ5cukF5mqbJfXlhRzt2tfVJcSoeX9M0edGYquuryrPbdBfkhrOm45L5E+H3OPH+kUFTErkdUIzYREWWYRpAP2EbVyu5h2nU50pW1gskJsZOriqW4QwAOHd2rfUuJlQru6nKWAhLfG6cHRcW/xsfEAYAr8Vj9+KEIOLU6VD/njJMEz9x/PqVfQhFYzh5coWp/4SKyBkRJ/zGyoDJ7tedEaNPS7ZXDoMpwjRCpGVyIURIQnVGMooRi5WsipEVi5qS3gfQ21sD6cXI718/iL2dA6gq9uLqpVMB6OFDubj0hZK2ghdcNFd3x57f3iaTlY322gGc3KQv8K/Hq1TE8Zhao+/b/sPmrpjdg2EMhCKy1HiqIpqtJPu+qMnA1hJc4YgYTbvMIm5OQxluu3A2/vPy+QnJ5YKmqiJ8dfksfHX5LFz7gakA9KtrEW4JeFzyO18rwzRDuO/ZnXj5vcP48Qu75WN1JTgp2TVKywZTB1altFeEgtVzgp7AKnJG0jsjMvHXIuSM+TS577sxwM/oXCscC9UZmaAkVhulv0b3ao/LqQxQNDsjk6uKMGOCLkaE+xCJxqQQUvvJAIm9RsQ+1pX5U+aMWMt6xX4ByWfTdPaH5HH6+86OhM6+zV1DaO8NynNOpkT09t6gFP3nza5DwOvCB47Tz89/e9veUA3FiE1Umqpp0h8Gt8uJ0+P9RtQywmxRhUKJL/kVpLXcd3JVEZafqF/Rzm0sQ1NV6hM+YH49ky3bXhwP1QDGwiHFiOi+6nObTlzJUEWbdfKxWIRbuocQjERlTP+aM6alfDxryKq+zI+ZtUYyYpVS2huNZdc5FUjtjAgX4lDXYNomV2rOiFVkpcLa80L0pJhcZVQ1JUOGaQ4nF0ihSAw/jJe8fu6s6abPiVpRk6z7quDEiWWYUl2EYCSG5+P9ctRZHwssI9lFzsiUuDMiFoZSn5F82NI9ZFTSpAjRAMmdEfW9tCZWi4Wn01KJJXA4HLjxnBn4+MJJKZ8TAG764HG46YPHyQWsrXdICdEY75EQF/sOD8i4/aZ9Rsv5LuWqHzBaz+clZ0QRzapoK5bOiCVMExDVNOmdkU4p5MznqlyHRTZ3D+LOP2zF3o5+izNidkHlZ6/ISGANRWIyVKSW9QKGQO0LRqBpmkmMCGdEfOZ0UaO7PNWWz4JVcLQpjqb6N/UiJtlYDbVTsKZpeH3/ESmw1CnZ7b1B/P51vVuxN+5sHuoaNM2LyuSMPP9uGzQNmNdYLi90LjhRd72f2ZY6r28soBixieoSH46rLcHs+tKEuRDJuOuj8/CTTy/E2cendyiSoV6tpnJGrFfxU6qLsHRGNX553WL8+NOLsngO44s6ySJGls2pw/F1JTjjuGr87DOnAgDePtiNwVBUltdl8x743U4ZGrAuEiLTfdO+I7jhF5vQ0RdEfZkfF82tT/l41veitswnT0aAfjXq97hk/ky2eSOpckYmlPrgczsR09KHatrjdq8pgbUncfiXiux5Ed9+zsQy/PyaU/HL6xanLMcGIEVmW28w6ZXZL1/eh/2HB1BT4sOnl04x/U1a4r3BpJU0AofDId0REaoRCbNNVQGcHHeu3jjQZUqEFWEasXhNKFNyaLqHsK1Zt5XF1Wwy1EVWLCYt3friEY1p2N6iixFjdopwRswNz4aLsXAGje6rymOKq/wuZQJwz1BEWvNGX5Lsq28AfSFP1nBLZTClM6L/v9iawCrDNMlF+d6Ofqzf1SEraWosrlIuk3s1TcOt//MGHt2wD9/967uKM6KEaZI4I2oyrriPWkkDqJWD0XhjshicDl1cGGGaftNz1Jb6Er5HRuOzIYQiMfm6akv9mBifgdMfippybKxlvYA5TLNxz2F85Efr8dXfvgEACa3pX463HTj9OP3i9FD3oGlQZHMGZ0SEaM47wVhHzptdC6cD2HqwZ1TmWWULxYhNuJwOrLnlTPzpCx9Iu1gIakv9uODEepn9nAtmZyRFaa9FDEyOOxhnzpxgsvxT4XU75clnRo15cSjxufG3L5+NX123BNNrilFX5kMkpuGN97uUIXmZc2HcLif+/SNz8a1LT0xISj1lciU+NK8ekZiGF+L5KFedPiVpTxWBtbKovsyPmXXGvov3rSJgDudkIlWYxuFwyMV/fwonIhKNGYtvqU/2oQhFYimff+22VvmaGyoMK/mDs2qlu5CKyiKjU6nV4j3SH8J/Pat34b31guMTW4YrC3iyIXkqH4rnjTz3bhsGQhGTMzKzrgQupwM9QxEZt3Y5HQnVVLVKYuDBrkG8skfPrVBzqqyozsjyuDAVV497OvoxFI6hyOuSgkiUnRqhhtydSBV1orS1kgZAQhNBYQ4K59B6n4YK4WQZx+r5d9vwo3W7pJvy6t7DOOPu5/CtP76Tdt9knxGveVBeqgRWGaZJ4Yxc+8ir+NRPX5FOmvWCobokezHyt3da5YTkF3d0yERQXYzE3aG+IKIxTeZzie9po8XtU3uMAFByRiLye9hQHoDX7cT0uLDt6AuieyAsRX6tJUQDmBNYRWjV43KgskgXReL1q5Omkzkj4ns1FI7KEMqrew+bckG8lvPYefEcvkNdQ6bHb+0NyrykP2w5KEOf4vH/vlOvKlNzAKtLfFg0pQpFXpcU53ZAMWIjbpdTthceTbKppkmV35ALP/jkybjn8vlSyFhxOBxwOBxYNEVfPDbtO2IMyUtTqaOy4tTJuPr0qQm3O50O3P+pU/CTTy9EU1UAkyoDuOLUyWkfy9rHpL7cHKYRV6O5dGGNxjSZ35AsMbkpQ/WKPtVXz6GpLvbB53ZJW/9Qd+JVy3+seRfXPfoaugfDOHFiGc5L0wsmGQ6HQ6moMT/+fc/uQM9QBLPrS/GJJHknwhnp7DOcEWv4TDCvUU+IHgxH8Ycth+RVq96t0oXp8VDLK/HkzfKAJyHpdkKpXzo/L+3qQEdfCH6PE/ObypEKIXLLAx4Z6hQLjAjRzK4vlaJP9KfoTJEzkivCyegPRaWAUJ1Kr9spj6/L6cAnT9Xf59f2mvNnxH1kGCHunGiahq/+7g18d812vLBTF6RPvX4QMQ14bptRvZQM2YHV0qVZLI6q+CwzlfYmOiOdfUG8Fw+bia641cXWME12pb1D4Sj+/c/b5O99wQhejIvtCaU+VBd74XTo37W2XqMVgXDlpscvht6LuxtCYIrPZrHS4FEN0QD6hZNIAt/V3icdqPokYkSt9hIhwwklPhluFkMT31LKbZPljKjOiNjnIwNhtPYE5f5dfJIR6va6nDgr3mahuXsQezuMc4l4T94+1I1bHt+Cm369Wf5tw+5ODIajaCj3y4ovwT2fmI/Nt5+ftpfUaEMxUgBUZFNNo5yM9Am3uZ+ETz+uBh/LEEsHjF4Nm/YdkZUDqaohcsHhcOCCE+vx9/93Ll746gcTFjMrVmFWW+rHcbUlOHNmTTzL3FjIgOycETXUkSxfYXIGZ0TEnatLfNIFE/kfd//lXdOo9G3NPXhgnZ7seO0Z0/Dkv5w+rGoro6LG2Kfd7X34VXyA3R2XzEnqyKlllOnCNIB+bD56sv7ZuP95/cpZVOUAwKx6/TWKz0NFwJPQSG9CiU8uACLZbuGUSlNnXisBj36MT55cIe8rnBGRvDpnYpnMNRAL1+EUOSO5UuwzOv2qzfRURB7IOcdPwAXxPK1N+3Q7XoR2hBM4I1551N6rX7m39wZlaOnZd/ROx8Ila+kZSptbYjgj7qxKe0vTND0Twq7U55ahVJEPI0jV9MzaOv/n/9iL/YcHUFfmw6XzJwKAnKtVU+KD2+WUx2tnq1H1Ij5L0+LvkRBFYhuRnC5eV5/ijKgXXyLst7utTwpXERpSKfUb5c7C0VAdlJMm6SL5rfcVMSJcGjVMo0ztVat4tjX3yIZsH5xda+SD1ZegsSIApwNJG/kd6hrC2wf143Go2/gMiOaV551Qm5Cf11RVlLGQYrShGCkA1BNqqpwRj8sprcDJ1cUZk0lHghAjG3Z34mcv6TNTropXaeSLbMJZxV4X1JdZX653VfzldUvwwytOlreX59ASXp0vkaw6SIRpUiWMtis9RgTfvPREBDwu/H1nB7731+3y9sfiYuFD8+pxxyVz0i7K6RDOiFpR88c3DiEa03D28RNw+ozkCbBicWnLkDMi+OgpjabnmVQZkJ+z2XExIhyB8iIPAh6XyZ6eUOpDfTwWL97n06ZVp31tCyZXwOEAPjS3Qd63rXcIsZgmKxNOaCiT4ltctXdauq+OBOG6bG8RYsT8Hp0Yn4D8z6dNwSnxyqK9nQPoUBKDxX1K/R65KO1q7zWVYz67rRW72/tMx3GrpfpCxWjO54TP7ZSD8YpSJbDKdvCJlWViSvFZsybgF9cuxscXTjL1tgGMtvpD4Zh0RN98vwvn3bMOX/mfN+R2T8ar7m49fxYuWzDR9BhC4IhQzY64wCvxuaXLLFy29zr0hX1nm76NEPWyHXwoIvdblJcDZvdJ9hgpT3RGACOJ9b/ipe+1igATYuQNRYz0ymTaRPEHGN2AAWBbSw/2xc8TU6qKcGbcDZnTUAa3yynfA6Ofkn58mrsH5fuiPuam+LTpdAntdkIxUgAElCTMVGIEMBT65KrMOSIjYc7EMgQ8LgyGo4hpwKXzJ+L8OWNvDzocDpNTlOzqBzC+5NbOoMlQkwKTCTopRlKU0oqTSINy8juhoQz/8fGTAAAPvrAbf3mrGf3BiMysv3LJlMQHyoFkAmn9Lt2hEBVVyZjdYAgIkUSXTow0VRXhtOlGfsckpTnerHp9QRaWe0XAA4fDYeonU1vqM70vAORU61RcOn8itn5zOT5xahNqS31wxK8mO/qC2BKf8bGgqUJWfojYv0xgHWGYBjCaZYkrdatj9+3L5uKvXzoLH5xdi/Iij5xBs2nfEZkzok5CFnlNu9r68K4S42/tCcp8DcHbaTpyGqW9eiWbCF/I0l5r07P4sQ1HjQng8nmEy9RQhtOPq8F/Xj4/oS9Hsdc4DwnRt257O2Ka3kNDNCcTIagPzq7FGcfVmKoNhUgXTsZvNu6X+ycQwmJPPOSxI+6MiPdNiJG+oQg27tEdqCXTjc/RjFrDGZHdV0uTi5G5jbrgCEVicDkdWKacx0TTxh2tvVL4JQvTqI6EOkRw874ueXEypboItyybiY8vnIR/Oec4AEjo/Ctyp5q7hrCjzeywDIai8txibSZ5tJB70woy7nA49BbhLT1DKUt7Af1k0T0Yzpj0OFI8Lj3O//J7h1FT4sU3Lz1xVJ8vHWV+D3qHIij1u5P2pACMBelgEgHxg7U78ej6vYhqGtxOJ+bHr4ZShUtESCSVM/LXt/Vqk7NnmZu+XTp/It480IWfvrQHt/72DXxq8WT0BSOYWl2EpdPTL8iZsDojA6EIXj+gOxRnHJf6sec0lOHEiWV4+1CPHN6VrM+IysdOmSQrAtQEVeGMCERYorLIYyp1Vq1/v8eZ1YlVLD4elxMTSnxo6w3ixZ0d6A1GUOR1YVZdqbTPO/uCiERj8op4QknyRSgXhMiNKp1UVUp8bhmmAoCFU6qwo7UPm/YdSaimAfQwwt93dmBXW19CmewfthwCoCdXHuwaxNaDqRMS1XbwgO6E9AYjRmlv/Pvgchqi3ekAYpoeqlEXUeEyWXMRVBwOvTy2uXsInf0hNFUVyQTLwXAU21t70TMYgabp+y+O9QeOm4Bnt7XC63LKJmo3njMDa95ukVUvJjESzxk51D2E5u5B+fkRbeTF6xNJsSU+N+Yq+y1CYbva+6QzZxVWgjsvmYNL509EXZkfk6uKTN/7hnI/akq86OgL4Z3mHpwyuTJpAqvL6YDP7UwQeH+P5wCV+d2oKPKiosiL/7x8vunxBfVlfukIHeoexE6LM/JOczeiMQ01JYmC/miBzkiBcN0HpuHs4ydI6zAZ4ouUqadIPrhi8WRMKPXhex+fP+K4/EgQJ1lrQyOV+fEFb3N8wRW8sKMd9z6zA539IXQNhNHRF8TaeMvzVF11RUO4w/2hhL4lLd1D8jmSORJfu2g2lk6vxkAoip/Gw1tXLJ6cVTVWOiZZckY27jmMcFRDY0UgbSKzw+HAp5aYk4RTVdMIPjSvQV5xq2JkUmXA5FKJxUV1BCZYnJFFU6rklXa2iPs//VYzAN0V0XMQjMqgPR39CEX0KhtrRc9wsH62Mgm2RfEw5pOb35c5BGr1mLjC39nWh3fj5c0XWj4vnz9nBgBz8qQVtZoGMBI7rb+X+d0y+bxUCdUI+oMR6fqo3WeTIT5PWw926z01lJlEr+/vwpvxGT7qeer8OXoZak2J0URtbmM5PnfWdLmNdVK0eI9FblFjhfH5KrLkzZ06tdJUSCDCNAcOD8hS11Suaanfg7OOn4BZ9aVJq+eEWH4z/jqtPU8E6n3F8wtxkuriUK1ynFJdJD/bO1v7TP1GtjX34s14qGj+pPJRDcGPBIqRAuH6s6bj0WsXp01SaowvSumubvLFZQsa8eq/LsMHM3R2HW3EFUqybHmByHHZ3tIjY76dfUF8Jd4L4IrFTXh25dl47LNL8KF59XA6jMmtic9nJGZa3ZG/vaO7IqdMrkgqjtwuJ/77UyfLnipelzNj861sEG5NR18Ig6GoLKk847jqjCeuS+dPTLDz01Hsc+Mzp0+F1+XEmTMN98fhcMjwBGAs2OWWBmHlAY+07TOFaJIhrnDFVecpk/VjW63M2hHJiCc0lI1Y6AGJiZxWZ8TKmTNrUOp3o6MvJK+k1TyT4+IJlttbemVI48ZzZsicj8aKgEz8PNg1KGf+xGIafvnyPnzyJxvw9qHuhOZ8IkdEhGnEe6VenJQmmU8j5vvUWpyrZIgxDy/saMfezgFTUvjr+7vwhhQjFfL2i0+aiHNn1+KzZ05XHwpfPG+mdDGsnzvhEginUS3Zt873sn6OJpT4UOp3I6YZoax0FyvpmBcP47wZF4VyYF/ALIjUbrenTa8yXaCluiBQwzRTq4tl2bcIPYnjuru9T+ZiHa0hGoBihCjcc/l8PHb9EnmCLgRERU1tiisfQD8RTaoMIKYZWfOrnnwL7b1BHFdbgjsvORHH1Zbg9ONq8KMrF2LLnRfgR1eekvLxJqdIYl2zVT9xigZhyagu8eHBTy9EQ7kf135gWkKXy+FQFnDLhLoXdrTJCbdnZJHoVur3mJIMUw0lVPnq8lnY9p0LTaEJwMgbAYwyTLXstapIvzKeVV8GhwNyzEAuNMSTWMNRPWQihGZFwCOTnsXrF6WZI8W6kGUSI7Vlfrz0/87F9z5+EpadUIvLF04yNeMT/2/uHpIOzrzGcjnd+5xZE1Ae8MjZUlsPdeNg1yA+/fAruP2prXj5vcP4wdqdCf1w6ssC8X/98nkevXaxKZlbJrEqydzvZBGiEYhjtn5XBzbG+8SIUMjrB47gjQPxK3ilXLvE58bDnzkV137A3E3Z73Hhvz55MhY0VeDyRWZRPi0eqnklvjCL5FUgcUTAaZYwp8PhML3fRV5X2iGh6RAOj3AmxPtmbSugOiMzJpTghAZjf1O1SlBdwik1RbLRmmiet2hqJcoDHkRiGp6JNzs7KU0ZvN0wZ4RIrDH5QkCcFNI5I4C+aL1/ZBCb9h3BhFIf/vZOK9xOB/7rkwsS3CarBWtlUlUR3ni/21Tee7g/JE+c6ZJGAf3qZsOq89JukwsOhwNXLJ6MH7/4HlY9+Ra64ifMbJ2HKxZPxm82HoDDkbrPiPX5XEkMB/UELESN+LemxCtdiv++4mQ0dw/J5MFcsMb+T463ohezdtp7g3hJiJE8OYQJYZrizO9ReZEHly9qwuVJ+rtUl/hQVeyV5cfH15XC6XTgKxfMwg+f24nr4w7C3MZy7OscwHPvtuFr//sWDnYNwuNyIBzV8Hx8iCRgXEF/+7IT8ZGTG2U/FiBR8IkrerXXyNtKiXQm5jToZdQdfUFZSfdP8xvw5OaDsseGw2E4CpmY21iOp246I+F2kcQq8nRmKuLC69YrB0PRGEp97qSi87gJJTIPqr7MP+zQxry4GNnd3oe+YEQ6SunCNNMnlOCEI4P4RzyJfEoWzsiUqmJTw0NA/1yEIjG8suew7H00n84IIUcnp03X8w5Sla8KFim9UX73ml56eN4JtRlj5MlINin3mXdaEI1pmNNQlvJKaDRZecHxmF1fiiMDYWgacHxdiex/kYmTJlXg6x+ajTv/aU7WzeuSMUu5ehXhGWG/qyK5qaoo5ZC6TKiic8aEYpOTU21pCZ8/Z8TYd7fTkdD5dzgcp7TAFyJu8bQq/PK6JXJWz9z4Z/Pn/9iLg12DmFZTjL9+6SzUl/lNgweFGJlYEcDFJzWkDU2Jz4TofgsYYiSb74LT6cBZx+vfNVHlcu7sWtOwwxkTShKcg1yZbplXpDojgBGSWjytKmnjyRmKeEnnmmaittSPhnI/NE3Pk+m1tKaX++Mxfp9eU4zZymcv1fnAmjNSXew15VAdX1eCE5THmVQZsDU/LxMUI6SguXLJFLz9reX4wMz0YkSMjn99fxee2qKX1F6+MPU03HRYwzR7Ovrx3TV6/xDRNn2s8bld+MEVJ8veKJnEmZUbzpqBz6QZSpgNs5OEaUTfBmFBjxTVGREhGoEqeJwOJISRhosq6iqKvHlJIDxOyYGYVZd8P1V3obrYi0euORXTJ5Rg2RwjT8vnduaUF3PFYj1h+YlXD+BgfOCj6J+Sba6Z1W05eXIlTlZCw+mS7LNlumVekRp2AYzkXGuIRm6v3D+Ta5oJ4UY8926bDA9aE72FM+JzO9FYETCHaVI4IxVFHkyfUIzqYi9mTCiBw+EwhW5m1pWaBPXR7IoADNMQknZ+jWB2fRmKvS70BSPoC+phA2v5bbaIipo33u/Gb187gB88txOd/SGcOLFsxAv6SDi+rhTfu3w+fvLibvzzaelb6Y8G5UUezGkow672PllB8KF5DThwZNA0+XkkNKQRI2qDsxkTSvLWkTLgdaHM70bPUCSh4dlwURdLNddGZV5jOQIeF2KahoeuXiTf02Un1Mmp1rl27F06oxqnTa/Cy+8dxv3P70LA40IoGkN5wCMdv0ycNXMCHA7IpNeJ5X6cPLlC9s3Jx6I5pbpIPsekykCCYzejtgStPUMpE+hVZ2S4yauCi+bVY83bLbInitORmEQr3KlpNcVwOh2YWVuKpqoAPE6nzHOy4nA48OcvnIlwLCaPY0O5X86zmVlbAo/TOLfNy4PIG00oRgjJApfTgZMnV8p8go+c3JiViEnGrPpSuJ0OdPQF8dXfvQlAv/p55JrFw06UyxeXzp8oKzHs4PHPnYb+YETaycU+N1aef3zeHr+uzC8XKWuitpoMnK98EUFtmR89Q30Zk1ezRb3St/ZoEZQXefD7m06H1+U0OQVLZ1Sj2OtCfyhqquLIli8vOx4rfvKy7AAMAN+4+ISsHZbKYi/mT6rAlgNdOHlyBRwOBxbEBxUCwHzl/8PF73GhsSKA948MJoRoAODH/7wQHX3BlG0MmioDMq9kpGJk+Yn1qCjyyMqhUr8nwR0TFWki18XrduLZlWcDSN9NOuB1IQDjGAoHcWK5H6V+jxxCGY1peXGcRhOGaQjJEvVKOlliYbbUlvrx9C1n4qYPzsDM2hJMrynGL65dXHDJw8ko83tSXgnmA7/HhVvPPx43nDU9wbqvUcVInvJFBCJvJFOPkWyZ11iOIq8Ls+tL085gml1flhCy8Lld0tXzD2OW0ZLp1aZmeN++7MScvw8r4gMBLz5JF74nNJRhanURmqrMIYqRIGbRqGW9goDXlbafktvllPdP1fAsW/wel6k1vrWsFzAStVXh5HO7ch7xIJJYRYM3v8eFz501HefPqZMDSo9WhiVG7r//fkydOhV+vx9LlizBxo0b027/29/+FrNnz4bf78e8efPw9NNPD2tnCbETcQJfPLUq6dVWLhxfV4qvLp+NZ1aejee+co5MOiSjz83nzsTXP3RCwtWp2vo9386IaCeerwTCymIvXvjqB/G/N54+rPuL8QvDHVD5jYvnYHZ9Kb5z2YnDmiv1yVOb8OY3L5AunMflxJ+/eCbW3HLWsGcsWblsQSPqynxpS+XT8ZXls/DxhZNwzjDDsSqfVCaIlybpgv3ZM6dh5fnHj3hG13kn1KG+zC/nQAHA/7twNh66alHODQLHmpw94SeeeAIrV67Egw8+iCVLluC+++7D8uXLsX37dtTWJsbf1q9fjyuuuAKrV6/GP/3TP+Gxxx7Dhz/8YWzevBlz587Ny4sgZCw4ZXIl/njzB2TOBzm2qFHEyAl5dkZEwmk+Ry2MxEn7p5MmYk97f1a9ZJJxQkMZ1nzprGE/v8PhSChvHUklVjI+vnDSiJoCnj+nLm8zs2bVl+LkyRV4fX9XUmdkYkUAXzxv5oif55TJlXj56/kr+x9LHJp1/GIGlixZglNPPRX//d//DQCIxWJoamrCF77wBXzta19L2H7FihXo7+/Hn/70J3nbaaedhgULFuDBBx/M6jl7enpQXl6O7u5ulJWNfndQQkjhsaO1Fxd8/0U0VgTwj6+dm9fHHgpH8fJ7nThterXto9qJPfxhy0Hc8vgW/PNpk/FvH55n9+6MGdmu3zlJ0VAohE2bNmHVqlXyNqfTiWXLlmHDhg1J77NhwwasXLnSdNvy5cvx1FNPpXyeYDCIYDAof+/pST3siRBC8sHxdaW45/L5pkqKfOH3uHDOLHtHHxB7uWxBI6bVFCfk8BCdnIJIHR0diEajqKszW1d1dXVoaWlJep+WlpactgeA1atXo7y8XP40NQ0/WZAQQrLlYwsnmSo7CMknJ02qsL1i7mjlqMxoWbVqFbq7u+XPgQMH7N4lQgghhIwSOUm0mpoauFwutLa2mm5vbW1FfX3yzpH19fU5bQ8APp8PPh/LHAkhhJBCICdnxOv1YuHChVi7dq28LRaLYe3atVi6dGnS+yxdutS0PQA888wzKbcnhBBCSGGRc/Bq5cqVuPrqq7Fo0SIsXrwY9913H/r7+3HNNdcAAK666io0NjZi9erVAIBbbrkFZ599Nu655x5cfPHFePzxx/Haa6/hJz/5SX5fCSGEEELGJTmLkRUrVqC9vR133HEHWlpasGDBAqxZs0Ymqe7fvx9OpR/+6aefjsceewzf+MY38PWvfx0zZ87EU089xR4jhBBCCAEwjD4jdsA+I4QQQsj4I9v1+6ispiGEEEJI4UAxQgghhBBboRghhBBCiK1QjBBCCCHEVihGCCGEEGIrFCOEEEIIsRWKEUIIIYTYyrgYHyhaofT09Ni8J4QQQgjJFrFuZ2ppNi7ESG9vLwCgqanJ5j0hhBBCSK709vaivLw85d/HRQfWWCyGQ4cOobS0FA6HI2+P29PTg6amJhw4cOCY7ezK1zj+OdZfH8DXeCxwrL8+4Nh/jaPx+jRNQ29vLyZOnGgaFWNlXDgjTqcTkyZNGrXHLysrOyY/WCp8jeOfY/31AXyNxwLH+usDjv3XmO/Xl84RETCBlRBCCCG2QjFCCCGEEFspaDHi8/lw5513wufz2b0rowZf4/jnWH99AF/jscCx/vqAY/812vn6xkUCKyGEEEKOXQraGSGEEEKI/VCMEEIIIcRWKEYIIYQQYisUI4QQQgixlYIWI/fffz+mTp0Kv9+PJUuWYOPGjXbv0rBYvXo1Tj31VJSWlqK2thYf/vCHsX37dtM255xzDhwOh+nn85//vE17nDvf/OY3E/Z/9uzZ8u9DQ0O46aabUF1djZKSEnzsYx9Da2urjXucO1OnTk14jQ6HAzfddBOA8XcMX3zxRVxyySWYOHEiHA4HnnrqKdPfNU3DHXfcgYaGBgQCASxbtgw7d+40bXP48GFceeWVKCsrQ0VFBa677jr09fWN4atIT7rXGA6Hcdttt2HevHkoLi7GxIkTcdVVV+HQoUOmx0h23O++++4xfiWpyXQcP/OZzyTs/4UXXmja5mg+jpleX7LvpMPhwPe+9z25zdF8DLNZH7I5f+7fvx8XX3wxioqKUFtbi69+9auIRCJ528+CFSNPPPEEVq5ciTvvvBObN2/G/PnzsXz5crS1tdm9aznzwgsv4KabbsLLL7+MZ555BuFwGBdccAH6+/tN211//fVobm6WP9/97ndt2uPhceKJJ5r2/6WXXpJ/+/KXv4w//vGP+O1vf4sXXngBhw4dwkc/+lEb9zZ3Xn31VdPre+aZZwAAl19+udxmPB3D/v5+zJ8/H/fff3/Sv3/3u9/FD37wAzz44IN45ZVXUFxcjOXLl2NoaEhuc+WVV+Ltt9/GM888gz/96U948cUXccMNN4zVS8hIutc4MDCAzZs34/bbb8fmzZvx5JNPYvv27bj00ksTtv32t79tOq5f+MIXxmL3syLTcQSACy+80LT/v/nNb0x/P5qPY6bXp76u5uZmPPzww3A4HPjYxz5m2u5oPYbZrA+Zzp/RaBQXX3wxQqEQ1q9fj0cffRSPPPII7rjjjvztqFagLF68WLvpppvk79FoVJs4caK2evVqG/cqP7S1tWkAtBdeeEHedvbZZ2u33HKLfTs1Qu68805t/vz5Sf/W1dWleTwe7be//a28bdu2bRoAbcOGDWO0h/nnlltu0WbMmKHFYjFN08b3MQSg/f73v5e/x2Ixrb6+Xvve974nb+vq6tJ8Pp/2m9/8RtM0TXvnnXc0ANqrr74qt/nLX/6iORwO7eDBg2O279lifY3J2LhxowZA27dvn7xtypQp2ve///3R3bk8kew1Xn311dpll12W8j7j6Thmcwwvu+wy7dxzzzXdNp6OoXV9yOb8+fTTT2tOp1NraWmR2zzwwANaWVmZFgwG87JfBemMhEIhbNq0CcuWLZO3OZ1OLFu2DBs2bLBxz/JDd3c3AKCqqsp0+69//WvU1NRg7ty5WLVqFQYGBuzYvWGzc+dOTJw4EdOnT8eVV16J/fv3AwA2bdqEcDhsOp6zZ8/G5MmTx+3xDIVC+NWvfoVrr73WNBxyvB9DwZ49e9DS0mI6ZuXl5ViyZIk8Zhs2bEBFRQUWLVokt1m2bBmcTideeeWVMd/nfNDd3Q2Hw4GKigrT7XfffTeqq6tx8skn43vf+15e7e+xYN26daitrcWsWbNw4403orOzU/7tWDqOra2t+POf/4zrrrsu4W/j5Rha14dszp8bNmzAvHnzUFdXJ7dZvnw5enp68Pbbb+dlv8bFoLx809HRgWg0anpjAaCurg7vvvuuTXuVH2KxGL70pS/hjDPOwNy5c+Xtn/rUpzBlyhRMnDgRb775Jm677TZs374dTz75pI17mz1LlizBI488glmzZqG5uRnf+ta3cOaZZ2Lr1q1oaWmB1+tNOMHX1dWhpaXFnh0eIU899RS6urrwmc98Rt423o+hijguyb6D4m8tLS2ora01/d3tdqOqqmpcHtehoSHcdtttuOKKK0xDyL74xS/ilFNOQVVVFdavX49Vq1ahubkZ9957r417mz0XXnghPvrRj2LatGnYvXs3vv71r+Oiiy7Chg0b4HK5jqnj+Oijj6K0tDQhBDxejmGy9SGb82dLS0vS76r4Wz4oSDFyLHPTTTdh69atpnwKAKb47Lx589DQ0IDzzjsPu3fvxowZM8Z6N3Pmoosukv8/6aSTsGTJEkyZMgX/8z//g0AgYOOejQ4/+9nPcNFFF2HixInytvF+DAuZcDiMT3ziE9A0DQ888IDpbytXrpT/P+mkk+D1evG5z30Oq1evHhdtxz/5yU/K/8+bNw8nnXQSZsyYgXXr1uG8886zcc/yz8MPP4wrr7wSfr/fdPt4OYap1oejgYIM09TU1MDlciVkC7e2tqK+vt6mvRo5N998M/70pz/h+eefx6RJk9Juu2TJEgDArl27xmLX8k5FRQWOP/547Nq1C/X19QiFQujq6jJtM16P5759+/Dss8/is5/9bNrtxvMxFMcl3Xewvr4+IaE8Eong8OHD4+q4CiGyb98+PPPMMxlHsy9ZsgSRSAR79+4dmx3MM9OnT0dNTY38XB4rx/Hvf/87tm/fnvF7CRydxzDV+pDN+bO+vj7pd1X8LR8UpBjxer1YuHAh1q5dK2+LxWJYu3Ytli5dauOeDQ9N03DzzTfj97//PZ577jlMmzYt4322bNkCAGhoaBjlvRsd+vr6sHv3bjQ0NGDhwoXweDym47l9+3bs379/XB7Pn//856itrcXFF1+cdrvxfAynTZuG+vp60zHr6enBK6+8Io/Z0qVL0dXVhU2bNsltnnvuOcRiMSnEjnaEENm5cyeeffZZVFdXZ7zPli1b4HQ6E0Ib44X3338fnZ2d8nN5LBxHQHcrFy5ciPnz52fc9mg6hpnWh2zOn0uXLsVbb71lEpVCWM+ZMydvO1qQPP7445rP59MeeeQR7Z133tFuuOEGraKiwpQtPF648cYbtfLycm3dunVac3Oz/BkYGNA0TdN27dqlffvb39Zee+01bc+ePdof/vAHbfr06dpZZ51l855nz6233qqtW7dO27Nnj/aPf/xDW7ZsmVZTU6O1tbVpmqZpn//857XJkydrzz33nPbaa69pS5cu1ZYuXWrzXudONBrVJk+erN12222m28fjMezt7dVef/117fXXX9cAaPfee6/2+uuvy0qSu+++W6uoqND+8Ic/aG+++aZ22WWXadOmTdMGBwflY1x44YXaySefrL3yyivaSy+9pM2cOVO74oor7HpJCaR7jaFQSLv00ku1SZMmaVu2bDF9N0UFwvr167Xvf//72pYtW7Tdu3drv/rVr7QJEyZoV111lc2vzCDda+zt7dW+8pWvaBs2bND27NmjPfvss9opp5yizZw5UxsaGpKPcTQfx0yfU03TtO7ubq2oqEh74IEHEu5/tB/DTOuDpmU+f0YiEW3u3LnaBRdcoG3ZskVbs2aNNmHCBG3VqlV528+CFSOapmk//OEPtcmTJ2ter1dbvHix9vLLL9u9S8MCQNKfn//855qmadr+/fu1s846S6uqqtJ8Pp923HHHaV/96le17u5ue3c8B1asWKE1NDRoXq9Xa2xs1FasWKHt2rVL/n1wcFD7l3/5F62yslIrKirSPvKRj2jNzc027vHw+Otf/6oB0LZv3266fTwew+effz7p5/Lqq6/WNE0v77399tu1uro6zefzaeedd17C6+7s7NSuuOIKraSkRCsrK9OuueYarbe314ZXk5x0r3HPnj0pv5vPP/+8pmmatmnTJm3JkiVaeXm55vf7tRNOOEG76667TAu53aR7jQMDA9oFF1ygTZgwQfN4PNqUKVO066+/PuGi7mg+jpk+p5qmaT/+8Y+1QCCgdXV1Jdz/aD+GmdYHTcvu/Ll3717toosu0gKBgFZTU6PdeuutWjgcztt+OuI7SwghhBBiCwWZM0IIIYSQoweKEUIIIYTYCsUIIYQQQmyFYoQQQgghtkIxQgghhBBboRghhBBCiK1QjBBCCCHEVihGCCGEEGIrFCOEEEIIsRWKEUIIIYTYCsUIIYQQQmyFYoQQQgghtvL/Ac1DygS7obb0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8303666114807129, 0.43600964546203613, 0.34465500712394714, 0.30144426226615906, 0.4436497092247009, 0.3676455318927765, 0.11724674701690674, 0.28673577308654785, 0.16737131774425507, 0.28297141194343567, 0.20224523544311523, 0.24405409395694733, 0.13285663723945618, 0.12713485956192017, 0.04904010891914368, 0.19551661610603333, 0.13711465895175934, 0.08121583610773087, 0.07394548505544662, 0.05074707791209221, 0.17932824790477753, 0.12693901360034943, 0.08432620018720627, 0.08291278779506683, 0.09800174087285995, 0.10599951446056366, 0.03242930769920349, 0.13310953974723816, 0.10546713322401047, 0.15368838608264923, 0.028705155476927757, 0.06989912688732147, 0.050721798092126846, 0.06941945105791092, 0.16359727084636688, 0.1289345771074295, 0.11828752607107162, 0.04549470916390419, 0.08820825815200806, 0.06611989438533783, 0.04925491660833359, 0.05630623549222946, 0.032085612416267395, 0.040533293038606644, 0.15584562718868256, 0.060621730983257294, 0.15446124970912933, 0.21699008345603943, 0.04769039526581764, 0.12980610132217407, 0.100887730717659, 0.047524090856313705, 0.04415484890341759, 0.05693632364273071, 0.1286316215991974, 0.0650753378868103, 0.1206178143620491, 0.022044168785214424, 0.0758979395031929, 0.04204753041267395, 0.11406958103179932, 0.03355156630277634, 0.009110725484788418, 0.023857368156313896, 0.03169151395559311, 0.03170790150761604, 0.029263874515891075, 0.17074695229530334, 0.12541069090366364, 0.05688037350773811, 0.014206433668732643, 0.012436933815479279, 0.01861269399523735, 0.035910408943891525, 0.09480392932891846, 0.04121290519833565, 0.03415141627192497, 0.027151137590408325, 0.04096074029803276, 0.04498475790023804, 0.09756147116422653, 0.0506516732275486, 0.0650581493973732, 0.07160472869873047, 0.06141504645347595, 0.069512277841568, 0.02545955218374729, 0.017597364261746407, 0.03888898342847824, 0.048697490245103836, 0.0597015917301178, 0.09977268427610397, 0.036863069981336594, 0.022933313623070717, 0.10543686896562576, 0.1336531639099121, 0.06125985458493233, 0.04433223605155945, 0.029370645061135292, 0.07372850179672241, 0.04825564846396446, 0.01672227308154106, 0.09603965282440186, 0.018295466899871826, 0.07706403732299805, 0.02613815665245056, 0.04832237958908081, 0.08662905544042587, 0.06663522869348526, 0.16372600197792053, 0.0391596183180809, 0.06429868191480637, 0.012982883490622044, 0.037741534411907196, 0.06756030023097992, 0.003752105636522174, 0.033532701432704926, 0.10086827725172043, 0.08003858476877213, 0.05504199117422104, 0.06365028768777847, 0.1169484406709671, 0.08412530273199081, 0.05491705983877182, 0.06179056316614151, 0.006561613641679287, 0.08104781061410904, 0.09629814326763153, 0.0387057289481163, 0.053666505962610245, 0.029392320662736893, 0.02754019759595394, 0.10402615368366241, 0.04638773947954178, 0.011875202879309654, 0.04335551708936691, 0.02513568289577961, 0.044757694005966187, 0.016432398930191994, 0.022864433005452156, 0.026623183861374855, 0.008405937813222408, 0.14453408122062683, 0.026065537706017494, 0.15200933814048767, 0.028590073809027672, 0.11264187842607498, 0.021230459213256836, 0.010199887678027153, 0.015955505892634392, 0.04517805576324463, 0.04016535356640816, 0.10597754269838333, 0.09923874586820602, 0.031732238829135895, 0.012013999745249748, 0.037515122443437576, 0.011922555044293404, 0.03863387554883957, 0.0482855960726738, 0.029911527410149574, 0.0909762755036354, 0.035984765738248825, 0.02742845192551613, 0.10912994295358658, 0.04702302813529968, 0.009974670596420765, 0.04314809292554855, 0.13341106474399567, 0.016737712547183037, 0.03890562057495117, 0.08086102455854416, 0.046068187803030014, 0.010589282028377056, 0.06444953382015228, 0.10881904512643814, 0.0835425928235054, 0.036195702850818634, 0.03698550537228584, 0.09374791383743286, 0.0456230603158474, 0.018386846408247948, 0.004197108559310436, 0.09579572826623917, 0.14548704028129578, 0.010978685691952705, 0.04744618386030197, 0.01698784902691841, 0.0580410398542881, 0.03767770528793335, 0.06743896752595901, 0.019326476380228996, 0.05924206227064133, 0.009988154284656048, 0.04308299347758293, 0.01262860931456089, 0.03962831571698189, 0.05804724618792534, 0.06470189243555069, 0.04676413536071777]\n",
      "[71.42857142857143, 89.28571428571429, 88.39285714285714, 90.17857142857143, 86.60714285714286, 89.28571428571429, 97.32142857142857, 91.07142857142857, 93.75, 91.96428571428571, 93.75, 93.75, 94.64285714285714, 96.42857142857143, 97.32142857142857, 93.75, 94.64285714285714, 97.32142857142857, 97.32142857142857, 98.21428571428571, 95.53571428571429, 96.42857142857143, 98.21428571428571, 97.32142857142857, 97.32142857142857, 95.53571428571429, 99.10714285714286, 94.64285714285714, 97.32142857142857, 96.42857142857143, 100.0, 97.32142857142857, 97.32142857142857, 97.32142857142857, 94.64285714285714, 94.64285714285714, 94.64285714285714, 98.21428571428571, 95.53571428571429, 98.21428571428571, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 95.53571428571429, 97.32142857142857, 95.53571428571429, 96.42857142857143, 98.21428571428571, 98.21428571428571, 99.10714285714286, 98.21428571428571, 99.10714285714286, 98.21428571428571, 95.53571428571429, 99.10714285714286, 95.53571428571429, 99.10714285714286, 97.32142857142857, 99.10714285714286, 95.53571428571429, 99.10714285714286, 100.0, 99.10714285714286, 98.21428571428571, 99.10714285714286, 98.21428571428571, 95.53571428571429, 92.85714285714286, 97.32142857142857, 99.10714285714286, 100.0, 99.10714285714286, 98.21428571428571, 96.42857142857143, 99.10714285714286, 98.21428571428571, 98.21428571428571, 98.21428571428571, 98.21428571428571, 97.32142857142857, 97.32142857142857, 98.21428571428571, 98.21428571428571, 97.32142857142857, 96.42857142857143, 99.10714285714286, 100.0, 97.32142857142857, 99.10714285714286, 98.21428571428571, 96.42857142857143, 99.10714285714286, 100.0, 96.42857142857143, 93.75, 96.42857142857143, 97.32142857142857, 99.10714285714286, 99.10714285714286, 99.10714285714286, 100.0, 97.32142857142857, 100.0, 97.32142857142857, 99.10714285714286, 98.21428571428571, 96.42857142857143, 97.32142857142857, 95.53571428571429, 98.21428571428571, 98.21428571428571, 100.0, 99.10714285714286, 97.32142857142857, 100.0, 99.10714285714286, 96.42857142857143, 99.10714285714286, 99.10714285714286, 99.10714285714286, 93.75, 97.32142857142857, 97.32142857142857, 96.42857142857143, 100.0, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 98.21428571428571, 100.0, 96.42857142857143, 97.32142857142857, 100.0, 98.21428571428571, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 100.0, 96.42857142857143, 99.10714285714286, 93.75, 100.0, 96.42857142857143, 99.10714285714286, 100.0, 100.0, 96.42857142857143, 98.21428571428571, 97.32142857142857, 96.42857142857143, 99.10714285714286, 99.10714285714286, 99.10714285714286, 100.0, 98.21428571428571, 98.21428571428571, 98.21428571428571, 97.32142857142857, 99.10714285714286, 98.21428571428571, 96.42857142857143, 97.32142857142857, 100.0, 98.21428571428571, 95.53571428571429, 99.10714285714286, 97.32142857142857, 96.42857142857143, 98.21428571428571, 100.0, 97.32142857142857, 94.64285714285714, 97.32142857142857, 99.10714285714286, 97.32142857142857, 97.32142857142857, 98.21428571428571, 99.10714285714286, 100.0, 96.42857142857143, 97.32142857142857, 100.0, 98.21428571428571, 100.0, 98.21428571428571, 98.21428571428571, 96.42857142857143, 99.10714285714286, 96.42857142857143, 100.0, 97.32142857142857, 100.0, 98.21428571428571, 98.21428571428571, 98.21428571428571, 98.21428571428571]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [0.841748058795929, 0.5383376479148865, 0.37141960859298706, 0.2189747840166092, 0.2170722633600235, 0.2683789134025574, 0.1937561184167862, 0.2995546758174896, 0.13230514526367188, 0.12556131184101105, 0.08791607618331909, 0.13517722487449646, 0.1180429607629776, 0.2700677216053009, 0.23012836277484894, 0.11778731644153595, 0.08971132338047028, 0.0745047926902771, 0.044976893812417984, 0.030214795842766762, 0.14274518191814423, 0.16257527470588684, 0.13489486277103424, 0.22497442364692688, 0.04410076141357422, 0.0439407117664814, 0.0999048724770546, 0.09295899420976639, 0.05333646386861801, 0.042801376432180405, 0.0852958932518959, 0.035196453332901, 0.09896297752857208, 0.09667126089334488, 0.11132311820983887, 0.07094293087720871, 0.11317868530750275, 0.17386971414089203, 0.04825839400291443, 0.1526862233877182, 0.12213451415300369, 0.0335562527179718, 0.14572270214557648, 0.14732243120670319, 0.08901072293519974, 0.10628568381071091, 0.1219853013753891, 0.04227989539504051, 0.1546023041009903, 0.07231778651475906, 0.08872615545988083, 0.06031284108757973, 0.11893129348754883, 0.07610543072223663, 0.05435555428266525, 0.03299633413553238, 0.06796611100435257, 0.09908641129732132, 0.1245361715555191, 0.13339823484420776, 0.044910043478012085, 0.039106521755456924, 0.08405368030071259, 0.03416334092617035, 0.18436889350414276, 0.06167331337928772, 0.05363277718424797, 0.03776988759636879, 0.010305949486792088, 0.08863425254821777, 0.11051689833402634, 0.03690870478749275, 0.021718373522162437, 0.08610344678163528, 0.08286675065755844, 0.05776119977235794, 0.09465332329273224, 0.032651614397764206, 0.07205092906951904, 0.0745658427476883, 0.08170061558485031, 0.10555801540613174, 0.016445361077785492, 0.12694816291332245, 0.11931197345256805, 0.08286337554454803, 0.07604096084833145, 0.04736681655049324, 0.07517056912183762, 0.13407494127750397, 0.02461135759949684, 0.026882896199822426, 0.050736844539642334, 0.03605273738503456, 0.056351643055677414, 0.09767205268144608, 0.07290007919073105, 0.08676333725452423, 0.0794496163725853, 0.04368472844362259, 0.050167299807071686, 0.04737326130270958, 0.05501176789402962, 0.08879045397043228, 0.01769072189927101, 0.11385718733072281, 0.045953329652547836, 0.057710688561201096, 0.03719104081392288, 0.07977698743343353, 0.02595260553061962, 0.1046842560172081, 0.06301649659872055, 0.02800893224775791, 0.024529291316866875, 0.020508909597992897, 0.14025148749351501, 0.05224132165312767, 0.02634393982589245, 0.03067580796778202, 0.010352589190006256, 0.030206164345145226, 0.09297139197587967, 0.1973668485879898, 0.11294060945510864, 0.10930002480745316, 0.0792819932103157, 0.11282505095005035, 0.06902279704809189, 0.034222979098558426, 0.01758032664656639, 0.20883719623088837, 0.0871180072426796, 0.021445829421281815, 0.058817390352487564, 0.11408091336488724, 0.04319537431001663, 0.028295835480093956, 0.009734376333653927, 0.0865861177444458, 0.013264675624668598, 0.03975219279527664, 0.03132316842675209, 0.07329122722148895, 0.031415101140737534, 0.057007454335689545, 0.07466187328100204, 0.03515228256583214, 0.01828647591173649, 0.034930113703012466, 0.04921986907720566, 0.05617351084947586, 0.025701504200696945, 0.07073844969272614, 0.0677885115146637, 0.0442965142428875, 0.08668070286512375, 0.01085565984249115, 0.10640285909175873, 0.042185988277196884, 0.045891039073467255, 0.010602300986647606, 0.07824820280075073, 0.029184645041823387, 0.1528889238834381, 0.0852082297205925, 0.01046351995319128, 0.26733046770095825, 0.008088228292763233, 0.1218838021159172, 0.06059052422642708, 0.17010393738746643, 0.09900021553039551, 0.027551589533686638, 0.009467942640185356, 0.0559978224337101, 0.015254249796271324, 0.06907999515533447, 0.026691734790802002, 0.09885875135660172, 0.01129892561584711, 0.03152812644839287, 0.08123517781496048, 0.04274165257811546, 0.03844240680336952, 0.06572488695383072, 0.10163140296936035, 0.020722707733511925, 0.016591958701610565, 0.10138952732086182, 0.10918857157230377, 0.028943251818418503, 0.04512939602136612, 0.040990330278873444, 0.04000023752450943, 0.045494887977838516, 0.011356256902217865, 0.05481533333659172, 0.013076278381049633, 0.04331720620393753]\n",
    "# acc_list_epoch_ = [71.42857142857143, 83.03571428571429, 84.82142857142857, 95.53571428571429, 91.07142857142857, 91.96428571428571, 93.75, 91.96428571428571, 96.42857142857143, 94.64285714285714, 98.21428571428571, 93.75, 96.42857142857143, 92.85714285714286, 94.64285714285714, 96.42857142857143, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 95.53571428571429, 95.53571428571429, 97.32142857142857, 91.96428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 97.32142857142857, 98.21428571428571, 95.53571428571429, 98.21428571428571, 96.42857142857143, 96.42857142857143, 95.53571428571429, 98.21428571428571, 95.53571428571429, 97.32142857142857, 99.10714285714286, 93.75, 95.53571428571429, 98.21428571428571, 94.64285714285714, 95.53571428571429, 97.32142857142857, 95.53571428571429, 94.64285714285714, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 98.21428571428571, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 96.42857142857143, 98.21428571428571, 98.21428571428571, 95.53571428571429, 99.10714285714286, 94.64285714285714, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 97.32142857142857, 95.53571428571429, 98.21428571428571, 100.0, 97.32142857142857, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 96.42857142857143, 99.10714285714286, 98.21428571428571, 94.64285714285714, 97.32142857142857, 96.42857142857143, 98.21428571428571, 95.53571428571429, 93.75, 100.0, 99.10714285714286, 98.21428571428571, 99.10714285714286, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 99.10714285714286, 95.53571428571429, 98.21428571428571, 96.42857142857143, 98.21428571428571, 98.21428571428571, 99.10714285714286, 97.32142857142857, 97.32142857142857, 98.21428571428571, 99.10714285714286, 99.10714285714286, 93.75, 97.32142857142857, 99.10714285714286, 98.21428571428571, 100.0, 99.10714285714286, 95.53571428571429, 91.07142857142857, 95.53571428571429, 95.53571428571429, 95.53571428571429, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 94.64285714285714, 98.21428571428571, 100.0, 98.21428571428571, 97.32142857142857, 98.21428571428571, 98.21428571428571, 100.0, 96.42857142857143, 100.0, 98.21428571428571, 98.21428571428571, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 99.10714285714286, 95.53571428571429, 98.21428571428571, 99.10714285714286, 98.21428571428571, 100.0, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 96.42857142857143, 99.10714285714286, 96.42857142857143, 97.32142857142857, 100.0, 91.96428571428571, 100.0, 96.42857142857143, 97.32142857142857, 91.96428571428571, 97.32142857142857, 99.10714285714286, 100.0, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 96.42857142857143, 100.0, 99.10714285714286, 99.10714285714286, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 100.0, 100.0, 95.53571428571429, 94.64285714285714, 99.10714285714286, 97.32142857142857, 98.21428571428571, 98.21428571428571, 98.21428571428571, 100.0, 98.21428571428571, 100.0, 99.10714285714286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 99.25%\n",
      "Loss on the train set: 0.02\n",
      "Accuracy on the test set: 94.17%\n",
      "Loss on the test set: 0.30\n",
      "Generalization error: 0.27657068\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
