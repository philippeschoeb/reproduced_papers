{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1637.5\" height=\"593.75\" viewBox=\"-30.0 0 1310.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.603162</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.156975</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.031835</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.31287</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.153627</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.117137</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.386538</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.907512</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.548331</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.837385</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.945385</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.915602</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.604925</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.352628</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.921202</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.132518</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.062993</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.95264</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.974156</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.125767</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.742038</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.494328</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.884382</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.706898</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.006519</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.72598</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.224621</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.519291</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.462948</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.682701</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.290325</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.542921</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.788517</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.206688</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.154253</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.368719</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.356765</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.884053</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.977163</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.971046</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.666611</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.820974</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.981512</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.339936</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.37455</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.4577</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.711758</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.635138</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.877017</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.587548</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.741518</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.237164</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.111107</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.684429</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.338451</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.463256</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.669465</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.345438</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.537334</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.974436</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.952355</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.881663</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.907512</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.927507</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.599064</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.016347</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.069921</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.493335</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.757528</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.283384</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.594759</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.035429</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.324742</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.753704</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.761847</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.386937</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.54619</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.595824</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.232567</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.339807</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.924271</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.078654</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.797787</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.983757</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.846457</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.928326</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.129125</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.293709</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.423773</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.814299</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.125912</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.298083</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.5109</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.507346</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.933973</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.512622</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25.0 L1240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,125.0 L1240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,175.0 L1240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,225.0 L1240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,275.0 L1240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,325.0 L1240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,375.0 L1240,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,425.0 L1240,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1250\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1250\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1250\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1250\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1250\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1250\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1250\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1250\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1250\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7295031bf340>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m=9, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.484397</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.588393</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.006853</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.373762</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.218508</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.181161</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.399534</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.330207</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.799811</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.637013</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=pi/6</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.35406</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.271099</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.464652</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.011593</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.418412</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.012946</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.829361</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.061611</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.73169</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.303535</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.473543</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.989336</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.336328</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.301522</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.469568</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.052334</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.085457</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.739696</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.120975</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.8291</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.596755</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.537529</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.625901</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.597759</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.46506</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.158931</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.638834</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.08643</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.433431</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.891803</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.93581</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.016387</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.893622</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.87118</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.335415</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.492484</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.021103</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.227054</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.960254</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.756876</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.671327</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.504906</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.27935</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.202792</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.326636</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.13816</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.035715</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.791042</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.754238</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.20723</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.614822</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.217182</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.859125</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.115576</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.257999</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.845913</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.495711</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.804354</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.394124</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.435082</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.106642</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.005972</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.094144</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.954116</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7295030d89a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m=8, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        #     super(CNNModel, self).__init__()\n",
    "        #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "        #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "        #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "        #     self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "        # def forward(self, x):\n",
    "        #     x = self.pool(self.conv1(x))\n",
    "        #     x = self.pool(self.conv2(x))\n",
    "        #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        #     x = self.fc1(x)\n",
    "        #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 74.83%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    # class MappingModel(nn.Module):\n",
    "    #     def __init__(self, input_size, hidden_sizes, output_size):\n",
    "    #         super().__init__()\n",
    "    #         # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "    #         self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "    #         self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "    #         self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    #     def forward(self, X):\n",
    "    #         # Ensure the input tensor is the same type as the weights\n",
    "    #         X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "    #         # Input layer with ReLU activation\n",
    "    #         X = self.input_layer(X)\n",
    "\n",
    "    #         # Hidden layers with ReLU activation\n",
    "    #         for hidden in self.hidden_layers:\n",
    "    #             X = hidden(X)\n",
    "\n",
    "    #         # Output layer with linear activation\n",
    "    #         output = self.output_layer(X)\n",
    "    #         # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "    #         return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "        # self.MappingNetwork = self.MappingModel(n_qubit+1, [8], 1).to(device)\n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit + 1, output_dim=1, bond_dim=4)\n",
    "\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        # self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[\n",
    "            :108\n",
    "        ]  # nn.Parameter(q_delta * torch.randn(135)).to(device)\n",
    "        self.q_params_2 = qnn_parameters[108:]\n",
    "        device = x.device\n",
    "\n",
    "        res_1 = bs_1.run(parameters=self.q_params_1, samples=100000)\n",
    "        trans_res_1 = bs_1.translate_results(res=res_1)\n",
    "        trans_res_1 = trans_res_1 / torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)\n",
    "\n",
    "        res_2 = bs_2.run(parameters=self.q_params_2, samples=100000)\n",
    "        trans_res_2 = bs_2.translate_results(res=res_2)\n",
    "        trans_res_2 = trans_res_2 / torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)\n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(126 * 70, 1)\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[: len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  496\n",
      "# of trainable parameter in QNN model:  192\n",
      "# of trainable parameter in full model:  688\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108 + 84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\n",
    "    \"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters\n",
    ")\n",
    "print(\n",
    "    \"# of trainable parameter in full model: \",\n",
    "    num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.1265, batch time: 0.20, accuracy:  22.66%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.1330, batch time: 0.26, accuracy:  15.62%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.0735, batch time: 0.42, accuracy:  22.66%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 1.9094, batch time: 0.31, accuracy:  28.12%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 1.6787, batch time: 0.26, accuracy:  39.06%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 1.6595, batch time: 0.20, accuracy:  35.16%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 1.7511, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 1.5741, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 1.7305, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 1.2728, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 1.1926510334014893, accuracy: 60.6 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 1.337706208229065, accuracy: 54.9 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 1.1437342166900635, accuracy: 59.7 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 1.245076060295105, accuracy: 61.1 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 1.1256769895553589, accuracy: 61.8 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 1.1414070129394531, accuracy: 61.7 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 1.1168285608291626, accuracy: 62.9 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 1.1187703609466553, accuracy: 62.8 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 1.1088491678237915, accuracy: 62.6 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 1.1109116077423096, accuracy: 62.7 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 1.1446, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 1.2031, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 0.8172, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 0.7562, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 0.9613, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 0.8981, batch time: 0.05, accuracy:  71.88%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 0.8504, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 0.8777, batch time: 0.05, accuracy:  71.88%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 0.9099, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 0.8874, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 0.7573632597923279, accuracy: 76.4 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 0.7745377421379089, accuracy: 75.0 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 0.818104088306427, accuracy: 71.5 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 0.7060327529907227, accuracy: 76.6 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 0.8412756323814392, accuracy: 72.7 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 0.6962078809738159, accuracy: 78.0 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 0.6788062453269958, accuracy: 78.7 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 0.6748738288879395, accuracy: 79.0 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 0.6669924855232239, accuracy: 78.7 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 0.6670101284980774, accuracy: 78.9 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 0.6865, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 0.5941, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 0.8441, batch time: 0.10, accuracy:  75.00%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 0.6849, batch time: 0.10, accuracy:  76.56%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 0.9313, batch time: 0.10, accuracy:  75.00%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 0.7225, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 0.6010, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 0.6161, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 0.6105, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 0.7419, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 0.5754337906837463, accuracy: 83.6 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 0.6765763163566589, accuracy: 79.2 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 0.5544646978378296, accuracy: 83.4 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 0.5490275621414185, accuracy: 83.8 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 0.6344430446624756, accuracy: 80.7 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 5.472433090209961, accuracy: 18.8 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 0.53409343957901, accuracy: 83.9 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 0.5333749651908875, accuracy: 84.0 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 0.5387846231460571, accuracy: 83.5 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 0.5320798754692078, accuracy: 83.4 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 0.7480, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 0.6969, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 0.4087, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 0.5830, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 0.8552, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 0.3875, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 0.4308, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 0.4506, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 0.4574, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 0.5345, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 0.4926045835018158, accuracy: 84.6 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 0.6304960250854492, accuracy: 80.7 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 0.49484118819236755, accuracy: 84.2 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 0.552751898765564, accuracy: 84.1 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 0.5175319910049438, accuracy: 83.1 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 0.4581889808177948, accuracy: 85.5 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 0.4574708342552185, accuracy: 85.3 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 0.45159614086151123, accuracy: 85.9 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 0.45301783084869385, accuracy: 85.8 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 0.45115816593170166, accuracy: 86.0 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 0.5263, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 0.5235, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 0.5048, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 0.4986, batch time: 0.04, accuracy:  82.03%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 0.5087, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 0.3249, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 0.2826, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 0.6340, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 0.6059, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 0.5098, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 0.4099445044994354, accuracy: 87.3 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 0.6037303805351257, accuracy: 81.5 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 0.39823344349861145, accuracy: 87.9 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 0.39497900009155273, accuracy: 87.8 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 0.4500551223754883, accuracy: 86.6 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 0.4383842349052429, accuracy: 85.5 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 0.3860664963722229, accuracy: 88.2 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 0.3799707293510437, accuracy: 88.4 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 0.3783111870288849, accuracy: 88.4 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 0.37998297810554504, accuracy: 88.1 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 0.3356, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 0.5356, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 0.5034, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 0.7394, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 0.6458, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 0.4067, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 0.3556, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 0.5335, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 0.3259, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 0.3444, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 0.3967902660369873, accuracy: 88.0 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 0.5005427598953247, accuracy: 84.5 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 0.402558833360672, accuracy: 88.2 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 0.3898581266403198, accuracy: 87.9 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 0.5843724012374878, accuracy: 84.0 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 0.38542643189430237, accuracy: 88.2 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 0.38630297780036926, accuracy: 87.8 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 0.381175696849823, accuracy: 88.7 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 0.3838721215724945, accuracy: 88.9 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 0.378089964389801, accuracy: 88.7 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 0.4053, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 0.3542, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 0.2900, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 0.5175, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 0.5669, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 0.5624, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 0.4233, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 0.4016, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 0.3149, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 0.5339, batch time: 0.04, accuracy:  81.25%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 0.42252597212791443, accuracy: 87.3 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 0.6701936721801758, accuracy: 78.0 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 0.4224267601966858, accuracy: 87.4 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 0.4191744029521942, accuracy: 86.6 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 0.5761763453483582, accuracy: 81.6 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 0.4333409368991852, accuracy: 86.3 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 0.40797197818756104, accuracy: 87.3 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 0.40430358052253723, accuracy: 87.9 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 0.4046640992164612, accuracy: 87.6 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 0.40912145376205444, accuracy: 87.1 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 0.4433, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 0.3789, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 0.4568, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 0.4049, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 0.2974, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 0.4775, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 0.4207, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 0.5032, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 0.3876, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 0.2911, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 0.41937291622161865, accuracy: 87.4 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 0.42339521646499634, accuracy: 87.5 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 0.5064488649368286, accuracy: 85.5 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 0.4122144877910614, accuracy: 88.2 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 0.41257232427597046, accuracy: 88.1 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 0.4893611669540405, accuracy: 86.5 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 0.4349195063114166, accuracy: 87.9 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 0.42847421765327454, accuracy: 87.7 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 0.4067716598510742, accuracy: 87.9 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 0.4209718704223633, accuracy: 87.3 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 0.4111, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 0.3189, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 0.3977, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 0.3236, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 0.3799, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 0.3567, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 0.3508, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 0.3767, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 0.3811, batch time: 0.08, accuracy:  87.50%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 0.4045, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 0.394704669713974, accuracy: 87.7 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 0.46556392312049866, accuracy: 86.1 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 0.3637787401676178, accuracy: 88.9 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 0.35918572545051575, accuracy: 88.7 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 0.4648703634738922, accuracy: 85.1 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 0.3853759467601776, accuracy: 88.3 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 0.3531065583229065, accuracy: 89.3 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 0.34584251046180725, accuracy: 90.0 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 0.34184637665748596, accuracy: 89.6 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 0.34039929509162903, accuracy: 89.6 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 0.3744, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 0.2976, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 0.3325, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 0.3245, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 0.4656, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 0.4180, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 0.4388, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 0.3997, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 0.3871, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 0.2744, batch time: 0.27, accuracy:  90.62%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 0.3632057011127472, accuracy: 87.9 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 0.4248500168323517, accuracy: 86.9 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 0.43881821632385254, accuracy: 85.3 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 0.3480748236179352, accuracy: 89.4 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 0.4498276710510254, accuracy: 85.6 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 0.39887771010398865, accuracy: 87.7 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 0.4384281039237976, accuracy: 85.7 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 0.3501180112361908, accuracy: 89.2 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 0.3335520625114441, accuracy: 89.6 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 0.33464765548706055, accuracy: 90.2 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 0.5003, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 0.4463, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 0.5242, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 0.3473, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 0.2961, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 0.4386, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 0.4650, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 0.4084, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 0.4457, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 0.2761, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 0.4079414904117584, accuracy: 88.0 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 0.544208288192749, accuracy: 84.8 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 0.39968323707580566, accuracy: 88.4 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 0.39765259623527527, accuracy: 88.4 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 0.4333094656467438, accuracy: 87.8 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 0.4079545736312866, accuracy: 87.6 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 0.39125245809555054, accuracy: 88.2 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 0.39704224467277527, accuracy: 88.9 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 0.38461291790008545, accuracy: 88.4 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 0.3846796452999115, accuracy: 88.8 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 0.4574, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 0.3376, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 0.3092, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 0.3007, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 0.2770, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 0.2241, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 0.3190, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 0.3367, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 0.3170, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 0.3454, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 0.4230113923549652, accuracy: 87.5 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 0.4474186599254608, accuracy: 86.1 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 0.41217002272605896, accuracy: 87.6 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 0.4101162552833557, accuracy: 87.4 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 0.45642101764678955, accuracy: 86.9 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 0.47025060653686523, accuracy: 86.6 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 0.38587629795074463, accuracy: 88.7 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 0.38086456060409546, accuracy: 89.1 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 0.3791823089122772, accuracy: 89.0 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 0.3748227655887604, accuracy: 88.9 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 0.3401, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 0.3625, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 0.3370, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 0.4879, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 0.4956, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 0.2661, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 0.5197, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 0.3627, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 0.4464, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 0.3118, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 0.3578415513038635, accuracy: 89.2 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 0.3990032970905304, accuracy: 87.7 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 0.342501699924469, accuracy: 88.4 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 0.3414649963378906, accuracy: 88.9 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 0.42381054162979126, accuracy: 86.9 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 0.3376122713088989, accuracy: 88.6 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 0.33215317130088806, accuracy: 89.1 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 0.3288683295249939, accuracy: 89.3 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 0.3463829755783081, accuracy: 88.3 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 0.32717248797416687, accuracy: 89.5 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 0.4043, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 0.3294, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 0.4743, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 0.4854, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 0.3794, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 0.4283, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 0.3538, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 0.4922, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 0.2797, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 0.3722, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 0.3772050738334656, accuracy: 88.5 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 0.4654768407344818, accuracy: 85.6 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 0.345350056886673, accuracy: 90.0 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 0.3449913561344147, accuracy: 89.6 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 0.46917596459388733, accuracy: 85.6 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 0.34235864877700806, accuracy: 89.8 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 0.3334002196788788, accuracy: 90.6 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 0.33460789918899536, accuracy: 89.9 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 0.33843234181404114, accuracy: 90.2 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 0.35908353328704834, accuracy: 88.2 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 0.4975, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 0.4168, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 0.2856, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 0.3697, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 0.3489, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 0.3098, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 0.2811, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 0.3715, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 0.3389, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 0.2103, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 0.3908185660839081, accuracy: 89.0 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 0.5673524141311646, accuracy: 84.7 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 0.3773854672908783, accuracy: 88.6 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 0.5729029178619385, accuracy: 84.3 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 0.42778947949409485, accuracy: 87.2 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 0.4620039165019989, accuracy: 86.1 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 0.34866029024124146, accuracy: 90.1 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 0.3420239984989166, accuracy: 90.0 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 0.34143948554992676, accuracy: 89.9 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 0.34980806708335876, accuracy: 90.2 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 0.4116, batch time: 0.04, accuracy:  82.81%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 0.3637, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 0.2653, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 0.3179, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 0.3493, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 0.4217, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 0.2180, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 0.2886, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 0.3016, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 0.3785, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 0.32743653655052185, accuracy: 90.0 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 0.4020116329193115, accuracy: 87.5 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 0.3225362300872803, accuracy: 90.4 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 0.3222692608833313, accuracy: 90.4 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 0.5646243691444397, accuracy: 83.6 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 0.31849467754364014, accuracy: 90.6 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 0.31299054622650146, accuracy: 91.3 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 0.33471739292144775, accuracy: 90.3 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 0.3137505352497101, accuracy: 90.7 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 0.3051193356513977, accuracy: 91.6 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 0.4202, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 0.4168, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 0.3155, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 0.2662, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 0.4293, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 0.2517, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 0.2492, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 0.3526, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 0.3927, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 0.4304, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 0.35277608036994934, accuracy: 90.1 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 0.4190267324447632, accuracy: 87.2 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 0.3471468687057495, accuracy: 89.3 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 0.3410172164440155, accuracy: 89.3 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 0.4662475883960724, accuracy: 85.9 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 0.3605445921421051, accuracy: 88.7 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 0.32676902413368225, accuracy: 89.6 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 0.330664724111557, accuracy: 90.6 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 0.3351747691631317, accuracy: 90.1 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 0.32798799872398376, accuracy: 90.9 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 0.4267, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 0.5477, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 0.4094, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 0.2835, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 0.2224, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 0.2662, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 0.4624, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 0.1772, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 0.5238, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 0.2691, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 0.31934452056884766, accuracy: 89.9 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 0.377527117729187, accuracy: 88.7 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 0.40136173367500305, accuracy: 87.7 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 0.31083717942237854, accuracy: 89.5 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 0.3489919900894165, accuracy: 89.0 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 0.3106059432029724, accuracy: 89.4 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 0.31371620297431946, accuracy: 90.0 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 0.36040809750556946, accuracy: 89.3 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 0.3068977892398834, accuracy: 89.6 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 0.30328506231307983, accuracy: 89.4 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 0.4220, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 0.2430, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 0.3118, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 0.2674, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 0.3828, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 0.3433, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 0.3677, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 0.2082, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 0.3375, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 0.2594, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 0.2772566080093384, accuracy: 89.7 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 0.34696871042251587, accuracy: 89.5 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 0.2739425301551819, accuracy: 90.4 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 0.27338647842407227, accuracy: 90.2 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 2.737304925918579, accuracy: 40.8 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 0.2643476128578186, accuracy: 91.2 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 0.26029518246650696, accuracy: 91.5 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 0.2608644664287567, accuracy: 90.9 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 0.25977441668510437, accuracy: 91.1 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 0.4387163519859314, accuracy: 84.5 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 0.4767, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 0.4136, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 0.1992, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 0.1975, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 0.4997, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 0.3552, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 0.4183, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 0.6164, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 0.4499, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 0.3480, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 0.32332608103752136, accuracy: 89.4 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 0.40694934129714966, accuracy: 87.1 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 0.32177484035491943, accuracy: 89.5 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 0.31889063119888306, accuracy: 89.5 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 0.7599095106124878, accuracy: 81.9 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 0.7220216393470764, accuracy: 77.9 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 0.31295284628868103, accuracy: 89.9 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 0.3130463659763336, accuracy: 89.6 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 0.3101123869419098, accuracy: 90.1 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 0.3437832295894623, accuracy: 88.5 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 0.2870, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 0.3978, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 0.3182, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 0.3783, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 0.4566, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 0.4579, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 0.3137, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 0.2872, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 0.2356, batch time: 0.09, accuracy:  89.84%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 0.3333, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 0.325965017080307, accuracy: 90.8 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 0.5921707153320312, accuracy: 82.5 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 0.32591375708580017, accuracy: 90.9 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 0.42994338274002075, accuracy: 87.2 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 0.32150644063949585, accuracy: 91.5 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 0.3181057870388031, accuracy: 91.4 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 0.3211580216884613, accuracy: 90.6 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 0.3129441440105438, accuracy: 91.8 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 0.31351009011268616, accuracy: 91.6 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 0.31313398480415344, accuracy: 91.0 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 0.3472, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 0.2246, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 0.4622, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 0.5238, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 0.4848, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 0.3706, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 0.3257, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 0.3352, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 0.3324, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 0.2883, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 0.32391121983528137, accuracy: 90.2 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 0.3640538454055786, accuracy: 89.1 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 0.3957282304763794, accuracy: 87.6 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 0.8945801854133606, accuracy: 72.5 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 0.3057709336280823, accuracy: 90.9 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 0.30426836013793945, accuracy: 90.7 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 0.3029102385044098, accuracy: 90.5 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 0.3121470808982849, accuracy: 90.8 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 0.3050493896007538, accuracy: 90.6 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 0.2978470027446747, accuracy: 90.7 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 0.1865, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 0.2537, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 0.4352, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 0.3510, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 0.2188, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 0.2928, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 0.2676, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 0.4325, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 0.4625, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 0.3029, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 0.33676159381866455, accuracy: 90.3 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 0.3426111936569214, accuracy: 90.0 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 0.3327510356903076, accuracy: 90.2 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 0.3212060332298279, accuracy: 90.5 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 0.4267297387123108, accuracy: 86.6 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 0.33873188495635986, accuracy: 90.4 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 0.3244938254356384, accuracy: 90.8 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 0.3120152950286865, accuracy: 91.4 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 0.3109362721443176, accuracy: 91.1 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 0.3106707036495209, accuracy: 90.9 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 0.2836, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 0.4074, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 0.2927, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 0.3485, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 0.4072, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 0.2868, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 0.4136, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 0.2689, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 0.4795, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 0.3132, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 0.37199002504348755, accuracy: 87.9 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 45.34665298461914, accuracy: 10.3 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 0.360733300447464, accuracy: 88.3 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 0.6317793130874634, accuracy: 81.6 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 0.3504631817340851, accuracy: 89.1 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 0.34521734714508057, accuracy: 89.1 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 0.3375336229801178, accuracy: 89.2 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 0.33544787764549255, accuracy: 89.1 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 0.3316158056259155, accuracy: 89.5 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 0.3252221643924713, accuracy: 89.5 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 0.4283, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 0.2943, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 0.2585, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 0.4000, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 0.3920, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 0.2382, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 0.3322, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 0.3463, batch time: 0.08, accuracy:  89.84%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 0.4676, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 0.4161, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 0.33548611402511597, accuracy: 89.9 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 0.5191184282302856, accuracy: 85.0 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 0.3198067247867584, accuracy: 89.8 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 0.31814706325531006, accuracy: 89.8 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 0.49441367387771606, accuracy: 83.2 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 0.3885619044303894, accuracy: 88.0 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 0.31052905321121216, accuracy: 90.0 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 0.3044355511665344, accuracy: 90.7 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 0.3050342798233032, accuracy: 90.9 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 0.3083646893501282, accuracy: 90.1 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 0.3181, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 0.5196, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 0.3002, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 0.4564, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 0.3462, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 0.3092, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 0.3494, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 0.2784, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 0.2399, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 0.2739, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 0.3755486309528351, accuracy: 89.2 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 0.7564437389373779, accuracy: 80.9 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 0.3589475452899933, accuracy: 89.9 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 0.34710341691970825, accuracy: 90.8 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 0.43473854660987854, accuracy: 86.9 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 0.38776251673698425, accuracy: 88.7 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 0.32619521021842957, accuracy: 90.7 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 0.32203027606010437, accuracy: 90.3 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 0.3456690013408661, accuracy: 89.9 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 0.3204557001590729, accuracy: 90.4 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 0.2991, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 0.2932, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 0.4410, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 0.3674, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 0.2856, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 0.3602, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 0.2256, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 0.4000, batch time: 0.06, accuracy:  89.84%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 0.3980, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 0.2792, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 0.25777560472488403, accuracy: 91.8 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 0.2973061501979828, accuracy: 90.8 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 0.25605249404907227, accuracy: 91.8 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 0.2755413353443146, accuracy: 90.6 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 0.2559175491333008, accuracy: 92.0 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 0.2452705055475235, accuracy: 93.3 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 0.24862900376319885, accuracy: 92.6 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 0.2434292882680893, accuracy: 92.3 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 0.24311555922031403, accuracy: 93.6 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 0.24375315010547638, accuracy: 92.8 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 0.2616, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 0.3250, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 0.3361, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 0.2804, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 0.3318, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 0.1978, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 0.3735, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 0.3297, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 0.3874, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 0.4381, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 0.28291940689086914, accuracy: 91.2 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 0.4699697494506836, accuracy: 84.4 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 0.3856171667575836, accuracy: 86.2 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 1.3216142654418945, accuracy: 64.1 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 0.2684652805328369, accuracy: 91.7 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 0.2642236053943634, accuracy: 91.9 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 0.26432761549949646, accuracy: 92.1 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 0.2613179087638855, accuracy: 92.0 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 0.259556382894516, accuracy: 92.5 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 0.25811079144477844, accuracy: 91.7 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 0.2485, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 0.3504, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 0.3080, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 0.2318, batch time: 0.06, accuracy:  92.19%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 0.2813, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 0.2538, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 0.3663, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 0.2114, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 0.2538, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 0.4838, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 0.2847568392753601, accuracy: 91.7 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 7.0549445152282715, accuracy: 32.2 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 0.3288104236125946, accuracy: 89.8 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 0.32106009125709534, accuracy: 90.4 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 0.27254313230514526, accuracy: 92.0 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 0.30852341651916504, accuracy: 90.7 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 0.2702522575855255, accuracy: 92.0 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 0.2670173645019531, accuracy: 92.2 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 0.2656528353691101, accuracy: 92.0 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 0.2647855877876282, accuracy: 92.3 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 0.4277, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 0.2951, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 0.2553, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 0.3303, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 0.2953, batch time: 0.07, accuracy:  89.06%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 0.4548, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 0.3427, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 0.2757, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 0.3390, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 0.4333, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 0.3238169550895691, accuracy: 91.1 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 0.4930475652217865, accuracy: 83.9 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 0.31580719351768494, accuracy: 90.3 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 0.3116632103919983, accuracy: 90.9 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 2.9341487884521484, accuracy: 46.4 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 0.30962735414505005, accuracy: 91.4 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 0.3189183175563812, accuracy: 91.1 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 0.3403535783290863, accuracy: 88.4 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 0.3023351728916168, accuracy: 90.9 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 0.3041088879108429, accuracy: 91.0 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 0.3943, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 0.2861, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 0.2889, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 0.2089, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 0.3867, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 0.3650, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 0.3412, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 0.3813, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 0.2370, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 0.4293, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 0.3159668743610382, accuracy: 90.7 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 0.3666227459907532, accuracy: 89.4 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 0.3013249337673187, accuracy: 90.4 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 0.30131661891937256, accuracy: 90.4 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 0.3030402660369873, accuracy: 90.7 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 0.2965637743473053, accuracy: 90.9 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 0.3045615255832672, accuracy: 91.2 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 0.298089861869812, accuracy: 90.8 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 0.29469841718673706, accuracy: 90.8 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 0.29202979803085327, accuracy: 91.0 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 0.1966, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 0.3647, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 0.4232, batch time: 0.09, accuracy:  90.62%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 0.2555, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 0.3707, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 0.2548, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 0.3555, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 0.2227, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 0.3400, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 0.2591, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 0.3773850202560425, accuracy: 89.5 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 0.4466732144355774, accuracy: 87.2 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 0.35179588198661804, accuracy: 89.2 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 0.3462908864021301, accuracy: 89.3 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 0.3287152349948883, accuracy: 90.5 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 0.3223859667778015, accuracy: 91.3 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 0.32885420322418213, accuracy: 91.5 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 0.3142778277397156, accuracy: 91.1 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 0.3371182978153229, accuracy: 91.0 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 0.32537177205085754, accuracy: 90.8 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 0.2941, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 0.2641, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 0.2908, batch time: 0.08, accuracy:  88.28%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 0.2518, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 0.5379, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 0.2705, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 0.4363, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 0.3708, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 0.3699, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 0.3024, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 0.3438873291015625, accuracy: 90.3 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 0.5907079577445984, accuracy: 84.6 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 0.32670220732688904, accuracy: 91.0 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 0.3247692584991455, accuracy: 91.0 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 0.42064976692199707, accuracy: 87.2 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 0.39280441403388977, accuracy: 89.1 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 0.31092479825019836, accuracy: 91.1 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 0.3101014494895935, accuracy: 91.3 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 0.3763107359409332, accuracy: 88.9 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 0.3084893524646759, accuracy: 90.6 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 0.7152, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 0.2531, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 0.2194, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 0.4193, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 0.2984, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 0.2307, batch time: 0.29, accuracy:  89.84%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 0.4011, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 0.3170, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 0.2809, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 0.2287, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 0.30486586689949036, accuracy: 90.8 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 0.46491292119026184, accuracy: 85.0 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 0.2917015254497528, accuracy: 92.0 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 0.2870529294013977, accuracy: 91.8 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 0.3220891058444977, accuracy: 90.3 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 0.302015095949173, accuracy: 91.1 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 0.274277001619339, accuracy: 91.9 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 0.28528890013694763, accuracy: 91.1 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 0.2670834958553314, accuracy: 92.0 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 0.2671993672847748, accuracy: 92.1 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 0.1660, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 0.4762, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 0.2721, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 0.3378, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 0.3546, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 0.2192, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 0.3318, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 0.3034, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 0.3062, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 0.2699, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 0.2822776734828949, accuracy: 91.7 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 0.33644920587539673, accuracy: 90.0 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 0.3700861930847168, accuracy: 88.0 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 0.26174813508987427, accuracy: 92.4 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 0.46419215202331543, accuracy: 85.9 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 0.2590177655220032, accuracy: 92.7 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 0.2598640024662018, accuracy: 92.2 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 0.28600308299064636, accuracy: 91.2 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 0.2530057728290558, accuracy: 92.1 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 0.2562488317489624, accuracy: 91.9 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 0.2951, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 0.2840, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 0.3654, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 0.2727, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 0.2587, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 0.3424, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 0.5417, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 0.2541, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 0.2424, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 0.1896, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 0.2893977463245392, accuracy: 91.3 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 0.3762912154197693, accuracy: 88.9 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 0.39998894929885864, accuracy: 88.8 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 0.8170953392982483, accuracy: 72.3 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 0.2795931100845337, accuracy: 92.1 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 0.2778651714324951, accuracy: 91.7 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 0.27502742409706116, accuracy: 91.3 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 0.2794204652309418, accuracy: 90.9 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 0.274659126996994, accuracy: 91.9 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 0.2824154794216156, accuracy: 91.2 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 0.1214, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 0.3267, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 0.1698, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 0.2981, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 0.2828, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 0.3016, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 0.2605, batch time: 0.22, accuracy:  93.75%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 0.3427, batch time: 0.09, accuracy:  89.06%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 0.3018, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 0.3573, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 0.25795748829841614, accuracy: 92.1 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 0.42241886258125305, accuracy: 86.6 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 0.25717687606811523, accuracy: 92.0 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 0.6779981851577759, accuracy: 80.6 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 0.3597199022769928, accuracy: 88.2 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 0.24395909905433655, accuracy: 91.9 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 0.24264635145664215, accuracy: 92.1 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 0.239138662815094, accuracy: 92.6 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 0.24105845391750336, accuracy: 92.2 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 0.24693946540355682, accuracy: 92.1 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 0.2999, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 0.2711, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 0.2860, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 0.3608, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 0.3162, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 0.3725, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 0.2480, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 0.2691, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 0.2858, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 0.2399, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 0.31103137135505676, accuracy: 90.9 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 0.5203866362571716, accuracy: 85.1 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 0.29522284865379333, accuracy: 91.1 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 0.4968394339084625, accuracy: 85.2 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 0.29416441917419434, accuracy: 91.2 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 0.2819633483886719, accuracy: 90.7 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 0.2825670838356018, accuracy: 90.7 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 0.2796429991722107, accuracy: 91.1 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 0.28366905450820923, accuracy: 91.1 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 0.3083074688911438, accuracy: 90.1 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 0.4200, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 0.4990, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 0.3118, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 0.2546, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 0.3753, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 0.3373, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 0.3712, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 0.3575, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 0.3461, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 0.3473, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 0.24309705197811127, accuracy: 91.7 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 0.5010715126991272, accuracy: 83.9 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 0.2735399901866913, accuracy: 91.1 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 0.35230308771133423, accuracy: 88.8 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 0.23116078972816467, accuracy: 91.7 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 0.2393566370010376, accuracy: 91.3 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 0.22475600242614746, accuracy: 92.2 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 0.22550983726978302, accuracy: 91.9 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 0.22012373805046082, accuracy: 92.1 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 0.21999642252922058, accuracy: 92.1 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 0.2069, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 0.2937, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 0.2112, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 0.1993, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 0.2240, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 0.2028, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 0.2494, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 0.2434, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 0.3771, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 0.2493, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 0.26455458998680115, accuracy: 92.5 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 0.3614465594291687, accuracy: 89.2 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 0.4850156307220459, accuracy: 84.9 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 0.47528842091560364, accuracy: 84.0 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 0.24880406260490417, accuracy: 93.1 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 0.26742514967918396, accuracy: 91.7 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 0.2660719156265259, accuracy: 92.1 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 0.24080513417720795, accuracy: 93.3 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 0.23869554698467255, accuracy: 93.6 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 0.23685576021671295, accuracy: 93.6 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 0.1070, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 0.2120, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 0.2206, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 0.2769, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 0.3306, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 0.3265, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 0.2492, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 0.2815, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 0.3642, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 0.1644, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 0.21859630942344666, accuracy: 92.5 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 0.2753448784351349, accuracy: 90.7 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 0.40511593222618103, accuracy: 86.6 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 0.40517210960388184, accuracy: 86.0 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 0.2100452333688736, accuracy: 92.9 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 0.20123659074306488, accuracy: 93.1 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 0.20073643326759338, accuracy: 93.2 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 0.1942213922739029, accuracy: 93.6 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 0.19981695711612701, accuracy: 92.8 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 0.1912212371826172, accuracy: 93.5 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 0.2666, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 0.2268, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 0.3714, batch time: 0.09, accuracy:  89.06%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 0.2471, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 0.3246, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 0.2439, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 0.2410, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 0.3594, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 0.3968, batch time: 0.06, accuracy:  89.06%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 0.3337, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 0.2989426255226135, accuracy: 91.2 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 0.3688695728778839, accuracy: 89.6 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 0.5874784588813782, accuracy: 84.5 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 0.7536184787750244, accuracy: 78.1 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 0.28737497329711914, accuracy: 91.6 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 0.3593519628047943, accuracy: 89.9 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 0.2855275273323059, accuracy: 92.1 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 0.2852464020252228, accuracy: 92.1 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 0.2778485119342804, accuracy: 92.5 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 0.2774903476238251, accuracy: 92.5 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 0.2697, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 0.2035, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 0.1957, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 0.2731, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 0.1537, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 0.1893, batch time: 0.08, accuracy:  93.75%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 0.3352, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 0.2086, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 0.3046, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 0.4324, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 0.24392569065093994, accuracy: 92.8 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 0.34356576204299927, accuracy: 89.5 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 0.29442664980888367, accuracy: 90.8 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 0.7695489525794983, accuracy: 75.1 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 0.23538000881671906, accuracy: 92.4 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 0.2289634346961975, accuracy: 93.0 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 0.23176464438438416, accuracy: 92.6 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 0.2324623167514801, accuracy: 92.6 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 0.2285705953836441, accuracy: 92.8 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 0.23069319128990173, accuracy: 92.8 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 0.1782, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 0.2695, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 0.2429, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 0.2364, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 0.2477, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 0.2499, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 0.2204, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 0.4591, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 0.2864, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 0.3403, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 0.27988284826278687, accuracy: 92.2 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 0.6420274376869202, accuracy: 79.1 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 0.2706631124019623, accuracy: 91.9 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 0.26875925064086914, accuracy: 92.2 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 1.681262493133545, accuracy: 60.0 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 0.26391661167144775, accuracy: 91.4 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 0.2611600458621979, accuracy: 92.3 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 0.2522328495979309, accuracy: 92.7 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 0.24765938520431519, accuracy: 92.7 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 0.26726847887039185, accuracy: 91.0 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 0.2647, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 0.2004, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 0.3779, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 0.2849, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 0.3206, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 0.3180, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 0.2853, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 0.2551, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 0.2044, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 0.4593, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 0.27149221301078796, accuracy: 91.7 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 0.4162288010120392, accuracy: 88.6 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 0.4150220453739166, accuracy: 87.3 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 0.4676702320575714, accuracy: 85.3 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 0.26284661889076233, accuracy: 92.0 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 0.2911544144153595, accuracy: 91.0 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 0.26295432448387146, accuracy: 92.1 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 0.28259971737861633, accuracy: 91.4 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 0.249630868434906, accuracy: 92.4 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 0.24919238686561584, accuracy: 92.2 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 0.2066, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 0.3248, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 0.1734, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 0.3370, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 0.2291, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 0.2198, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 0.2986, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 0.2392, batch time: 0.21, accuracy:  92.19%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 0.1993, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 0.2967, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 0.25472110509872437, accuracy: 92.2 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 0.7615624070167542, accuracy: 78.0 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 0.24826934933662415, accuracy: 92.6 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 0.2480330467224121, accuracy: 92.7 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 0.401466965675354, accuracy: 86.6 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 0.26467302441596985, accuracy: 92.3 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 0.23833581805229187, accuracy: 92.7 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 0.2355165332555771, accuracy: 92.6 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 0.23540246486663818, accuracy: 92.6 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 0.23565275967121124, accuracy: 92.5 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 0.2167, batch time: 0.09, accuracy:  91.41%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 0.3621, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 0.1780, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 0.2606, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 0.2797, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 0.2864, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 0.2152, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 0.5096, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 0.2810, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 0.4078, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 0.2873876094818115, accuracy: 91.2 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 0.8041684031486511, accuracy: 75.1 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 0.272914856672287, accuracy: 91.4 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 0.271524578332901, accuracy: 91.5 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 0.2730523347854614, accuracy: 92.1 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 0.26631075143814087, accuracy: 91.4 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 0.2750833332538605, accuracy: 91.6 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 0.25786292552948, accuracy: 92.2 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 0.28906503319740295, accuracy: 91.2 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 0.2583790421485901, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 0.1805, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 0.2925, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 0.4142, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 0.3450, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 0.2894, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 0.3088, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 0.1768, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 0.3516, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 0.2012, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 0.4246, batch time: 0.09, accuracy:  89.06%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 0.2981514036655426, accuracy: 91.6 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 0.6010527014732361, accuracy: 81.2 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 0.2848147749900818, accuracy: 91.4 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 0.27631279826164246, accuracy: 91.4 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 0.33603155612945557, accuracy: 89.8 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 0.2674619257450104, accuracy: 92.1 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 0.2782987058162689, accuracy: 92.2 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 0.2610359191894531, accuracy: 91.7 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 0.25873878598213196, accuracy: 92.3 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 0.25976186990737915, accuracy: 92.3 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 0.1826, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 0.3236, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 0.2776, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 0.5076, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 0.4420, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 0.2975, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 0.1988, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 0.2644, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 0.3782, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 0.2297, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 0.2472921460866928, accuracy: 92.3 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 0.3399958312511444, accuracy: 90.2 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 0.3130801022052765, accuracy: 90.6 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 0.3240399956703186, accuracy: 90.1 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 0.23772741854190826, accuracy: 92.3 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 0.2318451851606369, accuracy: 92.6 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 0.3088381290435791, accuracy: 90.7 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 0.2365327775478363, accuracy: 92.2 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 0.2296765148639679, accuracy: 92.6 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 0.2277766615152359, accuracy: 92.8 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 0.3008, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 0.2297, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 0.2592, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 0.2605, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 0.2645, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 0.1722, batch time: 0.06, accuracy:  94.53%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 0.2713, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 0.1868, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 0.2344, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 0.4834, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 0.257002055644989, accuracy: 91.5 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 0.35857608914375305, accuracy: 88.0 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 0.2533358931541443, accuracy: 92.4 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 0.2478780299425125, accuracy: 92.6 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 0.24388541281223297, accuracy: 92.3 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 0.24496209621429443, accuracy: 92.6 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 0.33686909079551697, accuracy: 89.4 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 0.23778651654720306, accuracy: 92.6 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 0.22837774455547333, accuracy: 92.2 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 0.24868243932724, accuracy: 92.3 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 0.2001, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 0.4491, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 0.3948, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 0.3133, batch time: 0.09, accuracy:  91.41%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 0.1183, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 0.2120, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 0.3766, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 0.3180, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 0.2919, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 0.2678, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 0.2681301534175873, accuracy: 90.5 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 0.46692702174186707, accuracy: 85.1 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 0.36892640590667725, accuracy: 88.3 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 0.35234275460243225, accuracy: 88.6 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 0.23885692656040192, accuracy: 92.4 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 0.23516827821731567, accuracy: 91.7 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 0.24184274673461914, accuracy: 92.0 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 0.2232414186000824, accuracy: 92.8 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 0.3031500577926636, accuracy: 89.4 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 0.21712125837802887, accuracy: 93.1 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 0.2142, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 0.2876, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 0.2780, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 0.2580, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 0.2042, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 0.1894, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 0.2041, batch time: 0.09, accuracy:  92.19%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 0.1783, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 0.2230, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 0.3522, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 0.24364003539085388, accuracy: 93.2 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 0.5331065654754639, accuracy: 84.2 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 0.23882564902305603, accuracy: 93.1 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 0.23524267971515656, accuracy: 93.4 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 0.2555805742740631, accuracy: 92.7 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 0.2587817907333374, accuracy: 92.6 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 0.2282690405845642, accuracy: 93.3 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 0.22636276483535767, accuracy: 93.2 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 0.22908084094524384, accuracy: 93.6 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 0.22512589395046234, accuracy: 93.1 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 0.4533, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 0.3626, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 0.3568, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 0.1592, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 0.3944, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 0.3279, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 0.3178, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 0.3808, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 0.2049, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 0.2577, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 0.23319725692272186, accuracy: 93.3 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 0.2991914749145508, accuracy: 89.9 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 0.23109373450279236, accuracy: 93.0 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 0.2880933880805969, accuracy: 90.5 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 0.2275284081697464, accuracy: 93.4 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 0.22357769310474396, accuracy: 93.7 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 0.22514961659908295, accuracy: 93.2 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 0.2213873267173767, accuracy: 93.3 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 0.22141915559768677, accuracy: 93.6 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 0.2215745449066162, accuracy: 93.5 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 0.2374, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 0.2260, batch time: 0.07, accuracy:  91.41%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 0.2390, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 0.2514, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 0.3731, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 0.3158, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 0.2152, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 0.4939, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 0.1771, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 0.5172, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 0.28554415702819824, accuracy: 91.6 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 0.35253918170928955, accuracy: 87.9 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 0.3486468493938446, accuracy: 88.5 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 0.6220260858535767, accuracy: 80.3 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 0.30735936760902405, accuracy: 90.8 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 0.2931010127067566, accuracy: 90.0 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 0.2776269316673279, accuracy: 91.1 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 0.2760258913040161, accuracy: 91.5 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 0.27960270643234253, accuracy: 91.3 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 0.26933467388153076, accuracy: 91.5 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 0.4516, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 0.2876, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 0.3127, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 0.3572, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 0.2981, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 0.2598, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 0.2779, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 0.2220, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 0.3387, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 0.3078, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 0.24213682115077972, accuracy: 92.7 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 0.5932230353355408, accuracy: 81.0 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 0.23800776898860931, accuracy: 92.7 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 0.7187913656234741, accuracy: 76.2 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 0.2784031629562378, accuracy: 91.1 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 0.22699731588363647, accuracy: 93.0 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 0.22322776913642883, accuracy: 93.5 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 0.22291192412376404, accuracy: 93.3 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 0.23083756864070892, accuracy: 93.1 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 0.2274136245250702, accuracy: 92.8 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 0.1944, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 0.2483, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 0.2109, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 0.1887, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 0.1461, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 0.2895, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 0.2903, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 0.2153, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 0.2277, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 0.1456, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 0.2072090059518814, accuracy: 92.8 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 0.3074807822704315, accuracy: 88.6 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 0.21756742894649506, accuracy: 93.2 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 3.4166276454925537, accuracy: 53.6 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 0.2064540982246399, accuracy: 93.2 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 0.20318882167339325, accuracy: 93.0 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 0.20023104548454285, accuracy: 93.3 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 0.20231416821479797, accuracy: 93.0 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 0.1972329318523407, accuracy: 93.3 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 0.1974465698003769, accuracy: 93.3 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 0.4578, batch time: 0.06, accuracy:  88.28%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 0.1729, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 0.2510, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 0.1951, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 0.3217, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 0.2778, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 0.2631, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 0.1676, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 0.2867, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 0.2495, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 0.21399317681789398, accuracy: 93.7 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 0.2758505344390869, accuracy: 91.3 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 0.23151497542858124, accuracy: 93.8 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 0.47752389311790466, accuracy: 85.3 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 0.20710350573062897, accuracy: 94.3 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 0.19939999282360077, accuracy: 94.6 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 0.20516696572303772, accuracy: 94.5 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 0.19675835967063904, accuracy: 94.6 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 0.19585435092449188, accuracy: 94.5 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 0.1957416981458664, accuracy: 94.3 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 0.2493, batch time: 0.08, accuracy:  92.97%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 0.1914, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 0.3255, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 0.2693, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 0.2848, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 0.4900, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 0.2343, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 0.2919, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 0.3206, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 0.1809, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 0.21557384729385376, accuracy: 93.4 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 0.6459909081459045, accuracy: 81.1 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 0.21243220567703247, accuracy: 93.6 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 0.21206539869308472, accuracy: 93.6 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 0.4166485369205475, accuracy: 87.7 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 0.24610686302185059, accuracy: 92.8 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 0.20785406231880188, accuracy: 93.3 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 0.20172126591205597, accuracy: 93.8 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 0.20399537682533264, accuracy: 94.2 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 0.19991762936115265, accuracy: 94.0 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 0.3265, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 0.4003, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 0.3270, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 0.3063, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 0.2830, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 0.2869, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 0.2424, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 0.4117, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 0.3117, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 0.3453, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 0.2728598117828369, accuracy: 91.3 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 0.39693087339401245, accuracy: 87.3 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 0.3123115003108978, accuracy: 89.5 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 0.3005160987377167, accuracy: 90.0 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 0.3128643333911896, accuracy: 90.8 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 0.505074679851532, accuracy: 85.5 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 0.3269343376159668, accuracy: 89.5 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 0.23541584610939026, accuracy: 93.2 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 0.23610614240169525, accuracy: 92.8 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 0.23952822387218475, accuracy: 92.9 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 0.2467, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 0.2199, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 0.2072, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 0.3318, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 0.3936, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 0.3000, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 0.3412, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 0.3924, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 0.1647, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 0.3119, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 0.2731516659259796, accuracy: 90.7 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 0.49024659395217896, accuracy: 83.7 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 0.28838375210762024, accuracy: 90.5 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 0.2628306746482849, accuracy: 91.4 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 0.562040388584137, accuracy: 81.2 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 0.2700439393520355, accuracy: 91.7 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 0.25216713547706604, accuracy: 91.7 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 0.26309579610824585, accuracy: 90.7 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 0.24983753263950348, accuracy: 92.1 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 0.24803009629249573, accuracy: 91.4 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 0.2511, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 0.2614, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 0.2989, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 0.2137, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 0.2063, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 0.3271, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 0.3681, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 0.1933, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 0.2386, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 0.2591, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 0.21748878061771393, accuracy: 93.2 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 0.5115311145782471, accuracy: 83.4 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 0.21559058129787445, accuracy: 93.3 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 0.2154025137424469, accuracy: 93.4 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 0.2888032793998718, accuracy: 89.7 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 0.2103952020406723, accuracy: 92.8 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 0.20465795695781708, accuracy: 93.5 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 0.20188909769058228, accuracy: 93.8 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 0.20140384137630463, accuracy: 93.9 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 0.199506014585495, accuracy: 93.8 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 0.3331, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 0.2500, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 0.2556, batch time: 0.09, accuracy:  91.41%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 0.1702, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 0.2551, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 0.1331, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 0.2781, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 0.1777, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 0.2684, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 0.1349, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 0.23112322390079498, accuracy: 93.8 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 0.49972283840179443, accuracy: 84.4 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 0.2223440259695053, accuracy: 94.4 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 0.22174067795276642, accuracy: 94.7 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 0.5829262733459473, accuracy: 82.1 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 0.23215430974960327, accuracy: 93.5 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 0.28475093841552734, accuracy: 91.0 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 0.21773691475391388, accuracy: 94.6 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 0.21405255794525146, accuracy: 94.1 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 0.2123895287513733, accuracy: 94.4 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 0.2778, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 0.2756, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 0.2873, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 0.3307, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 0.2523, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 0.1605, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 0.3898, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 0.3240, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 0.4057, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 0.3621, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 0.25097423791885376, accuracy: 92.1 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 0.37936556339263916, accuracy: 87.7 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 0.25593578815460205, accuracy: 92.1 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 0.7018346190452576, accuracy: 78.6 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 0.24293091893196106, accuracy: 92.3 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 0.24083153903484344, accuracy: 92.0 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 0.24639452993869781, accuracy: 92.5 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 0.2517402768135071, accuracy: 91.6 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 0.23946727812290192, accuracy: 92.5 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 0.2447032332420349, accuracy: 92.2 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 0.2577, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 0.1805, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 0.2802, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 0.2775, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 0.2637, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 0.2148, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 0.2283, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 0.1585, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 0.1960, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 0.2688, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 0.24610252678394318, accuracy: 92.0 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 0.3762281835079193, accuracy: 87.9 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 0.23729462921619415, accuracy: 92.8 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 0.22957803308963776, accuracy: 93.2 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 0.29599472880363464, accuracy: 90.3 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 0.22823096811771393, accuracy: 92.8 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 0.2275952696800232, accuracy: 93.3 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 0.22127088904380798, accuracy: 94.1 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 0.21761268377304077, accuracy: 93.7 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 0.23703844845294952, accuracy: 91.7 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 0.2696, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 0.3168, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 0.1301, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 0.3789, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 0.1634, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 0.2481, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 0.2125, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 0.3082, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 0.1880, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 0.1970, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 0.25460925698280334, accuracy: 91.9 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 0.8860794901847839, accuracy: 77.0 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 0.24752889573574066, accuracy: 91.9 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 0.24752889573574066, accuracy: 91.9 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 0.247885599732399, accuracy: 91.6 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 0.24666917324066162, accuracy: 91.9 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 0.28028252720832825, accuracy: 91.2 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 0.24716973304748535, accuracy: 92.5 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 0.24403762817382812, accuracy: 91.9 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 0.24173487722873688, accuracy: 92.0 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 0.3213, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 0.2380, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 0.2559, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 0.3342, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 0.2259, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 0.1693, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 0.2178, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 0.2708, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 0.2603, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 0.3541, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 0.27953973412513733, accuracy: 91.6 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 0.42816275358200073, accuracy: 86.7 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 0.9902967214584351, accuracy: 72.5 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 0.539364755153656, accuracy: 83.6 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 0.24243244528770447, accuracy: 92.1 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 0.25580424070358276, accuracy: 92.1 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 0.24313275516033173, accuracy: 92.3 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 0.25008469820022583, accuracy: 91.2 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 0.2542911469936371, accuracy: 92.1 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 0.23618502914905548, accuracy: 92.2 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 0.1895, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 0.2575, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 0.2160, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 0.1338, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 0.2153, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 0.1926, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 0.1827, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 0.2280, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 0.4146, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 0.1603, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 0.23828661441802979, accuracy: 92.6 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 0.34561750292778015, accuracy: 87.8 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 0.23236195743083954, accuracy: 92.1 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 0.23019282519817352, accuracy: 92.8 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 0.558933675289154, accuracy: 82.1 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 0.2283347100019455, accuracy: 93.2 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 0.22241730988025665, accuracy: 93.2 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 0.2151869535446167, accuracy: 93.7 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 0.21771979331970215, accuracy: 93.6 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 0.21084317564964294, accuracy: 93.5 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 0.2112, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 0.2043, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 0.1914, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 0.3586, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 0.2924, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 0.3303, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 0.1905, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 0.2248, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 0.3058, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 0.2528, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 0.27241629362106323, accuracy: 92.1 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 0.5383471846580505, accuracy: 83.4 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 0.2653605043888092, accuracy: 92.5 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 0.2618665397167206, accuracy: 92.4 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 0.37647509574890137, accuracy: 89.0 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 0.2525765299797058, accuracy: 93.2 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 0.2572517991065979, accuracy: 93.0 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 0.24911059439182281, accuracy: 93.2 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 0.25675463676452637, accuracy: 93.0 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 0.284302681684494, accuracy: 92.0 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 0.3076, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 0.2906, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 0.1304, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 0.2680, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 0.4076, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 0.2275, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 0.3698, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 0.1105, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 0.2112, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 0.2660, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 0.24601972103118896, accuracy: 91.8 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 0.3925187587738037, accuracy: 88.0 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 0.22804851830005646, accuracy: 93.6 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 1.7783915996551514, accuracy: 52.9 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 0.23619817197322845, accuracy: 93.1 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 0.21744297444820404, accuracy: 93.7 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 0.22544261813163757, accuracy: 93.4 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 0.22064393758773804, accuracy: 93.5 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 0.22021743655204773, accuracy: 93.6 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 0.23292586207389832, accuracy: 92.5 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 0.3785, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 0.3483, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 0.2701, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 0.3352, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 0.3206, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 0.2990, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 0.2957, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 0.1905, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 0.4015, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 0.3046, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 0.30500611662864685, accuracy: 91.0 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 0.6168373823165894, accuracy: 81.3 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 0.38216277956962585, accuracy: 88.5 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 0.6370242834091187, accuracy: 79.8 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 0.29538968205451965, accuracy: 91.5 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 0.29121267795562744, accuracy: 91.8 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 0.2972395718097687, accuracy: 90.8 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 0.2892094552516937, accuracy: 91.1 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 0.28690406680107117, accuracy: 91.4 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 0.2843276858329773, accuracy: 91.6 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 0.3006, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 0.3170, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 0.3026, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 0.2415, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 0.3118, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 0.2467, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 0.3909, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 0.3525, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 0.2789, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 0.2792, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 0.23333638906478882, accuracy: 92.8 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 0.4341060519218445, accuracy: 87.1 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 0.2283218652009964, accuracy: 93.0 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 0.2370455414056778, accuracy: 92.2 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 0.2031790018081665, accuracy: 93.7 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 0.19760334491729736, accuracy: 94.3 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 0.1965717375278473, accuracy: 93.8 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 0.20178566873073578, accuracy: 93.6 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 0.19405828416347504, accuracy: 93.8 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 0.19389361143112183, accuracy: 94.0 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 0.2466, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 0.3624, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 0.2542, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 0.3336, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 0.3006, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 0.1887, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 0.4268, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 0.1979, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 0.2424, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 0.1524, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 0.24857330322265625, accuracy: 91.8 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 0.4590570330619812, accuracy: 85.5 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 0.24850739538669586, accuracy: 92.4 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 0.2506488561630249, accuracy: 92.4 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 0.24881470203399658, accuracy: 92.5 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 0.24069006741046906, accuracy: 93.2 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 0.29526063799858093, accuracy: 90.9 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 0.23456664383411407, accuracy: 92.7 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 0.23864632844924927, accuracy: 92.6 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 0.23312777280807495, accuracy: 92.9 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 0.2081, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 0.2685, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 0.3218, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 0.3423, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 0.3077, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 0.2712, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 0.3221, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 0.1888, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 0.2404, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 0.2032, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 0.2773991525173187, accuracy: 91.5 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 0.27165713906288147, accuracy: 92.2 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 0.8158428072929382, accuracy: 75.2 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 1.2324453592300415, accuracy: 72.6 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 0.2698051333427429, accuracy: 92.1 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 0.268112450838089, accuracy: 91.8 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 0.2594601809978485, accuracy: 91.8 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 0.25892943143844604, accuracy: 92.6 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 0.2762398421764374, accuracy: 90.8 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 0.2692667245864868, accuracy: 91.7 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 0.2386, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 0.2141, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 0.1704, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 0.2283, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 0.4471, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 0.1664, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 0.2657, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 0.1793, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 0.1878, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 0.2841, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 0.19244572520256042, accuracy: 93.9 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 0.4456201195716858, accuracy: 85.3 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 0.3451487123966217, accuracy: 88.2 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 0.4886503517627716, accuracy: 82.1 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 0.2151525765657425, accuracy: 92.6 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 0.17922890186309814, accuracy: 94.2 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 0.18551155924797058, accuracy: 93.7 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 0.17405900359153748, accuracy: 94.1 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 0.17390558123588562, accuracy: 94.3 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 0.174483060836792, accuracy: 94.4 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 0.2354, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 0.3277, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 0.3708, batch time: 0.08, accuracy:  88.28%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 0.2639, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 0.3610, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 0.1866, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 0.3827, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 0.2467, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 0.3156, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 0.2819, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 0.24981756508350372, accuracy: 92.5 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 0.6183252930641174, accuracy: 81.1 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 0.30578911304473877, accuracy: 91.5 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 0.33205512166023254, accuracy: 88.5 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 0.24304212629795074, accuracy: 92.6 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 0.3338640630245209, accuracy: 91.3 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 0.2376212179660797, accuracy: 93.1 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 0.23467271029949188, accuracy: 92.7 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 0.26633450388908386, accuracy: 91.0 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 0.23126496374607086, accuracy: 92.9 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 0.2822, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 0.2746, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 0.2318, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 0.2559, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 0.2266, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 0.3038, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 0.3218, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 0.2844, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 0.2948, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 0.3906, batch time: 0.12, accuracy:  90.62%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 0.21923834085464478, accuracy: 93.6 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 0.48701906204223633, accuracy: 82.5 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 0.27670755982398987, accuracy: 92.6 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 0.9349196553230286, accuracy: 72.5 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 0.20800550282001495, accuracy: 94.5 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 0.2168983668088913, accuracy: 94.3 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 0.2104911059141159, accuracy: 94.2 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 0.20349065959453583, accuracy: 94.3 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 0.20603567361831665, accuracy: 94.5 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 0.19849886000156403, accuracy: 94.5 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 0.2188, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 0.2800, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 0.1855, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 0.2208, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 0.2643, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 0.2487, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 0.2105, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 0.2111, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 0.2583, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 0.3188, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 0.27212440967559814, accuracy: 92.1 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 0.5389853715896606, accuracy: 83.8 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 0.2673228681087494, accuracy: 91.6 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 0.37667372822761536, accuracy: 87.3 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 0.26513656973838806, accuracy: 91.6 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 0.2710282504558563, accuracy: 91.9 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 0.2729826271533966, accuracy: 91.8 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 0.2674853801727295, accuracy: 91.5 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 0.262705534696579, accuracy: 91.6 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 0.25343629717826843, accuracy: 92.3 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 0.2459, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 0.2262, batch time: 0.07, accuracy:  92.97%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 0.3344, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 0.2746, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 0.3040, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 0.2217, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 0.2485, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 0.4118, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 0.3756, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 0.3793, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 0.2997962236404419, accuracy: 90.7 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 0.4453791677951813, accuracy: 86.5 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 0.43872490525245667, accuracy: 86.4 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 0.7586936354637146, accuracy: 75.9 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 0.2733664810657501, accuracy: 92.7 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 0.284288614988327, accuracy: 92.0 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 0.25769108533859253, accuracy: 93.6 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 0.26284289360046387, accuracy: 92.8 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 0.25856465101242065, accuracy: 92.8 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 0.2641187012195587, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 0.2743, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 0.2197, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 0.2120, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 0.2827, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 0.4208, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 0.3338, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 0.4206, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 0.3874, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 0.1973, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 0.3377, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 0.2397429496049881, accuracy: 92.7 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 0.2501125931739807, accuracy: 92.1 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 0.45422694087028503, accuracy: 84.6 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 0.7221490144729614, accuracy: 78.6 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 0.23987805843353271, accuracy: 93.0 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 0.22027450799942017, accuracy: 93.3 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 0.2279810905456543, accuracy: 93.1 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 0.23304195702075958, accuracy: 92.3 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 0.2191925048828125, accuracy: 92.8 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 0.20779506862163544, accuracy: 94.0 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 0.2773, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 0.3672, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 0.3362, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 0.2055, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 0.3038, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 0.2787, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 0.4326, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 0.3304, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 0.2217, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 0.2125, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 0.3323799967765808, accuracy: 89.9 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 0.7393911480903625, accuracy: 79.2 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 0.45931878685951233, accuracy: 87.0 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 0.7842568755149841, accuracy: 79.0 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 0.2896757423877716, accuracy: 91.4 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 0.29976001381874084, accuracy: 91.2 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 0.2821686565876007, accuracy: 91.1 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 0.2930116057395935, accuracy: 91.2 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 0.2766101658344269, accuracy: 91.0 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 0.27643781900405884, accuracy: 91.5 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 0.3802, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 0.2204, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 0.3164, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 0.1639, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 0.1680, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 0.3033, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 0.1786, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 0.3236, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 0.1589, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 0.3085, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 0.24108842015266418, accuracy: 92.2 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 0.7170671224594116, accuracy: 76.1 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 0.4072803258895874, accuracy: 87.5 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 0.614018976688385, accuracy: 79.1 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 0.23601216077804565, accuracy: 92.9 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 0.247974693775177, accuracy: 92.4 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 0.25176796317100525, accuracy: 92.3 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 0.24229788780212402, accuracy: 91.9 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 0.23951292037963867, accuracy: 92.6 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 0.22586074471473694, accuracy: 93.0 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 0.3613, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 0.3683, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 0.1786, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 0.1889, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 0.2491, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 0.2506, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 0.2822, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 0.2799, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 0.1768, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 0.2683, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 0.24744470417499542, accuracy: 92.4 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 0.7814522981643677, accuracy: 77.8 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 0.35506471991539, accuracy: 88.5 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 0.955722451210022, accuracy: 74.0 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 0.25934547185897827, accuracy: 91.7 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 0.23187193274497986, accuracy: 92.3 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 0.24897076189517975, accuracy: 91.6 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 0.2550848126411438, accuracy: 91.8 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 0.23817020654678345, accuracy: 92.9 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 0.2243441939353943, accuracy: 93.2 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 0.3019, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 0.1756, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 0.2388, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 0.2259, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 0.3135, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 0.3685, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 0.2904, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 0.2111, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 0.4107, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 0.2225, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 0.28098034858703613, accuracy: 90.9 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 0.7167873382568359, accuracy: 79.8 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 0.3539704382419586, accuracy: 88.6 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 0.48237645626068115, accuracy: 84.1 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 0.2665770351886749, accuracy: 90.2 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 0.2526903748512268, accuracy: 91.2 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 0.268520712852478, accuracy: 91.6 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 0.2544592320919037, accuracy: 91.4 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 0.2821750044822693, accuracy: 90.8 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 0.3061503469944, accuracy: 90.3 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 0.3181, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 0.2269, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 0.2887, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 0.1832, batch time: 0.07, accuracy:  92.97%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 0.3099, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 0.3991, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 0.2772, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 0.2778, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 0.3338, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 0.2765, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 0.263896107673645, accuracy: 91.8 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 0.34098172187805176, accuracy: 89.9 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 0.2480083405971527, accuracy: 92.4 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 0.247941255569458, accuracy: 92.4 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 0.2921696901321411, accuracy: 90.6 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 0.2463892698287964, accuracy: 92.6 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 0.2572302520275116, accuracy: 92.3 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 0.24480147659778595, accuracy: 92.8 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 0.2568032145500183, accuracy: 91.1 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 0.2553330361843109, accuracy: 91.6 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 0.2333, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 0.1840, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 0.2104, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 0.2236, batch time: 0.07, accuracy:  92.97%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 0.4244, batch time: 0.07, accuracy:  92.19%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 0.3455, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 0.2068, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 0.4998, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 0.3663, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 0.2627, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 0.25105324387550354, accuracy: 92.1 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 0.31647539138793945, accuracy: 89.8 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 0.5965831279754639, accuracy: 82.6 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 0.24601054191589355, accuracy: 91.8 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 0.6959609389305115, accuracy: 79.4 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 0.22960446774959564, accuracy: 92.8 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 0.2307700216770172, accuracy: 93.4 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 0.22384938597679138, accuracy: 93.3 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 0.22269639372825623, accuracy: 93.5 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 0.22268547117710114, accuracy: 93.6 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 0.1650, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 0.3347, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 0.1661, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 0.2334, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 0.1951, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 0.3249, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 0.2674, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 0.3310, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 0.2207, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 0.2500, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 0.2643735408782959, accuracy: 91.5 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 0.49087727069854736, accuracy: 83.7 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 0.5257639288902283, accuracy: 83.8 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 0.4682675302028656, accuracy: 87.6 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 0.23327933251857758, accuracy: 93.8 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 0.2266959398984909, accuracy: 93.8 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 0.2247108519077301, accuracy: 94.0 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 0.22479364275932312, accuracy: 93.7 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 0.23090507090091705, accuracy: 93.5 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 0.22070161998271942, accuracy: 93.7 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 0.3392, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 0.1912, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 0.2845, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 0.2523, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 0.2921, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 0.1809, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 0.3754, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 0.2146, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 0.3089, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 0.3779, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 0.2514253258705139, accuracy: 92.6 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 0.4211856424808502, accuracy: 87.6 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 0.41355636715888977, accuracy: 88.3 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 0.3596590459346771, accuracy: 88.5 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 0.24350330233573914, accuracy: 93.2 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 0.24145443737506866, accuracy: 93.1 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 0.2422744631767273, accuracy: 93.4 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 0.23985828459262848, accuracy: 93.5 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 0.24098990857601166, accuracy: 93.4 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 0.2369789332151413, accuracy: 93.5 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 0.2044, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 0.2626, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 0.1806, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 0.3440, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 0.1824, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 0.2542, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 0.4801, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 0.2551, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 0.3093, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 0.3514, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 0.22507375478744507, accuracy: 93.0 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 0.5058824419975281, accuracy: 83.8 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 0.21939235925674438, accuracy: 93.3 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 0.21394382417201996, accuracy: 93.2 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 0.2270551472902298, accuracy: 92.8 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 0.2378930151462555, accuracy: 92.5 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 0.25304898619651794, accuracy: 92.4 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 0.2619517743587494, accuracy: 91.4 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 0.20771269500255585, accuracy: 93.2 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 0.206924706697464, accuracy: 93.3 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 0.3810, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 0.1618, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 0.2733, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 0.2522, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 0.3642, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 0.2712, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 0.1469, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 0.2688, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 0.2038, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 0.2386, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 0.24796542525291443, accuracy: 92.6 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 0.5461544990539551, accuracy: 84.8 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 0.342018723487854, accuracy: 89.3 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 0.2526555061340332, accuracy: 92.6 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 0.24935780465602875, accuracy: 92.9 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 0.23771335184574127, accuracy: 93.0 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 0.2362293154001236, accuracy: 92.8 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 0.2415134310722351, accuracy: 93.2 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 0.23151038587093353, accuracy: 93.1 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 0.2314322292804718, accuracy: 92.9 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 0.2354, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 0.1619, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 0.3116, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 0.2530, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 0.1800, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 0.2535, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 0.1830, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 0.2717, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 0.1996, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 0.2781, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 0.20709818601608276, accuracy: 93.3 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 0.5539674758911133, accuracy: 83.3 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 0.44213640689849854, accuracy: 87.2 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 0.7449362874031067, accuracy: 76.1 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 0.1986311674118042, accuracy: 94.0 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 0.19520944356918335, accuracy: 93.7 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 0.2025577574968338, accuracy: 93.6 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 0.2020396739244461, accuracy: 93.7 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 0.19403700530529022, accuracy: 94.4 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 0.20346739888191223, accuracy: 93.7 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 0.2779, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 0.2592, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 0.2189, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 0.3294, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 0.1816, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 0.2448, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 0.3189, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 0.2475, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 0.2257, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 0.2813, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 0.2762663662433624, accuracy: 92.9 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 0.7746639251708984, accuracy: 77.8 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 0.2693164348602295, accuracy: 92.7 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 0.2654733657836914, accuracy: 92.7 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 0.260891318321228, accuracy: 92.7 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 0.2540631592273712, accuracy: 92.8 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 0.25648748874664307, accuracy: 92.7 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 0.24581629037857056, accuracy: 93.4 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 0.25304749608039856, accuracy: 93.4 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 0.24468666315078735, accuracy: 93.3 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 0.2892, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 0.2381, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 0.1804, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 0.3528, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 0.1721, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 0.2523, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 0.2302, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 0.2334, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 0.1547, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 0.2508, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 0.22524608671665192, accuracy: 93.3 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 0.4175809919834137, accuracy: 87.1 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 0.22903619706630707, accuracy: 93.5 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 0.8428349494934082, accuracy: 77.1 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 0.2186940610408783, accuracy: 93.6 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 0.22077347338199615, accuracy: 93.6 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 0.2169068604707718, accuracy: 93.5 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 0.21814680099487305, accuracy: 93.6 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 0.2261165827512741, accuracy: 93.1 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 0.21553902328014374, accuracy: 93.3 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 0.2630, batch time: 0.09, accuracy:  92.19%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 0.2884, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 0.1233, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 0.3464, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 0.2226, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 0.2372, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 0.2617, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 0.2155, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 0.2550, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 0.2079, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 0.2672208547592163, accuracy: 91.5 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 0.40633735060691833, accuracy: 88.0 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 0.5361138582229614, accuracy: 82.9 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 0.5942373871803284, accuracy: 81.8 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 0.2604998052120209, accuracy: 91.8 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 0.25103625655174255, accuracy: 92.7 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 0.26111552119255066, accuracy: 92.1 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 0.2734109163284302, accuracy: 91.4 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 0.2520960867404938, accuracy: 92.3 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 0.24558290839195251, accuracy: 93.0 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 0.3640, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 0.2222, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 0.1897, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 0.2735, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 0.1717, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 0.3381, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 0.2682, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 0.3417, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 0.2784, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 0.5463, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 0.27397990226745605, accuracy: 90.3 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 0.7695651054382324, accuracy: 78.2 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 0.2577960789203644, accuracy: 91.4 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 0.5455341339111328, accuracy: 82.1 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 0.2559691071510315, accuracy: 90.9 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 0.24333946406841278, accuracy: 92.3 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 0.2407349795103073, accuracy: 92.0 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 0.2305341511964798, accuracy: 93.0 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 0.22970788180828094, accuracy: 92.7 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 0.2348790168762207, accuracy: 93.5 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 0.3106, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 0.3908, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 0.2675, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 0.1802, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 0.1917, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 0.2416, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 0.1430, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 0.5526, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 0.1876, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 0.3330, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 0.26011475920677185, accuracy: 92.5 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 0.6268557906150818, accuracy: 83.1 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 0.25761088728904724, accuracy: 92.8 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 0.2512997090816498, accuracy: 92.6 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 1.0273675918579102, accuracy: 73.6 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 0.2486453652381897, accuracy: 93.1 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 0.2463921755552292, accuracy: 93.6 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 0.2575983703136444, accuracy: 92.8 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 0.24445679783821106, accuracy: 93.2 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 0.23816613852977753, accuracy: 92.9 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 0.2442, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 0.1756, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 0.2022, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 0.1309, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 0.2176, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 0.2680, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 0.2495, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 0.3839, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 0.3195, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 0.3613, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 0.25879019498825073, accuracy: 92.1 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 0.58766770362854, accuracy: 82.4 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 0.5178705453872681, accuracy: 83.7 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 1.051085114479065, accuracy: 72.3 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 0.24497272074222565, accuracy: 92.4 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 0.2486962527036667, accuracy: 92.4 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 0.24404571950435638, accuracy: 92.8 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 0.23769378662109375, accuracy: 92.7 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 0.2993033528327942, accuracy: 91.0 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 0.23674003779888153, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 0.1340, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 0.2572, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 0.2932, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 0.2508, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 0.3152, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 0.2454, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 0.2096, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 0.2073, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 0.2451, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 0.1701, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 0.21947133541107178, accuracy: 93.6 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 0.3024607002735138, accuracy: 90.0 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 0.21729731559753418, accuracy: 94.2 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 0.21725992858409882, accuracy: 94.2 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 0.21341992914676666, accuracy: 94.1 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 0.21338437497615814, accuracy: 94.1 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 0.22356781363487244, accuracy: 93.4 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 0.21056434512138367, accuracy: 94.5 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 0.21353162825107574, accuracy: 94.2 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 0.21425656974315643, accuracy: 94.3 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 0.4864, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 0.2841, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 0.3444, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 0.3446, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 0.2429, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 0.1847, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 0.2978, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 0.3073, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 0.2258, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 0.1945, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 0.21933415532112122, accuracy: 94.6 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 0.4597395658493042, accuracy: 86.7 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 0.2079877108335495, accuracy: 94.7 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 0.20451079308986664, accuracy: 94.5 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 0.33225494623184204, accuracy: 90.1 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 0.19458824396133423, accuracy: 94.1 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 0.19700366258621216, accuracy: 94.5 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 0.18862426280975342, accuracy: 94.8 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 0.18974196910858154, accuracy: 94.5 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 0.18764656782150269, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 0.1944, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 0.3684, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 0.2405, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 0.2820, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 0.1508, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 0.2292, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 0.2548, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 0.3701, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 0.2519, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 0.2139, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 0.27208882570266724, accuracy: 91.8 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 0.35654324293136597, accuracy: 89.4 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 0.25785762071609497, accuracy: 92.9 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 0.25777310132980347, accuracy: 92.9 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 0.24737681448459625, accuracy: 93.3 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 0.2414521425962448, accuracy: 93.0 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 0.24862079322338104, accuracy: 92.5 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 0.23784784972667694, accuracy: 93.4 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 0.23947101831436157, accuracy: 93.6 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 0.24246136844158173, accuracy: 93.1 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 0.2789, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 0.1972, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 0.3293, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 0.2700, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 0.3482, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 0.2659, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 0.4211, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 0.3567, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 0.3685, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 0.1735, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 0.2606707513332367, accuracy: 93.3 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 0.47203633189201355, accuracy: 87.7 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 0.2529340088367462, accuracy: 93.1 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 0.2519615888595581, accuracy: 93.3 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 0.7757471203804016, accuracy: 77.1 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 0.23837921023368835, accuracy: 93.5 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 0.2440498173236847, accuracy: 93.3 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 0.2359132170677185, accuracy: 93.6 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 0.2370987832546234, accuracy: 93.3 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 0.24876487255096436, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 0.1737, batch time: 0.06, accuracy:  93.75%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 0.2715, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 0.2553, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 0.1675, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 0.1753, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 0.2812, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 0.2836, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 0.2736, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 0.2839, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 0.2486, batch time: 0.07, accuracy:  93.75%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 0.22150450944900513, accuracy: 93.6 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 0.3160570561885834, accuracy: 89.2 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 0.21752145886421204, accuracy: 93.7 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 0.21726219356060028, accuracy: 93.8 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 0.22048470377922058, accuracy: 93.5 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 0.21373401582241058, accuracy: 93.9 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 0.22903071343898773, accuracy: 93.1 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 0.21178320050239563, accuracy: 93.9 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 0.21372616291046143, accuracy: 93.9 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 0.2045547515153885, accuracy: 94.1 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 0.4403, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 0.1825, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 0.2268, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 0.2367, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 0.3072, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 0.2767, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 0.2209, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 0.3007, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 0.3613, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 0.1529, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 0.2426294982433319, accuracy: 94.2 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 0.3010129928588867, accuracy: 91.6 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 0.2522091865539551, accuracy: 93.4 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 0.23227772116661072, accuracy: 94.4 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 0.34048375487327576, accuracy: 89.0 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 0.23154696822166443, accuracy: 94.1 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 0.2332509607076645, accuracy: 94.1 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 0.2212577611207962, accuracy: 94.4 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 0.22241109609603882, accuracy: 94.5 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 0.22769795358181, accuracy: 93.9 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 0.3781, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 0.2852, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 0.2407, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 0.4269, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 0.1998, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 0.4600, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 0.2297, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 0.2948, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 0.2332, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 0.2873, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 0.2755142152309418, accuracy: 91.8 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 0.3939434885978699, accuracy: 87.9 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 0.27484139800071716, accuracy: 91.9 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 0.35344645380973816, accuracy: 89.7 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 0.27723070979118347, accuracy: 92.6 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 0.26776304841041565, accuracy: 92.5 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 0.2499810755252838, accuracy: 92.9 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 0.251155823469162, accuracy: 92.8 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 0.25592970848083496, accuracy: 92.8 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 0.25162771344184875, accuracy: 93.2 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 0.3112, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 0.4547, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 0.2189, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 0.2634, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 0.2075, batch time: 0.09, accuracy:  92.97%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 0.1809, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 0.3930, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 0.2574, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 0.3196, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 0.1353, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 0.23090581595897675, accuracy: 93.4 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 0.65092933177948, accuracy: 80.8 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 0.4778989255428314, accuracy: 85.2 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 0.6451575756072998, accuracy: 80.0 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 0.2393563985824585, accuracy: 93.0 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 0.2209431529045105, accuracy: 94.0 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 0.2302970439195633, accuracy: 93.1 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 0.21628199517726898, accuracy: 93.7 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 0.21953171491622925, accuracy: 94.0 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 0.2128337025642395, accuracy: 94.1 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 0.2477, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 0.2088, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 0.2278, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 0.1059, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 0.2957, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 0.3330, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 0.1984, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 0.2064, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 0.2414, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 0.2652, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 0.23692528903484344, accuracy: 93.7 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 0.3247618079185486, accuracy: 90.4 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 0.23219946026802063, accuracy: 93.6 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 1.070054292678833, accuracy: 75.0 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 0.2271910458803177, accuracy: 93.7 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 0.22364264726638794, accuracy: 93.8 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 0.21646465361118317, accuracy: 94.1 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 0.24034447968006134, accuracy: 92.7 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 0.2518688440322876, accuracy: 92.5 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 0.2144119292497635, accuracy: 93.7 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 0.2082, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 0.2441, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 0.4261, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 0.3140, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 0.1969, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 0.2367, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 0.2220, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 0.1818, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 0.4128, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 0.3049, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 0.30074799060821533, accuracy: 91.4 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 0.43788981437683105, accuracy: 87.0 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 0.2852083742618561, accuracy: 91.6 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 0.2746892273426056, accuracy: 92.2 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 0.39688923954963684, accuracy: 89.1 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 0.2862197160720825, accuracy: 92.4 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 0.2697089612483978, accuracy: 92.4 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 0.26206329464912415, accuracy: 92.8 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 0.273261696100235, accuracy: 92.7 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 0.2585710287094116, accuracy: 93.0 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 0.2962, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 0.2659, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 0.3129, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 0.1957, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 0.2502, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 0.4281, batch time: 0.08, accuracy:  89.84%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 0.3128, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 0.2319, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 0.2215, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 0.2124, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 0.23590131103992462, accuracy: 92.1 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 0.4914885461330414, accuracy: 83.1 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 0.2721961438655853, accuracy: 90.4 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 0.5423294901847839, accuracy: 83.0 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 0.22907480597496033, accuracy: 92.8 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 0.21655520796775818, accuracy: 92.7 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 0.22072039544582367, accuracy: 92.6 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 0.24488864839076996, accuracy: 91.8 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 0.2221410572528839, accuracy: 92.0 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 0.2198738157749176, accuracy: 92.5 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 0.1649, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 0.2724, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 0.2063, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 0.2619, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 0.3066, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 0.1593, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 0.1411, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 0.3022, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 0.2438, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 0.1535, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 0.26754042506217957, accuracy: 92.2 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 0.7551440000534058, accuracy: 79.0 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 0.41722625494003296, accuracy: 87.5 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 0.7975687384605408, accuracy: 79.8 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 0.2751988470554352, accuracy: 92.0 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 0.2613646388053894, accuracy: 91.8 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 0.26019540429115295, accuracy: 91.7 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 0.26012682914733887, accuracy: 92.5 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 0.2483525425195694, accuracy: 92.2 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 0.25473058223724365, accuracy: 92.1 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 0.1883, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 0.3096, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 0.2509, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 0.2413, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 0.2924, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 0.1417, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 0.2553, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 0.3507, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 0.2687, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 0.2310, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 0.23100334405899048, accuracy: 92.9 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 0.28977373242378235, accuracy: 90.9 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 0.2238796502351761, accuracy: 92.7 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 0.48262453079223633, accuracy: 84.0 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 0.808192253112793, accuracy: 75.7 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 0.536853551864624, accuracy: 85.0 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 0.20922145247459412, accuracy: 93.8 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 0.20662201941013336, accuracy: 93.2 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 0.20346173644065857, accuracy: 93.8 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 0.21215344965457916, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 0.2416, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 0.4555, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 0.2826, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 0.2545, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 0.2376, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 0.2229, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 0.2786, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 0.3179, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 0.2467, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 0.2409, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 0.2390444427728653, accuracy: 92.9 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 0.3002084791660309, accuracy: 90.7 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 0.2354717254638672, accuracy: 92.9 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 0.23055149614810944, accuracy: 93.1 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 0.31611865758895874, accuracy: 89.8 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 0.22196702659130096, accuracy: 92.9 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 0.23894745111465454, accuracy: 93.3 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 0.23987187445163727, accuracy: 93.0 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 0.23248375952243805, accuracy: 93.0 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 0.21919062733650208, accuracy: 93.7 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 0.2470, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 0.2764, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 0.2912, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 0.3504, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 0.2666, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 0.1468, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 0.2055, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 0.2761, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 0.3387, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 0.2484, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 0.20879366993904114, accuracy: 93.8 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 0.3093101382255554, accuracy: 90.4 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 0.2161577045917511, accuracy: 92.9 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 0.2064947783946991, accuracy: 93.8 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 0.22560754418373108, accuracy: 92.9 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 0.2017916887998581, accuracy: 93.8 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 0.20164823532104492, accuracy: 94.5 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 0.20496335625648499, accuracy: 94.4 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 0.20458835363388062, accuracy: 94.3 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 0.20657290518283844, accuracy: 93.6 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 0.4282, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 0.1653, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 0.2280, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 0.3842, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 0.2679, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 0.1412, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 0.2361, batch time: 0.28, accuracy:  94.53%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 0.0818, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 0.3794, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 0.2042, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 0.25829648971557617, accuracy: 92.5 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 0.5458880662918091, accuracy: 83.0 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 1.6663850545883179, accuracy: 56.8 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 0.3943571448326111, accuracy: 86.6 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 0.22586381435394287, accuracy: 93.6 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 0.22394171357154846, accuracy: 93.6 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 0.22392641007900238, accuracy: 93.3 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 0.22221794724464417, accuracy: 93.3 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 0.22396595776081085, accuracy: 93.2 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 0.2501811385154724, accuracy: 92.8 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 0.1070, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 0.3675, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 0.2681, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 0.1987, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 0.2247, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 0.2100, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 0.3056, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 0.2411, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 0.3336, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 0.3126, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 0.25290989875793457, accuracy: 92.3 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 0.5520464181900024, accuracy: 82.0 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 0.39111730456352234, accuracy: 87.2 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 0.3903317153453827, accuracy: 89.0 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 0.25214052200317383, accuracy: 92.1 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 0.24277551472187042, accuracy: 92.6 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 0.23878589272499084, accuracy: 92.8 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 0.24041546881198883, accuracy: 93.0 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 0.24663370847702026, accuracy: 92.3 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 0.23692694306373596, accuracy: 92.9 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 0.1699, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 0.2382, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 0.2583, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 0.5197, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 0.2774, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 0.4841, batch time: 0.07, accuracy:  89.06%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 0.4025, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 0.2154, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 0.2138, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 0.1310, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 0.23188509047031403, accuracy: 92.6 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 0.38344836235046387, accuracy: 86.5 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 0.23188509047031403, accuracy: 92.6 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 0.2288619577884674, accuracy: 92.9 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 0.31202495098114014, accuracy: 89.6 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 0.2762441635131836, accuracy: 91.7 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 0.24883891642093658, accuracy: 92.3 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 0.25917237997055054, accuracy: 92.1 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 0.21713955700397491, accuracy: 94.1 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 0.20939049124717712, accuracy: 94.1 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 0.2125, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 0.3550, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 0.2456, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 0.2519, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 0.2647, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 0.2894, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 0.3693, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 0.3816, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 0.2830, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 0.1917, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 0.2696855664253235, accuracy: 91.5 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 0.3862621784210205, accuracy: 88.8 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 0.26275306940078735, accuracy: 91.9 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 0.2556428015232086, accuracy: 92.3 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 0.41544637084007263, accuracy: 86.1 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 0.25377652049064636, accuracy: 92.5 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 0.25909674167633057, accuracy: 92.3 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 0.2757439613342285, accuracy: 91.8 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 0.24962419271469116, accuracy: 92.8 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 0.24711214005947113, accuracy: 92.2 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 0.2961, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 0.3886, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 0.2351, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 0.2205, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 0.3914, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 0.2717, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 0.1564, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 0.2962, batch time: 0.30, accuracy:  92.19%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 0.2523, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 0.4347, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 0.2497199922800064, accuracy: 91.2 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 0.26125240325927734, accuracy: 91.2 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 0.22359058260917664, accuracy: 92.9 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 0.22359058260917664, accuracy: 92.9 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 0.2768023908138275, accuracy: 90.8 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 0.21730586886405945, accuracy: 92.9 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 0.47221997380256653, accuracy: 83.1 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 0.20936284959316254, accuracy: 93.6 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 0.21045537292957306, accuracy: 93.4 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 0.21116551756858826, accuracy: 93.5 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 0.3129, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 0.3284, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 0.2102, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 0.1844, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 0.3377, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 0.2293, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 0.2841, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 0.3323, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 0.2114, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 0.2755, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 0.2353951334953308, accuracy: 93.8 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 0.33422937989234924, accuracy: 89.8 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 0.2365652173757553, accuracy: 93.2 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 0.6431850790977478, accuracy: 79.5 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 0.22252818942070007, accuracy: 93.9 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 0.2195959985256195, accuracy: 94.0 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 0.22703766822814941, accuracy: 93.7 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 0.22622230648994446, accuracy: 93.5 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 0.214908167719841, accuracy: 93.9 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 0.23642057180404663, accuracy: 92.9 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 0.3555, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 0.3223, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 0.2011, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 0.2035, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 0.1669, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 0.2842, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 0.3675, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 0.2195, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 0.3044, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 0.2301, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 0.2561233341693878, accuracy: 92.4 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 0.7275534868240356, accuracy: 79.1 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 0.4576316773891449, accuracy: 85.6 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 0.32482609152793884, accuracy: 89.9 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 0.25742533802986145, accuracy: 91.6 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 0.24830907583236694, accuracy: 92.0 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 0.2564757168292999, accuracy: 91.9 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 0.243431955575943, accuracy: 92.0 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 0.2421986609697342, accuracy: 92.5 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 0.24083425104618073, accuracy: 92.2 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 0.2784, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 0.2424, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 0.1397, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 0.1988, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 0.2330, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 0.1436, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 0.3439, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 0.5430, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 0.1945, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 0.3523, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 0.2670115828514099, accuracy: 91.4 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 0.29393333196640015, accuracy: 91.2 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 0.24920043349266052, accuracy: 92.4 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 0.24849990010261536, accuracy: 92.7 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 0.34765201807022095, accuracy: 88.6 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 0.24524594843387604, accuracy: 93.3 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 0.2593437135219574, accuracy: 91.9 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 0.24202856421470642, accuracy: 93.1 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 0.2505077123641968, accuracy: 92.5 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 0.25962498784065247, accuracy: 92.5 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 0.3548, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 0.3150, batch time: 0.33, accuracy:  88.28%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 0.1512, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 0.2188, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 0.2567, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 0.3064, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 0.2477, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 0.3220, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 0.1732, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 0.2297, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 0.25107142329216003, accuracy: 93.2 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 0.39452308416366577, accuracy: 87.9 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 0.39871713519096375, accuracy: 87.7 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 0.6295225024223328, accuracy: 81.8 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 0.24446578323841095, accuracy: 93.5 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 0.2411104142665863, accuracy: 93.7 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 0.24721650779247284, accuracy: 93.4 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 0.24012117087841034, accuracy: 93.4 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 0.24505385756492615, accuracy: 93.3 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 0.23478710651397705, accuracy: 93.6 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 0.1630, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 0.1533, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 0.2991, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 0.2653, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 0.2916, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 0.3764, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 0.2767, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 0.3032, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 0.1411, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 0.2163, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 0.26253625750541687, accuracy: 92.0 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 0.384941965341568, accuracy: 88.4 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 0.33689939975738525, accuracy: 89.5 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 0.4042539596557617, accuracy: 87.5 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 0.29571473598480225, accuracy: 90.4 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 0.3395375907421112, accuracy: 88.8 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 0.3199571371078491, accuracy: 89.7 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 0.2514159083366394, accuracy: 92.3 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 0.24620822072029114, accuracy: 92.3 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 0.243382528424263, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 0.2907, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 0.2634, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 0.2175, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 0.2070, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 0.2161, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 0.1968, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 0.1606, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 0.1428, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 0.1252, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 0.3523, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 0.20544171333312988, accuracy: 94.4 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 0.2265094518661499, accuracy: 94.3 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 0.2541833221912384, accuracy: 92.9 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 0.4118979573249817, accuracy: 87.2 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 0.19951754808425903, accuracy: 94.6 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 0.19996832311153412, accuracy: 94.6 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 0.21327944099903107, accuracy: 93.5 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 0.19397835433483124, accuracy: 95.1 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 0.19270913302898407, accuracy: 94.7 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 0.19104334712028503, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 0.2631, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 0.2529, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 0.1634, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 0.2188, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 0.2863, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 0.2460, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 0.2920, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 0.3162, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 0.2143, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 0.2224, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 0.2347981035709381, accuracy: 93.2 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 0.23303213715553284, accuracy: 93.2 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 0.31637752056121826, accuracy: 90.2 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 0.26756879687309265, accuracy: 92.2 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 0.21930037438869476, accuracy: 93.5 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 0.25060251355171204, accuracy: 92.7 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 0.22561141848564148, accuracy: 92.8 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 0.2224917709827423, accuracy: 93.8 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 0.2080220729112625, accuracy: 93.8 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 0.20646585524082184, accuracy: 93.8 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 0.3177, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 0.2534, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 0.2319, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 0.2399, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 0.3182, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 0.1721, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 0.1928, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 0.1303, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 0.1947, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 0.2897, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 0.22312292456626892, accuracy: 92.7 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 0.4027838110923767, accuracy: 88.2 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 0.2154250293970108, accuracy: 93.4 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 1.3341031074523926, accuracy: 60.4 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 0.3186202645301819, accuracy: 89.6 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 0.19306248426437378, accuracy: 93.8 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 0.19235330820083618, accuracy: 93.9 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 0.18514981865882874, accuracy: 94.5 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 0.1900404393672943, accuracy: 93.5 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 0.18713326752185822, accuracy: 93.8 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 0.2091, batch time: 0.09, accuracy:  92.97%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 0.2735, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 0.1951, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 0.2797, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 0.2574, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 0.2123, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 0.2000, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 0.2749, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 0.1751, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 0.2696, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 0.25549429655075073, accuracy: 92.5 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 0.25718316435813904, accuracy: 92.6 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 0.38433486223220825, accuracy: 88.3 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 0.3615961968898773, accuracy: 89.1 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 0.2443784475326538, accuracy: 92.6 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 0.24828393757343292, accuracy: 91.9 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 0.24467766284942627, accuracy: 93.0 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 0.23830923438072205, accuracy: 92.7 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 0.2768349051475525, accuracy: 91.4 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 0.23698748648166656, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 0.1967, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 0.2127, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 0.3151, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 0.3207, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 0.2175, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 0.3353, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 0.2293, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 0.1572, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 0.2360, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 0.2068, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 0.19047890603542328, accuracy: 94.1 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 0.2273617535829544, accuracy: 92.6 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 0.18728867173194885, accuracy: 93.3 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 0.44959381222724915, accuracy: 84.8 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 0.17740292847156525, accuracy: 94.1 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 0.17460711300373077, accuracy: 94.6 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 0.16723701357841492, accuracy: 94.7 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 0.17576737701892853, accuracy: 93.8 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 0.17052693665027618, accuracy: 94.6 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 0.16498367488384247, accuracy: 94.9 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 0.2436, batch time: 0.06, accuracy:  92.97%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 0.3800, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 0.2105, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 0.2663, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 0.1888, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 0.2255, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 0.1853, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 0.1966, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 0.2029, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 0.2919, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 0.24293942749500275, accuracy: 92.2 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 0.32886946201324463, accuracy: 89.2 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 0.5435574054718018, accuracy: 84.3 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 0.47461551427841187, accuracy: 86.4 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 0.2339460700750351, accuracy: 93.2 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 0.22860080003738403, accuracy: 92.8 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 0.2275696098804474, accuracy: 93.1 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 0.232662633061409, accuracy: 92.8 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 0.25666406750679016, accuracy: 91.5 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 0.22586603462696075, accuracy: 93.0 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 0.2851, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 0.3272, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 0.3638, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 0.2218, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 0.2096, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 0.2274, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 0.0955, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 0.3533, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 0.3675, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 0.1872, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 0.2551990747451782, accuracy: 92.0 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 0.28923436999320984, accuracy: 90.1 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 0.411099374294281, accuracy: 87.0 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 0.6442220211029053, accuracy: 83.4 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 0.21694420278072357, accuracy: 93.2 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 0.21163426339626312, accuracy: 93.9 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 0.218342125415802, accuracy: 93.2 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 0.2067403644323349, accuracy: 93.1 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 0.20738008618354797, accuracy: 93.3 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 0.2213188111782074, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 0.2789, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 0.2703, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 0.3116, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 0.2889, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 0.1336, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 0.2248, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 0.2241, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 0.1094, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 0.2302, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 0.2890, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 0.24598431587219238, accuracy: 91.8 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 0.24508602917194366, accuracy: 92.3 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 0.33909741044044495, accuracy: 89.2 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 0.45711779594421387, accuracy: 85.7 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 0.23271632194519043, accuracy: 92.9 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 0.2586924731731415, accuracy: 92.0 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 0.22083093225955963, accuracy: 93.3 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 0.2518005073070526, accuracy: 92.2 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 0.22034280002117157, accuracy: 93.3 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 0.22429734468460083, accuracy: 93.1 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 0.2404, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 0.3918, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 0.2613, batch time: 0.06, accuracy:  92.19%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 0.2077, batch time: 0.06, accuracy:  96.09%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 0.4042, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 0.2815, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 0.2029, batch time: 0.06, accuracy:  94.53%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 0.2150, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 0.2265, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 0.2361, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 0.25254175066947937, accuracy: 92.7 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 0.2901853322982788, accuracy: 90.8 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 0.4213767945766449, accuracy: 86.7 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 0.5859093070030212, accuracy: 80.9 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 0.23497650027275085, accuracy: 92.8 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 0.2619006931781769, accuracy: 90.4 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 0.25341731309890747, accuracy: 91.8 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 0.23518577218055725, accuracy: 92.7 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 0.229086771607399, accuracy: 92.6 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 0.23144467175006866, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 0.2180, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 0.3611, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 0.2578, batch time: 0.08, accuracy:  96.09%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 0.2031, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 0.3037, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 0.2314, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 0.2455, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 0.2188, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 0.2775, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 0.3434, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 0.22960208356380463, accuracy: 93.1 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 0.2768755257129669, accuracy: 90.7 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 0.19976311922073364, accuracy: 93.5 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 0.19533459842205048, accuracy: 93.2 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 0.30428358912467957, accuracy: 90.5 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 0.2057632952928543, accuracy: 93.6 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 0.2012237012386322, accuracy: 93.8 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 0.18881988525390625, accuracy: 94.0 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 0.18453863263130188, accuracy: 94.1 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 0.1831328272819519, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 0.3538, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 0.2113, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 0.2962, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 0.3290, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 0.1682, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 0.2303, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 0.2366, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 0.1958, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 0.2750, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 0.1884, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 0.21783176064491272, accuracy: 93.5 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 0.25545549392700195, accuracy: 92.4 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 0.22198346257209778, accuracy: 93.3 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 0.6013904809951782, accuracy: 80.6 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 0.23592959344387054, accuracy: 92.7 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 0.2761743366718292, accuracy: 91.3 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 0.322204053401947, accuracy: 89.7 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 0.19775506854057312, accuracy: 94.9 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 0.3048272132873535, accuracy: 90.2 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 0.2901640832424164, accuracy: 91.2 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 0.2992, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 0.1552, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 0.3344, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 0.3306, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 0.3416, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 0.2846, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 0.2184, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 0.1940, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 0.2773, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 0.2727, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 0.25024548172950745, accuracy: 92.7 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 0.30800312757492065, accuracy: 90.7 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 0.24524569511413574, accuracy: 92.9 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 0.24181728065013885, accuracy: 92.7 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 0.33136799931526184, accuracy: 90.2 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 0.2252243310213089, accuracy: 92.9 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 0.22144648432731628, accuracy: 93.4 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 0.22334355115890503, accuracy: 92.9 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 0.23067264258861542, accuracy: 93.1 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 0.2364027053117752, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 0.3499, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 0.2294, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 0.1365, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 0.2016, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 0.2003, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 0.2916, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 0.3266, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 0.2364, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 0.2003, batch time: 0.06, accuracy:  93.75%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 0.1343, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 0.24489915370941162, accuracy: 92.4 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 0.2914965748786926, accuracy: 90.7 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 0.3503766655921936, accuracy: 89.0 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 0.2344447523355484, accuracy: 92.9 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 0.22880828380584717, accuracy: 93.6 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 0.2280554473400116, accuracy: 93.6 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 0.24502773582935333, accuracy: 92.6 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 0.2273959517478943, accuracy: 93.6 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 0.22878307104110718, accuracy: 93.2 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 0.2240748256444931, accuracy: 93.3 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 0.2888, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 0.2188, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 0.2626, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 0.1899, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 0.2718, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 0.2458, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 0.2338, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 0.2662, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 0.1550, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 0.1834, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 0.22077937424182892, accuracy: 92.7 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 0.2309306114912033, accuracy: 92.0 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 0.23707066476345062, accuracy: 92.5 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 0.21698039770126343, accuracy: 93.3 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 0.33453384041786194, accuracy: 89.7 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 0.24808549880981445, accuracy: 92.3 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 0.4033869206905365, accuracy: 87.6 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 0.214731827378273, accuracy: 93.6 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 0.2146175354719162, accuracy: 93.0 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 0.2027285099029541, accuracy: 93.2 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 0.3115, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 0.2633, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 0.3886, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 0.2748, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 0.2773, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 0.2398, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 0.3903, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 0.2941, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 0.3361, batch time: 0.06, accuracy:  93.75%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 0.1744, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 0.31370213627815247, accuracy: 90.1 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 0.39189061522483826, accuracy: 88.5 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 0.953235924243927, accuracy: 73.3 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 0.34581318497657776, accuracy: 89.6 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 0.25852879881858826, accuracy: 92.4 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 0.2617289125919342, accuracy: 92.2 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 0.2621569335460663, accuracy: 91.5 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 0.25768882036209106, accuracy: 92.7 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 0.24821919202804565, accuracy: 92.1 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 0.24227164685726166, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 0.2279, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 0.2244, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 0.3540, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 0.3193, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 0.3835, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 0.2480, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 0.3109, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 0.2139, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 0.2124, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 0.3171, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 0.20339973270893097, accuracy: 94.4 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 0.3131009638309479, accuracy: 89.8 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 0.20334812998771667, accuracy: 94.4 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 0.31426936388015747, accuracy: 90.3 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 0.2002347707748413, accuracy: 94.1 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 0.20815151929855347, accuracy: 94.0 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 0.21382877230644226, accuracy: 93.5 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 0.20221541821956635, accuracy: 94.6 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 0.1924860030412674, accuracy: 94.9 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 0.19075237214565277, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 0.1816, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 0.3546, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 0.2316, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 0.2185, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 0.1531, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 0.3485, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 0.2680, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 0.2878, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 0.3202, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 0.2600, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 0.27279335260391235, accuracy: 91.8 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 0.37371647357940674, accuracy: 89.3 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 0.6112162470817566, accuracy: 81.3 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 0.3852180540561676, accuracy: 89.5 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 0.27117297053337097, accuracy: 92.6 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 0.26476410031318665, accuracy: 92.4 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 0.25871431827545166, accuracy: 92.8 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 0.25262460112571716, accuracy: 93.0 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 0.25386548042297363, accuracy: 93.4 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 0.24922022223472595, accuracy: 93.0 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 0.2092, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 0.2010, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 0.1876, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 0.3852, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 0.1873, batch time: 0.06, accuracy:  93.75%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 0.3858, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 0.3126, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 0.2714, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 0.1390, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 0.2965, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 0.22220031917095184, accuracy: 93.0 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 0.3303167521953583, accuracy: 89.7 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 0.21180960536003113, accuracy: 93.7 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 0.21096529066562653, accuracy: 93.7 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 0.4568076729774475, accuracy: 84.5 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 0.20461823046207428, accuracy: 93.6 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 0.20756490528583527, accuracy: 93.8 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 0.19552677869796753, accuracy: 94.6 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 0.2049671709537506, accuracy: 93.8 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 0.19710104167461395, accuracy: 93.9 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 0.2009, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 0.1219, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 0.2346, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 0.3085, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 0.3171, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 0.3901, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 0.2886, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 0.1620, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 0.1501, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 0.1806, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 0.2028949111700058, accuracy: 94.3 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 0.48673656582832336, accuracy: 82.0 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 0.2016858607530594, accuracy: 93.7 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 0.3219121992588043, accuracy: 89.1 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 0.19698560237884521, accuracy: 94.2 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 0.19360603392124176, accuracy: 94.4 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 0.20768867433071136, accuracy: 94.1 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 0.19287413358688354, accuracy: 94.1 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 0.1986323595046997, accuracy: 94.2 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 0.19091546535491943, accuracy: 94.7 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 0.2455, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 0.2006, batch time: 0.06, accuracy:  93.75%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 0.2892, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 0.3622, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 0.2571, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 0.2106, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 0.2949, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 0.2236, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 0.3250, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 0.2186, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 0.2745298743247986, accuracy: 91.0 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 0.30801939964294434, accuracy: 91.3 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 0.2727892994880676, accuracy: 91.4 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 0.2693007290363312, accuracy: 91.7 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 1.4568758010864258, accuracy: 68.0 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 0.28861790895462036, accuracy: 90.2 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 0.2534651756286621, accuracy: 91.7 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 0.2527352571487427, accuracy: 92.4 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 0.2499120980501175, accuracy: 92.6 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 0.24742768704891205, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 0.2244, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 0.2895, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 0.1679, batch time: 0.07, accuracy:  94.53%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 0.1211, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 0.2004, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 0.3173, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 0.2914, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 0.2201, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 0.1965, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 0.3257, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 0.26989036798477173, accuracy: 91.4 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 0.44377031922340393, accuracy: 85.4 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 0.24571353197097778, accuracy: 91.8 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 0.24571353197097778, accuracy: 91.8 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 0.2968791425228119, accuracy: 91.4 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 0.24252325296401978, accuracy: 92.1 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 0.24260962009429932, accuracy: 92.4 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 0.2579898238182068, accuracy: 92.1 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 0.23688508570194244, accuracy: 92.8 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 0.23316866159439087, accuracy: 93.2 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 0.1755, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 0.2331, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 0.2327, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 0.2275, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 0.2581, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 0.3870, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 0.2867, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 0.3157, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 0.2359, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 0.1226, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 0.27093273401260376, accuracy: 91.4 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 0.35906684398651123, accuracy: 88.5 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 0.30548474192619324, accuracy: 91.2 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 0.2627602815628052, accuracy: 92.1 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 0.5341352224349976, accuracy: 85.1 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 0.26212045550346375, accuracy: 92.2 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 0.2660137116909027, accuracy: 92.3 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 0.2696685492992401, accuracy: 92.0 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 0.27153387665748596, accuracy: 91.6 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 0.249415323138237, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 0.2113, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 0.2807, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 0.1367, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 0.3506, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 0.2173, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 0.2344, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 0.1925, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 0.1129, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 0.2178, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 0.2930, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 0.21480049192905426, accuracy: 92.9 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 0.27778109908103943, accuracy: 91.1 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 0.2742013931274414, accuracy: 91.1 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 0.4195394814014435, accuracy: 85.5 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 0.22514504194259644, accuracy: 92.9 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 0.2157813161611557, accuracy: 93.4 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 0.20753513276576996, accuracy: 93.5 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 0.20213934779167175, accuracy: 93.4 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 0.19866317510604858, accuracy: 93.2 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 0.23285409808158875, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 0.2734, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 0.1583, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 0.1852, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 0.3128, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 0.1534, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 0.2545, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 0.2147, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 0.2919, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 0.1834, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 0.2922, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 0.22373172640800476, accuracy: 93.3 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 0.3558320999145508, accuracy: 89.1 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 0.2229352742433548, accuracy: 93.4 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 0.2124769240617752, accuracy: 93.9 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 0.44158634543418884, accuracy: 86.0 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 0.20594792068004608, accuracy: 93.5 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 0.20563195645809174, accuracy: 93.2 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 0.20571556687355042, accuracy: 94.0 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 0.20159506797790527, accuracy: 93.6 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 0.2132912576198578, accuracy: 93.2 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 0.3019, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 0.2793, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 0.1976, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 0.2410, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 0.2020, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 0.1876, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 0.2853, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 0.3995, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 0.3044, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 0.2731, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 0.2438533753156662, accuracy: 93.2 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 0.3422226905822754, accuracy: 89.1 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 0.23550665378570557, accuracy: 93.6 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 0.23182930052280426, accuracy: 93.6 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 0.3244926333427429, accuracy: 90.4 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 0.22688446938991547, accuracy: 93.5 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 0.21817490458488464, accuracy: 93.5 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 0.21606652438640594, accuracy: 93.8 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 0.21987152099609375, accuracy: 93.8 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 0.2968277037143707, accuracy: 90.4 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 0.1016, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 0.2100, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 0.1984, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 0.3729, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 0.1125, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 0.2168, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 0.2158, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 0.2187, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 0.3399, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 0.2883, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 0.26273679733276367, accuracy: 93.1 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 0.3303767144680023, accuracy: 90.1 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 0.25871542096138, accuracy: 92.9 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 0.25837311148643494, accuracy: 93.1 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 0.31219425797462463, accuracy: 91.0 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 0.2549588084220886, accuracy: 93.3 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 0.25787773728370667, accuracy: 93.5 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 0.24866563081741333, accuracy: 93.4 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 0.25819331407546997, accuracy: 93.0 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 0.25261345505714417, accuracy: 93.3 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 0.2028, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 0.2974, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 0.2226, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 0.3610, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 0.1971, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 0.1510, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 0.2713, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 0.2044, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 0.3103, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 0.3578, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 0.2217063009738922, accuracy: 93.6 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 0.31756356358528137, accuracy: 89.9 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 0.2214670032262802, accuracy: 93.8 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 0.21437175571918488, accuracy: 94.1 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 0.5364954471588135, accuracy: 83.9 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 0.21192441880702972, accuracy: 94.4 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 0.22042210400104523, accuracy: 93.3 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 0.21314828097820282, accuracy: 93.6 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 0.2121352255344391, accuracy: 94.3 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 0.2063632756471634, accuracy: 94.4 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 0.2048, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 0.2790, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 0.2394, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 0.4082, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 0.2495, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 0.3005, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 0.2908, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 0.2901, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 0.1490, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 0.2751, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 0.24913272261619568, accuracy: 91.8 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 0.34329694509506226, accuracy: 90.0 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 0.25360509753227234, accuracy: 91.7 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 0.23135358095169067, accuracy: 92.3 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 0.26319342851638794, accuracy: 91.3 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 0.2264283001422882, accuracy: 92.0 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 0.22688184678554535, accuracy: 92.5 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 0.2261664718389511, accuracy: 92.9 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 0.21387289464473724, accuracy: 93.5 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 0.21839822828769684, accuracy: 93.0 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 0.1621, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 0.1635, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 0.1619, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 0.2528, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 0.3278, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 0.2158, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 0.2541, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 0.3008, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 0.2607, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 0.1727, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 0.24935293197631836, accuracy: 92.4 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 0.3533824682235718, accuracy: 88.2 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 0.24042710661888123, accuracy: 92.2 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 0.23924528062343597, accuracy: 92.0 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 0.2613461911678314, accuracy: 91.9 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 0.25240862369537354, accuracy: 92.0 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 0.23816335201263428, accuracy: 92.3 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 0.23309636116027832, accuracy: 92.1 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 0.23108914494514465, accuracy: 92.4 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 0.23321031033992767, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 0.2689, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 0.3383, batch time: 0.07, accuracy:  87.50%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 0.1638, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 0.2268, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 0.1856, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 0.2794, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 0.2598, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 0.2311, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 0.2065, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 0.1459, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 0.21363399922847748, accuracy: 93.9 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 0.382834255695343, accuracy: 88.4 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 0.20911487936973572, accuracy: 94.1 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 0.20702756941318512, accuracy: 94.3 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 0.23256613314151764, accuracy: 93.1 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 0.786177933216095, accuracy: 74.3 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 0.20119944214820862, accuracy: 94.0 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 0.20592114329338074, accuracy: 93.4 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 0.2109149694442749, accuracy: 93.9 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 0.22018729150295258, accuracy: 92.8 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 0.2599, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 0.3134, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 0.2330, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 0.2507, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 0.4234, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 0.1754, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 0.3079, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 0.1960, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 0.3188, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 0.3145, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 0.23227627575397491, accuracy: 93.7 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 0.3322795331478119, accuracy: 89.4 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 0.22695384919643402, accuracy: 94.0 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 0.22695384919643402, accuracy: 94.0 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 0.23256686329841614, accuracy: 93.4 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 0.23140433430671692, accuracy: 93.9 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 0.2218230664730072, accuracy: 94.2 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 0.21781665086746216, accuracy: 94.5 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 0.2176900953054428, accuracy: 94.5 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 0.21748338639736176, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 0.3715, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 0.2178, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 0.2116, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 0.2918, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 0.2841, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 0.2189, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 0.2566, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 0.2194, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 0.2030, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 0.2014, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 0.2277030050754547, accuracy: 93.5 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 0.26556816697120667, accuracy: 92.1 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 0.2110672891139984, accuracy: 93.9 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 0.2093592882156372, accuracy: 93.7 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 0.39911770820617676, accuracy: 86.8 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 0.1910661906003952, accuracy: 94.8 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 0.19683445990085602, accuracy: 94.1 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 0.20042072236537933, accuracy: 94.1 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 0.19213852286338806, accuracy: 94.6 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 0.1970958113670349, accuracy: 94.7 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 0.2662, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 0.3520, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 0.0979, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 0.1834, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 0.2561, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 0.3478, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 0.3654, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 0.2537, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 0.3332, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 0.3272, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 0.23199759423732758, accuracy: 92.7 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 0.4324147403240204, accuracy: 85.2 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 0.21994072198867798, accuracy: 93.6 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 0.2196022868156433, accuracy: 93.7 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 0.21599777042865753, accuracy: 93.8 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 0.21103988587856293, accuracy: 93.9 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 0.20773014426231384, accuracy: 94.0 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 0.21846666932106018, accuracy: 93.5 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 0.21859948337078094, accuracy: 92.6 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 0.2013676017522812, accuracy: 94.1 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 0.2443, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 0.1959, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 0.3203, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 0.1701, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 0.2663, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 0.1721, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 0.1927, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 0.2949, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 0.2486, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 0.3730, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 0.2701350450515747, accuracy: 91.3 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 0.3438897728919983, accuracy: 89.2 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 0.25738441944122314, accuracy: 91.7 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 0.25738441944122314, accuracy: 91.7 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 0.2551402449607849, accuracy: 91.7 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 0.2549755573272705, accuracy: 91.8 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 0.2545337378978729, accuracy: 92.2 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 0.26177459955215454, accuracy: 91.8 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 0.2666711211204529, accuracy: 91.9 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 0.2438538521528244, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 0.2272, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 0.1310, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 0.2962, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 0.3028, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 0.4241, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 0.2265, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 0.2485, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 0.2282, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 0.1654, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 0.3517, batch time: 0.06, accuracy:  88.28%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 0.2918057441711426, accuracy: 90.1 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 0.35297691822052, accuracy: 88.7 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 0.2777908444404602, accuracy: 92.1 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 0.6080313920974731, accuracy: 80.5 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 0.2632390856742859, accuracy: 92.7 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 0.2654874324798584, accuracy: 92.5 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 0.26193076372146606, accuracy: 93.0 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 0.26015305519104004, accuracy: 93.2 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 0.2548709809780121, accuracy: 93.0 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 0.2521233856678009, accuracy: 92.7 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 0.2707, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 0.2257, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 0.2142, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 0.3768, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 0.3160, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 0.2412, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 0.1662, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 0.2906, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 0.1976, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 0.3105, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 0.2583070993423462, accuracy: 91.7 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 0.3433646261692047, accuracy: 89.5 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 0.2532042860984802, accuracy: 92.0 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 0.4184761047363281, accuracy: 86.2 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 0.24373142421245575, accuracy: 92.4 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 0.24035881459712982, accuracy: 92.2 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 0.23503263294696808, accuracy: 93.0 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 0.23995904624462128, accuracy: 91.8 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 0.23637130856513977, accuracy: 93.1 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 0.22747987508773804, accuracy: 92.5 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 0.1897, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 0.3080, batch time: 0.06, accuracy:  90.62%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 0.1722, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 0.1802, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 0.2989, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 0.1701, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 0.3100, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 0.3012, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 0.1601, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 0.2301, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 0.21415817737579346, accuracy: 94.2 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 0.24428702890872955, accuracy: 93.0 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 0.21392029523849487, accuracy: 94.0 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 1.0953569412231445, accuracy: 70.7 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 0.22069379687309265, accuracy: 93.5 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 0.2159176915884018, accuracy: 94.1 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 0.21198329329490662, accuracy: 94.2 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 0.20050184428691864, accuracy: 95.1 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 0.19585584104061127, accuracy: 94.9 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 0.19547158479690552, accuracy: 94.9 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 0.2892, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 0.2006, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 0.3802, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 0.0769, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 0.2996, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 0.2160, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 0.2694, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 0.4765, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 0.2100, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 0.2641, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 0.1900286227464676, accuracy: 93.3 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 0.31966131925582886, accuracy: 89.8 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 0.18331041932106018, accuracy: 93.7 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 1.4991308450698853, accuracy: 68.5 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 0.18983258306980133, accuracy: 93.4 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 0.1753966361284256, accuracy: 94.0 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 0.17562434077262878, accuracy: 93.9 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 0.17212122678756714, accuracy: 94.5 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 0.17186561226844788, accuracy: 94.2 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 0.1705656796693802, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 0.2357, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 0.2996, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 0.3195, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 0.2353, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 0.2142, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 0.2580, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 0.1760, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 0.1838, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 0.2657, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 0.2415, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 0.25204843282699585, accuracy: 91.6 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 0.2538105249404907, accuracy: 91.8 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 3.1370463371276855, accuracy: 50.1 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 1.5039982795715332, accuracy: 63.7 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 0.23264820873737335, accuracy: 93.0 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 0.23203860223293304, accuracy: 92.5 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 0.4007081091403961, accuracy: 86.7 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 0.24450471997261047, accuracy: 92.7 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 0.21587423980236053, accuracy: 93.9 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 0.21260148286819458, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 0.2399, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 0.2620, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 0.2402, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 0.4150, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 0.2423, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 0.2594, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 0.1672, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 0.3448, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 0.4405, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 0.2934, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 0.20098064839839935, accuracy: 94.2 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 0.29579004645347595, accuracy: 91.3 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 0.2084677666425705, accuracy: 93.8 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 0.19656115770339966, accuracy: 94.0 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 0.19590812921524048, accuracy: 94.0 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 0.18940360844135284, accuracy: 94.4 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 0.18796589970588684, accuracy: 94.2 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 0.18636251986026764, accuracy: 94.3 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 0.19972528517246246, accuracy: 93.9 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 0.19067133963108063, accuracy: 94.3 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 0.1589, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 0.2316, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 0.1917, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 0.1773, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 0.2214, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 0.1293, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 0.1575, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 0.1785, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 0.1939, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 0.1716, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 0.1818590760231018, accuracy: 93.7 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 0.4752389192581177, accuracy: 84.3 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 0.18345090746879578, accuracy: 93.8 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 0.17690014839172363, accuracy: 93.7 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 0.2332138866186142, accuracy: 91.6 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 0.17123037576675415, accuracy: 94.2 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 0.17205379903316498, accuracy: 94.3 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 0.17271262407302856, accuracy: 93.9 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 0.1661028414964676, accuracy: 94.3 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 0.1645537167787552, accuracy: 94.4 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 0.3054, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 0.1206, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 0.1912, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 0.2104, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 0.2327, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 0.1820, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 0.3144, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 0.2101, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 0.2943, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 0.2035, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 0.2599603533744812, accuracy: 91.9 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 0.49525517225265503, accuracy: 85.9 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 0.25577273964881897, accuracy: 92.3 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 0.24788181483745575, accuracy: 92.7 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 0.4234684407711029, accuracy: 87.7 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 0.2460920214653015, accuracy: 92.7 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 0.2583404779434204, accuracy: 92.1 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 0.2386624813079834, accuracy: 92.9 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 0.23382991552352905, accuracy: 92.7 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 0.253993421792984, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 0.2230, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 0.2506, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 0.1739, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 0.2158, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 0.1557, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 0.2501, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 0.2953, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 0.2287, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 0.2484, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 0.2915, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 0.25762704014778137, accuracy: 92.0 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 0.41169849038124084, accuracy: 87.0 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 0.282680481672287, accuracy: 91.6 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 0.2462063431739807, accuracy: 92.2 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 0.40804556012153625, accuracy: 87.8 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 0.23716793954372406, accuracy: 93.8 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 0.24718350172042847, accuracy: 92.8 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 0.2385757863521576, accuracy: 93.5 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 0.2453397959470749, accuracy: 92.4 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 0.22843849658966064, accuracy: 93.3 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 0.1780, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 0.3820, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 0.1132, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 0.3755, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 0.2408, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 0.1620, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 0.2956, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 0.2152, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 0.1792, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 0.1660, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 0.23727013170719147, accuracy: 92.2 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 0.33186882734298706, accuracy: 90.0 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 0.22431941330432892, accuracy: 92.6 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 1.1839998960494995, accuracy: 69.9 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 0.3183489143848419, accuracy: 89.5 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 0.20698924362659454, accuracy: 93.2 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 0.20637500286102295, accuracy: 93.7 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 0.2203425168991089, accuracy: 93.1 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 0.20804212987422943, accuracy: 93.0 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 0.19980628788471222, accuracy: 93.8 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 0.4198, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 0.2588, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 0.1459, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 0.3004, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 0.2329, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 0.3340, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 0.1974, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 0.2427, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 0.2870, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 0.2182, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 0.20068785548210144, accuracy: 93.6 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 0.3546375632286072, accuracy: 88.9 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 0.2016535997390747, accuracy: 92.7 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 0.6954470872879028, accuracy: 78.4 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 0.41818052530288696, accuracy: 86.5 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 0.19090668857097626, accuracy: 93.8 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 0.18885868787765503, accuracy: 93.7 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 0.19555839896202087, accuracy: 93.1 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 0.18570782244205475, accuracy: 93.9 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 0.18280655145645142, accuracy: 93.8 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 0.1917, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 0.3408, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 0.0929, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 0.1466, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 0.2555, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 0.2248, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 0.2272, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 0.1759, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 0.1951, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 0.1837, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 0.1985270380973816, accuracy: 94.3 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 0.2938278913497925, accuracy: 90.0 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 0.2159811407327652, accuracy: 93.2 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 0.19613052904605865, accuracy: 94.2 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 0.25367122888565063, accuracy: 92.3 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 0.21853908896446228, accuracy: 93.5 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 0.1962859034538269, accuracy: 94.1 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 0.19122780859470367, accuracy: 94.5 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 0.18989703059196472, accuracy: 94.3 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 0.1919621080160141, accuracy: 94.3 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 0.3112, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 0.2421, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 0.3246, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 0.2461, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 0.1127, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 0.1314, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 0.1875, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 0.1738, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 0.2827, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 0.2571, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 0.22798529267311096, accuracy: 92.9 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 0.3144490420818329, accuracy: 89.7 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 0.22659268975257874, accuracy: 92.1 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 0.2669152021408081, accuracy: 92.1 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 0.22605034708976746, accuracy: 92.1 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 0.22726856172084808, accuracy: 92.5 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 0.21624979376792908, accuracy: 92.3 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 0.22422899305820465, accuracy: 91.9 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 0.21793319284915924, accuracy: 92.5 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 0.2099752128124237, accuracy: 93.1 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 0.2974, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 0.2564, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 0.2960, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 0.2339, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 0.2200, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 0.0670, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 0.1916, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 0.2046, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 0.1663, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 0.1558, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 0.2132718861103058, accuracy: 93.8 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 0.3253783881664276, accuracy: 89.1 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 0.45901694893836975, accuracy: 86.1 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 0.21186178922653198, accuracy: 93.8 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 1.4088190793991089, accuracy: 67.3 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 0.2863653302192688, accuracy: 90.8 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 0.2174263745546341, accuracy: 93.5 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 0.2175004780292511, accuracy: 93.3 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 0.2162206470966339, accuracy: 93.3 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 0.20764261484146118, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 0.2155, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 0.2037, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 0.2098, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 0.2869, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 0.2941, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 0.1053, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 0.3036, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 0.1700, batch time: 0.06, accuracy:  93.75%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 0.3041, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 0.1858, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 0.1854826807975769, accuracy: 94.3 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 0.21955029666423798, accuracy: 92.4 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 0.18120557069778442, accuracy: 94.3 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 0.33568617701530457, accuracy: 89.5 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 0.17485392093658447, accuracy: 94.8 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 0.16811691224575043, accuracy: 94.7 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 0.1683606505393982, accuracy: 94.8 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 0.18164855241775513, accuracy: 93.9 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 0.16591894626617432, accuracy: 94.4 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 0.1809920221567154, accuracy: 93.7 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 0.3392, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 0.2978, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 0.2258, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 0.2358, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 0.3554, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 0.2274, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 0.2636, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 0.2247, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 0.3442, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 0.1371, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 0.17982271313667297, accuracy: 93.9 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 0.2669157385826111, accuracy: 91.2 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 0.16835741698741913, accuracy: 94.0 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 0.1862831562757492, accuracy: 94.0 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 0.15959057211875916, accuracy: 94.5 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 0.15223614871501923, accuracy: 94.7 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 0.15593382716178894, accuracy: 95.3 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 0.1512168049812317, accuracy: 95.2 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 0.15240050852298737, accuracy: 95.1 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 0.142333984375, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 0.2794, batch time: 0.06, accuracy:  92.19%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 0.2075, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 0.1972, batch time: 0.06, accuracy:  93.75%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 0.3610, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 0.3286, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 0.1546, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 0.1384, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 0.2886, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 0.2321, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 0.3015, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 0.21682533621788025, accuracy: 93.4 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 0.2170240730047226, accuracy: 93.2 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 3.8544461727142334, accuracy: 39.5 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 1.6232414245605469, accuracy: 63.0 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 2.4330649375915527, accuracy: 55.8 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 0.22525636851787567, accuracy: 93.4 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 0.20298421382904053, accuracy: 94.1 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 0.22389499843120575, accuracy: 93.1 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 0.2025877982378006, accuracy: 94.1 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 0.20388436317443848, accuracy: 94.1 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 0.2776, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 0.4296, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 0.3200, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 0.2996, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 0.3127, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 0.3271, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 0.2733, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 0.2409, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 0.1782, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 0.1470, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 0.2813524305820465, accuracy: 91.3 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 0.32480862736701965, accuracy: 90.0 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 0.24361804127693176, accuracy: 92.5 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 0.24071359634399414, accuracy: 92.4 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 0.2519184648990631, accuracy: 92.6 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 0.2493019700050354, accuracy: 92.1 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 0.2196524292230606, accuracy: 93.2 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 0.21234941482543945, accuracy: 93.7 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 0.22086244821548462, accuracy: 93.3 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 0.22919906675815582, accuracy: 92.7 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 0.2655, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 0.1584, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 0.2808, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 0.3095, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 0.1419, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 0.3256, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 0.2085, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 0.1623, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 0.2326, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 0.2746, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 0.23649005591869354, accuracy: 91.9 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 0.3366893231868744, accuracy: 88.2 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 0.23212802410125732, accuracy: 91.5 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 0.23123504221439362, accuracy: 91.8 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 0.23874031007289886, accuracy: 92.0 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 0.23273199796676636, accuracy: 92.2 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 0.2386987805366516, accuracy: 91.7 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 0.22608408331871033, accuracy: 92.4 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 0.23754459619522095, accuracy: 92.0 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 0.22265014052391052, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 0.2094, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 0.2334, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 0.2308, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 0.2305, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 0.2004, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 0.2080, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 0.3181, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 0.1883, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 0.2137, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 0.2985, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 0.23861972987651825, accuracy: 92.5 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 0.32972151041030884, accuracy: 89.0 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 0.23581308126449585, accuracy: 92.5 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 0.2326582968235016, accuracy: 92.4 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 0.29505956172943115, accuracy: 90.5 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 0.22657504677772522, accuracy: 92.0 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 0.22368142008781433, accuracy: 92.1 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 0.22383679449558258, accuracy: 92.1 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 0.21651716530323029, accuracy: 92.4 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 0.21945346891880035, accuracy: 92.5 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 0.2962, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 0.1161, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 0.2334, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 0.2276, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 0.2693, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 0.2084, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 0.2395, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 0.2390, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 0.2168, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 0.2386, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 0.2573969066143036, accuracy: 91.9 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 0.4021081328392029, accuracy: 87.6 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 0.2639939486980438, accuracy: 91.9 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 0.2566106915473938, accuracy: 92.4 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 0.27446553111076355, accuracy: 91.1 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 0.25476500391960144, accuracy: 91.8 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 0.25539806485176086, accuracy: 91.9 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 0.2516269385814667, accuracy: 92.0 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 0.2494278848171234, accuracy: 91.8 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 0.2466985136270523, accuracy: 92.2 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 0.2708, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 0.1988, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 0.1460, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 0.2404, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 0.3350, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 0.2017, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 0.2117, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 0.2555, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 0.2911, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 0.2546, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 0.2601151168346405, accuracy: 92.0 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 0.40726524591445923, accuracy: 86.7 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 0.25847145915031433, accuracy: 91.8 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 0.2545953691005707, accuracy: 92.0 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 0.3401274085044861, accuracy: 89.8 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 0.24702191352844238, accuracy: 92.1 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 0.24907001852989197, accuracy: 92.2 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 0.2468506395816803, accuracy: 92.7 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 0.24282509088516235, accuracy: 92.9 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 0.24414308369159698, accuracy: 92.7 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 0.2622, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 0.2083, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 0.2155, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 0.3550, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 0.1798, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 0.4146, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 0.2268, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 0.2778, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 0.2325, batch time: 0.09, accuracy:  93.75%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 0.1679, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 0.2756013870239258, accuracy: 92.3 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 0.4336874485015869, accuracy: 87.3 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 0.28150060772895813, accuracy: 92.1 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 0.2579425871372223, accuracy: 93.1 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 0.25319328904151917, accuracy: 93.1 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 0.24482406675815582, accuracy: 93.3 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 0.2539462447166443, accuracy: 92.7 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 0.2517004609107971, accuracy: 92.6 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 0.23898324370384216, accuracy: 93.2 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 0.24550876021385193, accuracy: 93.3 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 0.1323, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 0.2209, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 0.2481, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 0.1485, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 0.2370, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 0.2004, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 0.2312, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 0.2368, batch time: 0.08, accuracy:  92.97%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 0.2665, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 0.3044, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 0.2488427311182022, accuracy: 92.5 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 0.415190726518631, accuracy: 87.4 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 0.4676542282104492, accuracy: 85.4 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 0.23145614564418793, accuracy: 92.7 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 0.3448329567909241, accuracy: 89.0 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 0.22281867265701294, accuracy: 93.3 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 0.2243584245443344, accuracy: 93.1 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 0.2115074098110199, accuracy: 93.8 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 0.21130748093128204, accuracy: 93.5 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 0.2342408299446106, accuracy: 92.2 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 0.2156, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 0.1936, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 0.3942, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 0.1494, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 0.2243, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 0.2395, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 0.1863, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 0.1687, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 0.2665, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 0.2680, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 0.24700456857681274, accuracy: 92.1 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 1.1407266855239868, accuracy: 67.6 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 0.25380632281303406, accuracy: 92.1 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 0.673783004283905, accuracy: 78.6 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 0.24241207540035248, accuracy: 91.4 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 0.23676860332489014, accuracy: 92.2 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 0.2558799982070923, accuracy: 91.2 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 0.2771945893764496, accuracy: 90.5 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 0.2519686222076416, accuracy: 91.6 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 0.23505492508411407, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 0.3177, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 0.2286, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 0.5341, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 0.1876, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 0.1883, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 0.2230, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 0.3413, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 0.2634, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 0.2419, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 0.1841, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 0.22387652099132538, accuracy: 92.8 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 1.4428906440734863, accuracy: 68.0 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 0.29530206322669983, accuracy: 90.4 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 0.39162689447402954, accuracy: 87.6 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 0.22430258989334106, accuracy: 93.1 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 0.21825671195983887, accuracy: 93.3 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 0.23877058923244476, accuracy: 91.8 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 0.23545819520950317, accuracy: 92.4 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 0.22885414958000183, accuracy: 93.1 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 0.22193917632102966, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 0.1791, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 0.3197, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 0.1837, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 0.2695, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 0.3162, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 0.1614, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 0.2165, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 0.1861, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 0.1934, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 0.2653, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 0.24804382026195526, accuracy: 91.8 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 0.3634997606277466, accuracy: 89.0 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 0.24401737749576569, accuracy: 92.6 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 0.38658174872398376, accuracy: 88.5 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 0.39190781116485596, accuracy: 87.7 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 0.235643669962883, accuracy: 92.4 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 0.2314373254776001, accuracy: 92.4 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 0.23587337136268616, accuracy: 92.8 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 0.2290249913930893, accuracy: 92.5 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 0.21692514419555664, accuracy: 93.3 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 0.1956, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 0.2260, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 0.2236, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 0.2592, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 0.1956, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 0.2064, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 0.1361, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 0.2250, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 0.2402, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 0.2438, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 0.24894556403160095, accuracy: 92.8 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 0.3250233829021454, accuracy: 89.8 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 0.33803921937942505, accuracy: 89.4 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 0.23929305374622345, accuracy: 93.0 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 0.8108091950416565, accuracy: 78.4 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 0.2380899339914322, accuracy: 92.6 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 0.24413372576236725, accuracy: 92.8 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 0.22511667013168335, accuracy: 93.5 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 0.2299862802028656, accuracy: 93.3 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 0.24836452305316925, accuracy: 92.3 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 0.3127, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 0.2215, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 0.3192, batch time: 0.07, accuracy:  92.19%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 0.2862, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 0.1986, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 0.2116, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 0.1825, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 0.1558, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 0.2186, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 0.3974, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 0.26515305042266846, accuracy: 92.0 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 0.32267987728118896, accuracy: 90.8 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 0.24777700006961823, accuracy: 92.3 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 0.24608667194843292, accuracy: 92.1 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 0.909835696220398, accuracy: 74.2 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 0.4044479429721832, accuracy: 87.9 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 0.23591037094593048, accuracy: 92.9 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 0.23266065120697021, accuracy: 93.2 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 0.24241822957992554, accuracy: 93.0 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 0.2330271452665329, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 0.2497, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 0.2063, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 0.2416, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 0.2840, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 0.1771, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 0.1943, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 0.2095, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 0.2957, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 0.1609, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 0.2140, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 0.24744358658790588, accuracy: 92.7 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 0.8843338489532471, accuracy: 73.4 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 1.0376132726669312, accuracy: 71.5 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 0.6525615453720093, accuracy: 80.5 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 0.2393897920846939, accuracy: 93.0 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 0.23909352719783783, accuracy: 93.2 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 0.24265700578689575, accuracy: 92.8 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 0.2584773004055023, accuracy: 92.0 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 0.25385522842407227, accuracy: 92.0 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 0.23703113198280334, accuracy: 93.2 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 0.2231, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 0.3235, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 0.2473, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 0.1863, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 0.2810, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 0.2150, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 0.2356, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 0.1767, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 0.2960, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 0.2338, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 0.264133095741272, accuracy: 91.9 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 0.41081979870796204, accuracy: 87.5 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 0.23553048074245453, accuracy: 92.4 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 0.2354673445224762, accuracy: 92.5 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 0.23545953631401062, accuracy: 92.5 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 0.21923251450061798, accuracy: 93.6 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 0.22280625998973846, accuracy: 92.5 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 0.21200869977474213, accuracy: 93.6 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 0.21660636365413666, accuracy: 92.8 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 0.21148806810379028, accuracy: 93.6 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 0.1712, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 0.1854, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 0.1004, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 0.3406, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 0.1815, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 0.1351, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 0.2346, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 0.2713, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 0.2267, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 0.1874, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 0.21661376953125, accuracy: 93.4 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 0.26666492223739624, accuracy: 91.4 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 0.21876820921897888, accuracy: 92.7 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 0.44856128096580505, accuracy: 86.0 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 0.2121354043483734, accuracy: 93.6 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 0.2159474939107895, accuracy: 93.7 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 0.2101181298494339, accuracy: 93.5 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 0.20946863293647766, accuracy: 93.6 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 0.2142135351896286, accuracy: 93.1 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 0.20199285447597504, accuracy: 94.5 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 0.2106, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 0.3051, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 0.2279, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 0.1480, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 0.1995, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 0.2805, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 0.2368, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 0.2263, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 0.1609, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 0.2433, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 0.2332514226436615, accuracy: 93.1 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 0.7820790410041809, accuracy: 76.3 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 0.2558319568634033, accuracy: 92.0 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 0.503760039806366, accuracy: 82.7 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 0.2154756635427475, accuracy: 93.5 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 0.2149946689605713, accuracy: 93.4 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 0.21879516541957855, accuracy: 93.2 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 0.23292160034179688, accuracy: 92.5 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 0.22089992463588715, accuracy: 92.6 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 0.23916371166706085, accuracy: 91.7 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 0.2423, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 0.2070, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 0.1650, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 0.3067, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 0.1705, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 0.3750, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 0.2176, batch time: 0.09, accuracy:  90.62%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 0.1367, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 0.2198, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 0.3079, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 0.24126727879047394, accuracy: 92.5 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 0.25640952587127686, accuracy: 93.0 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 0.23710523545742035, accuracy: 92.7 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 0.8485442399978638, accuracy: 77.3 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 0.2503654658794403, accuracy: 92.2 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 0.22723720967769623, accuracy: 93.3 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 0.23421388864517212, accuracy: 92.7 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 0.22879332304000854, accuracy: 92.6 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 0.22148381173610687, accuracy: 92.8 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 0.20865078270435333, accuracy: 94.0 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 0.1431, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 0.3318, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 0.1657, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 0.2979, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 0.2973, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 0.2423, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 0.2132, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 0.2683, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 0.2310, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 0.1992, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 0.25134289264678955, accuracy: 91.5 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 1.3429814577102661, accuracy: 65.5 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 0.7239382863044739, accuracy: 81.4 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 0.6589060425758362, accuracy: 80.1 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 0.22172141075134277, accuracy: 92.7 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 0.23455946147441864, accuracy: 91.9 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 0.2307153344154358, accuracy: 92.7 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 0.22066128253936768, accuracy: 93.0 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 0.22059480845928192, accuracy: 93.0 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 0.218107208609581, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 0.4166, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 0.4333, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 0.1410, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 0.3366, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 0.2868, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 0.2493, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 0.2609, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 0.2764, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 0.2730, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 0.1786, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 0.22166408598423004, accuracy: 93.2 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 0.38791602849960327, accuracy: 88.5 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 0.22056496143341064, accuracy: 93.2 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 0.2091851681470871, accuracy: 93.1 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 0.29743820428848267, accuracy: 90.0 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 0.5246118307113647, accuracy: 82.5 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 0.20723514258861542, accuracy: 93.8 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 0.20616717636585236, accuracy: 93.2 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 0.20525968074798584, accuracy: 93.6 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 0.2110261619091034, accuracy: 92.7 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 0.1417, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 0.1528, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 0.2396, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 0.2375, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 0.2199, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 0.2977, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 0.2765, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 0.3123, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 0.2896, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 0.1746, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 0.2240399718284607, accuracy: 92.8 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 0.3694734573364258, accuracy: 88.0 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 0.3822821378707886, accuracy: 87.1 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 0.5386193990707397, accuracy: 83.7 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 0.21893034875392914, accuracy: 92.4 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 0.22403115034103394, accuracy: 92.7 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 0.25235238671302795, accuracy: 92.3 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 0.22287102043628693, accuracy: 92.9 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 0.22080054879188538, accuracy: 92.2 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 0.22090105712413788, accuracy: 92.5 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 0.4797, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 0.2430, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 0.2848, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 0.2103, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 0.2244, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 0.2549, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 0.2541, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 0.1847, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 0.3826, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 0.1871, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 0.21205656230449677, accuracy: 94.1 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 0.2401975393295288, accuracy: 92.6 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 0.20793050527572632, accuracy: 94.3 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 0.44176334142684937, accuracy: 86.0 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 0.20490747690200806, accuracy: 94.4 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 0.21428214013576508, accuracy: 93.4 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 0.2147228866815567, accuracy: 93.9 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 0.21326693892478943, accuracy: 93.5 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 0.203288272023201, accuracy: 93.8 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 0.19404619932174683, accuracy: 94.4 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 0.3062, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 0.2612, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 0.2359, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 0.3184, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 0.2292, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 0.2121, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 0.2730, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 0.3090, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 0.1894, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 0.2301, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 0.20166446268558502, accuracy: 94.1 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 0.3230678141117096, accuracy: 90.1 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 0.2870936989784241, accuracy: 91.0 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 0.6920384168624878, accuracy: 76.9 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 0.18861733376979828, accuracy: 94.3 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 0.184897318482399, accuracy: 94.3 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 0.18917417526245117, accuracy: 94.3 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 0.19079042971134186, accuracy: 94.4 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 0.18266838788986206, accuracy: 94.6 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 0.18633070588111877, accuracy: 94.4 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 0.2637, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 0.2431, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 0.1982, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 0.1784, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 0.3391, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 0.3149, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 0.2299, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 0.1830, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 0.2101, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 0.2706, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 0.2076386958360672, accuracy: 93.9 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 0.20954501628875732, accuracy: 93.7 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 0.21765956282615662, accuracy: 93.1 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 0.267965704202652, accuracy: 92.8 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 0.2067401111125946, accuracy: 93.8 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 0.20112760365009308, accuracy: 94.3 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 0.2051638662815094, accuracy: 93.8 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 0.20999035239219666, accuracy: 93.5 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 0.2001105546951294, accuracy: 94.0 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 0.20482122898101807, accuracy: 94.5 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 0.0902, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 0.2086, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 0.2388, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 0.1579, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 0.1032, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 0.0834, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 0.3094, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 0.1819, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 0.3088, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 0.2634, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 0.25231295824050903, accuracy: 92.5 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 0.39227724075317383, accuracy: 88.1 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 0.2653961777687073, accuracy: 91.8 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 0.24748210608959198, accuracy: 92.5 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 0.24740919470787048, accuracy: 92.0 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 0.23005017638206482, accuracy: 92.8 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 0.2312954068183899, accuracy: 92.9 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 0.2548041343688965, accuracy: 92.1 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 0.23067684471607208, accuracy: 93.0 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 0.2384708821773529, accuracy: 92.7 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 0.2724, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 0.2742, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 0.2585, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 0.3141, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 0.1652, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 0.2959, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 0.2234, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 0.1812, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 0.2028, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 0.2000, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 0.2752911150455475, accuracy: 90.9 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 0.46951228380203247, accuracy: 84.4 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 0.25659045577049255, accuracy: 92.5 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 0.25408294796943665, accuracy: 92.4 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 0.5117170810699463, accuracy: 83.8 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 0.2466294765472412, accuracy: 92.9 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 0.2500320374965668, accuracy: 91.7 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 0.2509278655052185, accuracy: 92.3 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 0.2509586811065674, accuracy: 91.7 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 0.2544025778770447, accuracy: 91.9 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 0.1677, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 0.1526, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 0.2231, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 0.2787, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 0.1799, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 0.2816, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 0.1029, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 0.1278, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 0.3764, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 0.2108, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 0.20693136751651764, accuracy: 93.7 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 0.25093841552734375, accuracy: 91.7 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 0.20569346845149994, accuracy: 93.4 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 0.3574502468109131, accuracy: 89.8 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 0.19897177815437317, accuracy: 94.4 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 0.20768219232559204, accuracy: 93.9 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 0.19631361961364746, accuracy: 94.0 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 0.19913527369499207, accuracy: 94.6 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 0.2195567786693573, accuracy: 93.2 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 0.1930529922246933, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 0.1046, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 0.2534, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 0.2361, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 0.1427, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 0.2919, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 0.2542, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 0.1802, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 0.1859, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 0.1934, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 0.2900, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 0.23437809944152832, accuracy: 91.7 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 0.30292046070098877, accuracy: 89.3 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 0.23342131078243256, accuracy: 92.9 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 0.5415158867835999, accuracy: 80.9 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 0.23210668563842773, accuracy: 92.4 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 0.23218588531017303, accuracy: 92.5 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 0.2191155105829239, accuracy: 92.9 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 0.2193451225757599, accuracy: 92.9 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 0.2518000602722168, accuracy: 91.4 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 0.22656451165676117, accuracy: 93.1 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 0.1362, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 0.2913, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 0.1171, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 0.2724, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 0.2174, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 0.2708, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 0.1612, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 0.1894, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 0.2805, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 0.2071, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 0.2145543247461319, accuracy: 92.9 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 0.3141193091869354, accuracy: 89.5 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 0.21096739172935486, accuracy: 92.7 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 0.5168799757957458, accuracy: 83.9 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 0.2070586383342743, accuracy: 93.9 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 0.20050030946731567, accuracy: 93.6 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 0.21069039404392242, accuracy: 92.8 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 0.20437128841876984, accuracy: 93.1 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 0.19756843149662018, accuracy: 93.3 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 0.21255254745483398, accuracy: 93.1 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "loss_list_epoch = []\n",
    "acc_list_epoch = []\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0\n",
    "\n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter)\n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "\n",
    "            qnn_train_step += 1\n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\"\n",
    "                )\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA\n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(\n",
    "            qnn_minimize_loss,\n",
    "            init_param,\n",
    "            method=\"COBYLA\",\n",
    "            options={\"maxiter\": 1000, \"adaptive\": True},\n",
    "        )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB9P0lEQVR4nO29eZhcVZ3//669el/Se/Z0AgkQdowBBYUIMoxGYVCRGcUFXNAR98l8BXcRdNQHh4HRQUQdcPmNgCsQwiYSwhpNCITsCUm6O0nvS+3398e959xzb92qruqurtvd9/16njxJqqqrz93OeZ/P6tM0TQMhhBBCSJnwuz0AQgghhHgLig9CCCGElBWKD0IIIYSUFYoPQgghhJQVig9CCCGElBWKD0IIIYSUFYoPQgghhJQVig9CCCGElJWg2wOwk8lkcOjQIdTU1MDn87k9HEIIIYQUgKZpGBoaQkdHB/z+/LaNaSc+Dh06hPnz57s9DEIIIYRMgAMHDmDevHl5PzPtxEdNTQ0AffC1tbUuj4YQQgghhTA4OIj58+fLdTwf0058CFdLbW0txQchhBAywygkZIIBp4QQQggpKxQfhBBCCCkrFB+EEEIIKSsUH4QQQggpKxQfhBBCCCkrFB+EEEIIKSsUH4QQQggpKxQfhBBCCCkrFB+EEEIIKSsUH4QQQggpKxQfhBBCCCkrFB+EEEIIKSsUH4SUCU3T8L+b9uGlQwNuD4WUkMFYErc9tgsHekfla0/tOopfPrPfxVHNTl46NIC7N+2HpmluD6Uk7D4yjP9+fBfGEumcnznQO4rbHtuFwViyjCObeqZdV1tCZiub9vTi/927FQvnVOKxz72poM6PZPrzf8+/hpseeAV7j47gpn86GQDwmV/9DV2DMbx+yRwsaqpyeYSzh3+/dyv+dqAfDZUhXLyy3e3hTJrvPrQdf9rShba6KNaeOtfxM//12E7c88wBVEUCeN/qReUd4BRCywchZWLfsRHj71G80jXk8mhIqdhvWDy6BmMAgHRGQ89QzPIaKQ3iGXrwpS6XR1IaDg/o98fAWG6rRs9gHABwdDhRljGVC4oPQspEtzGJAMD6bd0ujoSUErE49I3qi8PgWBIZwyvQNzK7Fgw3iSXT6B/VF+lHXulBMp1xeUSTR9wf8WTuYxHulpF4qixjKhcUH4SUCXUXTPExexDXtddYSHpHTcGh/ptMjh5FvA/GUnh2T6+LoykN4p6Jp3LHfAyO6aJjOEbxQQiZAD2K+NhycACH+sdcHA0pFd3GdRW7WNXaQctH6egesrqwHprhAj6ZzmDQEBTx1PiWj+EExQchZAKIHXIooAeaPvzyzJ48iZ7BJHbkI4k0Ysm03M0CQO/I7MpQcJOuAevzs35b94zOehEuJCC/+BgyBArdLqQgBkaT8mEhBDBjPi4+SY/Sf+glio+9R0cQS+Y2OU93+kaTSCixB/2jSRn7ob+v/1vTNOzsGR43TmHPDD8fU4mwMJ13XAuiIT8O9o/hpUODLo9q4qj3STzHNU+lMxiOl1Z8DIwl8firR/C3A/0l+b6JQvExRVx2+1M4/z8ekzcO8TbJdAZHh3Xx8S+rFwIAnt59LG9+/2zn5cODeNN3H8Nnfr3Z7aFMmG5bNkvfaMJi7RBWkCd3HsWa7z2Or/1+W87v+vtr/Xjzdx/DF//v71Mz2BmOONeL5lTijcuaAQCPbe9xc0iTQrWQ5bJ8qOvHUIliPnZ0D+H9P3kGn/rliyX5volC8TFF7D06gtFEGkeG4uN/mMx6jg7HoWlA0O/DGQsa4PcBqYyGoVlWOKgYdh0ZBoAZnXZsT6XtG0k4Wj62HtR36OKYndhycGDcz3gZYTlsq4vixI5aAMChGWxd7lfuk0QO8SGCTQFgpEQxH6PGhqcy7G6ZL4qPKSCT0ZAycu1y3VTEWwgXXEtNBH6/D+Gg/ujl8/XOdoQZeSYHZfbYxEfvaMIW86H/W+za85nOxeI6EveuNSwfQui11EbRWBUGMLPvHdVClmseUKualuq+GDVETGU4UJLvmyiscDoFqD7gfClUxDuIhaW1LgoACAf8iCUznhYfwozcP5ZEOqMh4J95FV+7BqyWzb6RhGO2ixAfQ3nEhxAypTKvzzbE+WmrjcrXemew+LDEfORYJwaV4mOlcuELy0eFy+KDlo8pQBUftHwQALLiZWuNPnFGQvqD7+X7Q+zkNC1/hcfpjD39s3ckaantMZJII55Ky117PstHIZ/xKpqmmQK+NoLGSsPyMYPrqBQS86FaPhKpTEnmCyE+quh2mX0kUxQfxIpwu7TWRgDolg/AKlS9hurDnqk72G7juko3wGjCkkIJ6BkwPQW4VMTiOpZMI52ZuSmkU8FgLIUxIyOktTaKhqoQgJmdyqxayHJVOFVjPoDSCNPp4nah+JgCLG4XDy8uxMTudokYMR9eFqeqGXmm7mCF5WNFew0AXUTZhdTR4bi0fI0kUsjkEBZq5kypggtnC8LlUlcRQjQUkGKvfzQxY2t99BbidrEFpJfC9UK3yywmmTIfhnw1+4l3EAuLcLuYAafTIybozr/uwfnffayoqquxZBrvuPWvWHH9A1hx/QP4xx/+pajUYbVc9GQCB8U4vnz/1qz39h4dwZu/+xju3mS2t//eQ9vx1h88UZCr55k9vTjvO4/i0VfMlM51v92Cq+58BolURsZ8LG/Tsy+ODsfl984xFshdR0aQTOtzgqYBow41HeIpa3GymVRK+xN3v4B/uWPTlFprhEtKWA4bDLdLKqPljaOZzvQV4nax3aMjiRTSGQ1X/s/T+MyvNk/o94pntCpCt8usI5FOK/+m+CCm+GibppaP3/3tEHYfHcEjrxReN2HLwQFsPtCPsWQaY8k0th4clOmihTBSIsvH5gP92HygH7998WDWe0/uPIo9R0dw74uvydd+/dxreKVrCC/s6xv3uze80o19x0bxxy2HAehC555n9uOx7UfwxKtHcGxEiA/d8rHn6Ij82UVNVQCAVw5bC2E5mc7VviW5PjMdSaYz+MPfD+MvO45ajr3UmPEe+vMTDQWk22CmZrz0FVDhdDCW7XZ5rW8Uf915DL998eCErD7CqlYRouVj1hFnzAexYd+5haeZ+BCLXTE1Jnb16J9dtbgRpy2oB1BcC3nVhDwZ370Y80g8lTUZm9km+uKVzmg4YhR7K2Ss4rwI8aiKhLuf2S9rt3S2VAMwW6TXVYTQXK1f65dt4sPJdN5jC1ydKcUJxxQrzlTWJ5GWQyXTRVg/Zmq8kDXmY/xsF0DPhCokUDUfZp0Pio9ZhzCxAtNncSHuMZpIyfRJMXlK8TFNLGPCzL/rSOG7V7HYnNBRi/kNlQCy617kQ41rmIzlY1ePPuaMZl0MAdOv3j0Yg6ZpODYSl+4Be3VSJ8R5EaJDzW551Kiu2VITQVNVxPJzjVVhNBhuF3sRNSerhj1ld6bU+oglyis+1DRbNch3ppFIZSzuosItH2lbWfbi5w/hdql02e3COh9TQMJi+ZgZkwiZOsSuuzIcQLXxwItsl+lS50PstIU1oxCEUFnSXI2gX/93Mf2M1AV2MrvX3UfNMQ/HU5bKjX2yZXkGA2NJdCuLfEHiwxijsJKoxyeMLK11ZvaFoKEyhEbjtcMD41s17GMZjs+MLA6L5aNn6twu9mwxAKivnLkZL/02wVRIqi2gC9expFkPR48ZC6EYRoT4oNtl9qGKj+myuBD3UHdtPp8+cUynCqeapskJ6dDAWMFBo7uNnW5nc5W06HQX0U5gqEQBp+qO224x6FX86t2Dccsi3z04/liFlWJgLIlYMu0oWFproqiOBGW3VcCwfBhuATtOwaTZ4mNmbFpU8aGKwFIj7qtWJ8vHDHS79GaJj/xuFyG0huMpy/HGJmT5YKrtrCXJImNEoVuWhTZ3bZHg9CkyFk9lpCtC01BQ4GA8lcb+3lEAwNLmalN8FGX5mLzbJZZM47U+M0PH7tJQJ+quwZglzqMQK43qGuoejMlr2V5nLoJtdbqoVMVGQ2Vu8eGURmsXHzMl4FQVqrt6hqcs7bV7IHfMx0x0uwhLn8iISqY1x2whIdDb6yoA6OJDFS6xCVjWhUB32+1C8TEFWAJOS+TT339sFF//wzYcHig8FbIU/PiJ3fjkPS/ik/e8iO88+ErOGgXFMhhL4qYHXpG7ZwB4YOth3ProTjmBDcaS+OYft2FrngyKWDKNG//8Mp7b21uScU0FTv5qe8DpkaE4vv6HbUX7zR/e1o0fPPyqPGdjiTS++vuX5DX75TP7x/mG7HLehYxh37FRZDSgJhJEc01EsXwUJj7SGc2ya+4bLdx0vu3QIL7z4CsYS6Sx99gI1PXO7tJQF6buwZglJsUe5OmEaqXQLSf6DvzyM+YhaJSDF6JS7MTFv9X/A0A05DfGqB/3X3cexW2P7UImo0lRZH5m4uJD0zTcsmEH1m/rntDPJ1IZfG/9q9hcQMt19RoOxlI4Ojx5IbDryDC+/odt8vqoQcJtddMj5uPp3cdw66M7J5xe3Ge4itTjcdqICMvH3Hr9cyPxlMVlE8sRqJoPcc3ctnww5mMKmArLx8827sUdT+5BdSSIT7/luJJ853jsPzaKb/7pZctr5y5rxqolcyb93f/16C7c/vgu9A4ncNM/nQwAuP7+l3BkKI6LT2rDkuZqPLi1Cz/+yx7sPTaKH7/vTMfvefSVHvz347ux5bUB3H316yc9rqlAdDZurjEtH3bxce+Lr+GOJ/dgLJnGt965suDvXnfvFhwZiuOC5a1YOa8OD7/cjTv/ule+/4e/H8L5K1rQUhPN+R32XfbuAoJOhWhc0lwFn88nhVXXgB7YKdxLOX+nbfdfTMzHfzy0HRte6UF1JIQFjZWW9+wuDdXy0T1gtXwcHU4gkcrIa+GEKgJUy8nS1hqcd1wzNrzSg+Na9DRbi+VDCTgVLGmqxrbDg/J833D/Vuw6MoIlzVUyoFV8ZjLi45WuIXxv/avoqIviLSe0Fv3zv3p2P27ZsAPP7unFPdfkf6bsi9/uI8OW+3wi/M9fduOeZw6gpSaCj5zXib7RhFzk51RZzzHgTrbLV3+/DS8fHsT8xkq8/ZSOon9eCKb2uiheOqRnQ8VTaUvhr7RSw8Ri+Zik22WUqbazl6mI+eg3FLA9UGkq2dGjR+nPra9AZ7Nes+BQiSwvD23rAmDdtQwYu1+xCxZlqo/kiSM4aBTFsgdmTSfEQlITNQPDzIBTffIWZZR7i9g59o8m5Lk5Mmykghr/Xzm3Dkuaq6BpwIaX89fusC90hVg+RLBpZ7OeYip2//FUJqsktOPvtImEgbEkUgVaCYWb5aFtXVljVUVNLJmWsSyAbpWxx3mIHXUuVGHWo1hOWmsi+M7lp+DH7zsTF6xoAWCzfFSGZf8RgUjHtWfQPPRStxQ14jOTcbuIZ+rIcHxCbpCHDItJIZYh++JXTLZULsR5EfOAOF9V4QCCAXPJkv1dXAg4FffBRK1LQhQ310RkQ0X7WqE+I+2K5UM93olYPkbjLDI2a7F2tS2N+BC+1XJW8xMT+2kL6nHKvHoAhQXpjcfOnmG5uxYmwGQ6I8+bWAzF3/nMqsKlUUxlzXIz7PCwR0JWy4eYRIoRUepELyL+xaR2+oJ6XHraXADAQy915f0e+0JXkPgwsmLEYhkNBWRQXDH1M2qiQQgjSX+BzeWEa2fzgX48vfuY5T1VSNl7rHQNxLNiK/LFfWQymkW8dCmWk7Y6va37W05olVYecfzi32oGTCjgw7wGc/eqplo++FKXrL2wxChMNhnLh1i0kmmt6O8ZGEti4y79nBbiCrM/d6VItxUxDSLjRxyDfbGU/V3K7HbJZDQ5Jz32Ss+ErNtizA2V4ZwFB8VcEA35UV+hCy17zEex64umabLCrttuF4qPKWAq3C5iR1fOQLTdSipli2JWnyzqbkEcz6gyiY3YxEc+s2qXIYYmYn4sF+J4qiPmwx6xNZYTgWPFiA81XkaIDjEx1VeG8ZYT2gAAf911LO8iJO6tGmNy331kZNzYnl1GUKpYLAGzdHxhKaz676yrCKGuImQ5hnzEkmkpKjQNeMpYKMXY1efDft/0DJkBozVR/fP56pLYXUM7eoblfaYGPgrsMR9qBkyLkREjxqhaMIcVIdZkuCwm85xb6qcUaRV4bHsPUsa171fcHbmw11XZXQLxIe4DERhpPj828VHpTrbLYCwJcVqG4qksAVwIYsyNVab4sGe8iDL9tdEQqoy5IzvbpbhNVyJtBpezt8ssJDEFAadicS5n8aFdSiplm2FWL8QUOx7C5QKYx6XuoMRkLCadoVjKIuhUpOVjAubHcuG0c7PHfIhiQYW4LAQWy4exmKmT2nGt1Vg4pxKJVAZPvHok5/eIgNMV7bUI+n0YS6bzWi80TcNum+UDMJvmFWb50K9XdSRYVKVKexlywcp5dQCsKapidyosK/t7R+Vu/mTj8/nGan/W/v5aPwCzuZkde8yHz+dDvfFaW50iPhIpx916W21UiqhJWT7U+ilFWgUeUjYGGS27wqYdsfh1GNe+FG4XcR/IeSDhbPlQA05LFQhfzPgE6nxW8HeMihTasMx8s2+gxEaktiIkxfJQLGWxBBcrPkaVe4N1PmYhCYvlozSLolicy1l2WfXrt5bI8tEzFLNE0QvRMKrs1uyWDyC362VGuF1i2Ts3u/iIGX8X53ZxsHwYf4vF7y0r9IDDfL5pscjWVoSwcE5l1nfbOTIUx1A8Bb8P8vOAHgcBFFblVJjUqyJBNBjuikLM/PasEEAvb35Cu97YzdKszrhnFs/RrTPCYhIJ+rHMCBLN50bMzpzRf14tdKVij/lQ/26tjcjrby+RLWitjcoFdjJ1PiwpzEVYBeKpNB7fbhWp44kX8dyd0KGLuQN9oxOKQxAk0xlZ1VPdfADZlg/h5spo2RlbU4l9Lnp4W0/RsTXmJiGUs+aP2IjURoOoMgrndQ3EoOqsWJGWdeFyCQf9lvgZN6D4mAKmIuBUqP9yiY8+pTX4kuYquatVJ+tn9/YWbfLc8HIPNE01kwvxoVg+bJOPPh594u8ZiuHF/XpDME3TLJaPUtUYONg/hpcOFdYgbSyRxsZdx/IGS4prZxEftgqnYsIeimX3JxmOp7Bp97Gs3Z1FfBgTolhgxaJ34Ym66+WRV3os1qPn9/XJ66u6hZYYAaT5Kp3uNH7vgsZKuWsDzLTBQuKChhXLRzEpk+J6nzy3HosM4bOgsVIuRE4Lb2dLtQzqA/RF3hxrPsuH/l1+W+KOk8sFMLMv/D5dyOmvheTPVFncLvp1OrGjVprd9c8Eso4D0OMMntvbW1AXZFWAFZMJ8vTuXgzHU2ipiWB+ox6fMl6Au9g8zGuoQG00CE0D9h7Lbf0YS6Tx3N7enM+qGqdjWkCdAyQjQbNicO9oAvuPjZa0ud1YIo0Htnbh/s0H8ce/H5ZuEDEXLW+rQWU4gK7BWMENFV/Y34f7Nx+UJRPUmA9xbXf2DKF7MGaxfIhjP2a7nrl6wgD6/LDT9hxPlwJjAMXHlGAtr17agNNyxXyIaoUddVFUhoNywu0ZiiGT0fDMnl5cfvtGfOH//l7U9z5m9MN460n6oigeBov4SFgnHcCcRD/y8+fxzv96Cjt7hjA4lrKYKksl9P7lfzZh7X/+FUfHyYQAgFse2YErfvw0fvP8azk/M+LgdokYJk+7+EhnNMu5AIBv/ellvPtHT2P9y6b1IpnOYP+xUfl/MSHKQDZj0TtjYQMaq8IYGEtKt8HWgwO47Lan8JlfbwZgTvLV0aDMXtmdZxLfbvQqEUJFIOOCigg4LdbtIhuMKWmknS3VchEaTqgLr35OmqojaFHSP9tqozI1OJ/4EOdlvi2dN5f4EGmgjVVhKXbmGM3l2lW3Szwtj3VufQXesLTJ4TPW5/y/n9iNf7p9I3721L6c47WPGyiuBoZwzV2wogWNRq+a8UqXqzUjhAtuu62XjcoN92/FP92+MaclzikWxilmSiDu84N9Y1h765N42w+fLFkMyA82vIqP/uJ5fOqXm3Ht3S/ghvu3AjCfsba6KM47rhkAsixGTuzsGcKl//UUPvXLzbIeSlN1RAafx1MZHBmK4x9ueRLv+dHT0uVVGw1lWX0Euea8oVgS7/jPv+Kdt/7VsgZJIRd2/r5yQvExBUxFwOlomd0uok+DmFDE5J1M65Hemw/o1odXu3NPNE4c6NUV/1mLGgHoZkBN0xzdLkMOk+irxsT299cGsgpaTcbcK4in0th9dASpjFaQi2nz/n4AetGtXAzHc1s+hItObRBld72IyVyt5Lm/d1QGBgL6hKhpmiXmAwACfp+shXHMmPBEZVIRUKzGpIiU6nxul0de0QXk6xY3Wl4XC3phbhfxOwNFlcnuVlJdP3peJy4/Yx7+9fxlFquCQNwzjVUhKYwAPS1YpAbnE0pijHqpdDNzpS2H+DihvRZXnb0IX3jrcvnah96wGO88bS7WnjrXMWiwsSqMdf+wApeePhdXvn6BKaJsboT7XjwIAFk7WScmWjlWCKLFTVVorCwsCFg8cxWhgLwfxP1hJ55K409bDgOArG2RawxAtvvVKTVUWPju33wQfaNJDMdTOX9/sYjnQ9QtEc+hvHaVYSw15sdCNip/O6BbRxqrwji7cw4+ct4SzGuokNbDeDKDg/1jSKQy2HN0BH/ZcRSAHohcHXUWC7nmvMe2H8FQPIWheMpyP4h1xO1gU4DiY0qYmoBTcxcwVSWMVcxgU/3hCgX8aKrWH/SuwZgUJ6JbaKGIgNXFxiKnabp6t2a7ZFt5+kYTGI6nZOrjriPDWeKgFEGnakBjIUJPnKdcsRqpdEZaZ5xjPvQxq2WS7UGnYsFVJxrhFhGxD30jCQzFU1KQqMGPIlhNpjAbC1uf3e0SDipuF2fLx2AsKaP7L7QVsGotYEEXqAuKLBZVwEIpspva6qKYU63X2lg5r85x0ZbxL5VhGY8CWC0fuQJYAat1RrV2tNY5iw+/34evvP1EvOvM+fK10xc04PvvPhWttVHLdTAtVPoC9r13nYr2ugpLUKp4rvYdG8F2Q+QXEhM04mD9KQRxvJXhwq/JmLKYifvB7uITPLXrmHx+cwWuq2IpK9vFYQEW4/yjIWqAiQWAOo7FuH+ueN0CAGYNHfXa1Rq1e+zdZ50Qc8U/rGzD3Ve/HusuXgGfz2dxu6hz3l926NaU2orclo9c4kO1LKlzy1jSrJniNhQfU0AibS7GpbB8JNMZJI3vdGobPhWYHUuVVEplwhZumViysKJSgH4uhLlRDVQciacs4mPIMeYjYREbu4+MZJnMSxF0qn6nUwMwlaFYUk5IubICVNdRIdkugHWB0TRNLpDq8Qm3yKnz6wHok7awbFSEApZsDGFite8kh4x6E06Wj67BmKP4emz7ESTTGjqbq7LcLuL+ODIUHzdF0+p2KTzV1uyTYxUAZqCmk+UjbClj3VoblWMdjqdyikzpLgsHLb+vdYIVPFXrTK+ye3b6jPqcqwtJIeLDkvFThAtCdaE0FpjGKn4mGgrg1PkNaKoOYyiWwqbd2e0O1OPIZVVUxdJwPIVMxqxVUu3gKhAiW50/nnj1aEmsoEJkrGirMcaWQDyVtlitaiv0MY2XFQQopQuarM9NRAk4VQNnxSNUGw0hEvRb4pYETiUGEqkMHlWsP+pnxHxEy8cspdQBp/YYgHK4XnbbLB+Aubh0DcYsKXWF9vMQ1SRDAR+aqiJy1z6aSI+b7dI7krSY83cdGc4WHyWYcNRgSacGYCpqGfJcOx8RgxAO+C1lvCO2CHer5cOcyPpGk9J6NuZg+ThzoW7qzmj6DhlAVk8RewaFKur6RxOWnWV9ZVhauPY4pE2KgmUikFWlqToCv08fy3hm6GGL+BABp+NP4OIesLs+qhSLgcBi+bBZLqoiQRn0nCvuY0g5L21KhktbDsvHeIgxqi49ewn2ynBApgaLc6SmvxZWPdY8j8Wk2op5pjIcKLh0+ZixsFWEAgj4fVhjZFfZrQ+ZjGYRH7mCku1uotFkOq/bRbXw1VeG0F4XxVgyjb/uPJp33IUgRMbi5ir57PYMxqVAaqhULR/j37vSmtxiFx9m/JdTTF9tRRA+n8/RWuEksjbtOWZxWaufGZPXmDEfs5JEiWM+Rm2L4FTX+kikMthnxAU4iY/tXUOWSanQ9FvxuZaaKPx+n3wAxpJpq9slodf1UIVb32jCInL2Hh3Fwf7Sx3yoLoPxRJ4aF5Hb8mHGNqhkpdpaGnSZ36WeW4v4MH738vYaaZIVYkitrAmYgXpS1KkLtOHO0j+nf490vdjiPhKpjAysc+oZEvD7pH98vEJjahBuodkummY2YLOnuwqXhvpsiMyJhiqb+DDGKOI+cnXizel2yRHzMR5qkJ+I31FjSQDA5/PJHf6wkZKrNk0syO0yQcuHxe1SoCCM2WIIxH3x8LZuizv2b6/1W9ok5Lo/7GJnRIlZcHI9NCr3+vnLW6Tr56GXJlb2XJDOaLLibmNVWN5v3YMxeZ82VIZkVtN4ojCVzsgsoE7FmgyY1Y7jybTjhkcIHLU9gwhudkq1tQfzqnPLKLNdZjfJKbZ8lDrjRdM0Sxrn/t5RpDMaqsIByyQv/v3ULuuuwmkicSr602NbOMQDYHe7DNuCpAB9UuoaMCevRDqD5/dZTbtjidznutAiRKp1ZbzzbLV8OE/SaiaJiiypLCqcqm4XZSJTBZeYRDRNs9RgEWJDiAV7K/dqW8yHPYXZXv5dTI72apVP79Z3VM01EZxqlNu3IywS+3vz13uwFBkrcJc9GEvlrDDq5HZRXRutDpYLmW6rnGNN0+SiaaZ4BuTv8/t0C89ECPh9spmXTLW0WT7UYxmJp7Hh5W7ZPRgozLyfK9tlvGfA4napErVXCnO7iOM6Z2kTKsMBHBqI4YX9fRhNpDCaSOGBrbol5OxOvSnlsZGE48bMLpb0ucC4V/LEfADAhSe0yaq+G17pHtf1l+98DI4lZbdkPWbITCPvc4z5yH9dXusbQzKtIRryo8NoEidQraDi2oWVGhxC4KgbGNHrRU21FTEjdvGhrkEjinXLbSg+poBSFxmzxzKUuqDOdb/ajPO++6i88XfJjqXVlu6kYmF5tdu6KNnFx6Pbe3DKVx/CH/9+2PK62hcDMB+AsUQao8qEOeLgh+8bTWT9Hvs4crldegZjeN23HsZXfveSfO1HT+zC6775MHb2WLN1uoqI+bBaPnK4XWRTLOvEGQ7ox+5o+VAWGHVXLj7TO5LAwFgSPp/ITAhbxpPb7WINOAX082pPZeyUlg+r20WY0tesaIXfwf8MmLEYn7j7Ray44QHc+uhOx88NqZYPY/z5KtkC5n3mVGFUWAsSqQwSqQzGEml5PzRUhRwtF+qCAuiL0aW3PYVLb3vKEmtQpVg+1EZgE0EsoGLds8d86L/PzIp52Eiv/sdT2gHoAmy8AG9LefXRJDRNw11P7cUpX31I1shx/DklHqDQ0uUxJeZD/H3uMj399LLbNuKEGx7ECTc8iP9+YjcA4N1nzZcl552CTu1iZ8TI2ADyZ7tEgn6ce1wTVi1pRE00iKPDZkaeEz95cg9O+dpD2JqjPodwV9VEgwgF/JbqvROJ+RDP5uKm6qxnR3W7iGfz/OUt8v1a455Rj7+tVhcwwvLxpy2HcdKXH8SJX34QhwdiqAwHZCYO3S4eotTZLvYdeKktH49tP4IDvWN4+bCe/nbQMAnb25XnMjfb/bdih2wv6S0+J9q7VxgPwGgiLSvvAfriaHct9Y4kckbIi11hLvGxcfcxHB1OWFLwHtjahZ6hOO7edMA2RtXtkl84WsRHjp1PLpOxWtVQ0zTL7kT9LvXciolDBO02VIaNhm5CfIzI11XstSOGbfVTzDHqO6xOB7dLJqPh4W36+bNnuai8ZUWrXJw1LXdlVfW81FaEZCGvQpoIOlUYVXeFI3GzBHUo4EN1JIhFc6pwfGsNzj2uWS6UckExBN6R4The3N+PF/f34+hwXC4ENZEgTl9Qj+aaCC48ITvWpRiy+pM4WD7U67X1oP5MXmTE2DjVgVHRNM0iLtMZDYOxFP645TCG4qm8sRCi5k5V2HSFjZvtkrS6XQDgvasWWOKbBAsaK3H+8hb5/DvFffTa3Dz6XJC7zsdZixsxt74C7z97ESrDulB4/RLdurLltdyFvx7d3oOhWO7zYU9ZF0L1cP+YdMc0VIalK2Qkkc5baFBtVWHHKduls6UKl542F8taqnG8EfCq3jvtxr0rhMVfdhyVSQkA8N7XLZCiRbWqjk4jy4f78mcWYu9qq2maxYJQLKO2RXW8QMhiEZX1xORuTvJWsWH//3Gt1Xi1ezgrtVL4ge0TV4/N8iECqEYSKYt1ZySRxpCxAIsARjXbRfxewcKmSmw9OCh/rx0RnKnu4oQve/3LXbj+H1fI62MJOM0j8tIZDXuPmrU9EqkMYsl01o48V7Cc2snS7ppTLVuqS8Beil5MIGKCFD71LMtH2Gr5sGcRmTtL/ftEhtPuoyNIZzQE/D5sOTiArsEYqsIBrDZM506866z5ePupHdh8oB/v+dHTOWt+qOIj4Nd7oPSOJNA3kpSLkx1x/Z1EcDDgRzTkRyypm64HlAXC5/MhHPThz596I9THUJaDH7Le9/q/45aeInOqI9i07oKcFp9CUUVSwO+TC4SKsI4cGY7jYL++ETh5Xj2Cfh9SGQ2DsWTOdujxVEamW6vPjnCh5Qr0tHc79fv17x8YSyKVzuQsxR2zuV0A4NzjmrH1KxchlbHe19FgAH6/D211URzsH3O8N8QzKsauumCdjrmpOoK//tv5lteWtlRj/bbuvH1mhEsu1/lQg5UBoK3OqPXRPSTdMfW2eJ2hWMpRTAJK3SRbhhigxnxklMq/IXzv3cstn7OID5vbRZyjf7t4Oa46exGioQDe++On9c8o1nfGfMxyVMuHpsFSDGoi2N0upcx20TRNKmMxuXdLkWDdYdp3nGd36pUZ7ZOIWCTtJlt7sKDqdrEv9GIhbTf8oyOJNPYbBcrE7wX0CXxefaXl99oRHVhFailgTi4HesfwilE8SC3XDlgDM+281jeKRDqDcNAvFzQnd1iuGgVqwGk8R0MpwOp2EZkF9t2L3dJhD2KsjlotH6p47RmKy3MiJrd5DZUIB/xIpDI4ZCx+woJx3vHNjk3VVKKhgEyl7hmKO/rWh22Cp75y/BgDkdacywKn1shQ02wFfr/Psgmw9ytSg3vVVGOx6E1WeABW95sQRrk+I0p2N1SGDBP/+MGN6nMknp09x0aktSxXDZZYMiMX1YpwAPXG79I0s7uqE2JuUnvtAPr9XRkOWv6I85evHoyYM8znPpUVED0eotOyKAfgRJ8UH/nrjYhnSdwrYq6oNdwxoYBfPof53OFiLEscLR/Z2S5OVh5VfIm4ETF3i3PUUBmyuMD0z6jiQ1iq3Lc7UHxMAXa/9WQzXuwL83ixCMWg7rrF5N6Vw/LRWBWW/lrADB6zTyJikbRbPuwWFdXtYhcO4jvb66LSjC/SN89Wdt7N1RH5UOYUH0pVyP7RBFLpjGVCFQvrsD3wNc95lnExTVVmMKCD6yVXjYKwEnBqH3fOgNOEtQ+O8Ns22rJb7Luv6jwxHwf6TOuNOI8Bvw+LjQlc9HER56hQt0NTdQQ+ny687f0oNE3LckcVUldCiINcFUZlbEssJS1b9t2pir1fUbctGyNflsVEqYmq4sN5bOL3iXL4YrdcKzub5hYDMm4jFMAcI2X6+b1m7EMuS5SaUVcZDiIY8MvflyvjRdO0rIDTQsjldkmkMtIKN69B9JZJyjmq0OsgUllzFcoDzLkpd9aNmSkFWGvYqK8DKCjoVA0Qt6O6XfKlFavHL6zHIkXfFGjmPRUNWdP5AXPuYJGxWYpdbExWfNgXp1LGfKi7bjG5i6JWdvHh8/nkxFEVDuAUo8CVvaiU2A3ZF5Ju2/eKB0CPiE87frY6GsyapFctNsVHa20EFWG/5feqZDKapdlU32gyaycnAintE1G+86yWnzd3pE7iw7kpluoTty8m1lRbJeYjh9vFLjZyFa4SC5NqORMpn5GgvosTdLYYZdZ7hmWFzYDfhzcfbwbC5UOviOucdjuWTMuAS2GVKaSiZr6YD8DqXrL77J2w9ytSrUzdgzHHbsSTRb0PcpnoxWdeOazvsqX4qBh/kRuydAvWv/9ZJVU3l+VDPH9qMavxUqAT6Yy8jtEiFrNcTf1EXxe/T+95o3/GvP9zuZrsdBpFvHIVyhtLpE1rb47zIcZidiW2zoWqtXG8oFN7k047qgs2n/gQVsKaaFDek2L+dkrpjwadLB/651hkbJZiDzKdbNBpdpGx0tX5UItbiVLpuSwfgDlxLGmuRlO1HvlvLyolbvb+saQUJWolSdPyIcRHtttF7NDUSRQAmqrDqDOKCYnvqnAwLwoO9o9ZlH/vSEJOphHDZbL14CAO9Y9l7cTyubeEGbWzqUoGnTkVGstlRlVT6eyLiZjEkukMjo04iQ+r28UuNrItH2b2hDomADhg1HOxL7CiCuPuoyPS6rFqcSPq8lgS7Ki1EVTEOPw+c8dciOUjVyySwKlxm90lpWLvV2SN+ch2u5QC9bucMl0AU5AJd60QgnKHndftImIGzJ45fzMsKEDu6rNyR+wgjnKlQMeU1PZiLB+57gshPOsrw9JCJOaBsE0c56OuMpS3UJ4qcHsG447ZQ/L+Mc6B3drWWITlw96k047aZFI8mzWOlo+Q/N3CqpFt+TB/LiLnRaeAU7pdZiVJm6VDtS5kMhq+8+Ar+O0Lr8nX/nagH9f98kXpX7czalsES2n5UBdsMeGKG9Rphyle62yu0otKOexuxSKpaeZCKt6vjpiqvVIRH7ncLjVKHQj990eN318t/y8mPie3i71QVt9oQppUO+orcMaCBgDAwy93S8uPGggL6MLq07/ajGf2mDtIi+UjmnvnkyvmI6JYPuyLiRAxR4biUOfFXG6XLMtHlvgw281nMprM9QdMk6x9gRUL3p+3HMbtj+tpkvmyXJwQE7Z9d6l21hQxD+ZCZz2H8VQaX/j//ob3/vhp6W/PKT6U2BanmA879n5F6ji7BuPyPJXS8lFdgOXD/vtMy4fVvfc/f9mN7zz4iuWz6v0mhJe6+OSqPit3xIqIUAXhhpe7ccP9Wy0uZfG8Bf2+goUBYK2UrNInK4eG5LUUbkenxTgfuQrl6b/HFB+JdMbRrWS/fyrCAUtwsNXy4SwK12/rxr/csQn//tutALIrmwrUOh/5gmvFJqKhMizjRGK2gFNL52zje50sH3S7zFKyLR/mxX9y51Hc+ugufOOPL8vX7npqL+7bfAj3Gp0r7agmUaC0AaeqVaB7MC5FQk006KiOj2vV076Ey0UGjznUowCyfauqoKmUMR+prGPsUiwf6g5RTFyip8lxbTXS5OvkdrFHvPcqJtCGyhAuPNGsiCgmOjFxCbP7n7d24d4XD+L2x3fJ79nXq3/vojlVec3huWoU+Hw+af0QPycmfr3AkRn8KuJsxGQ/liPbRWCPcxCm2FRGy+nWsI/vZKOIWN9oEkeH4wgFfI4l1fMhan5kWZRi2eckV1GrB1/qxq+few1P7TqGeEoP8FX7Ajkdw3A8Je/HOXnEB2DtV6Q2mdt/bERaCOzVaSeDGnBqj9UxP2P9fUtkzIfp3kukMvjWn17GrY/uwn6lo7K01oSDOb/fKc5hzGZNA0xxdGwkgS/+3xb8bOM+PLnDTE2dSLwHYD3nKuqCL66l3BAUKT6c0sXtv0fgdD6cLGeq6FXPrdx82HoyfeV3L+EvO47KpoCn5CjMZ3a1zR/zsWCOviFY0lwlM2T0QGHN0fIRzWP5mA5uF/dtL7MQe4yHusALE/aAscD4fD550+YqUy5S4FpqIzjQO1ZS8WEpQJNMy5bduYL6PnpeJ1YtnoMzFzUYY4oCGLAE66kWiL6RBNDsbDJXLR/CuiOOUUxMVTksH584fynOWdqEMxc14BdP78v6vYIsy8dIwuLTfssJbfjWn17B07uPSTN8Z3MVthwckDv0Y8ZO8bBxfVLpjJKNE81rDs8XtBgO+pFIZ6Slo6U2gn3HRpHK6IF84pzNb6zE7iMjSGU0JNMZuSMXE4gqNqojQTmZCdQFL1eAnX1n2dlcjXs/fjYOGDEhnc1V6KivcPrRnJidY53dLuqiLiZ5u4lfPC//eHI7LjyxDce1Vsu6JnZU95JovGdvfmentTaKlw4NZlk+9vcqgbglNFFX59g9q6gLTyjgw3wj+LJGLnIpPU7FsIrtOjKMBYYgs/TMsQmv5poIjgzF0TUQw8nzrL9TVr60CEL95x99pUdaS44oVhOZ6VLkQmZv6ieeDXXBF691K/NAMZhVeh3cLlmxaDGsaK+1vCasIaqwb6uLYocxP6rntiaaHfP18uEhHOwfQyTox83/dDIqQgGce1yz41ilhUKJ+XCaL85d1oTffHS1rPshGFViWKziwwxkFbDI2CxHWD5EFp0QI5pmNldKZ8wUV5GilTMYTCzMRrBnad0uVqH0N6MwTy7TdjSk13kQZlaxwFgqcSoWCHs+fVsu8WEIB+HGMR/CgCXgVFhO1HFUOCh8gahvIH5v72jCMsktbqrCspZqpDIa/rRVr8gqdk2JtF4t056Wd2wkgYymZ4XMqY5Ic7hTFoLaGdWOCDodVHpICGE0FEvJc7ZojhmkNpZMywlEfKe9uZYdvY+Ofo6EqKuNBi2VOp1296ctaMDbT+nA20/pwIkddVnvj0eulErTNWCOVRxDv7IrTaQyeMwoDPfBNyzG20/pwPI26yKhIs7HwFhSNtnLZeo2x6jfF/uOjVoCkcXCXhUOlCTFVlDtILjsqBkxi+ZUyRobquVDFZGqwFbN7+r3V4QCcuetbhQEMohZsWKIe+m5fWa2jOqymKjlQ3W9qsfRpzyX9to0Tqmn+chr+XAQH3ZkaX7FwqHWn3EMOFVivkQQ+xuXNWPtqXNx4YltOVPU1XnAHoit4vP5cNaiRtRGQzKYVB0rYBVpTpaPEdb5mN3IugnGAyQsH6JQk0AGABo3RO40OOeFuRTYgzRFel+hzbOcgscslg9jMZFN5Sziw9zxiNgGe4Gp6kjIuvtwGJewADgFnAq3i7DU9I0kzEnO+F7RDEs8pOpueSSeklUXRUttcSzNRsBtvoCzXL1dAHPHI8RHNBiwxI+Ie2VBY6UUsrGkGZwrjjsU8MsFK1eMg5jsZSxNNGQRdaUMqhS05nC7iPvdshA7ZLsU0ktGRZzjlw8PIpnWUBEKoH2c+1jcv1sO9gPQd4tqzYpSn5cqB8tCvs+oqZmqe089p+oCO+wQ8wHopnoRpO3USM/J7eIUEKteH6cCY4XS6tDUT3x3Q1U463kpNu5GnDdRKE/FXkXVfn+m0hn5LKtWNrXukUV8OFg+zNT08eOkxDxwTLEqVY5zTkMBn6wKLKxS9s7Z0aA1KDWjbHgpPmYh6YyWpV6FGLGXmpZFnwzzfi7Lx5jidgGmWnwIy0dhzbOcgsdU8SECCEUVSWvMh/4AqBkdoiuqoCoSyOl3FURzBJwOxpLSPXLmQkN8jCalSVV8rz2WoaM+KhcgNW0T0C0H0oVkTOb5ij+pDdTsyB2PMdFFQ37bAmO6qqR1J5GxVKIUiIUs1266OsuHbj2vpQyqFJjiw3pfDzn0u5FpnUrAaSG9ZFTEMYiy2oubqsb9OSFmxX3fVhu13GOlPi/FpNoC1tRMM6UzZbV8KPUsVDefKm6WNFfnzDIBnN0uTuPrV67PRN0ugHJvKHVs+hRrg/28FysC5zZU6G7NVEa2i7D/HmH5s8+7A0pTOVFsTR2zPkaHgFPjOT7YP4aXDg3C7wMuWDF+arrIShmUz8X41jafzyfnPWH5yApqF1k0IlZMmR/pdpmFqPEeNTbxYW/zLIs+xc3sBqc0ODGhCMtHSd0uOUp7F275sAaPqeoaMC0fTm4XsXM/OmSmvtY47HgaHWI+VKT4sAWcCn9vS00E840+NX2jCSWwTZ80Tp5bJ+M9AN23qxbmUgPUeoZipigwfsYp4EyQL4BMBpwaoiUaCljiR9QgXTWjx+52AUzRMd5uWohAeyzNVIgP6eoyLEYCpzgYscsejqcQT6WRyWhF7R4B8xhFkO94LhfAvJ+GZNxNVPbxAJwtVpOhxuGY7VTnsnwoFjZ1wVQreaoBpw2Ky6CzuUpZ8LPdLmMObhene8li+UgJy0fxy4jMhFLq2PQqmwL781Ls/Rnw+7DYcFfuslU6FccgKqHaLc7iea+rCFnKyucOOLWm2q9/SRfNZyxswJwCOiBHbH1wChVa4ueE5cPuOo0qQamAaXH0+bIr0rqB+yOYphzoHcXD27plDrimaXjopS68plSEdEIVH+ImSqQzlkJNTTb3iZiM1TS4TbuPyR2ccLsIy4e96dpkiDu4KoDCxUeb0u0RQFafErHLcHK7iMVTKPKqSDBrss8OOM1+mHPV+RCVTfW282ZAoz2S3e/3SdeLz2iZbhbmslo+ugbippDKsnxYxYemaUp/kOzdod3yEQn6LemUalE21bpjd7sA41s+xO+XxdtsWURT4XaprwzJY+xx6JmjXusaJQalfzSJLQcH0D0YH7eXjEpWurBDQSc79vu8rTYqLVpAaYNNAbvlI3+FU8AqoNT7TD2fR4cTMlbGLGpntWx1Nleb4sN4Fp/f14cdRiaGUxaE+vPnLNWvgSXmIzFxt0uLg1WsX8l2scd4TOT+FOniv3nuAO786x7pnhK/RwSZ2i0fwlprF1/qvZKvyNj6l4urBmwXH4UKXjEniNL59ns1Ksu2iyw5w7oVCkyq11ipoPjIwWd/8zd8+GfP4aVDelfJF/b345qfP491v92S9+fUNFtxMyRSGTxpdE88a1GD9L2OxFNZXSq7B2PoHUngn+/YhH++YxMyyvsiHiKRzlh2kpPBbvkQFOx2McY0MJZELJldr6NvNIF0RpM77jZlYrf7HStCgawdTnUkKF0x0ZDfcTeWq87HNqNLb2dLlaVmgVMNCOF6aa+NIhTwWwLe1N1e92AsK3NHzUJQGU2kpfm2JpK90NgDTlXLx9HhhDQXt9ZG5aKgtopXz5+w3NjdVgJR60OIQHs2xFRYPnw+n7yP1I7ETlVf/X6fjEHpHUnIjshqF9rxsC9YTqWs7djv89baiLRo2cdYCsSi5XSvC2orQvD59CJsFreLcW8MxVJZmXEitkkWqTJ6j4hzuqy12qwsOhTD3qMjePd/b8RVdz4LQC0yZp7D5uqIjCt415nzAeSI+ZiA20XMgSIwWNM0WedIFx+2/kQTuA5LW/SskD9t6cJXf78NH//FCwBMcbG8XX/fHvOhpuKrdBjN3EIBH+oqsi0fQ7EUYsk0Nu3W6wGtKdBiF7Hd34Ueq3gujhniw/5z9oDT6dTXBWCqbU4OD+gPgj5p1knTXK5CYAIhPsJBv6Vmv7hBFjdVyW6ow/FUVofaroEYRuJpJNMaBsaS6BtNyJumSTHhjcTTWSmVEyGuLGSqCFJFQj5UN4luMreKmd4RfRFNpjWEg35Ht4ugMhzIUu/VkSDm1lfg//3DCrTURhwVuyyvrogPTdOwwdiBrF7SJBfakUQaaeNaqovvucua8O//sFzWMREP8tHhhMWN1K2kZArx4RRwBpgLgT+HmVMGnMZMt0vGUCvrt3VhLJlGU3UES5qqLNYdpyqFV5+7BNWRIP7pDFsOpUG1tHyYbhfVdDwVlg9AF6cHescs5nVh6amNWif3hsowjg7r4lCkNIp6MoVgX7CcSlnbEf2KRDtyuyWk2CyL8Wiri+JLl6xAc43zvaz/ziC+tvYkhAM+yzmyWsX06yg6+e4+MowzFjZkufm++c6V2HtsBMe31kj3Xv9oEvdvPoRURsPB/jHjnhJZEOZ9UFcZwk2XnYxQwC+tBE7ZLtEJzENnLWoEAGzcfQxjiTR29Azh6HACleEAVrTXZvXHmoj4+OdVC3B0OI6B0ST+uOUwdvQMIZZMy2MQx3R0OI5kOiMz+HIVqGupieIrbzsBNVGrO0a1SO09pqfE10aDWJSjHo2dLLdLgeJABqqOOKcjm7VArG0ZSlm3ZjJQfORAFEISC4+9jG0uRHXTiBJ5nEhl5MJUEw1Zem3Y4ze6h+KywRugmwSFP7a2Iignm5F4Km/1xkIRN+aCxkpZQVK4HgpBpHGKEuliEhf0jSYtTdgs6Z22h6wyEsx6gMT/rz53Sc4xOMV87OwZxt5jowgH/Djv+GZUhQMI+H2WFGfV7eDz+XDNuZ3y/8L0qdZ7APTF2+x9o5+juhxFxtQCY04LTThoFhUD9Mki6Ne/62lj9/SWE1rg9/ss1h2Req1aPjqbq/Glfzwh5zkS51E0eau2pWKWOrZB4BR0Ko5XLKaCBmmdMu+ZQqwXAvukKkrE50P0KxKt61tro1Dv4Kk4Lx9+Y+57WfAvr1+Y9ZqoJ5FMa7Inz1mLGvGXHUel5cNewO0fVrbLn6+tCCIS9COeyuCeZ/bL1/tHk+au2LYLv9yweIjAbdEyIeD3Ycworz6RgNMV7TWY11CB1/rG8MSOI9hqdPB9k9E1ORyYWByESkttFN9650pomoYnvnoEQ7EU9h4bkdabpc3VCPp9SGU0HB2Oy066+UrzX3XO4qzXxAZsKJ7Cq93GfdtSXbBrY6IxH1mWj2gOy0fKWhl5Im6yqYBulxyIuAqxOMugnXHiLYTlIxQ0xUc8lVF2e0GlGFIyW3wMxCypc92DMZndUBEOWAIhS4E4LrVqZFN1pKhyyWplSXvcRe9IIudCkmX5yOF2GQ/xMMVTGdm+/SEjWPHspXNQbSz+DRaxYe5Y8h2TPcanK4/lI5bMWGJ+xuuKaq9wGg0GssYkYlHUKq5O2S7j4XRerdkuUzMhOWU1iODOGrvlw7DEHBuJy2DhQuI2BOoxzq2vKNgdoFr52uqiFuvcVFmEJkJVOCDdIGKeEfEw4hkz05id60TYY7QAWKyruXbFouaHpkHWQ5lonQ8xFnFvr9/WLYPxxWtqbZp84yr0d4m5Z8trA/IZnVMdlu5K1Y3Vr6T8FoJq/f3bgX4AxYlmuwXbHnSf++esAaf2ztlmeXWr22U6pNkCFB+OJFIZ+XCLCyfcEyOJlGMjIvVnASPnOmC2TRcTbm1FSFms01lN4roHY5aqfPuOjcq4gcpw0BIIWQqEWJjXUCkntkLjPQQ1iiVHTEjiARoYS+JVI6jNvpBEgn6oGWWV4YBFvQf8voKistVFRqj8hxxawKs+3PqKkMUKY0csxq/1Wt1s+5ViVGJhVcesFhrLV60QMCcHYS2KhPyW/hGV4QDO7mzSjzFkupZGHdIix8MpdVG1nJU6sFLgVM9BFeIqYjzbDg1iLJnWq3s2Fma6BnKnqBY6RkB3E6n/t0/obuLz+SzitCYSxMq5evE3KT7Guedaa7LdqX0jCaXbqfPPqbVkhFtiMnU+APPZ/NOWwzIY//zjzTgJ9RgKXZBzIcTA80bBtEhQL07o1AKgd8TMuimESDAg56kX9/dZfl8hhAI+qEaSQoWWtHwYlhq7UI7aAvFNt8v0uKeLFh9DQ0O47rrrsHDhQlRUVODss8/Gs88+K9/XNA033HAD2tvbUVFRgTVr1mDHjh0lHfRUoy7sIrAzJquUZneZVTEtHz6r20Xxc6sNsIZtQYpdg1bLh9oOviJkxkQMlUh8yMZi4YB0teQqrZ4LU0wlpeujXdlNigfeXura5/NZFr3KSNCyA68KFxaVrfqcxxJ6WXKxA1mj5NmrO5nxdjViXAcMy4c4nkMDpq9dLJ4Bv08KMDXodMQhsFLFbm61Wz7OU4ItxQQ/HE9JgTteISLL8WRZPgKWczBVE5LZPt0h5qMiO+YDMFvAL2isLMoClytFdTzUOI+W2ojl/9NlohaoMSCtdVF5nPuPjSKZzl+eW/yMnd7RhCUTIhdmLRZ9sRtzyJAphrMWNaC+MiTnU3vXZPUYJiuOhRgV91ZjVVi3BIlSAUNWS5D+mcI7OIvrstVIUChG/Pp8PstcULjbRf8ZWecjK9XWtAgDs8Dt8uEPfxjr16/Hz3/+c2zZsgUXXngh1qxZg4MH9aZoN998M2655Rbcfvvt2LRpE6qqqnDRRRchFnMuoDUdUV0aMuZDcSc4uTyEYFEtH7JhUCojg71qK4JyNzWitJkX7O8dlf5nwBQf0ZAfAb/PIlycyJUFo9ffyH5PvBYJBeSk21K0+BALo2n5qI4EZSzELmlCz14Q1ImrMhSwPHiFBpn5/ebDO5ZMy/oQp86vtxyLGuORq8aC/N3GeRbm6eW2fgpttVGLMFKDzpLpjLEQJPMeR9guPpRsF8A0QQPmeVJLKRcz6TtaPpRzMNmdZS5EhpY15sN4FmxuF7G45btf8hEJ+hE0rFmF1PgQiPu+vjKEaCiAaCgg792pioWZKGqcTGttBG21UVSGA0hlNOw5OiLnq1wLmJrJs9ioc9E3klCKjOW+p+z9d2TA6QQXs2DAj/OPNzcHb7Flh6jHMFkRaJZb1+8tcSxOjTHzxXzkQjz/Yv4v/t41z2Gh1jZx3kVtqKyYD2Xzm8loZn2gaSKoixIfY2Nj+L//+z/cfPPNOPfcc7F06VJ85StfwdKlS3HbbbdB0zT84Ac/wJe+9CWsXbsWJ598Mn72s5/h0KFDuO+++6boEEqPVXxYYz7s7wPAA1u7cNJXHsQvnt4no7TDwUBOy4daDEmICKHAVTcLYIoPEYUuFhEn8fHA1sM4/ksP4NfPHsh677sPbcdJX34QL+zvs7wuLDpRRXwUa/lQx6Sm39kDYp12A6r/sSIcmPCEo5ZYF1kuomOtoBjLhzgmcS3mNVRaCkTZBZpYvHuG4njL9x7H2374pFxkc5lRs8WHWeE04Pfh/OUtynvW4LKA35dlOcmHU9GmhjJku9hjDDIZTbqmcgWcCooREIBhSTOOo5hYEXG/qy4JsShNRQryZLBYPmqj8Pt98rnavL9fvpfrnhPXY0FjJV6/RM846R1JFtRwTFo+Rq3iYzI7afUZzRYfyoI8yeuwtMV6P4hjac0RA6N+phBUF2LQ78vZeTkX6rNccJ0PewPJHG4XQN8AC0vsdOhoCxQpPlKpFNLpNKJR68RbUVGBJ598Env27EFXVxfWrFkj36urq8OqVauwceNGx++Mx+MYHBy0/HEbdWEXMQSq1cC+8D+x4wg0DXhhf59i+fA5ZrvUVoQsi7UIEOu0PRxiUy2sIGKRVuNF7Pxso97d9eGXrZVUU+kM7n5mP1IZDb96xipMYnL34sfbT+3AojmVlkWvENTjUQsPqTEWbbVRxwVOneyqItZU22J2nTIbJJGRHU3PXNho+YxqRh3P8mEfa0NV2GKytgs0IRr+tOUw9h4bxStdQ3jcqFWRa2G3R/RHQwGcPK8Or1vUiKvfuMTSV0IcX6+RVldsoSCnXhnVkSAuWdmONx/fPG7r+YnSVK1/72hCr8w6kkjJ9gNZqbY2M7eoQFkMl54+F6fMr8dp8xsK/pmzO+egs7kKl50xV752+RnzsbSlWvYEmi7YxQdgtmp/wKisqVpd7Vx4gt4Z+FMXLLOICRkPkGdhMi0f+lxmbjQmHjr4puNbcHbnHFzxuvmY12BdsNXU6cmK4wWN1kw7sfkQv3P/Md29mkpnZDmFQssNAFYXYrHuQsBMiwWKd7sI7AJNFTSxZFpaYu0drN2iqFHU1NRg9erV+PrXv44VK1agtbUV99xzDzZu3IilS5eiq0u/+VtbrQq2tbVVvmfnxhtvxFe/+tUJDn9qUC0bcRFwmsrtdhGVNAfHTH+8vc6HiAXIivkwvqujrkKmwQHACe21eOnQoBJsqk8KMtvFFisyMJrEpj26P9PeyfG5fX3oN0oXb3ilW6bKAYr4CAZkB9NikZacWEqavaMhq+XDLq4EquWjMqxXuRSpu8XsdsTiPJowCzDZBYKl++s4/tws8VEZQmttBDuNa20PyhWLwgNbzftciI9cD7vd8hEJ+hENBfDrj67O+qwpPvRdWbG7F6eKkT6fD7deeXpR31Ms1ZGgrKPRN5qQaaxh41hVJmv5AIAvv+3Eon+mpTaKDZ99k+W1q89dkje92y1Ua5G4v99yQiv+d9N+RezmvjcWzKnEQ58+DwDwP3/ZDUAXHyMFxG+IzYS0fJQghiAaCuDuq1/v+J56z07WLRgO+rGgsVJaksWxCAuZmDMPGDWJKkIBdBipt4WgikJ7bFshWNwuhZZXt513e1xMMOCXqcSxVFpx/RceyzKVFC1Zf/7zn0PTNMydOxeRSAS33HILrrjiCvj9E1O/69atw8DAgPxz4EC2y6DcOLld4qrbxbbwCz/iYCxpBpwGTPHRN5qUfrnaiqDFeqHm5atK+2xbSekK6XbRbzh7cbJHtnfL37HPCD4TqD1ljg4nZES2elwT9dvqY1IsH8b3VYQClp17Lh+oOtmJSUycn2KCzMSD2D0UlwKuxSYQGoqJ+bBN4I1VYUsgor0YlTC7qoXOxPXIHXDqHCDmxHiR7eORq37KVKOmOPeOJEwLYDR7ArSbuTsLqNPhNayWD/3+Xt2pp5OPd7/ZEdfl6HDcDGLO88ypLQqAycd8jIc4jmJdjLlQXXHi2EUtmL7RpF4WwNhcFNKUUEUVhbk2WvmYUMBpAWXZZdBpMpMzy8wtir6inZ2dePzxxzE8PIwDBw7gmWeeQTKZxJIlS9DWpqdOdXdbzf7d3d3yPTuRSAS1tbWWP25jzXaxFhkDrAv/wFhS5lkPjiUtlg+xsxWtkgNGsSinOh810aDF53zGwkaEAmpBLrvbxSo+1I65qYyGA0ZxLE3TsP5lfTcuSm+rnxUWnck83DL9N5Ey/cC2mI9cJvQqm9sFMMVMUTEfhglyn7GzEcGDKo1FxXxkZ2LkFR9qCmQ0WNBk4hTzkQtR50PEfBS727QLuakKMHVCNe+b4iP796vXpKk6bMl8IDo1Dm6XSDCA845rlq8XunMW10Xt+pqvBoT4fH+JUm3HQ84DBWa9jYdqkRDHUhEOYG69buHYdWTYrElUpNVNvS4TEc2WmI8CU20LKcsum8ul0jmzzNxiwitOVVUV2tvb0dfXhwcffBBr167F4sWL0dbWhg0bNsjPDQ4OYtOmTVi9OtuUPF1R4ymcA07N93crLo6hWMosr67U+RCNf2qjQUtQ3IhS56MqErTEFCxrrZaZAkC222XEZp15fLthcjU+J6wxr3QN4UDvGCJBP75w0fEA9BoYolZJrISWj+F42jIhWRpb5XiYrQGnQnSIYy18TMKCstfw3TrVM1AXt/FjPhwsH7bOtyrqYnrB8ha8YWmT/H+h2S75yuXb+9cUWyjILjbKGfFusXyIAmMOE2BNJCjddhMxXXsBa7aLeQ+qgZsFWz6M5+FQv+6m9Pvyb0Ls2S5i7piqAEZxHKUK+rVYPtSNkfH6blV8FBGwDFgtUhOzfKhul8LEgX3Odrru4ntjyYxS3G+GWj4efPBBPPDAA9izZw/Wr1+PN7/5zVi+fDk+8IEPwOfz4brrrsM3vvEN/O53v8OWLVvwvve9Dx0dHXjHO94xBcOfGuwLu/q3/f1dSkGwwbGkLK+uVjgVlhGhONWmZeK7qiJBubgF/T4saKy0xBVU2LJdVNfPxl3HMJJIo7U2gjcZwaLiIRJWjjcua8ZbT2pDOODHnqMj8n1h0ZlMi2VzTGbUvB7zobb0Ht/tImoMiO+bSMDpXqNRlVM9A1VwFJrton5eFRx2caPuJt5yQpslcr+YVNtc2HeXxRQYA7InpmJqhEwWc8eczGv58Pl88roUm6roFcQi5/NZmwi+6fgWKdwKtnwYz4PYMFWGndsAyM9LC9bkK5wWwkTmgXyo91Sjg0t415ERpbJucfefKgoLKetvxxpwWmiRMXtZ9uyfiyr9XfK5PN2g6Ks6MDCAdevW4bXXXkNjYyMuu+wyfPOb30QopB/QF77wBYyMjOCaa65Bf38/3vCGN+CBBx7IypCZzoxb5yOmig/F8qHEPKi9XURxF3HRhfJMpDIyeKs6Yqa6LpyjR0u3WVp753a7iGqebzmhVRYKExaZh7bpLpcLT2hFTTSE1Z1z8PirR/DQtm4sbalRsl0mPoGolhzVDyx2SpXhQM70XXVRrJyE20WMX3TJbHXo7qpmU4yXRmf/3Y2VYUt6rT2eRFxb0UtmLJGGz7cFmlZ4kbF8u057RkGx4iFk3I+JVEYv012EP3uy1CvdakXjvFym38bKMI4MxYveeXoFcd7mVFlbINRVhPD6JXPw5M6jBYsPe3bReNY0sZnotRUZm6qYj4nMA/lQBYV67MIqu6vHtHwUUyQMMJ//OVXhgsuyq6iZbwV3tbWXZXewmKhVTgeVKtvTgaK3u+9617uwa9cuxONxHD58GP/5n/+Juro6+b7P58PXvvY1dHV1IRaL4eGHH8Zxxx1X0kFPNcMOqbZqt1b1/d22zBIhJvRsF+vNIdSx+jCJJnJV4SBOMkolixRR1e0iLARiQT8ybFaMfMGoIPqm41osKv5Q/xi2HhyEzwecb1T6FO6Alw7qKc2m22UyMR9m9U1zN+THca018PmAMxY25Fzs1F2TCHYTrbCXFrH7EN8jXFxOaXKiQ25tNDhuLRN1AogE/agIB9DZVI2KUABLW6qzJtwTOvRYpX9Y2YbqSBDNNRFcsLwFAb8Px9sKlKnfq1JIwKlgIv0ZSj2ZF4oa8zGkZH05Ic7VmYsaHd/3OktbquHzASfNzY6Nu/xMvaOxuBfHQ2QiCca7p8TcM2AU0pvqgFMhCoqZB/LRUBVGZ7PeIVpN6+004tFe2N8nrTrFWi+Wteqfn2hqthq/UejzqVpLxuucHUtmZr7lwwuMjGP5yOV2AUwXS0ixfAjERVd3oSIttDoaxOrOOdjw2fMwr0EPgFIXUDExLDYUuSin7Pf5ZPrY8W01cnLfdWRYulzOXNggLSJzjLoLIvhIVjidQFtsgbDkjCRSiCkpe4uaqvD4594sf6cT1lRb/d+fu/A4XH7mvKLqPNj9zk5VWn0+H/7wyTcgmc6M66cW1TJTGU0unnWVITzyufNQGcp+bE6aW4e/fOHNFlP4LVechv7RJDrqnVP2sut85LF8ZLldJiY+ekcSZa/aqcYKiGO2FxgT3PxPJ+O6NcsY85GDxcYz1exg2Vt76lycOr8+5/1mx+fzod6wNAG5+7oI6pQds1qxdqpiPs5Y2IBHP/cmdNSXzmr+24+dg9FkynIsQuQI4VFMU0LB8rZaPPa5N2UFoheKEAmRoL/gGiGq5SNX52whDPtHE0gpGZfTgekximmGY28XJeBUZLuk0hlp5hft2sXOOxz0Zy0uquKsjgTRm0pYypEDVtOgGvMhrALttVFUhAIYS6ZxoHcUAb8PiXQGkaAfHfUVMtumfzSJXxmVTtX4AzGGwbEkNE2TFp3IpCwfaqqtdTe0YJxKf2rsghAfwYC/aJ+rfXHOZdko1CQqAoMHxpKWwNn2PLn/9iZoleFg3tTFomI+7B2AJ9DrotQBfIWiWj7ENc61+4qGAhQe45DvmVo4pzh3QaMiPvIVGAP057KuIoSBsaQMUgWyUz5LyeIJFJrLR11lCHWw3nstNRFUR4LSoj2R+jIAsGgSYxXio5hnU50vcv2c+IywsAeNjMvpALvaOjCkxHQ4FRkT76sFaRYaC8+xfJYPRXE69dqwo6poMWn7/T75QKoBUoub9Ap+aurYtsO6a+UtSmdX2YMklrK4kiYV8yGa3cVSRQehVTq4XSaCffzFduZ1QlyjYsosF4N6fwT8vrw7Hvv5nMgEIrKHpqqDbS7M+hDJaVfoyOuosQ+F7PbFs3B4QE/PDQf8CBZZzXO64fP5LDEeE6msO1mE5bm4OLfx40TEZ0TjvNqKUEnSlkvBzL5rpgi1jodTqq2wjKgFaURNAuF2USucCtRccKdeG3acxAegBEhZUsOqs94HgGUt1Zbdg3CRDMWSlsJp9uClYhBjj6cyMhi3ULOlk9tlIth/X7H9aZwQsSwTCSArBNXVNV6dFbvYKDQi3vozLsV8VJrdUKdboSOvowrrQp4/URlUtH2YTKzYdCLX/FkuhOV5IkH2+X5OzOs9Rlfp6fTczY47p8SMONT5UC0f4n21II0wI4siUBEH8aFeeHsNi/HFh1JBb5y8dPXf9mZNZvfVlAym9ftgCTwrFvXGF+KrYMuH8bPj1RgYD/X3Bfw+zKkuoeVjiopdqZaP8SxPUdvCMJ5/3glxPOXO8xe7677RBAamWdCb11FdioVYxBplbRBdfEyXJmWTJdf8WS7E3FdM3xVrYbIcGXXGvCISFGqm0XNH8eGANdslg3RGQzKtZb1v5oRXyUVdBPWElMZyAtXUrC7YPp/zrkM0/wJslg8lo2VXjz4G1U+u/vvCE62VZYUASqQzst9LtMgmZXbUaq59yncWgjiu8WoMjIcqPpqrI5YmUhNFXKOpsnyoMUHj+c2zAk4n5HaxFnErF2KBi6cy6BY7sGkS9OZ1VMtHIUJCXMundh3Tf2aaxA9MFovlw4WYI9PtUvj5tFo+nH9OCBQR1zOdnjuKDwfUOh7pjJZVylz8X2SZLG6qyjJnhfNkuwBWpVqVZ+EVQYyNDhX5dh0Zxu6j2W6XE9r1dMW22ihOnmumQYvfJdZl4QcsRaqcXXkXuiMSxzXZuAo1YLYU8R6ALmKA0rhwnCjG8hEymkQJJiIgZMZTVWnOT6FUhgPZBfem0Q7My6j9lwpxu7QbGXhi41U/TqXgmcJxRop3fWUILQ6ZRFONqIVTjMW2kE649oDT6fTcTR8ZNE1IZzRLczBA7xirMhJPQdM0dBnpZnPrK7IC6MLBQHa2S0UO8ZFnIbnx0pXYvL8Pp86vl6+JHPR+ZVxqwNTpCxpw02UrsaK9Nqu+ht/vQ01Uj1gXargUTZuqIgH0KlnHhe6IOpur8a13rpy0qVP9fRNNd7PzqTXLcHxbDd42gU6/haCed3ufBicqQgEMxUVMTfGP7vvOXoiqSFDWgygXPp8PjZVh+bwADDidLqhViAsJ+H7f2YuQ0fS4OL/Ph7WnTs2zUW46m6tx02UrMbe+0pWAzLed0oHBsSQuPqm94J9RNyy53DUiJkdkQVJ8TGPs3WIBSD+1IJXRU1TFZNpaG826qKGAL2tBUU1eVRHnf9s5dX69RXgAZjMkEfTVXhe1uXF8ePdZC3J+Z21F0CI+SmH5sPuLizHHvndV7rEWimppKZX4WDinCh85r7Mk3+VExGL5GF8ARsOm+JhIcG5LTRQfe9PUHU8+Gqps4mMaTYJepqFIy0dTdQSfM3pEzTbyzZlTTXUkWPRcY6/z4fiZPGuQ29DtYkNksgSVNs79Y6IEunnhXusbk2qypTaSFcQ3Xp0P9WYpJshIYEkNm2Ap4J4SWj7sx1/uQDRV7DhVN52OqG6XQq6BKlAmkxnkBuoOOxTwzZosiZmOJdulzFlQZHKEAj7pQs+d7ZJ7DXIbzgA2RLxHdTQoVaOwfFSEA3LSF2XVGypDiAQD2W6XgD8rg8TSdr1Ay0cuJhMgZRcfJbF82I6hFIKmGNRjcMNnOxGKifkAnEvRzxTUHXZtdPrUGvA6FsvHLAke9Qo+n08Gqo6X7SKYTu5Oig8bIpi0KhyUuzMzK8QvF1lRVl2Y+LMCToN++HxmxovfZ60gWKjbJRdqLnqx4kNYKXoGRcBpKWI+zGOomGT2zERQLS0zxvJhyXYpVnzMrIVC3WFPl5bepPg6H2R6Iebu8YqMCeh2mYYcHhhDKp2RNTyqI9mWj2gwIC+yqK8hxUdWwKlZqx/Q86vVBVkNMp1IuevOpkm4XYyxljLmo1rZibuR+z8VAadTTTDglynBBcV8zGDxoWZFTKfdl9dRM5Hodpl5iDlhvCJjAqfOt25B8QG9m+HqGx/B9fdvNS0fkYAZ82F0qo2E/FI0CPHRJi0f9oBTq/iwK05VcExIfLQ41/UoBDHWUma7qM3K3Mj9r5yCgNNyIKwfBbldwjPX7aIWaptOfmevIzKRgPF7u5Dph5hrc1kTswNOp8+zN7NmsCliR/cQAGDT7l6cYbSzr46GZMEw1fIRNOI4dku3ix5fYBcXYjchu3jaJtzqSbpdWmoieM9Z85HOaOgo0s0gxioyJ0od8+FGMGF9ZRiXnzEPkZDf0rFyuhMO+jGWTBckAMVEEw76S1JErZyohdqmk+mXAB98wyI8ufMYTrLVBCLTn/etXoiHX+7B6QsaHN+3NwydTs/e9BmJi4wabeD39Y5KK0d1JIBYwuZ2CQXkwipea61ztnwI0SFEiP39Kovlo/jF3+fz4duXnVz0zzmNZTJ9XQTqMZRCzEyE71x+iiu/dzKI+6OYgNOZuENVYwto+ZheXHNuJ645150UbDI5rjpnMa46Z3HO97MsH9Po2aPbBab4SGc02Qm2KhyUqtEp4FTQWhM13gtYshek5aMAt0u5G33ZTW9TEXBKCkOI1EKKjEWVUvQzjQbGfBBSdrL6i02jZ4/iA8CoUljs768NANAXU3vAaSQUyBIKamaFqirlomJYFfJZPsouPmz+wVKXV58tzabKgRC4hQhAIepm4vm1Wj5mnngiZCaizu32jEu3ofiAafkAzEDSmmhQCTg1Yz7sBcFalD4i6qQayrJ8WMWHGiA0kSJjk8E+lkJ23eNRbYn5mD43+HRHBpwWkWo7nSaQQqHlg5Dyo87FtRXTq74OxQeA0bgpPjSjea1q+RAVTiM2t0vA70OT0qSrpiLb8pEr4DSiBA2W3/KRPZbJQrfLxBDn3h4Y5oSweMxEy0dF2IyXmk5+Z0JmM2qF0+n23FF8ABi1NZIDhPjQT08sqZdRjwatbpeWmoilcZtq+bDHfNhToXw+n9zBllt82MdScrcLxUfByIDTAiwfMqd/BsZ8AJApnSwyRkh5sDSfm2bPHcUHgDGHZnLVkUDWghAN+S1ZHfZ6ErUOlo8TO2rh8wEr52WnsZ08rx5V4QCWNE2uo2uxTEXAKWM+JsaJHXUI+H043mjpnY8V7TXw+fR7aiZy6oJ6hAP+go6VEDJ5ItPY8jG9pJBLjMSzLR/VkVCWRSAaCqBaqRDXWmvtIWIJODUu+ucvOh5Xv3GJpc6B4KcfOAujyXTZb4qaSBA+n+liKkWqbRVjPibEl992Aq5bs8xSATQXZ3c24YUvvQX1ldNrEimUH15xOoZjKdTN0PETMtMIBvwI+n1IZbRpVeMDoOUDQC63SyArFiKqVDgFzOqmAnFx/T7IeA6fz+coPAD9xnBDjfr9vpIHiNLtMjF8Pl9BwkPQUBWeVkFjxRDw+yg8CCkzYn6fbpYPig+Ybhd10VR7uwh0y4cS82EXH8bFDZcggHOqUW/EUrhdoiG/bO9cEZ7+x08IIV5ABnpPsywzrhIw3S4nKL50NeBUEAlas12yLR+G+AhM/9Oq3oiRErhdfD7TmkLLByGETA9y1Zpym+m/SpaBMcPtslLpbVATCWbVv7BbPrICTo1o4plh+Sh9LxZxbhjzQQgh0wPT8sGYj2mHqHCqNlaqcnC7RIJW8dFWZws4naGWj1KJBWEVYrYLIYRMDxjzMU1JZzRZx+PU+XUI+n2oiQRREXIOOK2OBlEZ1vu4tNVVWN7vMP7fWF14AKFb1EyB5UOUmm+qjozzSUIIIeVAzMftRXY/n2qmlx3GBcaUTJd5DZX46QdepwdP+n2OAaehgB93XnUW0hnNYgUBgOPbavBfV56OpS3VZRn7ZFBVcCliPgDgG+84CS/u78frFjWW5PsIIYRMjq+vPQkv7O/D65fMcXsoFjwvPoTLxefTA0rfsKxJvhfNsnzoi/SqPBfxH1a2T8EoS89UuF0WzqnCwjnlLZhGCCEkNwvmVGLBnEq3h5GF590uoq9LZSiQVT8hO+Zj9pwuNeC0kL4ihBBCSKnw/KojOtpWOvRXcXK7zBYslo8SuV0IIYSQQvC8+BhL6m6XSocMDaeA09mCiPnw+4BQYGZWzCSEEDIzmT2r6QQRBcacCmNlWT5mkYVA5HxHHdxNhBBCyFTiefEh3C5Obe3tlo7Z5Hapr9DTgZ0sPoQQQshUwmyXRG63y2wOOF3eVoN3nzkfJ86dme3ZCSGEzFwoPhK53S6q2AgH9NofswW/34eb/ulkt4dBCCHEg8yerfwEGcvjdvH5fLJPC9NRCSGEkNLg+RV1xHC75OpHIgqNzaZ4D0IIIcRNPC8+hOWjMoe4EKJjNqXZEkIIIW7i+RU1X5ExQBEfsyjNlhBCCHETz4uPkTzZLoBp8WDMByGEEFIaPL+iSrdLTvFBywchhBBSSjwvPqTbJezsdokw4JQQQggpKRQf47pdGHBKCCGElBLPr6iyyFgO8REx3C0RWj4IIYSQkuB58SGLjOVwuwiLB2M+CCGEkNLgefExfraLsHx4/lQRQgghJcHzK+r4bhdaPgghhJBS4mnxoWnauG6XjvoK4+9o2cZFCCGEzGY83dU2kc4gldEA5LZ8fPCcxTihvRarO+eUc2iEEELIrMXT4kNYPYDcMR8V4QDevLylXEMihBBCZj2edruIeI9wwI9QwNOnghBCCCkbnl5xRYGxXC4XQgghhJQej4uP/H1dCCGEEFJ6KD5A8UEIIYSUE4+LD1FgzNNxt4QQQkhZ8bj4oOWDEEIIKTcUH6D4IIQQQsqJt8VHnG4XQgghpNx4W3wkafkghBBCyo2nxccY3S6EEEJI2fG0+BiJi462dLsQQggh5cLT4mMsKWI+aPkghBBCyoW3xQfdLoQQQkjZ8bT4iCUzAIBI0NOngRBCCCkrnl51Yynd8hEJ0fJBCCGElAtviw8j1TZK8UEIIYSUDU+Lj3hKd7tE6XYhhBBCyoanV10R80HLByGEEFI+ihIf6XQa119/PRYvXoyKigp0dnbi61//OjRNk5/RNA033HAD2tvbUVFRgTVr1mDHjh0lH3gpiBtuFwacEkIIIeWjqFX3pptuwm233Yb//M//xMsvv4ybbroJN998M374wx/Kz9x888245ZZbcPvtt2PTpk2oqqrCRRddhFgsVvLBTxbGfBBCCCHlp6jSnk899RTWrl2LSy65BACwaNEi3HPPPXjmmWcA6FaPH/zgB/jSl76EtWvXAgB+9rOfobW1Fffddx/e8573lHj4kyOWotuFEEIIKTdFWT7OPvtsbNiwAa+++ioA4G9/+xuefPJJXHzxxQCAPXv2oKurC2vWrJE/U1dXh1WrVmHjxo2O3xmPxzE4OGj5Uy7i0vJBtwshhBBSLoqyfPzbv/0bBgcHsXz5cgQCAaTTaXzzm9/ElVdeCQDo6uoCALS2tlp+rrW1Vb5n58Ybb8RXv/rViYx90tDyQQghhJSforb8v/71r/G///u/uPvuu/HCCy/grrvuwne/+13cddddEx7AunXrMDAwIP8cOHBgwt9VDMl0BumMHigbDVJ8EEIIIeWiKMvH5z//efzbv/2bjN1YuXIl9u3bhxtvvBHvf//70dbWBgDo7u5Ge3u7/Lnu7m6ceuqpjt8ZiUQQiUQmOPyJI4JNASBCtwshhBBSNopadUdHR+H3W38kEAggk9HdF4sXL0ZbWxs2bNgg3x8cHMSmTZuwevXqEgy3dIgaHwBTbQkhhJByUpTl421vexu++c1vYsGCBTjxxBPx4osv4nvf+x4++MEPAgB8Ph+uu+46fOMb38CyZcuwePFiXH/99ejo6MA73vGOqRj/hIkpNT58Pp/LoyGEEEK8Q1Hi44c//CGuv/56fPzjH0dPTw86OjrwkY98BDfccIP8zBe+8AWMjIzgmmuuQX9/P97whjfggQceQDQaLfngJ0OcwaaEEEKIK/g0tTzpNGBwcBB1dXUYGBhAbW3tlP2erQcH8I8/fBKttRFs+vc14/8AIYQQQnJSzPrt2WCHeIrVTQkhhBA38Kz4EAGnDDYlhBBCyotnV172dSGEEELcwbPiQwacssAYIYQQUlY8Kz5kqi0LjBFCCCFlxbMrr4j5oNuFEEIIKS8eFh9mkTFCCCGElA/PrrwxptoSQgghruBd8SHdLp49BYQQQogreHbllUXGmO1CCCGElBXvig8GnBJCCCGu4FnxYRYZ8+wpIIQQQlzBsyuvme1CywchhBBSTjwsPhhwSgghhLiBZ1dekWobYcwHIYQQUlY8Kz4YcEoIIYS4g2fFhywyxgqnhBBCSFnx7MrL3i6EEEKIO3hWfMTZ24UQQghxBc+uvGadD1o+CCGEkHLiWfERT9HtQgghhLiBZ8UHK5wSQggh7uDZlTdGywchhBDiCp4UH8l0BumMBoBdbQkhhJBy40nxIVwuABCh24UQQggpK55ceUWND4CptoQQQki58eTKG0+ZNT58Pp/LoyGEEEK8hSfFB6ubEkIIIe7hUfHBNFtCCCHELTy5+ppuF1o+CCGEkHLjSfFhul08efiEEEKIq3hy9RWWD8Z8EEIIIeXHk+JDWj7odiGEEELKjkfFhxHzQbcLIYQQUnY8ufoy1ZYQQghxD4+KD7PIGCGEEELKiydX3xgDTgkhhBDX8KT4iDPVlhBCCHENT66+0vLBbBdCCCGk7HhSfMQZcEoIIYS4hifFB3u7EEIIIe7hydXXzHah5YMQQggpNx4VHww4JYQQQtzCk6uv7GrLmA9CCCGk7HhSfLDCKSGEEOIe3hQfMtXWk4dPCCGEuIonV19h+aDbhRBCCCk/nhQf8SQtH4QQQohbeHL1jacY80EIIYS4hSfFRzKti49QwJOHTwghhLiKJ1ffdEYDAAQDPpdHQgghhHgPT4qPlCE+An6KD0IIIaTceFN8GG6XIMUHIYQQUna8KT5o+SCEEEJcw5PiQ8R8MOCUEEIIKT+eW301TaPlgxBCCHERz4kPQ3cAYMwHIYQQ4gaeEx+pTEb+m5YPQgghpPx4T3ykTdNH0O+5wyeEEEJcx3Orb0rxu9DyQQghhJQfz4mPdEa1fFB8EEIIIeXGc+JDxHz4fYCf4oMQQggpO54TH7KvC+M9CCGEEFfw3AosAk4Z70EIIYS4g/fEh7R8UHwQQgghbuA58ZE2Yj4CAYoPQgghxA08Jz5SjPkghBBCXMVzK7CI+aDbhRBCCHEHz4mPNJvKEUIIIa7iOfEh6nwEGfNBCCGEuIL3xAdTbQkhhBBXKUp8LFq0CD6fL+vPtddeCwCIxWK49tprMWfOHFRXV+Oyyy5Dd3f3lAx8ogi3S4gBp4QQQogrFLUCP/vsszh8+LD8s379egDA5ZdfDgD49Kc/jd///vf4zW9+g8cffxyHDh3CpZdeWvpRT4IUYz4IIYQQVwkW8+Hm5mbL/7/97W+js7MT5513HgYGBnDHHXfg7rvvxvnnnw8AuPPOO7FixQo8/fTTeP3rX1+6UU8CWV6dMR+EEEKIK0zY95BIJPCLX/wCH/zgB+Hz+fD8888jmUxizZo18jPLly/HggULsHHjxpzfE4/HMTg4aPkzldDyQQghhLjLhMXHfffdh/7+flx11VUAgK6uLoTDYdTX11s+19raiq6urpzfc+ONN6Kurk7+mT9//kSHVBCptJHtQvFBCCGEuMKExccdd9yBiy++GB0dHZMawLp16zAwMCD/HDhwYFLfNx60fBBCCCHuUlTMh2Dfvn14+OGH8dvf/la+1tbWhkQigf7+fov1o7u7G21tbTm/KxKJIBKJTGQYE0JmuwSY7UIIIYS4wYRW4DvvvBMtLS245JJL5GtnnHEGQqEQNmzYIF/bvn079u/fj9WrV09+pCWClg9CCCHEXYq2fGQyGdx55514//vfj2DQ/PG6ujp86EMfwmc+8xk0NjaitrYWn/zkJ7F69eppk+kCmF1tGfNBCCGEuEPR4uPhhx/G/v378cEPfjDrve9///vw+/247LLLEI/HcdFFF+G//uu/SjLQUpFkhVNCCCHEVYoWHxdeeCE0TXN8LxqN4tZbb8Wtt9466YFNFbLOByucEkIIIa7guRU4xSJjhBBCiKt4TnyImA+6XQghhBB38Jz4kJYPig9CCCHEFTwnPtIy4NRzh04IIYRMCzy3Aidp+SCEEEJcxXPigzEfhBBCiLt4TnykZHl1ig9CCCHEDTwnPhjzQQghhLiL51ZgZrsQQggh7uI58ZFmYzlCCCHEVTwnPlJsLEcIIYS4ivfEh4j5YMApIYQQ4gqeEx/C7RJiwCkhhBDiCp5bgVOM+SCEEEJcxXPiI82utoQQQoireE58JNOscEoIIYS4iefER5p1PgghhBBX8Zz4MIuMee7QCSGEkGmB51ZgxnwQQggh7uI58ZFiV1tCCCHEVTwnPhjzQQghhLiL58RHkl1tCSGEEFfx3ApMywchhBDiLp4THykGnBJCCCGu4jnxkWbAKSGEEOIqnhMfrPNBCCGEuIvnVuA0G8sRQgghruI58ZFKM+CUEEIIcRPviQ/GfBBCCCGu4jnxIdwuoYDnDp0QQgiZFnhuBU4x5oMQQghxFc+JjzRjPgghhBBX8Zz4SDLmgxBCCHEVz4mPNCucEkIIIa7iOfHBImOEEEKIu3hqBc5kNGi69mDMByGEEOISnhIfwuoBAAG6XQghhBBX8JT4SCvig5YPQgghxB08JT5EpgvAbBdCCCHELTwlPkSND4ABp4QQQohbeGoFFjEfPh8tH4QQQohbeEp8yBofFB6EEEKIa3hKfLCjLSGEEOI+nhIfaRYYI4QQQlzHU6twMs2OtoQQQojbeEp8MOaDEEIIcR9PiQ8R88GmcoQQQoh7eEp8MOaDEEIIcR9PrcKizgdjPgghhBD38Jb4SDPmgxBCCHEbb4kP1vkghBBCXMdT4kPGfAQ8ddiEEELItMJTq3CKqbaEEEKI63hKfKRZZIwQQghxHU+JD1o+CCGEEPfxmPhgwCkhhBDiNp4SH2bAKcUHIYQQ4haeEh9mnQ9PHTYhhBAyrfDUKszGcoQQQoj7eEp8sLw6IYQQ4j6eEh9pdrUlhBBCXMdT4iMp63x46rAJIYSQaYWnVmHGfBBCCCHu4ynxwSJjhBBCiPt4Snww5oMQQghxH0+JD2a7EEIIIe7jLfHBImOEEEKI63hqFablgxBCCHEfT4kPxnwQQggh7uMp8cFsF0IIIcR9PCU+0hkWGSOEEELcpuhV+ODBg/jnf/5nzJkzBxUVFVi5ciWee+45+b6mabjhhhvQ3t6OiooKrFmzBjt27CjpoCcKLR+EEEKI+xQlPvr6+nDOOecgFArhz3/+M7Zt24b/+I//QENDg/zMzTffjFtuuQW33347Nm3ahKqqKlx00UWIxWIlH3yxpNJ6zAcDTgkhhBD3CBbz4Ztuugnz58/HnXfeKV9bvHix/LemafjBD36AL33pS1i7di0A4Gc/+xlaW1tx33334T3veU+Jhj0xaPkghBBC3Kcoy8fvfvc7nHnmmbj88svR0tKC0047DT/+8Y/l+3v27EFXVxfWrFkjX6urq8OqVauwceNGx++Mx+MYHBy0/JkqZG+XAGM+CCGEELcoahXevXs3brvtNixbtgwPPvggPvaxj+Ff//VfcddddwEAurq6AACtra2Wn2ttbZXv2bnxxhtRV1cn/8yfP38ix1EQtHwQQggh7lOU+MhkMjj99NPxrW99C6eddhquueYaXH311bj99tsnPIB169ZhYGBA/jlw4MCEv2s80mkWGSOEEELcpijx0d7ejhNOOMHy2ooVK7B//34AQFtbGwCgu7vb8pnu7m75np1IJILa2lrLn6mClg9CCCHEfYoSH+eccw62b99uee3VV1/FwoULAejBp21tbdiwYYN8f3BwEJs2bcLq1atLMNzJkcow24UQQghxm6KyXT796U/j7LPPxre+9S28613vwjPPPIMf/ehH+NGPfgQA8Pl8uO666/CNb3wDy5Ytw+LFi3H99dejo6MD73jHO6Zi/EVhBpxSfBBCCCFuUZT4OOuss3Dvvfdi3bp1+NrXvobFixfjBz/4Aa688kr5mS984QsYGRnBNddcg/7+frzhDW/AAw88gGg0WvLBFwu72hJCCCHu49M0TXN7ECqDg4Ooq6vDwMBAyeM/3nX7Rjyztxe3XXk6Ll7ZXtLvJoQQQrxMMeu3p0wAjPkghBBC3Mdj4oMxH4QQQojbeEt8pNnVlhBCCHEbT63CItslRLcLIYQQ4hqeEh+M+SCEEELcx1Pig3U+CCGEEPfxlPgQAaeM+SCEEELcw1OrsFlkjJYPQgghxC28JT4y7GpLCCGEuI2nxEfaCDgNMeaDEEIIcQ1PiQ/GfBBCCCHu46lVWGa70O1CCCGEuIanxAdjPgghhBD38Zb4SOsxH7R8EEIIIe7hGfGRyWgwDB+0fBBCCCEu4hnxkdY0+e9gwDOHTQghhEw7PLMKi2BTgG4XQgghxE08Iz5Sivig24UQQghxD++IDyPYFKDlgxBCCHET74gPWj4IIYSQaYFnxIdaYMzno/gghBBC3MIz4oMFxgghhJDpgWfERzrN0uqEEELIdMAz4iNldLSl5YMQQghxl6DbAygXdRUhfPL8pQixwBghhBDiKp4RH3OqI/jshce7PQxCCCHE89AMQAghhJCyQvFBCCGEkLJC8UEIIYSQskLxQQghhJCyQvFBCCGEkLJC8UEIIYSQskLxQQghhJCyQvFBCCGEkLJC8UEIIYSQskLxQQghhJCyQvFBCCGEkLJC8UEIIYSQskLxQQghhJCyMu262mqaBgAYHBx0eSSEEEIIKRSxbot1PB/TTnwMDQ0BAObPn+/ySAghhBBSLENDQ6irq8v7GZ9WiEQpI5lMBocOHUJNTQ18Pl9Jv3twcBDz58/HgQMHUFtbW9Lvni7M9mOc7ccHzP5jnO3HB/AYZwOz/fiA0h+jpmkYGhpCR0cH/P78UR3TzvLh9/sxb968Kf0dtbW1s/ZmEsz2Y5ztxwfM/mOc7ccH8BhnA7P9+IDSHuN4Fg8BA04JIYQQUlYoPgghhBBSVjwlPiKRCL785S8jEom4PZQpY7Yf42w/PmD2H+NsPz6AxzgbmO3HB7h7jNMu4JQQQgghsxtPWT4IIYQQ4j4UH4QQQggpKxQfhBBCCCkrFB+EEEIIKSueER+33norFi1ahGg0ilWrVuGZZ55xe0gT5sYbb8RZZ52FmpoatLS04B3veAe2b99u+cyb3vQm+Hw+y5+PfvSjLo24OL7yla9kjX358uXy/VgshmuvvRZz5sxBdXU1LrvsMnR3d7s44uJZtGhR1jH6fD5ce+21AGbm9XviiSfwtre9DR0dHfD5fLjvvvss72uahhtuuAHt7e2oqKjAmjVrsGPHDstnent7ceWVV6K2thb19fX40Ic+hOHh4TIeRX7yHWMymcQXv/hFrFy5ElVVVejo6MD73vc+HDp0yPIdTtf+29/+dpmPxJnxruFVV12VNfa3vvWtls/M5GsIwPG59Pl8+M53viM/M52vYSHrQyFz6P79+3HJJZegsrISLS0t+PznP49UKlWycXpCfPzqV7/CZz7zGXz5y1/GCy+8gFNOOQUXXXQRenp63B7ahHj88cdx7bXX4umnn8b69euRTCZx4YUXYmRkxPK5q6++GocPH5Z/br75ZpdGXDwnnniiZexPPvmkfO/Tn/40fv/73+M3v/kNHn/8cRw6dAiXXnqpi6MtnmeffdZyfOvXrwcAXH755fIzM+36jYyM4JRTTsGtt97q+P7NN9+MW265Bbfffjs2bdqEqqoqXHTRRYjFYvIzV155JV566SWsX78ef/jDH/DEE0/gmmuuKdchjEu+YxwdHcULL7yA66+/Hi+88AJ++9vfYvv27Xj729+e9dmvfe1rlmv7yU9+shzDH5fxriEAvPWtb7WM/Z577rG8P5OvIQDLsR0+fBg/+clP4PP5cNlll1k+N12vYSHrw3hzaDqdxiWXXIJEIoGnnnoKd911F37605/ihhtuKN1ANQ/wute9Trv22mvl/9PptNbR0aHdeOONLo6qdPT09GgAtMcff1y+dt5552mf+tSn3BvUJPjyl7+snXLKKY7v9ff3a6FQSPvNb34jX3v55Zc1ANrGjRvLNMLS86lPfUrr7OzUMpmMpmkz+/ppmqYB0O699175/0wmo7W1tWnf+c535Gv9/f1aJBLR7rnnHk3TNG3btm0aAO3ZZ5+Vn/nzn/+s+Xw+7eDBg2Ube6HYj9GJZ555RgOg7du3T762cOFC7fvf//7UDq4EOB3f+9//fm3t2rU5f2Y2XsO1a9dq559/vuW1mXINNS17fShkDv3Tn/6k+f1+raurS37mtttu02pra7V4PF6Scc16y0cikcDzzz+PNWvWyNf8fj/WrFmDjRs3ujiy0jEwMAAAaGxstLz+v//7v2hqasJJJ52EdevWYXR01I3hTYgdO3ago6MDS5YswZVXXon9+/cDAJ5//nkkk0nL9Vy+fDkWLFgwY69nIpHAL37xC3zwgx+0NFOcydfPzp49e9DV1WW5bnV1dVi1apW8bhs3bkR9fT3OPPNM+Zk1a9bA7/dj06ZNZR9zKRgYGIDP50N9fb3l9W9/+9uYM2cOTjvtNHznO98pqTl7qnnsscfQ0tKC448/Hh/72Mdw7Ngx+d5su4bd3d344x//iA996ENZ782Ua2hfHwqZQzdu3IiVK1eitbVVfuaiiy7C4OAgXnrppZKMa9o1lis1R48eRTqdtpxEAGhtbcUrr7zi0qhKRyaTwXXXXYdzzjkHJ510knz9ve99LxYuXIiOjg78/e9/xxe/+EVs374dv/3tb10cbWGsWrUKP/3pT3H88cfj8OHD+OpXv4o3vvGN2Lp1K7q6uhAOh7Mm89bWVnR1dbkz4Ely3333ob+/H1dddZV8bSZfPyfEtXF6DsV7XV1daGlpsbwfDAbR2Ng4I69tLBbDF7/4RVxxxRWWpl3/+q//itNPPx2NjY146qmnsG7dOhw+fBjf+973XBxtYbz1rW/FpZdeisWLF2PXrl3493//d1x88cXYuHEjAoHArLuGd911F2pqarLcujPlGjqtD4XMoV1dXY7PqnivFMx68THbufbaa7F161ZLTAQAi4915cqVaG9vxwUXXIBdu3ahs7Oz3MMsiosvvlj+++STT8aqVauwcOFC/PrXv0ZFRYWLI5sa7rjjDlx88cXo6OiQr83k60f04NN3vetd0DQNt912m+W9z3zmM/LfJ598MsLhMD7ykY/gxhtvnPalvN/znvfIf69cuRInn3wyOjs78dhjj+GCCy5wcWRTw09+8hNceeWViEajltdnyjXMtT5MB2a926WpqQmBQCArkre7uxttbW0ujao0fOITn8Af/vAHPProo5g3b17ez65atQoAsHPnznIMraTU19fjuOOOw86dO9HW1oZEIoH+/n7LZ2bq9dy3bx8efvhhfPjDH877uZl8/QDIa5PvOWxra8sKAk+lUujt7Z1R11YIj3379mH9+vXjtipftWoVUqkU9u7dW54BlpAlS5agqalJ3pez5RoCwF/+8hds37593GcTmJ7XMNf6UMgc2tbW5visivdKwawXH+FwGGeccQY2bNggX8tkMtiwYQNWr17t4sgmjqZp+MQnPoF7770XjzzyCBYvXjzuz2zevBkA0N7ePsWjKz3Dw8PYtWsX2tvbccYZZyAUClmu5/bt27F///4ZeT3vvPNOtLS04JJLLsn7uZl8/QBg8eLFaGtrs1y3wcFBbNq0SV631atXo7+/H88//7z8zCOPPIJMJiPF13RHCI8dO3bg4Ycfxpw5c8b9mc2bN8Pv92e5K2YCr732Go4dOybvy9lwDQV33HEHzjjjDJxyyinjfnY6XcPx1odC5tDVq1djy5YtFiEphPQJJ5xQsoHOen75y19qkUhE++lPf6pt27ZNu+aaa7T6+npLJO9M4mMf+5hWV1enPfbYY9rhw4fln9HRUU3TNG3nzp3a1772Ne25557T9uzZo91///3akiVLtHPPPdflkRfGZz/7We2xxx7T9uzZo/31r3/V1qxZozU1NWk9PT2apmnaRz/6UW3BggXaI488oj333HPa6tWrtdWrV7s86uJJp9PaggULtC9+8YuW12fq9RsaGtJefPFF7cUXX9QAaN/73ve0F198UWZ6fPvb39bq6+u1+++/X/v73/+urV27Vlu8eLE2NjYmv+Otb32rdtppp2mbNm3SnnzySW3ZsmXaFVdc4dYhZZHvGBOJhPb2t79dmzdvnrZ582bLsykyBJ566int+9//vrZ582Zt165d2i9+8QutublZe9/73ufykenkO76hoSHtc5/7nLZx40Ztz5492sMPP6ydfvrp2rJly7RYLCa/YyZfQ8HAwIBWWVmp3XbbbVk/P92v4Xjrg6aNP4emUintpJNO0i688EJt8+bN2gMPPKA1Nzdr69atK9k4PSE+NE3TfvjDH2oLFizQwuGw9rrXvU57+umn3R7ShAHg+OfOO+/UNE3T9u/fr5177rlaY2OjFolEtKVLl2qf//zntYGBAXcHXiDvfve7tfb2di0cDmtz587V3v3ud2s7d+6U74+NjWkf//jHtYaGBq2yslJ75zvfqR0+fNjFEU+MBx98UAOgbd++3fL6TL1+jz76qON9+f73v1/TND3d9vrrr9daW1u1SCSiXXDBBVnHfuzYMe2KK67QqqurtdraWu0DH/iANjQ05MLROJPvGPfs2ZPz2Xz00Uc1TdO0559/Xlu1apVWV1enRaNRbcWKFdq3vvUty+LtJvmOb3R0VLvwwgu15uZmLRQKaQsXLtSuvvrqrE3cTL6Ggv/+7//WKioqtP7+/qyfn+7XcLz1QdMKm0P37t2rXXzxxVpFRYXW1NSkffazn9WSyWTJxukzBksIIYQQUhZmfcwHIYQQQqYXFB+EEEIIKSsUH4QQQggpKxQfhBBCCCkrFB+EEEIIKSsUH4QQQggpKxQfhBBCCCkrFB+EEEIIKSsUH4QQQggpKxQfhBBCCCkrFB+EEEIIKSsUH4QQQggpK/8/ueHGeh3aVmMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3459564447402954, 0.8122889399528503, 0.5795169472694397, 0.41677528619766235, 0.47586679458618164, 0.24589388072490692, 0.6878281831741333, 0.3956710696220398, 0.4825539290904999, 0.3138173222541809, 0.3524552881717682, 0.49099090695381165, 0.14112448692321777, 0.35986047983169556, 0.31099486351013184, 0.29686999320983887, 0.3917240798473358, 0.2895827293395996, 0.24416311085224152, 0.28914645314216614, 0.3060329854488373, 0.1781768500804901, 0.39992350339889526, 0.37441185116767883, 0.3190411925315857, 0.4433394968509674, 0.4524306654930115, 0.36422595381736755, 0.41500958800315857, 0.39861860871315, 0.42790108919143677, 0.2260330766439438, 0.3167969584465027, 0.19586558640003204, 0.204384446144104, 0.21697810292243958, 0.2357160896062851, 0.2093343585729599, 0.2921162247657776, 0.46137914061546326, 0.268244206905365, 0.328357458114624, 0.219474196434021, 0.27347713708877563, 0.29226455092430115, 0.3418180048465729, 0.20366160571575165, 0.25178852677345276, 0.17917653918266296, 0.30523791909217834, 0.182761549949646, 0.35327884554862976, 0.1634141057729721, 0.32759061455726624, 0.3515686094760895, 0.3305867314338684, 0.2030898779630661, 0.39001938700675964, 0.30192574858665466, 0.2517388164997101, 0.3933390974998474, 0.2563457787036896, 0.35330289602279663, 0.2751792371273041, 0.36345067620277405, 0.28584060072898865, 0.16404621303081512, 0.3440837860107422, 0.2496252804994583, 0.24165716767311096, 0.2607589662075043, 0.08317112922668457, 0.23944346606731415, 0.3126036524772644, 0.2522415816783905, 0.33522310853004456, 0.33669763803482056, 0.26429709792137146, 0.28393080830574036, 0.2421886920928955, 0.19652703404426575, 0.3095102310180664, 0.2124585062265396, 0.30395060777664185, 0.15615282952785492, 0.36226803064346313, 0.20161578059196472, 0.2578200399875641, 0.1428430825471878, 0.18153098225593567, 0.22583839297294617, 0.30617067217826843, 0.25330689549446106, 0.25170639157295227, 0.1658823937177658, 0.2272174060344696, 0.1792328655719757, 0.31951043009757996, 0.35113710165023804, 0.43016257882118225, 0.2853950560092926, 0.22258803248405457, 0.33529025316238403, 0.2514476180076599, 0.2548259198665619, 0.2860252261161804, 0.28899404406547546, 0.3232738673686981, 0.26510703563690186, 0.17589691281318665, 0.3364056646823883, 0.2738742232322693, 0.15515637397766113, 0.22876974940299988, 0.2389013022184372, 0.1885417401790619, 0.30844444036483765, 0.25483134388923645, 0.3192032277584076, 0.17204774916172028, 0.22696788609027863, 0.2133113145828247, 0.17025116086006165, 0.13000597059726715, 0.21849648654460907, 0.11142183095216751, 0.2893931269645691, 0.12098173797130585, 0.2050427347421646, 0.16207286715507507, 0.14592857658863068, 0.16897794604301453, 0.20993949472904205, 0.3902491629123688, 0.23048579692840576, 0.425483763217926, 0.3184049427509308, 0.27971187233924866, 0.27862268686294556, 0.20700882375240326, 0.23197433352470398, 0.37949565052986145, 0.24753503501415253, 0.25734779238700867, 0.3959682285785675, 0.24841739237308502, 0.18162958323955536, 0.22515727579593658, 0.2814136743545532, 0.3568824827671051, 0.3713689148426056, 0.1629958301782608, 0.303665429353714, 0.2554556727409363, 0.19544874131679535, 0.2564903199672699, 0.23636598885059357, 0.23138315975666046, 0.2624374032020569, 0.2896060347557068, 0.22538910806179047, 0.3109210133552551, 0.17093394696712494, 0.13753226399421692, 0.17136895656585693, 0.2699549198150635, 0.1782534122467041, 0.24666288495063782, 0.28596433997154236, 0.2729349434375763, 0.2966150939464569, 0.22311004996299744, 0.30373677611351013, 0.4346809685230255, 0.27496930956840515, 0.2123655080795288, 0.14622339606285095, 0.2953520715236664, 0.15889880061149597, 0.22238561511039734, 0.24969717860221863, 0.20590628683567047, 0.21535034477710724, 0.2594860792160034, 0.1844479739665985, 0.23562481999397278, 0.12851396203041077, 0.27986082434654236, 0.1655726581811905, 0.2604636251926422, 0.1190200224518776, 0.21880485117435455, 0.16249583661556244, 0.4167555272579193, 0.19893574714660645, 0.27740615606307983, 0.2397858202457428, 0.3806946873664856, 0.41730302572250366, 0.12281816452741623]\n",
      "[56.25, 73.21428571428571, 81.25, 87.5, 85.71428571428571, 91.07142857142857, 83.03571428571429, 91.07142857142857, 85.71428571428571, 88.39285714285714, 90.17857142857143, 85.71428571428571, 96.42857142857143, 86.60714285714286, 91.07142857142857, 91.96428571428571, 86.60714285714286, 91.96428571428571, 89.28571428571429, 91.07142857142857, 88.39285714285714, 94.64285714285714, 89.28571428571429, 87.5, 89.28571428571429, 90.17857142857143, 88.39285714285714, 89.28571428571429, 90.17857142857143, 89.28571428571429, 84.82142857142857, 92.85714285714286, 90.17857142857143, 92.85714285714286, 94.64285714285714, 94.64285714285714, 91.96428571428571, 93.75, 91.07142857142857, 85.71428571428571, 92.85714285714286, 89.28571428571429, 91.07142857142857, 93.75, 94.64285714285714, 88.39285714285714, 94.64285714285714, 89.28571428571429, 94.64285714285714, 91.07142857142857, 93.75, 91.96428571428571, 94.64285714285714, 87.5, 90.17857142857143, 91.07142857142857, 92.85714285714286, 89.28571428571429, 92.85714285714286, 91.96428571428571, 91.07142857142857, 93.75, 88.39285714285714, 91.96428571428571, 89.28571428571429, 91.96428571428571, 93.75, 89.28571428571429, 90.17857142857143, 89.28571428571429, 94.64285714285714, 97.32142857142857, 96.42857142857143, 86.60714285714286, 94.64285714285714, 90.17857142857143, 91.07142857142857, 93.75, 86.60714285714286, 92.85714285714286, 94.64285714285714, 91.07142857142857, 94.64285714285714, 94.64285714285714, 93.75, 88.39285714285714, 93.75, 90.17857142857143, 95.53571428571429, 93.75, 91.96428571428571, 91.96428571428571, 92.85714285714286, 93.75, 95.53571428571429, 95.53571428571429, 92.85714285714286, 92.85714285714286, 90.17857142857143, 86.60714285714286, 91.07142857142857, 96.42857142857143, 92.85714285714286, 89.28571428571429, 91.07142857142857, 91.96428571428571, 91.96428571428571, 94.64285714285714, 93.75, 95.53571428571429, 90.17857142857143, 91.96428571428571, 95.53571428571429, 92.85714285714286, 95.53571428571429, 92.85714285714286, 90.17857142857143, 92.85714285714286, 90.17857142857143, 95.53571428571429, 92.85714285714286, 95.53571428571429, 94.64285714285714, 97.32142857142857, 93.75, 97.32142857142857, 93.75, 96.42857142857143, 91.07142857142857, 94.64285714285714, 93.75, 96.42857142857143, 91.07142857142857, 92.85714285714286, 93.75, 89.28571428571429, 91.96428571428571, 90.17857142857143, 89.28571428571429, 94.64285714285714, 91.07142857142857, 92.85714285714286, 90.17857142857143, 91.07142857142857, 87.5, 93.75, 94.64285714285714, 91.07142857142857, 91.96428571428571, 88.39285714285714, 88.39285714285714, 95.53571428571429, 93.75, 92.85714285714286, 92.85714285714286, 92.85714285714286, 93.75, 91.07142857142857, 90.17857142857143, 91.07142857142857, 94.64285714285714, 89.28571428571429, 94.64285714285714, 97.32142857142857, 96.42857142857143, 92.85714285714286, 93.75, 92.85714285714286, 91.07142857142857, 91.07142857142857, 89.28571428571429, 92.85714285714286, 90.17857142857143, 88.39285714285714, 90.17857142857143, 93.75, 93.75, 91.07142857142857, 94.64285714285714, 93.75, 89.28571428571429, 91.07142857142857, 91.96428571428571, 91.96428571428571, 93.75, 93.75, 97.32142857142857, 88.39285714285714, 93.75, 92.85714285714286, 97.32142857142857, 91.96428571428571, 95.53571428571429, 87.5, 92.85714285714286, 92.85714285714286, 93.75, 85.71428571428571, 90.17857142857143, 96.42857142857143]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [1.3416526317596436, 0.8452426195144653, 0.7347771525382996, 0.4746026396751404, 0.5219899415969849, 0.5387921929359436, 0.43029364943504333, 0.38769060373306274, 0.3696261942386627, 0.3858962953090668, 0.42164546251296997, 0.2908497452735901, 0.5623461008071899, 0.3886418044567108, 0.22590608894824982, 0.38559359312057495, 0.52858966588974, 0.47088032960891724, 0.5569213032722473, 0.40970322489738464, 0.381511926651001, 0.26856428384780884, 0.4906581938266754, 0.36847561597824097, 0.47636255621910095, 0.2890775799751282, 0.2824912667274475, 0.2797100841999054, 0.3798418939113617, 0.2907555103302002, 0.2851353585720062, 0.33959701657295227, 0.3982016146183014, 0.34518831968307495, 0.40950557589530945, 0.3387496769428253, 0.23571375012397766, 0.3216594159603119, 0.5188934206962585, 0.3808043301105499, 0.2812941074371338, 0.2904089093208313, 0.2924942672252655, 0.2843538224697113, 0.2601202428340912, 0.197922945022583, 0.2858329117298126, 0.23954877257347107, 0.20947003364562988, 0.335345596075058, 0.2960520386695862, 0.552936315536499, 0.2982129752635956, 0.4001619815826416, 0.41513580083847046, 0.19043298065662384, 0.38766247034072876, 0.22428174316883087, 0.2849329113960266, 0.5222831964492798, 0.178243950009346, 0.21158470213413239, 0.26807108521461487, 0.3989032208919525, 0.395412415266037, 0.2967429757118225, 0.29856133460998535, 0.26891109347343445, 0.34613698720932007, 0.42516809701919556, 0.20503918826580048, 0.1960158497095108, 0.41627636551856995, 0.4484294354915619, 0.21405839920043945, 0.4661746025085449, 0.3277336657047272, 0.26888328790664673, 0.2340928614139557, 0.4039158523082733, 0.33395832777023315, 0.5052871108055115, 0.3811931014060974, 0.2644921839237213, 0.14447887241840363, 0.24091783165931702, 0.2897756099700928, 0.29174306988716125, 0.2550751268863678, 0.17407368123531342, 0.31884700059890747, 0.21641814708709717, 0.24227260053157806, 0.3657779395580292, 0.28702616691589355, 0.31789350509643555, 0.24169278144836426, 0.194771409034729, 0.25107458233833313, 0.22186632454395294, 0.34476473927497864, 0.3759719431400299, 0.20537205040454865, 0.3264927864074707, 0.3455698788166046, 0.338596373796463, 0.3582548201084137, 0.1653965413570404, 0.24335002899169922, 0.3829379975795746, 0.4071730971336365, 0.2720097601413727, 0.22117607295513153, 0.346655935049057, 0.19252197444438934, 0.27975985407829285, 0.249946728348732, 0.1756216436624527, 0.23455746471881866, 0.20107603073120117, 0.36043381690979004, 0.33167022466659546, 0.3241746127605438, 0.2770763039588928, 0.3356516659259796, 0.2736641764640808, 0.2691058814525604, 0.32515949010849, 0.2505704462528229, 0.34024766087532043, 0.16940507292747498, 0.2902301251888275, 0.1759033501148224, 0.22289936244487762, 0.3171321451663971, 0.3857164680957794, 0.26528412103652954, 0.1112801656126976, 0.500318706035614, 0.2637786567211151, 0.2730024456977844, 0.29311683773994446, 0.2821519672870636, 0.16473205387592316, 0.1402854025363922, 0.17906589806079865, 0.28233954310417175, 0.38690999150276184, 0.1552046686410904, 0.28253239393234253, 0.36126449704170227, 0.28401559591293335, 0.24700382351875305, 0.2452603131532669, 0.11380153894424438, 0.3551804721355438, 0.2210237681865692, 0.2082502543926239, 0.21414650976657867, 0.26936787366867065, 0.20790818333625793, 0.313697874546051, 0.2828652560710907, 0.37426185607910156, 0.2836432158946991, 0.35353294014930725, 0.3094039857387543, 0.26676103472709656, 0.18778523802757263, 0.19712309539318085, 0.355189710855484, 0.22118091583251953, 0.27607300877571106, 0.27260592579841614, 0.3821001648902893, 0.19854353368282318, 0.2618470788002014, 0.17272675037384033, 0.4241201877593994, 0.3117583394050598, 0.11619223654270172, 0.25980639457702637, 0.24249811470508575, 0.1330007016658783, 0.2160424292087555, 0.32202476263046265, 0.17995251715183258, 0.3524015545845032, 0.24187257885932922, 0.17747963964939117, 0.3234505355358124, 0.2678682208061218, 0.3024080693721771, 0.32635697722435, 0.18573179841041565, 0.2051049917936325, 0.22060556709766388, 0.17498664557933807, 0.1995350867509842, 0.23745262622833252]\n",
    "# acc_list_epoch_ = [52.67857142857143, 69.64285714285714, 76.78571428571429, 83.92857142857143, 84.82142857142857, 84.82142857142857, 88.39285714285714, 91.07142857142857, 86.60714285714286, 85.71428571428571, 89.28571428571429, 88.39285714285714, 85.71428571428571, 86.60714285714286, 94.64285714285714, 85.71428571428571, 86.60714285714286, 83.92857142857143, 83.92857142857143, 88.39285714285714, 89.28571428571429, 88.39285714285714, 88.39285714285714, 87.5, 86.60714285714286, 91.96428571428571, 91.96428571428571, 86.60714285714286, 90.17857142857143, 91.07142857142857, 89.28571428571429, 89.28571428571429, 86.60714285714286, 90.17857142857143, 84.82142857142857, 90.17857142857143, 91.96428571428571, 91.07142857142857, 83.92857142857143, 88.39285714285714, 91.07142857142857, 89.28571428571429, 91.07142857142857, 90.17857142857143, 91.07142857142857, 94.64285714285714, 91.96428571428571, 92.85714285714286, 92.85714285714286, 89.28571428571429, 91.07142857142857, 85.71428571428571, 91.07142857142857, 86.60714285714286, 84.82142857142857, 92.85714285714286, 85.71428571428571, 93.75, 91.07142857142857, 85.71428571428571, 93.75, 95.53571428571429, 91.96428571428571, 88.39285714285714, 87.5, 93.75, 89.28571428571429, 86.60714285714286, 90.17857142857143, 87.5, 93.75, 95.53571428571429, 84.82142857142857, 86.60714285714286, 94.64285714285714, 86.60714285714286, 92.85714285714286, 91.07142857142857, 93.75, 88.39285714285714, 91.96428571428571, 85.71428571428571, 87.5, 90.17857142857143, 96.42857142857143, 94.64285714285714, 89.28571428571429, 92.85714285714286, 90.17857142857143, 95.53571428571429, 91.07142857142857, 93.75, 91.96428571428571, 89.28571428571429, 91.96428571428571, 89.28571428571429, 91.07142857142857, 93.75, 91.07142857142857, 92.85714285714286, 90.17857142857143, 89.28571428571429, 95.53571428571429, 88.39285714285714, 88.39285714285714, 90.17857142857143, 91.07142857142857, 93.75, 90.17857142857143, 91.07142857142857, 89.28571428571429, 91.96428571428571, 93.75, 91.96428571428571, 93.75, 91.96428571428571, 91.07142857142857, 94.64285714285714, 92.85714285714286, 92.85714285714286, 91.07142857142857, 85.71428571428571, 89.28571428571429, 92.85714285714286, 90.17857142857143, 88.39285714285714, 93.75, 90.17857142857143, 91.96428571428571, 91.07142857142857, 94.64285714285714, 91.96428571428571, 96.42857142857143, 92.85714285714286, 93.75, 92.85714285714286, 91.96428571428571, 97.32142857142857, 83.92857142857143, 92.85714285714286, 94.64285714285714, 89.28571428571429, 91.96428571428571, 96.42857142857143, 95.53571428571429, 95.53571428571429, 88.39285714285714, 86.60714285714286, 96.42857142857143, 90.17857142857143, 90.17857142857143, 86.60714285714286, 91.96428571428571, 93.75, 95.53571428571429, 91.96428571428571, 92.85714285714286, 92.85714285714286, 93.75, 92.85714285714286, 92.85714285714286, 91.07142857142857, 91.96428571428571, 89.28571428571429, 91.07142857142857, 89.28571428571429, 87.5, 93.75, 96.42857142857143, 91.96428571428571, 89.28571428571429, 92.85714285714286, 91.07142857142857, 92.85714285714286, 88.39285714285714, 92.85714285714286, 89.28571428571429, 92.85714285714286, 91.96428571428571, 92.85714285714286, 95.53571428571429, 95.53571428571429, 92.85714285714286, 97.32142857142857, 95.53571428571429, 89.28571428571429, 93.75, 87.5, 91.96428571428571, 94.64285714285714, 91.96428571428571, 91.07142857142857, 90.17857142857143, 91.96428571428571, 93.75, 92.85714285714286, 95.53571428571429, 93.75, 94.64285714285714, 91.96428571428571]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 93.28%\n",
      "Loss on the train set: 0.22\n",
      "Accuracy on the test set: 93.67%\n",
      "Loss on the test set: 0.28\n",
      "Generalization error: 0.06553371\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
