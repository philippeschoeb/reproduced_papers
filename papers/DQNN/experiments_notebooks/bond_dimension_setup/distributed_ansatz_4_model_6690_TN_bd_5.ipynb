{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1637.5\" height=\"593.75\" viewBox=\"-30.0 0 1310.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.653113</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.483279</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.23486</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.01824</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.529656</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.875807</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.976146</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.956836</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.472237</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.048875</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.199958</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.666938</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.473874</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.653931</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.777954</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.224747</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.261055</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.884278</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.672585</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.776361</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.009956</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.542843</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.210425</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.74936</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.495711</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.350746</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.737985</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.753766</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.645222</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.003298</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.34303</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.57866</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.959374</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.648473</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.575036</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.051661</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.55062</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.534786</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.425572</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.045024</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.892965</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.698589</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.793697</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.391697</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.805037</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.021399</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.686707</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.109028</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.824875</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.727848</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.897323</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.853962</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.989779</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.130002</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.630902</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.342928</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.674244</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.690839</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.682464</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.81408</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.72881</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.543261</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.639203</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.942816</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.665489</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.308808</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.998959</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.209623</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.164159</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.475412</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.985251</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.310625</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.247156</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.883313</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.652397</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.248793</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.122443</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.269985</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.383908</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.995635</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.47681</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.301041</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.555114</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.687584</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.011876</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.463286</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.627819</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.818537</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.707576</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.269892</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.544743</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.472121</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.01652</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.385776</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.344032</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.532623</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25.0 L1240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,125.0 L1240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,175.0 L1240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,225.0 L1240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,275.0 L1240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,325.0 L1240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,375.0 L1240,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,425.0 L1240,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1250\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1250\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1250\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1250\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1250\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1250\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1250\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1250\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1250\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7d1622d01340>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m=9, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.599996</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.578787</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.230216</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.649308</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.324193</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.701871</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.514698</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.796044</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.436149</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.676179</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.249302</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.280014</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.501518</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.471946</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.015642</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.915091</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.949437</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.904786</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.897481</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.652366</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.205965</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.928336</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.024387</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.591953</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.617105</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.138759</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.996248</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.943532</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.670805</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.721505</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.79371</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.191102</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.429642</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.065583</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.945944</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.997656</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.628496</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.268864</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.107169</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.952175</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.348991</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.980044</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.446023</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.879627</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.154321</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.480011</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.201107</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.740207</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=8.268952e-4</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.122585</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.226676</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.812762</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.398482</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.201011</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.128198</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.944378</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.962134</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.961918</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.242622</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.74651</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.532504</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.477984</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.297437</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.259781</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.123868</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.047969</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.38422</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.267128</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.756571</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.201208</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.440779</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.42657</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.347692</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.416339</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.886598</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7d1622c97820>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m=8, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        #     super(CNNModel, self).__init__()\n",
    "        #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "        #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "        #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "        #     self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "        # def forward(self, x):\n",
    "        #     x = self.pool(self.conv1(x))\n",
    "        #     x = self.pool(self.conv2(x))\n",
    "        #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        #     x = self.fc1(x)\n",
    "        #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 74.50%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    # class MappingModel(nn.Module):\n",
    "    #     def __init__(self, input_size, hidden_sizes, output_size):\n",
    "    #         super().__init__()\n",
    "    #         # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "    #         self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "    #         self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "    #         self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    #     def forward(self, X):\n",
    "    #         # Ensure the input tensor is the same type as the weights\n",
    "    #         X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "    #         # Input layer with ReLU activation\n",
    "    #         X = self.input_layer(X)\n",
    "\n",
    "    #         # Hidden layers with ReLU activation\n",
    "    #         for hidden in self.hidden_layers:\n",
    "    #             X = hidden(X)\n",
    "\n",
    "    #         # Output layer with linear activation\n",
    "    #         output = self.output_layer(X)\n",
    "    #         # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "    #         return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "        # self.MappingNetwork = self.MappingModel(n_qubit+1, [8], 1).to(device)\n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit + 1, output_dim=1, bond_dim=5)\n",
    "\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        # self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[\n",
    "            :108\n",
    "        ]  # nn.Parameter(q_delta * torch.randn(135)).to(device)\n",
    "        self.q_params_2 = qnn_parameters[108:]\n",
    "        device = x.device\n",
    "\n",
    "        res_1 = bs_1.run(parameters=self.q_params_1, samples=100000)\n",
    "        trans_res_1 = bs_1.translate_results(res=res_1)\n",
    "        trans_res_1 = trans_res_1 / torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)\n",
    "\n",
    "        res_2 = bs_2.run(parameters=self.q_params_2, samples=100000)\n",
    "        trans_res_2 = bs_2.translate_results(res=res_2)\n",
    "        trans_res_2 = trans_res_2 / torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)\n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(126 * 70, 1)\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[: len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  775\n",
      "# of trainable parameter in QNN model:  192\n",
      "# of trainable parameter in full model:  967\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108 + 84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\n",
    "    \"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters\n",
    ")\n",
    "print(\n",
    "    \"# of trainable parameter in full model: \",\n",
    "    num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.2656, batch time: 0.37, accuracy:  14.06%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.0553, batch time: 0.32, accuracy:  21.88%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 1.8679, batch time: 0.18, accuracy:  26.56%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 1.8072, batch time: 0.18, accuracy:  35.94%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 1.6744, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 1.4042, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 1.3591, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 0.9902, batch time: 0.09, accuracy:  69.53%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 1.3435, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 0.9946, batch time: 0.04, accuracy:  67.19%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 1.0623329877853394, accuracy: 65.6 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 1.4247299432754517, accuracy: 54.4 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 1.064864993095398, accuracy: 64.8 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 1.1079856157302856, accuracy: 62.1 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 1.014642596244812, accuracy: 67.0 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 1.1082175970077515, accuracy: 63.3 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 1.0068576335906982, accuracy: 67.3 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 1.010347604751587, accuracy: 68.0 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 1.0176421403884888, accuracy: 68.2 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 1.000198483467102, accuracy: 68.7 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 1.1080, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 0.9622, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 0.7848, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 1.0017, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 0.8912, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 0.6820, batch time: 0.04, accuracy:  78.91%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 0.8197, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 0.9943, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 0.9374, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 0.7918, batch time: 0.11, accuracy:  78.12%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 0.7332167625427246, accuracy: 74.7 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 0.8299471139907837, accuracy: 71.2 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 0.7265170812606812, accuracy: 75.1 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 0.7774067521095276, accuracy: 74.3 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 0.7430019974708557, accuracy: 74.8 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 1.0139542818069458, accuracy: 68.7 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 0.7109575867652893, accuracy: 76.3 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 0.7121490240097046, accuracy: 76.1 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 0.7102293968200684, accuracy: 76.2 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 0.7132567763328552, accuracy: 76.0 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 0.6825, batch time: 0.09, accuracy:  80.47%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 0.7464, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 0.9113, batch time: 0.05, accuracy:  72.66%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 0.7019, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 0.7579, batch time: 0.11, accuracy:  75.00%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 0.6278, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 0.6861, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 0.5962, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 0.7097, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 0.7673, batch time: 0.10, accuracy:  71.88%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 0.6640342473983765, accuracy: 79.0 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 0.6985210180282593, accuracy: 76.9 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 0.6400895714759827, accuracy: 79.2 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 0.628728449344635, accuracy: 79.7 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 0.6286429166793823, accuracy: 79.9 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 0.6707028746604919, accuracy: 78.3 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 0.617614209651947, accuracy: 80.9 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 0.6548324227333069, accuracy: 78.8 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 0.6119016408920288, accuracy: 81.0 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 0.6113613247871399, accuracy: 81.2 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 0.5370, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 0.5985, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 0.7385, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 0.7017, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 0.4485, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 0.5699, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 0.6263, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 0.6110, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 0.5399, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 0.6376, batch time: 0.04, accuracy:  82.03%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 0.5868628025054932, accuracy: 81.6 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 1.0332067012786865, accuracy: 66.1 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 0.7414880990982056, accuracy: 76.6 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 1.007187008857727, accuracy: 66.9 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 0.5552148222923279, accuracy: 82.0 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 0.5818129777908325, accuracy: 82.5 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 0.5487654805183411, accuracy: 82.4 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 0.5936933159828186, accuracy: 80.9 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 0.5444040298461914, accuracy: 82.5 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 0.5664206147193909, accuracy: 82.1 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 0.6126, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 0.5080, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 0.9885, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 0.6303, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 0.5989, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 0.6333, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 0.4809, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 0.6303, batch time: 0.08, accuracy:  77.34%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 0.5208, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 0.4625, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 0.5282881259918213, accuracy: 83.8 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 1.6267125606536865, accuracy: 58.2 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 0.562309980392456, accuracy: 80.8 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 0.5098849534988403, accuracy: 84.0 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 0.5146467685699463, accuracy: 83.6 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 0.5411568880081177, accuracy: 83.3 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 0.5268375277519226, accuracy: 84.2 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 0.48388659954071045, accuracy: 85.4 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 0.48034247756004333, accuracy: 85.7 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 0.47990119457244873, accuracy: 85.7 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 0.7237, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 0.7676, batch time: 0.10, accuracy:  74.22%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 0.8736, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 0.5076, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 0.4302, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 0.4911, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 0.5609, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 0.5611, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 0.3822, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 0.4420, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 0.42330047488212585, accuracy: 88.5 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 0.5591065287590027, accuracy: 82.1 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 0.4142642915248871, accuracy: 88.3 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 0.4117402732372284, accuracy: 88.4 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 0.43329086899757385, accuracy: 86.0 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 0.45247891545295715, accuracy: 86.7 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 0.41667094826698303, accuracy: 88.0 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 0.42447102069854736, accuracy: 87.1 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 0.40059179067611694, accuracy: 88.7 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 0.39659520983695984, accuracy: 88.5 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 0.6140, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 0.4729, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 0.4834, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 0.3799, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 0.4098, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 0.5547, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 0.4232, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 0.5610, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 0.3587, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 0.4100, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 0.46234360337257385, accuracy: 86.1 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 0.5861270427703857, accuracy: 82.8 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 0.4431331753730774, accuracy: 87.4 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 0.4334549307823181, accuracy: 87.0 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 0.4334779679775238, accuracy: 86.9 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 0.4729215204715729, accuracy: 86.2 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 0.5863367319107056, accuracy: 81.9 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 0.9730416536331177, accuracy: 70.9 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 0.5280395746231079, accuracy: 83.3 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 0.42857295274734497, accuracy: 87.1 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 0.4026, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 0.4815, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 0.4933, batch time: 0.04, accuracy:  82.03%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 0.3489, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 0.4613, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 0.3148, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 0.4586, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 0.3044, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 0.2985, batch time: 0.08, accuracy:  91.41%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 0.4095, batch time: 0.08, accuracy:  86.72%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 0.35380980372428894, accuracy: 89.5 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 1.955080509185791, accuracy: 56.0 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 0.8220276236534119, accuracy: 73.4 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 0.41370949149131775, accuracy: 85.0 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 0.4538196921348572, accuracy: 86.1 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 0.315789133310318, accuracy: 90.5 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 0.31050533056259155, accuracy: 90.8 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 0.30807381868362427, accuracy: 91.3 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 0.30811965465545654, accuracy: 91.1 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 0.31050390005111694, accuracy: 90.8 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 0.5675, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 0.4024, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 0.4104, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 0.2467, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 0.3091, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 0.2571, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 0.2531, batch time: 0.09, accuracy:  92.19%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 0.4035, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 0.3355, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 0.4576, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 0.4359937012195587, accuracy: 87.5 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 0.4428045153617859, accuracy: 87.2 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 0.40176060795783997, accuracy: 88.7 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 0.3997102975845337, accuracy: 88.7 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 0.7977185249328613, accuracy: 76.2 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 0.42847901582717896, accuracy: 87.8 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 0.40069106221199036, accuracy: 88.1 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 0.39592909812927246, accuracy: 88.2 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 0.3836446702480316, accuracy: 88.9 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 0.392147421836853, accuracy: 88.7 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 0.4358, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 0.3886, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 0.1970, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 0.3269, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 0.2499, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 0.4251, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 0.4183, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 0.2144, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 0.3241, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 0.3134, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 0.3629741370677948, accuracy: 88.3 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 0.5311341285705566, accuracy: 84.1 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 0.3291074335575104, accuracy: 89.8 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 0.3271755576133728, accuracy: 90.1 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 0.32473447918891907, accuracy: 90.4 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 0.38341808319091797, accuracy: 87.9 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 0.3464174270629883, accuracy: 89.1 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 0.3165980577468872, accuracy: 89.6 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 0.31275784969329834, accuracy: 90.4 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 0.3117527365684509, accuracy: 90.1 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 0.3612, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 0.4268, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 0.2899, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 0.4131, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 0.3351, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 0.4138, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 0.3460, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 0.2524, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 0.2365, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 0.5856, batch time: 0.04, accuracy:  83.59%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 0.34056079387664795, accuracy: 89.4 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 0.4153987765312195, accuracy: 86.0 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 0.3164531886577606, accuracy: 91.0 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 0.29430726170539856, accuracy: 91.7 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 0.2768496572971344, accuracy: 92.2 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 0.4544389843940735, accuracy: 85.2 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 0.5556230545043945, accuracy: 80.2 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 0.2691245377063751, accuracy: 91.9 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 0.2647590637207031, accuracy: 92.2 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 0.27521073818206787, accuracy: 91.6 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 0.3998, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 0.2605, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 0.3201, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 0.3130, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 0.5689, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 0.3268, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 0.3142, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 0.2750, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 0.3110, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 0.4720, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 0.3276837170124054, accuracy: 90.6 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 0.40388599038124084, accuracy: 87.4 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 0.3329380750656128, accuracy: 90.6 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 0.45214930176734924, accuracy: 86.2 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 0.3179704248905182, accuracy: 90.5 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 0.3103446066379547, accuracy: 90.7 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 0.31101536750793457, accuracy: 90.5 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 0.3057776987552643, accuracy: 90.6 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 0.3062398433685303, accuracy: 91.0 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 0.3019900918006897, accuracy: 91.1 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 0.3214, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 0.2921, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 0.2920, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 0.4972, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 0.2354, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 0.4302, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 0.3490, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 0.4177, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 0.3549, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 0.4869, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 0.39060989022254944, accuracy: 88.9 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 0.4044325053691864, accuracy: 89.0 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 0.34609392285346985, accuracy: 89.8 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 0.33325275778770447, accuracy: 90.4 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 0.3888562321662903, accuracy: 88.6 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 0.3179387152194977, accuracy: 90.9 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 0.31676822900772095, accuracy: 91.0 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 0.3130810558795929, accuracy: 91.4 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 0.3132264018058777, accuracy: 91.3 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 0.3184928596019745, accuracy: 91.1 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 0.2293, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 0.3099, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 0.3814, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 0.2985, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 0.3654, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 0.3446, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 0.3318, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 0.3465, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 0.3899, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 0.3997, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 0.3501376807689667, accuracy: 89.8 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 0.350869357585907, accuracy: 90.3 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 0.3430897891521454, accuracy: 90.2 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 0.3280629813671112, accuracy: 90.5 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 0.3250105381011963, accuracy: 91.2 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 0.3455424904823303, accuracy: 89.4 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 0.5541306734085083, accuracy: 81.4 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 0.30969154834747314, accuracy: 91.2 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 0.3060920536518097, accuracy: 91.7 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 0.3057538568973541, accuracy: 91.5 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 0.3550, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 0.2132, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 0.3408, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 0.2684, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 0.3271, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 0.4282, batch time: 0.04, accuracy:  83.59%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 0.4351, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 0.3185, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 0.2874, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 0.3264, batch time: 0.08, accuracy:  89.06%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 0.28730738162994385, accuracy: 91.0 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 0.2892695367336273, accuracy: 91.0 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 0.26135459542274475, accuracy: 92.2 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 0.2543889880180359, accuracy: 91.7 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 0.2527102530002594, accuracy: 91.8 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 0.2551118731498718, accuracy: 92.5 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 0.24593408405780792, accuracy: 92.2 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 0.3567103147506714, accuracy: 87.8 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 0.24328406155109406, accuracy: 92.6 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 0.24295231699943542, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 0.3068, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 0.6259, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 0.3568, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 0.4386, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 0.3358, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 0.2164, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 0.3669, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 0.2195, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 0.2933, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 0.3727, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 0.31894299387931824, accuracy: 90.4 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 0.3372792899608612, accuracy: 89.5 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 0.3106817603111267, accuracy: 91.5 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 0.30418023467063904, accuracy: 92.0 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 0.38423433899879456, accuracy: 88.5 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 0.29917797446250916, accuracy: 91.2 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 1.204517126083374, accuracy: 72.2 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 0.28989413380622864, accuracy: 91.5 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 0.29345276951789856, accuracy: 91.3 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 0.2853282392024994, accuracy: 91.4 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 0.2751, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 0.2846, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 0.3500, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 0.3224, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 0.3396, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 0.3147, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 0.2345, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 0.3937, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 0.4776, batch time: 0.08, accuracy:  89.84%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 0.2250, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 0.2542378306388855, accuracy: 91.8 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 0.27881020307540894, accuracy: 91.2 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 0.40357306599617004, accuracy: 86.5 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 0.2435636967420578, accuracy: 93.1 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 0.2834475338459015, accuracy: 91.2 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 0.23915648460388184, accuracy: 92.8 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 0.2377866506576538, accuracy: 92.8 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 0.23767438530921936, accuracy: 93.1 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 0.23931561410427094, accuracy: 92.8 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 0.23826436698436737, accuracy: 92.7 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 0.4287, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 0.3333, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 0.3677, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 0.2217, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 0.3638, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 0.4214, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 0.3044, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 0.2119, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 0.2261, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 0.2022, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 0.3141106963157654, accuracy: 91.9 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 0.4750373959541321, accuracy: 85.3 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 0.28906330466270447, accuracy: 91.6 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 0.28720250725746155, accuracy: 92.3 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 0.4528426229953766, accuracy: 85.1 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 0.2846328318119049, accuracy: 92.2 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 0.28585460782051086, accuracy: 92.0 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 0.29265180230140686, accuracy: 91.8 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 0.2935500741004944, accuracy: 91.4 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 0.28301528096199036, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 0.2455, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 0.2398, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 0.3506, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 0.4288, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 0.2803, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 0.1988, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 0.2982, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 0.2558, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 0.4312, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 0.1507, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 0.2858765125274658, accuracy: 90.7 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 0.3018488883972168, accuracy: 90.8 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 0.3004189133644104, accuracy: 90.5 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 0.27358365058898926, accuracy: 91.4 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 0.27467575669288635, accuracy: 91.0 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 0.44887080788612366, accuracy: 85.9 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 0.4721415042877197, accuracy: 85.3 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 0.40522903203964233, accuracy: 86.9 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 2.0945112705230713, accuracy: 57.8 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 0.2678522765636444, accuracy: 91.9 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 0.2733, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 0.4818, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 0.3612, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 0.2577, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 0.4325, batch time: 0.19, accuracy:  90.62%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 0.4066, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 0.1072, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 0.2337, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 0.1630, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 0.2869, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 0.3024846315383911, accuracy: 91.4 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 0.3377898335456848, accuracy: 89.6 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 0.3922727108001709, accuracy: 87.4 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 0.2959851324558258, accuracy: 90.8 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 0.32893863320350647, accuracy: 90.0 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 0.29503709077835083, accuracy: 91.7 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 0.64951491355896, accuracy: 80.4 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 0.2820054590702057, accuracy: 91.2 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 0.28274646401405334, accuracy: 90.8 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 0.28867465257644653, accuracy: 92.1 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 0.2786, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 0.2495, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 0.2493, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 0.4275, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 0.3602, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 0.3708, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 0.1912, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 0.3203, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 0.1746, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 0.3391, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 0.3226437270641327, accuracy: 89.1 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 0.2923789322376251, accuracy: 90.6 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 0.2885112464427948, accuracy: 90.8 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 0.27172404527664185, accuracy: 91.0 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 0.2706231474876404, accuracy: 91.2 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 0.335621178150177, accuracy: 88.4 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 0.25794517993927, accuracy: 91.4 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 0.2548929750919342, accuracy: 91.9 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 0.2606944143772125, accuracy: 91.4 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 0.25122350454330444, accuracy: 91.8 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 0.3299, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 0.4062, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 0.3004, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 0.2171, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 0.3380, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 0.1249, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 0.1741, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 0.2480, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 0.3520, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 0.2412, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 0.27587494254112244, accuracy: 91.6 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 0.2763843238353729, accuracy: 91.8 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 0.27425074577331543, accuracy: 91.7 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 0.43633008003234863, accuracy: 86.6 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 0.3583139181137085, accuracy: 89.5 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 0.2749819755554199, accuracy: 92.1 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 0.3726469874382019, accuracy: 88.6 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 0.2637326717376709, accuracy: 91.9 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 0.2629048526287079, accuracy: 91.4 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 0.2597666382789612, accuracy: 91.9 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 0.2261, batch time: 0.06, accuracy:  91.41%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 0.3141, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 0.3049, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 0.2289, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 0.4311, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 0.2174, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 0.2819, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 0.2526, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 0.3156, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 0.2876, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 0.21958598494529724, accuracy: 92.7 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 0.29111334681510925, accuracy: 89.2 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 0.2009032666683197, accuracy: 93.9 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 0.19998382031917572, accuracy: 93.9 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 0.2211596816778183, accuracy: 93.1 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 0.19521299004554749, accuracy: 93.9 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 0.19431912899017334, accuracy: 93.9 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 0.19341306388378143, accuracy: 94.1 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 0.19248820841312408, accuracy: 93.9 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 0.1948838233947754, accuracy: 94.0 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 0.2775, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 0.2251, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 0.2616, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 0.3309, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 0.3316, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 0.1228, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 0.2148, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 0.2319, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 0.3789, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 0.2164, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 0.3267000615596771, accuracy: 89.6 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 4.27430534362793, accuracy: 42.3 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 0.29722827672958374, accuracy: 90.7 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 0.2951948344707489, accuracy: 90.7 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 0.31062883138656616, accuracy: 90.3 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 0.7154554724693298, accuracy: 79.3 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 0.32386183738708496, accuracy: 89.9 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 0.28235697746276855, accuracy: 90.6 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 0.2708495855331421, accuracy: 91.4 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 0.267659991979599, accuracy: 91.3 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 0.2969, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 0.3672, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 0.3520, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 0.2428, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 0.3437, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 0.2772, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 0.1551, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 0.2878, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 0.1792, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 0.3031, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 0.2585596442222595, accuracy: 92.3 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 3.9265124797821045, accuracy: 48.7 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 0.2499162256717682, accuracy: 92.3 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 0.23585394024848938, accuracy: 93.6 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 0.24740459024906158, accuracy: 92.5 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 0.31625643372535706, accuracy: 90.0 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 0.23198215663433075, accuracy: 93.5 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 0.2361181229352951, accuracy: 93.6 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 0.22814859449863434, accuracy: 93.6 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 0.23035500943660736, accuracy: 93.6 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 0.3080, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 0.2891, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 0.2349, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 0.4002, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 0.3862, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 0.1943, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 0.2963, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 0.2567, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 0.3301, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 0.2725, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 0.27052512764930725, accuracy: 91.9 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 0.2842358350753784, accuracy: 90.8 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 0.26326754689216614, accuracy: 92.2 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 0.2613005042076111, accuracy: 92.2 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 0.3327735364437103, accuracy: 88.9 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 0.2748904526233673, accuracy: 91.4 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 0.2797408699989319, accuracy: 91.2 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 0.2825983762741089, accuracy: 92.6 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 0.24983200430870056, accuracy: 93.2 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 0.24719133973121643, accuracy: 93.8 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 0.3860, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 0.3226, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 0.3055, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 0.2952, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 0.3992, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 0.1598, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 0.2359, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 0.2351, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 0.4380, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 0.2294, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 0.26727890968322754, accuracy: 92.2 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 2.925353765487671, accuracy: 57.0 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 0.25352174043655396, accuracy: 93.1 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 0.24577482044696808, accuracy: 93.1 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 0.7684584259986877, accuracy: 76.0 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 0.2738785743713379, accuracy: 91.7 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 0.22621552646160126, accuracy: 93.1 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 0.23391485214233398, accuracy: 93.6 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 0.22313754260540009, accuracy: 93.1 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 0.22390298545360565, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 0.3073, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 0.3075, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 0.2462, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 0.2134, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 0.2404, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 0.2686, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 0.2860, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 0.3639, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 0.2064, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 0.3276, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 0.2701038420200348, accuracy: 91.8 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 0.29287630319595337, accuracy: 91.2 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 0.255473792552948, accuracy: 92.1 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 0.25239261984825134, accuracy: 92.0 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 0.2591012120246887, accuracy: 91.9 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 0.24790765345096588, accuracy: 93.0 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 0.2696716785430908, accuracy: 92.0 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 0.2387893944978714, accuracy: 92.6 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 0.23190544545650482, accuracy: 92.7 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 0.23790542781352997, accuracy: 92.3 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 0.1349, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 0.2230, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 0.1710, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 0.3006, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 0.3021, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 0.3304, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 0.2645, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 0.1528, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 0.1696, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 0.1878, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 0.2552325427532196, accuracy: 91.6 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 0.2674480080604553, accuracy: 91.5 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 0.23967093229293823, accuracy: 92.4 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 0.23735849559307098, accuracy: 92.8 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 0.23701539635658264, accuracy: 92.9 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 0.2309030294418335, accuracy: 93.2 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 0.23266373574733734, accuracy: 92.8 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 0.23416128754615784, accuracy: 92.9 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 0.2283463329076767, accuracy: 93.3 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 0.22928166389465332, accuracy: 93.2 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 0.1914, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 0.1387, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 0.2812, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 0.2170, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 0.1673, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 0.2566, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 0.1845, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 0.1982, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 0.1938, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 0.2371, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 0.2996266782283783, accuracy: 89.8 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 0.34478363394737244, accuracy: 87.4 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 0.24769219756126404, accuracy: 92.7 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 0.24657006561756134, accuracy: 92.5 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 0.2940925359725952, accuracy: 91.1 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 0.2423611283302307, accuracy: 93.0 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 0.24308596551418304, accuracy: 92.6 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 0.2399081289768219, accuracy: 92.6 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 0.2422313392162323, accuracy: 92.8 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 0.2705926299095154, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 0.4401, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 0.2376, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 0.1843, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 0.2367, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 0.3525, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 0.2724, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 0.1394, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 0.2457, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 0.1117, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 0.2367, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 0.28291139006614685, accuracy: 91.9 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 0.27535542845726013, accuracy: 91.3 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 0.26284295320510864, accuracy: 92.3 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 0.2552567720413208, accuracy: 92.9 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 0.25708749890327454, accuracy: 92.3 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 0.47416335344314575, accuracy: 84.8 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 0.244609996676445, accuracy: 93.1 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 0.23503990471363068, accuracy: 93.7 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 0.23607245087623596, accuracy: 93.4 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 0.23069800436496735, accuracy: 93.5 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 0.2265, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 0.2909, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 0.2808, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 0.1653, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 0.3555, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 0.1743, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 0.3825, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 0.1614, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 0.1618, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 0.3636, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 0.35041025280952454, accuracy: 88.8 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 0.3266710638999939, accuracy: 89.7 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 0.28080204129219055, accuracy: 90.9 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 0.27493607997894287, accuracy: 91.3 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 0.27724483609199524, accuracy: 91.7 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 0.30264729261398315, accuracy: 90.6 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 0.31642255187034607, accuracy: 89.8 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 0.41616034507751465, accuracy: 86.5 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 0.2600868046283722, accuracy: 91.6 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 0.3922133147716522, accuracy: 87.0 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 0.3225, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 0.2460, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 0.2100, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 0.2428, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 0.2072, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 0.3605, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 0.1266, batch time: 0.07, accuracy:  96.09%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 0.2893, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 0.2732, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 0.2980, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 0.2684163749217987, accuracy: 92.1 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 0.381026029586792, accuracy: 87.0 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 0.27987048029899597, accuracy: 91.5 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 0.4450288712978363, accuracy: 86.4 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 0.2627372145652771, accuracy: 91.8 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 0.25127190351486206, accuracy: 92.4 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 0.2524451017379761, accuracy: 91.6 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 0.24894043803215027, accuracy: 92.0 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 0.24571552872657776, accuracy: 91.9 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 0.2458726316690445, accuracy: 92.5 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 0.3097, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 0.2561, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 0.2729, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 0.2905, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 0.2286, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 0.3677, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 0.2327, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 0.1828, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 0.1484, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 0.3320, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 0.22267648577690125, accuracy: 93.0 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 0.24045926332473755, accuracy: 92.6 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 0.21756130456924438, accuracy: 93.3 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 0.21148088574409485, accuracy: 93.6 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 0.2193579375743866, accuracy: 93.2 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 0.2438117265701294, accuracy: 92.0 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 0.2096344381570816, accuracy: 93.6 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 0.20399801433086395, accuracy: 93.2 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 0.2017958015203476, accuracy: 93.4 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 0.20132653415203094, accuracy: 93.6 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 0.2615, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 0.1711, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 0.3006, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 0.1713, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 0.2082, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 0.3700, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 0.1842, batch time: 0.09, accuracy:  92.19%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 0.3187, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 0.1254, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 0.2983, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 0.23168039321899414, accuracy: 91.8 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 1.8006792068481445, accuracy: 58.7 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 0.9189552664756775, accuracy: 72.4 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 0.31250202655792236, accuracy: 90.4 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 0.24734468758106232, accuracy: 91.7 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 0.27243772149086, accuracy: 91.0 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 0.20728202164173126, accuracy: 93.1 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 0.21084904670715332, accuracy: 93.2 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 0.20260562002658844, accuracy: 93.5 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 0.2036680281162262, accuracy: 93.0 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 0.3498, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 0.3976, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 0.1982, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 0.2330, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 0.2136, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 0.3523, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 0.2416, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 0.2930, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 0.2797, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 0.2176, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 0.2647447884082794, accuracy: 91.9 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 0.23088888823986053, accuracy: 93.2 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 0.22911468148231506, accuracy: 93.1 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 0.22541983425617218, accuracy: 93.3 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 0.2913272976875305, accuracy: 91.2 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 0.2616785764694214, accuracy: 91.5 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 0.21798288822174072, accuracy: 93.5 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 0.21771417558193207, accuracy: 93.5 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 0.21201777458190918, accuracy: 94.0 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 0.21101096272468567, accuracy: 93.6 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 0.2539, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 0.3506, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 0.2776, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 0.2166, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 0.3307, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 0.2929, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 0.2434, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 0.3634, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 0.2145, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 0.3822, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 0.19814498722553253, accuracy: 94.0 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 0.22797304391860962, accuracy: 93.5 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 0.18540403246879578, accuracy: 94.4 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 0.1853746622800827, accuracy: 94.4 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 0.23754195868968964, accuracy: 93.9 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 0.5182722210884094, accuracy: 81.9 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 0.272318035364151, accuracy: 91.6 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 0.5074472427368164, accuracy: 83.0 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 0.2147904932498932, accuracy: 94.2 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 0.4851348102092743, accuracy: 82.9 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 0.2077, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 0.2606, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 0.2556, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 0.1498, batch time: 0.07, accuracy:  96.09%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 0.2728, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 0.2201, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 0.2395, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 0.2916, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 0.1666, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 0.2843, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 0.22427459061145782, accuracy: 93.5 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 0.21811653673648834, accuracy: 93.8 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 0.2596256732940674, accuracy: 93.0 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 0.2163294106721878, accuracy: 94.2 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 0.24593329429626465, accuracy: 92.8 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 0.21093235909938812, accuracy: 93.9 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 0.2019018828868866, accuracy: 94.3 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 0.20174120366573334, accuracy: 94.0 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 0.20113416016101837, accuracy: 94.1 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 0.19732588529586792, accuracy: 94.1 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 0.2789, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 0.2400, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 0.3052, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 0.3134, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 0.3349, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 0.2839, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 0.2198, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 0.2673, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 0.2018, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 0.1367, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 0.226668119430542, accuracy: 93.3 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 0.2410096824169159, accuracy: 92.7 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 0.21433885395526886, accuracy: 93.6 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 0.20966112613677979, accuracy: 93.8 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 0.2068352848291397, accuracy: 93.8 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 0.38905277848243713, accuracy: 87.2 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 0.1982407420873642, accuracy: 94.2 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 0.19898825883865356, accuracy: 93.9 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 0.19343289732933044, accuracy: 94.0 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 0.2057158499956131, accuracy: 93.1 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 0.1014, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 0.2490, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 0.2669, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 0.1667, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 0.1728, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 0.2555, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 0.2208, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 0.3794, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 0.2105, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 0.1713, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 0.204883873462677, accuracy: 93.7 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 0.2431797981262207, accuracy: 92.0 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 0.1976834386587143, accuracy: 94.8 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 0.19698825478553772, accuracy: 94.9 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 0.18836884200572968, accuracy: 94.7 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 0.32081931829452515, accuracy: 88.8 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 0.3105955421924591, accuracy: 89.5 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 0.24701440334320068, accuracy: 91.8 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 0.2294841855764389, accuracy: 93.0 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 0.4342561662197113, accuracy: 85.2 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 0.2552, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 0.3637, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 0.2609, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 0.1898, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 0.3380, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 0.1582, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 0.1869, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 0.4429, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 0.2223, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 0.2144, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 0.21535824239253998, accuracy: 93.0 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 0.21140165627002716, accuracy: 93.4 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 0.20286361873149872, accuracy: 94.0 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 0.19989480078220367, accuracy: 93.5 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 0.19877889752388, accuracy: 94.0 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 0.24092087149620056, accuracy: 91.8 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 0.21034936606884003, accuracy: 93.1 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 0.2029336541891098, accuracy: 93.8 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 0.19523048400878906, accuracy: 94.3 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 0.19574475288391113, accuracy: 93.9 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 0.2961, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 0.1411, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 0.2107, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 0.2150, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 0.2383, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 0.2360, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 0.2279, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 0.1734, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 0.1574, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 0.4227, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 0.23840786516666412, accuracy: 93.4 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 0.24868148565292358, accuracy: 93.0 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 0.22712871432304382, accuracy: 93.7 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 0.22498176991939545, accuracy: 93.9 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 0.38121360540390015, accuracy: 87.0 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 0.23135420680046082, accuracy: 93.2 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 0.28293919563293457, accuracy: 91.8 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 0.35310375690460205, accuracy: 88.4 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 0.2173480987548828, accuracy: 94.1 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 0.2150924801826477, accuracy: 94.5 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 0.1962, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 0.2533, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 0.2577, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 0.2858, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 0.2169, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 0.2551, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 0.1646, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 0.2319, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 0.2530, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 0.2085, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 0.2194051295518875, accuracy: 93.5 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 1.6860469579696655, accuracy: 64.2 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 0.5937275290489197, accuracy: 83.8 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 0.26913926005363464, accuracy: 92.1 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 0.3139171898365021, accuracy: 90.4 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 0.2182563990354538, accuracy: 93.0 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 0.38209617137908936, accuracy: 87.7 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 0.1993880271911621, accuracy: 94.3 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 0.1866919845342636, accuracy: 94.8 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 0.18654292821884155, accuracy: 94.7 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 0.2060, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 0.2771, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 0.2014, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 0.3708, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 0.1988, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 0.2248, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 0.2621, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 0.2475, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 0.1823, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 0.1475, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 0.22615854442119598, accuracy: 93.1 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 0.23310700058937073, accuracy: 93.0 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 0.21926791965961456, accuracy: 93.7 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 0.2175234854221344, accuracy: 93.6 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 0.20722270011901855, accuracy: 93.8 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 0.219623401761055, accuracy: 92.5 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 0.316303551197052, accuracy: 90.1 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 0.20447078347206116, accuracy: 93.8 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 0.2212952822446823, accuracy: 93.4 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 0.20429152250289917, accuracy: 94.1 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 0.2344, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 0.2295, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 0.2557, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 0.0828, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 0.2142, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 0.3304, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 0.1044, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 0.2340, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 0.3973, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 0.2724, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 0.1962442547082901, accuracy: 93.3 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 0.2059721052646637, accuracy: 92.9 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 0.19215689599514008, accuracy: 93.8 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 0.1894725263118744, accuracy: 94.6 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 0.1919584721326828, accuracy: 94.3 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 0.18817773461341858, accuracy: 94.5 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 0.19069217145442963, accuracy: 94.6 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 0.18571501970291138, accuracy: 94.4 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 0.18635891377925873, accuracy: 94.6 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 0.18750716745853424, accuracy: 94.2 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 0.2765, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 0.2549, batch time: 0.07, accuracy:  92.97%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 0.1481, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 0.1164, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 0.3596, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 0.3158, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 0.2491, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 0.2707, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 0.2716, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 0.2802, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 0.2142496407032013, accuracy: 92.9 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 0.22488732635974884, accuracy: 92.9 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 0.20668452978134155, accuracy: 93.3 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 0.2035583257675171, accuracy: 93.4 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 0.24127726256847382, accuracy: 92.0 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 0.3594607412815094, accuracy: 86.6 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 0.20216406881809235, accuracy: 93.0 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 0.1951383352279663, accuracy: 93.1 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 0.19468331336975098, accuracy: 93.4 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 0.19341899454593658, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 0.1921, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 0.1617, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 0.2656, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 0.2021, batch time: 0.06, accuracy:  92.97%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 0.1463, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 0.2100, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 0.1911, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 0.1960, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 0.2238, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 0.3103, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 0.22015877068042755, accuracy: 92.8 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 0.23213639855384827, accuracy: 92.5 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 0.21963687241077423, accuracy: 92.7 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 0.19514356553554535, accuracy: 93.6 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 0.19289501011371613, accuracy: 93.8 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 0.21225406229496002, accuracy: 93.3 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 0.1891200691461563, accuracy: 93.7 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 0.18719075620174408, accuracy: 93.6 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 0.19057732820510864, accuracy: 93.6 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 0.1884111613035202, accuracy: 93.3 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 0.2647, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 0.2514, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 0.3100, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 0.3257, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 0.2343, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 0.1962, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 0.3512, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 0.2418, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 0.1214, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 0.2739, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 0.23273569345474243, accuracy: 93.3 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 4.055357933044434, accuracy: 50.1 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 0.2262982428073883, accuracy: 93.5 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 0.2253820300102234, accuracy: 93.5 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 0.2325761765241623, accuracy: 93.3 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 0.452251136302948, accuracy: 85.5 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 0.24277937412261963, accuracy: 92.7 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 0.35912609100341797, accuracy: 90.1 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 0.28405526280403137, accuracy: 91.4 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 0.24407027661800385, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 0.2318, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 0.3255, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 0.2094, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 0.2313, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 0.1943, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 0.2248, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 0.2353, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 0.1556, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 0.1542, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 0.3031, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 0.2261269986629486, accuracy: 92.5 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 0.23760658502578735, accuracy: 92.2 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 0.2843018174171448, accuracy: 89.9 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 0.21676044166088104, accuracy: 92.9 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 0.2489982545375824, accuracy: 91.9 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 0.21213729679584503, accuracy: 92.7 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 0.20826369524002075, accuracy: 93.2 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 0.20677021145820618, accuracy: 93.0 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 0.20683696866035461, accuracy: 92.9 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 0.2038116455078125, accuracy: 93.1 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 0.2649, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 0.1760, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 0.2517, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 0.1506, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 0.0883, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 0.1335, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 0.2582, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 0.2516, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 0.2543, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 0.2759, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 0.20075538754463196, accuracy: 94.3 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 0.692743182182312, accuracy: 78.6 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 1.6505221128463745, accuracy: 62.4 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 0.1776634156703949, accuracy: 94.8 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 0.17523273825645447, accuracy: 94.7 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 0.19224615395069122, accuracy: 93.9 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 0.3534190058708191, accuracy: 86.8 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 0.17933474481105804, accuracy: 95.0 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 0.25959956645965576, accuracy: 92.0 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 0.16744379699230194, accuracy: 95.2 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 0.2232, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 0.1743, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 0.2140, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 0.1524, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 0.1987, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 0.3776, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 0.1957, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 0.1324, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 0.2264, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 0.1820, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 0.20931944251060486, accuracy: 94.3 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 0.5030305981636047, accuracy: 85.6 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 0.20792415738105774, accuracy: 94.0 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 0.2002967745065689, accuracy: 94.0 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 0.2194698452949524, accuracy: 93.3 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 0.25121182203292847, accuracy: 92.5 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 0.18664465844631195, accuracy: 94.2 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 0.18329426646232605, accuracy: 94.3 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 0.1816919445991516, accuracy: 93.8 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 0.1820061057806015, accuracy: 94.1 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 0.2301, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 0.2502, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 0.1305, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 0.2769, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 0.2735, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 0.2307, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 0.2440, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 0.2530, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 0.2583, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 0.1687, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 0.20044592022895813, accuracy: 94.3 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 0.8606039881706238, accuracy: 71.7 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 0.24249301850795746, accuracy: 93.3 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 0.19651371240615845, accuracy: 94.3 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 0.18786154687404633, accuracy: 95.5 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 0.19216859340667725, accuracy: 95.2 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 0.1868189573287964, accuracy: 94.7 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 0.18485750257968903, accuracy: 95.1 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 0.18086902797222137, accuracy: 95.3 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 0.17934902012348175, accuracy: 95.2 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 0.2030, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 0.2669, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 0.2512, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 0.3697, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 0.2040, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 0.1753, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 0.1540, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 0.1659, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 0.2183, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 0.2061, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 0.23832771182060242, accuracy: 92.9 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 0.24226407706737518, accuracy: 93.0 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 0.21451936662197113, accuracy: 93.8 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 0.20187275111675262, accuracy: 94.1 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 0.2005654275417328, accuracy: 94.4 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 0.28267979621887207, accuracy: 91.1 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 0.20102934539318085, accuracy: 94.1 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 0.1986273229122162, accuracy: 94.4 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 0.19602134823799133, accuracy: 94.5 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 0.1959380954504013, accuracy: 94.4 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 0.2054, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 0.2633, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 0.2387, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 0.2400, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 0.2007, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 0.2848, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 0.1436, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 0.0803, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 0.1699, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 0.2521, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 0.215105339884758, accuracy: 93.5 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 0.24088428914546967, accuracy: 93.0 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 0.21042400598526, accuracy: 94.1 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 0.20984771847724915, accuracy: 93.8 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 0.23333343863487244, accuracy: 93.4 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 0.22352701425552368, accuracy: 93.5 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 0.2001323252916336, accuracy: 94.7 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 0.1999439150094986, accuracy: 95.0 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 0.1994941234588623, accuracy: 94.6 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 0.1970333307981491, accuracy: 94.5 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 0.2820, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 0.3206, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 0.1772, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 0.3397, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 0.2748, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 0.2228, batch time: 0.07, accuracy:  94.53%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 0.2140, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 0.2167, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 0.2561, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 0.2382, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 0.1916518360376358, accuracy: 95.2 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 0.2088765949010849, accuracy: 94.3 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 0.1825631707906723, accuracy: 95.3 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 0.18202266097068787, accuracy: 95.1 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 0.1939856857061386, accuracy: 95.0 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 0.19475960731506348, accuracy: 94.8 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 0.17504708468914032, accuracy: 95.5 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 0.17396681010723114, accuracy: 95.6 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 0.17228373885154724, accuracy: 95.9 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 0.174411803483963, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 0.1840, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 0.2029, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 0.1836, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 0.1979, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 0.2753, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 0.2266, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 0.1229, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 0.2952, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 0.1266, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 0.3211, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 0.2304316908121109, accuracy: 93.3 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 0.2724761962890625, accuracy: 92.0 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 0.22327862679958344, accuracy: 94.2 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 0.2212662696838379, accuracy: 94.1 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 0.31490179896354675, accuracy: 89.2 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 0.2302531749010086, accuracy: 93.1 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 0.21412904560565948, accuracy: 93.8 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 0.2125372737646103, accuracy: 94.1 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 0.2126544862985611, accuracy: 93.8 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 0.21009394526481628, accuracy: 93.6 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 0.2426, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 0.2223, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 0.4126, batch time: 0.08, accuracy:  92.19%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 0.2403, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 0.1734, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 0.2871, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 0.1237, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 0.1407, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 0.3572, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 0.1982, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 0.20591887831687927, accuracy: 93.7 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 0.22823409736156464, accuracy: 93.6 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 0.19667287170886993, accuracy: 94.5 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 0.19664010405540466, accuracy: 94.5 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 0.1967943012714386, accuracy: 94.6 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 0.3761240541934967, accuracy: 86.8 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 0.20342500507831573, accuracy: 94.3 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 0.20254741609096527, accuracy: 94.0 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 0.42656397819519043, accuracy: 86.6 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 0.1900508552789688, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 0.2176, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 0.2034, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 0.3977, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 0.2658, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 0.3384, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 0.2651, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 0.1791, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 0.2066, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 0.3588, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 0.1731, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 0.1742558628320694, accuracy: 94.4 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 0.19461704790592194, accuracy: 94.2 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 0.17972877621650696, accuracy: 94.8 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 0.22495797276496887, accuracy: 92.5 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 0.1672419309616089, accuracy: 94.6 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 0.16712196171283722, accuracy: 94.7 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 0.16605012118816376, accuracy: 94.3 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 0.16986671090126038, accuracy: 94.5 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 0.16693198680877686, accuracy: 94.4 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 0.16431766748428345, accuracy: 94.7 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 0.2633, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 0.1694, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 0.1890, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 0.2584, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 0.1280, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 0.1815, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 0.2024, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 0.1874, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 0.0645, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 0.1806, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 0.22300690412521362, accuracy: 93.7 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 0.26044756174087524, accuracy: 92.7 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 0.21540889143943787, accuracy: 93.3 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 0.2587823271751404, accuracy: 92.0 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 0.2033901959657669, accuracy: 94.4 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 0.19181182980537415, accuracy: 94.7 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 0.19109779596328735, accuracy: 94.5 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 0.1864784061908722, accuracy: 94.6 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 0.18570181727409363, accuracy: 94.8 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 0.18501968681812286, accuracy: 94.7 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 0.2986, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 0.2112, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 0.1895, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 0.1248, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 0.2533, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 0.1923, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 0.1701, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 0.2449, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 0.3291, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 0.1980, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 0.23417285084724426, accuracy: 93.1 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 0.24079082906246185, accuracy: 93.5 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 0.20692753791809082, accuracy: 94.3 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 0.20263570547103882, accuracy: 94.3 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 0.23946423828601837, accuracy: 93.7 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 0.19281019270420074, accuracy: 94.9 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 0.1864904761314392, accuracy: 94.8 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 0.18485583364963531, accuracy: 94.8 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 0.18883952498435974, accuracy: 94.6 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 0.18509800732135773, accuracy: 95.1 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 0.1327, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 0.1124, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 0.2712, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 0.2498, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 0.1708, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 0.1328, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 0.1206, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 0.3214, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 0.1875, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 0.2320, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 0.18285933136940002, accuracy: 94.5 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 0.21836240589618683, accuracy: 92.9 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 0.1958712935447693, accuracy: 93.9 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 0.2742893099784851, accuracy: 90.9 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 0.17845293879508972, accuracy: 94.5 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 0.17329300940036774, accuracy: 94.5 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 0.17376098036766052, accuracy: 94.6 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 0.17187410593032837, accuracy: 94.6 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 0.1711280792951584, accuracy: 94.6 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 0.17148476839065552, accuracy: 94.7 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 0.1569, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 0.2260, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 0.1859, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 0.1899, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 0.1763, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 0.2010, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 0.3494, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 0.2289, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 0.1494, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 0.2371, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 0.16471636295318604, accuracy: 94.3 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 0.18903136253356934, accuracy: 94.5 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 0.16362299025058746, accuracy: 94.6 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 0.24453307688236237, accuracy: 91.1 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 0.15508237481117249, accuracy: 95.0 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 0.15446870028972626, accuracy: 94.8 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 0.15629588067531586, accuracy: 94.9 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 0.15524907410144806, accuracy: 95.1 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 0.1512349396944046, accuracy: 95.0 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 0.150844544172287, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 0.2504, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 0.1420, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 0.2722, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 0.2632, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 0.3393, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 0.3590, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 0.2236, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 0.1723, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 0.2592, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 0.2329, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 0.1891084462404251, accuracy: 94.0 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 0.17431987822055817, accuracy: 95.1 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 0.17259246110916138, accuracy: 95.4 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 0.16496923565864563, accuracy: 95.4 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 0.17617647349834442, accuracy: 95.0 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 0.16026398539543152, accuracy: 95.5 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 0.17056149244308472, accuracy: 95.2 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 0.15367873013019562, accuracy: 96.1 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 0.15215815603733063, accuracy: 96.3 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 0.15084446966648102, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 0.1586, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 0.1743, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 0.1838, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 0.2404, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 0.1157, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 0.1983, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 0.1453, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 0.2739, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 0.2239, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 0.2473, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 0.187310129404068, accuracy: 94.4 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 0.17801210284233093, accuracy: 94.7 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 0.21907292306423187, accuracy: 93.7 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 0.17659319937229156, accuracy: 94.7 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 0.24616755545139313, accuracy: 92.3 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 0.17253443598747253, accuracy: 94.9 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 0.16954562067985535, accuracy: 94.9 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 0.16864581406116486, accuracy: 95.4 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 0.16905628144741058, accuracy: 95.1 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 0.16946882009506226, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 0.1980, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 0.1400, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 0.1284, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 0.0595, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 0.1387, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 0.2667, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 0.2500, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 0.1596, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 0.2183, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 0.2207, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 0.18490289151668549, accuracy: 94.6 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 0.3465318977832794, accuracy: 89.1 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 0.18915455043315887, accuracy: 94.7 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 0.2126222550868988, accuracy: 93.1 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 0.1642623394727707, accuracy: 95.5 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 0.16296009719371796, accuracy: 95.3 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 0.16261211037635803, accuracy: 95.5 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 0.16234451532363892, accuracy: 95.3 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 0.161194309592247, accuracy: 95.8 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 0.1619117707014084, accuracy: 95.5 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 0.2125, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 0.2512, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 0.2329, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 0.2356, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 0.1801, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 0.2667, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 0.2650, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 0.1402, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 0.3915, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 0.2488, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 0.21672748029232025, accuracy: 93.0 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 0.21979795396327972, accuracy: 92.8 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 0.20859289169311523, accuracy: 93.6 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 0.20077171921730042, accuracy: 93.7 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 0.24933455884456635, accuracy: 92.4 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 0.23951956629753113, accuracy: 92.6 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 0.195312961935997, accuracy: 93.5 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 0.19434258341789246, accuracy: 93.6 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 0.1949213147163391, accuracy: 93.7 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 0.19247911870479584, accuracy: 93.7 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 0.1195, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 0.2009, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 0.1815, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 0.2298, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 0.3426, batch time: 0.24, accuracy:  89.84%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 0.1087, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 0.2609, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 0.4152, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 0.1050, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 0.1468, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 0.2174130380153656, accuracy: 94.2 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 0.38297802209854126, accuracy: 88.9 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 0.3839726746082306, accuracy: 88.3 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 0.22699853777885437, accuracy: 93.8 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 0.1984780728816986, accuracy: 94.7 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 0.1958366185426712, accuracy: 94.7 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 0.19714245200157166, accuracy: 94.7 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 0.19751638174057007, accuracy: 95.0 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 0.19642558693885803, accuracy: 94.7 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 0.1958026885986328, accuracy: 94.9 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 0.1584, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 0.1719, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 0.1827, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 0.1860, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 0.1341, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 0.3365, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 0.1627, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 0.0983, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 0.1568, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 0.2445, batch time: 0.06, accuracy:  91.41%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 0.21505610644817352, accuracy: 93.2 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 0.2630477845668793, accuracy: 91.4 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 0.20463581383228302, accuracy: 93.8 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 0.19708281755447388, accuracy: 93.7 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 0.2021622359752655, accuracy: 93.5 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 0.18965229392051697, accuracy: 94.2 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 0.18770895898342133, accuracy: 94.1 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 0.18331262469291687, accuracy: 94.9 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 0.18244415521621704, accuracy: 94.9 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 0.1846274882555008, accuracy: 94.2 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 0.1651, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 0.1799, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 0.1605, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 0.2804, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 0.1631, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 0.1936, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 0.1553, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 0.1623, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 0.1760, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 0.1899, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 0.19707663357257843, accuracy: 94.2 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 0.2185104340314865, accuracy: 93.5 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 0.18918801844120026, accuracy: 94.7 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 0.1779177039861679, accuracy: 94.7 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 0.18382324278354645, accuracy: 94.6 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 0.9195859432220459, accuracy: 76.5 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 0.17966245114803314, accuracy: 94.9 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 0.17317502200603485, accuracy: 95.1 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 0.17198698222637177, accuracy: 95.2 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 0.1706342101097107, accuracy: 95.1 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 0.2691, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 0.1840, batch time: 0.07, accuracy:  93.75%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 0.1445, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 0.1650, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 0.1404, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 0.2084, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 0.1312, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 0.2614, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 0.2661, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 0.0927, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 0.17253220081329346, accuracy: 94.8 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 0.18285423517227173, accuracy: 93.9 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 0.2728588283061981, accuracy: 91.6 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 0.16352762281894684, accuracy: 94.8 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 0.36864399909973145, accuracy: 87.9 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 0.18150869011878967, accuracy: 94.9 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 0.15593139827251434, accuracy: 95.4 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 0.15497981011867523, accuracy: 95.2 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 0.15507017076015472, accuracy: 95.3 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 0.15056289732456207, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 0.1863, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 0.2229, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 0.2907, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 0.2685, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 0.2092, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 0.1910, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 0.2291, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 0.2285, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 0.3412, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 0.2058, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 0.16883592307567596, accuracy: 94.1 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 0.20925068855285645, accuracy: 94.1 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 0.16268840432167053, accuracy: 94.7 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 0.18818025290966034, accuracy: 93.7 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 0.20367328822612762, accuracy: 92.9 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 0.15730570256710052, accuracy: 94.8 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 0.15159006416797638, accuracy: 94.4 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 0.14940255880355835, accuracy: 94.8 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 0.14853055775165558, accuracy: 94.6 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 0.14741872251033783, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 0.1367, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 0.2192, batch time: 0.09, accuracy:  91.41%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 0.2716, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 0.1284, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 0.1571, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 0.3655, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 0.1373, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 0.3127, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 0.1941, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 0.1805, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 0.18927648663520813, accuracy: 93.3 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 0.18155163526535034, accuracy: 93.9 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 0.17552196979522705, accuracy: 94.0 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 0.1692034900188446, accuracy: 93.7 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 0.2836736738681793, accuracy: 91.0 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 0.21419525146484375, accuracy: 92.9 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 0.18142351508140564, accuracy: 93.7 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 0.1595797836780548, accuracy: 94.2 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 0.15840929746627808, accuracy: 94.2 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 0.1661805957555771, accuracy: 93.9 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 0.1470, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 0.1665, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 0.4014, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 0.2574, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 0.2022, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 0.1944, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 0.1980, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 0.1987, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 0.2571, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 0.1074, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 0.20424021780490875, accuracy: 93.9 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 0.23638775944709778, accuracy: 92.6 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 0.2165331393480301, accuracy: 93.0 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 0.1855819672346115, accuracy: 94.8 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 0.19585564732551575, accuracy: 94.6 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 0.3023917078971863, accuracy: 90.7 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 0.3644278645515442, accuracy: 87.9 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 0.18042846024036407, accuracy: 94.7 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 0.17937226593494415, accuracy: 94.8 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 0.17936517298221588, accuracy: 95.1 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 0.3454, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 0.1242, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 0.1839, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 0.2642, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 0.2061, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 0.1990, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 0.2109, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 0.1189, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 0.1472, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 0.2464, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 0.20798656344413757, accuracy: 93.6 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 0.2769473195075989, accuracy: 91.7 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 0.194962278008461, accuracy: 94.6 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 0.19123193621635437, accuracy: 94.1 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 0.24786178767681122, accuracy: 92.5 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 0.2175452560186386, accuracy: 93.6 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 0.21151815354824066, accuracy: 93.2 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 0.18846631050109863, accuracy: 94.5 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 0.22670046985149384, accuracy: 93.5 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 0.23857340216636658, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 0.1483, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 0.2243, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 0.1268, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 0.2209, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 0.2485, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 0.1235, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 0.1764, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 0.1505, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 0.1122, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 0.1417, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 0.16048012673854828, accuracy: 95.0 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 0.18673409521579742, accuracy: 94.0 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 0.1660059690475464, accuracy: 94.4 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 0.1552126407623291, accuracy: 95.1 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 0.2510245740413666, accuracy: 91.9 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 0.16529101133346558, accuracy: 95.1 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 0.20999471843242645, accuracy: 93.6 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 0.18273882567882538, accuracy: 94.4 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 0.1451846957206726, accuracy: 95.6 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 0.1433688998222351, accuracy: 95.7 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 0.1735, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 0.1689, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 0.1797, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 0.2352, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 0.2683, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 0.2455, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 0.1148, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 0.0703, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 0.2090, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 0.3447, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 0.24688023328781128, accuracy: 93.0 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 0.9339672923088074, accuracy: 75.7 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 0.31563788652420044, accuracy: 90.2 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 0.25760790705680847, accuracy: 92.1 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 0.18914511799812317, accuracy: 94.9 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 0.1884433925151825, accuracy: 95.2 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 0.18838757276535034, accuracy: 95.3 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 0.2196734994649887, accuracy: 92.7 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 0.17952381074428558, accuracy: 95.1 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 0.17856547236442566, accuracy: 94.9 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 0.1359, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 0.1215, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 0.1746, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 0.3402, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 0.1858, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 0.1306, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 0.2660, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 0.1817, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 0.1907, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 0.2737, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 0.21485649049282074, accuracy: 93.6 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 0.22723522782325745, accuracy: 92.2 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 0.2033822238445282, accuracy: 93.6 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 0.19449859857559204, accuracy: 93.7 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 0.20484058558940887, accuracy: 93.7 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 0.2009456306695938, accuracy: 93.9 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 0.20135775208473206, accuracy: 94.3 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 0.1889345943927765, accuracy: 94.3 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 0.1829279661178589, accuracy: 94.4 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 0.17627738416194916, accuracy: 94.5 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 0.2381, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 0.2087, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 0.1801, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 0.2312, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 0.1723, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 0.1838, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 0.2835, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 0.1561, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 0.2036, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 0.1630, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 0.20508973300457, accuracy: 93.4 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 0.21894113719463348, accuracy: 93.2 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 0.19818036258220673, accuracy: 93.9 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 0.18880712985992432, accuracy: 93.9 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 0.19002798199653625, accuracy: 93.9 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 0.22122468054294586, accuracy: 93.1 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 0.18599216639995575, accuracy: 93.8 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 0.18241021037101746, accuracy: 94.4 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 0.1821233034133911, accuracy: 94.2 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 0.18202786147594452, accuracy: 94.3 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 0.1965, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 0.3143, batch time: 0.09, accuracy:  92.19%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 0.1602, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 0.3104, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 0.2492, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 0.2247, batch time: 0.08, accuracy:  92.19%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 0.2843, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 0.1689, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 0.2222, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 0.1682, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 0.16606611013412476, accuracy: 94.3 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 0.18347370624542236, accuracy: 92.4 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 0.19074073433876038, accuracy: 92.6 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 0.1597277969121933, accuracy: 94.4 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 0.18531450629234314, accuracy: 93.6 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 0.15912498533725739, accuracy: 94.7 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 0.15682649612426758, accuracy: 94.8 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 0.15484121441841125, accuracy: 94.7 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 0.15564893186092377, accuracy: 94.9 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 0.15473730862140656, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 0.1953, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 0.3100, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 0.1091, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 0.1360, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 0.3001, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 0.1849, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 0.2479, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 0.2596, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 0.1572, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 0.1850, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 0.17243066430091858, accuracy: 93.9 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 0.21826207637786865, accuracy: 93.2 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 0.1622581034898758, accuracy: 94.4 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 0.24984504282474518, accuracy: 91.7 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 0.19790534675121307, accuracy: 94.1 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 0.15013161301612854, accuracy: 94.8 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 0.14560651779174805, accuracy: 95.5 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 0.1437404602766037, accuracy: 95.4 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 0.14231261610984802, accuracy: 95.6 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 0.1504533737897873, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 0.1369, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 0.2794, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 0.1787, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 0.2326, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 0.1201, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 0.2410, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 0.1518, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 0.1039, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 0.1608, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 0.1976, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 0.22257736325263977, accuracy: 93.9 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 0.24680709838867188, accuracy: 93.4 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 0.21613404154777527, accuracy: 94.4 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 0.20177891850471497, accuracy: 94.4 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 0.20864705741405487, accuracy: 94.5 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 0.22156482934951782, accuracy: 94.0 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 0.1958910971879959, accuracy: 94.7 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 0.1956668645143509, accuracy: 94.8 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 0.18866586685180664, accuracy: 95.2 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 0.18748441338539124, accuracy: 95.1 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 0.2120, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 0.2286, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 0.1712, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 0.1210, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 0.2066, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 0.1448, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 0.1983, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 0.2135, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 0.1386, batch time: 0.09, accuracy:  96.09%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 0.3045, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 0.1822998970746994, accuracy: 95.6 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 0.19540029764175415, accuracy: 94.4 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 0.17520388960838318, accuracy: 95.2 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 0.17432546615600586, accuracy: 95.4 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 0.17966340482234955, accuracy: 95.2 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 0.22504223883152008, accuracy: 92.4 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 0.18704792857170105, accuracy: 94.5 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 0.1693224161863327, accuracy: 95.6 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 0.16667866706848145, accuracy: 95.3 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 0.1659720093011856, accuracy: 95.5 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 0.2716, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 0.2065, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 0.2803, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 0.1587, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 0.1981, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 0.1132, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 0.1727, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 0.2285, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 0.1170, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 0.2089, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 0.17077767848968506, accuracy: 95.0 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 0.18444125354290009, accuracy: 94.9 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 0.17205917835235596, accuracy: 95.0 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 0.22544771432876587, accuracy: 93.0 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 0.1646762490272522, accuracy: 95.0 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 0.16229604184627533, accuracy: 95.0 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 0.16195550560951233, accuracy: 95.0 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 0.16218765079975128, accuracy: 94.9 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 0.15905705094337463, accuracy: 95.0 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 0.1582842618227005, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 0.2005, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 0.1323, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 0.2414, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 0.2983, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 0.1506, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 0.2880, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 0.2945, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 0.1471, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 0.3043, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 0.1574, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 0.1689653843641281, accuracy: 94.3 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 0.1700456738471985, accuracy: 94.4 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 0.2057085931301117, accuracy: 93.4 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 0.16721686720848083, accuracy: 94.5 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 0.1778588443994522, accuracy: 94.2 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 0.17392349243164062, accuracy: 94.4 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 0.16407158970832825, accuracy: 95.0 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 0.18848754465579987, accuracy: 93.8 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 0.17799489200115204, accuracy: 94.3 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 0.19831641018390656, accuracy: 92.8 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 0.2237, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 0.1638, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 0.1081, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 0.2095, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 0.1802, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 0.1883, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 0.2231, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 0.1695, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 0.1807, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 0.1870, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 0.16811560094356537, accuracy: 95.0 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 0.16907483339309692, accuracy: 95.3 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 0.16915258765220642, accuracy: 94.9 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 0.16524752974510193, accuracy: 94.9 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 0.17020949721336365, accuracy: 94.9 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 0.16989779472351074, accuracy: 94.9 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 0.1652175486087799, accuracy: 95.8 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 0.15065898001194, accuracy: 95.9 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 0.1480282098054886, accuracy: 96.4 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 0.1463446021080017, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 0.2195, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 0.1697, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 0.2129, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 0.1261, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 0.2480, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 0.1226, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 0.1745, batch time: 0.06, accuracy:  92.19%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 0.1101, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 0.1436, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 0.1732, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 0.16768112778663635, accuracy: 94.3 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 0.19978481531143188, accuracy: 93.3 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 0.15725700557231903, accuracy: 95.2 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 0.1564546674489975, accuracy: 95.5 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 0.15173116326332092, accuracy: 95.3 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 0.15225209295749664, accuracy: 95.1 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 0.21561622619628906, accuracy: 92.9 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 0.18510645627975464, accuracy: 93.8 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 0.1426413208246231, accuracy: 95.6 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 0.14261360466480255, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 0.2041, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 0.1505, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 0.0987, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 0.1897, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 0.1036, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 0.2106, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 0.1330, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 0.1429, batch time: 0.09, accuracy:  93.75%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 0.2251, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 0.1714, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 0.17250953614711761, accuracy: 94.6 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 0.18316768109798431, accuracy: 94.5 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 0.2542210817337036, accuracy: 91.8 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 0.2053348273038864, accuracy: 93.7 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 0.161412313580513, accuracy: 94.8 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 0.1603439897298813, accuracy: 95.1 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 0.1610082983970642, accuracy: 94.7 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 0.15930257737636566, accuracy: 95.2 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 0.15809711813926697, accuracy: 94.8 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 0.15871630609035492, accuracy: 95.2 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 0.2216, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 0.1557, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 0.2455, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 0.1360, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 0.1902, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 0.2355, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 0.1858, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 0.1800, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 0.1824, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 0.2069, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 0.17666779458522797, accuracy: 95.0 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 3.1884961128234863, accuracy: 54.6 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 0.16343453526496887, accuracy: 95.4 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 0.1612776219844818, accuracy: 95.6 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 0.15797846019268036, accuracy: 95.6 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 0.17293314635753632, accuracy: 95.1 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 0.23391418159008026, accuracy: 92.3 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 0.15775302052497864, accuracy: 95.5 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 0.1521216183900833, accuracy: 95.6 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 0.14954137802124023, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 0.1584, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 0.2965, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 0.2659, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 0.1998, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 0.1003, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 0.1311, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 0.2212, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 0.4000, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 0.1288, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 0.2824, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 0.142411008477211, accuracy: 95.1 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 0.13491255044937134, accuracy: 95.7 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 0.28941747546195984, accuracy: 91.1 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 1.0802479982376099, accuracy: 69.9 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 0.12481924146413803, accuracy: 96.3 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 0.12922357022762299, accuracy: 95.4 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 0.12002357840538025, accuracy: 96.2 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 0.14310593903064728, accuracy: 94.9 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 0.1260521411895752, accuracy: 95.6 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 0.11598823964595795, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 0.1372, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 0.1926, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 0.3511, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 0.2213, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 0.1365, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 0.1533, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 0.0971, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 0.2696, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 0.2281, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 0.2585, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 0.18054209649562836, accuracy: 93.5 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 0.17672336101531982, accuracy: 93.9 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 0.29684507846832275, accuracy: 90.3 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 0.25222569704055786, accuracy: 92.0 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 0.1693972945213318, accuracy: 94.2 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 0.1675015091896057, accuracy: 94.5 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 0.18581221997737885, accuracy: 94.1 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 0.17247579991817474, accuracy: 94.8 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 0.16753411293029785, accuracy: 94.9 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 0.16881056129932404, accuracy: 94.9 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 0.0682, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 0.2193, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 0.1439, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 0.2474, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 0.1777, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 0.3269, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 0.2251, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 0.1347, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 0.1974, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 0.2275, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 0.17869646847248077, accuracy: 94.0 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 0.17113560438156128, accuracy: 94.4 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 0.16280965507030487, accuracy: 94.8 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 0.16057376563549042, accuracy: 94.7 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 0.16185319423675537, accuracy: 95.1 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 0.17161975800991058, accuracy: 94.1 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 0.26448655128479004, accuracy: 90.8 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 0.15348832309246063, accuracy: 95.2 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 0.15223273634910583, accuracy: 95.4 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 0.1511792689561844, accuracy: 95.6 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 0.1913, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 0.2231, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 0.1137, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 0.1084, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 0.2452, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 0.1962, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 0.0780, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 0.3350, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 0.2190, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 0.2756, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 0.1866036057472229, accuracy: 94.5 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 0.19094103574752808, accuracy: 94.8 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 0.18286968767642975, accuracy: 94.9 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 0.18165744841098785, accuracy: 94.9 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 0.19260352849960327, accuracy: 94.3 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 0.17776836454868317, accuracy: 95.0 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 0.17728592455387115, accuracy: 95.0 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 0.17524142563343048, accuracy: 94.9 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 0.17517396807670593, accuracy: 94.8 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 0.173603355884552, accuracy: 95.1 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 0.1365, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 0.2278, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 0.1787, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 0.3684, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 0.2683, batch time: 0.06, accuracy:  93.75%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 0.1417, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 0.2076, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 0.3349, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 0.0964, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 0.2933, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 0.18799419701099396, accuracy: 94.2 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 0.1711178570985794, accuracy: 94.4 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 0.16386666893959045, accuracy: 94.5 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 0.20505021512508392, accuracy: 93.4 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 0.17738118767738342, accuracy: 93.9 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 0.1595282256603241, accuracy: 94.6 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 0.15846464037895203, accuracy: 94.5 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 0.15503905713558197, accuracy: 95.1 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 0.15389153361320496, accuracy: 94.7 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 0.15396827459335327, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 0.1102, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 0.1456, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 0.1587, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 0.2159, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 0.0705, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 0.1075, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 0.1996, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 0.1591, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 0.1876, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 0.2464, batch time: 0.08, accuracy:  92.97%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 0.17797937989234924, accuracy: 93.9 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 0.1943439245223999, accuracy: 93.0 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 0.17974242568016052, accuracy: 93.5 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 0.21387912333011627, accuracy: 92.2 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 0.16711485385894775, accuracy: 94.5 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 0.16362051665782928, accuracy: 94.4 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 0.16517336666584015, accuracy: 94.4 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 0.16290536522865295, accuracy: 94.5 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 0.1617756187915802, accuracy: 94.4 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 0.16240908205509186, accuracy: 95.1 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 0.1734, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 0.2513, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 0.2343, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 0.2017, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 0.1329, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 0.1548, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 0.2008, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 0.0838, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 0.1843, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 0.1326, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 0.1897478550672531, accuracy: 93.7 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 0.9965973496437073, accuracy: 69.6 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 0.17739616334438324, accuracy: 94.2 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 0.17580285668373108, accuracy: 93.9 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 0.1821446269750595, accuracy: 94.1 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 0.16620926558971405, accuracy: 94.6 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 0.16207093000411987, accuracy: 94.8 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 0.16106140613555908, accuracy: 95.0 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 0.15880538523197174, accuracy: 94.9 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 0.15788669884204865, accuracy: 94.9 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 0.1083, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 0.3133, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 0.1761, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 0.1931, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 0.1617, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 0.1461, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 0.2428, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 0.1887, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 0.2894, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 0.1384, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 0.18864011764526367, accuracy: 94.4 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 0.24350637197494507, accuracy: 92.7 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 0.26828309893608093, accuracy: 91.8 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 0.22398018836975098, accuracy: 93.5 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 0.17372827231884003, accuracy: 94.3 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 0.17029398679733276, accuracy: 94.6 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 0.17071443796157837, accuracy: 94.5 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 0.16754311323165894, accuracy: 94.9 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 0.17092697322368622, accuracy: 95.1 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 0.18103882670402527, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 0.2468, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 0.2837, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 0.1646, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 0.2034, batch time: 0.07, accuracy:  92.97%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 0.1434, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 0.1450, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 0.1322, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 0.2652, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 0.0580, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 0.1746, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 0.18610502779483795, accuracy: 93.3 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 0.19379575550556183, accuracy: 93.6 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 0.17571529746055603, accuracy: 93.9 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 0.17554263770580292, accuracy: 93.8 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 0.18299569189548492, accuracy: 93.0 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 0.1857086718082428, accuracy: 93.0 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 0.16239938139915466, accuracy: 93.7 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 0.15984021127223969, accuracy: 93.8 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 0.15878404676914215, accuracy: 94.0 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 0.15951453149318695, accuracy: 93.9 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 0.2608, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 0.0959, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 0.0887, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 0.2010, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 0.1653, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 0.2628, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 0.1912, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 0.1120, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 0.1431, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 0.1607, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 0.17890271544456482, accuracy: 95.1 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 0.18403127789497375, accuracy: 95.0 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 0.17061114311218262, accuracy: 95.3 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 0.16881589591503143, accuracy: 95.7 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 0.18376979231834412, accuracy: 94.4 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 0.17601367831230164, accuracy: 95.3 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 0.2196633517742157, accuracy: 93.6 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 0.15978112816810608, accuracy: 95.4 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 0.1586441844701767, accuracy: 95.6 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 0.15924328565597534, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 0.1887, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 0.2741, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 0.1251, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 0.2310, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 0.2283, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 0.1428, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 0.2462, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 0.2688, batch time: 0.32, accuracy:  92.19%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 0.1585, batch time: 0.09, accuracy:  96.09%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 0.1527, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 0.17036844789981842, accuracy: 95.5 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 1.2792426347732544, accuracy: 74.0 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 0.15163679420948029, accuracy: 95.4 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 0.15115930140018463, accuracy: 95.6 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 0.17962440848350525, accuracy: 94.7 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 0.16290472447872162, accuracy: 94.4 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 0.1775495707988739, accuracy: 94.5 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 0.16973601281642914, accuracy: 95.0 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 0.20526452362537384, accuracy: 93.8 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 0.1628742516040802, accuracy: 94.3 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 0.1318, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 0.1955, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 0.1332, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 0.2514, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 0.1442, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 0.1200, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 0.0981, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 0.1175, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 0.1357, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 0.1582, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 0.182136669754982, accuracy: 95.3 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 0.18695813417434692, accuracy: 95.2 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 0.16999511420726776, accuracy: 94.4 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 0.1673695147037506, accuracy: 94.8 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 0.17692983150482178, accuracy: 94.8 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 0.21311651170253754, accuracy: 94.1 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 0.16263845562934875, accuracy: 95.4 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 0.16255570948123932, accuracy: 95.8 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 0.16168218851089478, accuracy: 95.9 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 0.1607525795698166, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 0.1824, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 0.2656, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 0.2000, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 0.3678, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 0.1241, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 0.2359, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 0.1924, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 0.1230, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 0.1889, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 0.2911, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 0.13427595794200897, accuracy: 95.4 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 0.8683717250823975, accuracy: 80.4 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 4.221089839935303, accuracy: 34.3 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 0.12561777234077454, accuracy: 96.2 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 0.12395606935024261, accuracy: 96.0 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 0.12973828613758087, accuracy: 95.5 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 0.19274207949638367, accuracy: 93.1 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 0.12129294127225876, accuracy: 96.4 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 0.21363086998462677, accuracy: 92.5 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 0.11623496562242508, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 0.2035, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 0.1658, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 0.0928, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 0.1900, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 0.2971, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 0.1521, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 0.1744, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 0.1799, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 0.1714, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 0.2249, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 0.1653091460466385, accuracy: 94.6 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 1.3004426956176758, accuracy: 72.2 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 0.1589217185974121, accuracy: 94.7 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 0.15719027817249298, accuracy: 95.0 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 0.18855305016040802, accuracy: 93.7 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 0.19770902395248413, accuracy: 92.7 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 0.20385512709617615, accuracy: 93.9 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 0.1469419300556183, accuracy: 95.4 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 0.14744873344898224, accuracy: 95.4 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 0.14870615303516388, accuracy: 94.9 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 0.2017, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 0.1758, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 0.2799, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 0.2230, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 0.1697, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 0.1458, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 0.2148, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 0.2716, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 0.1594, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 0.2159, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 0.14155980944633484, accuracy: 96.0 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 0.6430993676185608, accuracy: 82.4 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 0.135234996676445, accuracy: 96.1 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 0.13396035134792328, accuracy: 96.3 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 0.13695918023586273, accuracy: 96.1 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 0.13278836011886597, accuracy: 96.4 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 0.13248753547668457, accuracy: 96.9 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 0.1301826536655426, accuracy: 97.0 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 0.13026541471481323, accuracy: 96.8 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 0.1292845755815506, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 0.1870, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 0.2282, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 0.1577, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 0.1681, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 0.2267, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 0.1915, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 0.3018, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 0.2436, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 0.1336, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 0.2035, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 0.1598678082227707, accuracy: 95.3 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 0.9162490367889404, accuracy: 76.2 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 0.4446164667606354, accuracy: 84.0 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 0.1459970325231552, accuracy: 94.8 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 0.15035516023635864, accuracy: 95.4 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 0.14157840609550476, accuracy: 95.4 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 0.14924392104148865, accuracy: 95.5 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 0.13970211148262024, accuracy: 95.5 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 0.13589878380298615, accuracy: 95.1 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 0.13563065230846405, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 0.2708, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 0.1319, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 0.1063, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 0.1412, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 0.2194, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 0.2412, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 0.2262, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 0.1498, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 0.1474, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 0.2988, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 0.1406954675912857, accuracy: 95.1 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 0.5025925636291504, accuracy: 84.7 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 0.13481682538986206, accuracy: 95.1 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 0.12836627662181854, accuracy: 95.3 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 0.13676436245441437, accuracy: 94.9 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 0.12666620314121246, accuracy: 95.5 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 0.12322873622179031, accuracy: 95.8 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 0.12207955121994019, accuracy: 96.0 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 0.1225181594491005, accuracy: 96.0 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 0.12092919647693634, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 0.1050, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 0.2126, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 0.1790, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 0.1282, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 0.1739, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 0.1104, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 0.1318, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 0.2465, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 0.1777, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 0.2451, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 0.1507352590560913, accuracy: 94.8 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 0.23299075663089752, accuracy: 91.8 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 0.15675024688243866, accuracy: 95.4 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 0.1636742800474167, accuracy: 94.9 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 0.15235495567321777, accuracy: 94.5 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 0.1382887214422226, accuracy: 95.5 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 0.13812822103500366, accuracy: 95.2 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 0.13844630122184753, accuracy: 95.7 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 0.13549117743968964, accuracy: 96.0 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 0.1338953822851181, accuracy: 95.7 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 0.1616, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 0.2775, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 0.2510, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 0.2214, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 0.0967, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 0.1674, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 0.2393, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 0.1306, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 0.1227, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 0.2344, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 0.18025720119476318, accuracy: 94.7 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 0.2690086364746094, accuracy: 92.2 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 0.18357433378696442, accuracy: 95.0 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 0.17035984992980957, accuracy: 95.2 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 0.17193478345870972, accuracy: 95.3 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 0.1671094447374344, accuracy: 95.6 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 0.17057199776172638, accuracy: 95.2 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 0.16676746308803558, accuracy: 95.8 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 0.16563813388347626, accuracy: 95.4 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 0.1673790067434311, accuracy: 95.6 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 0.3750, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 0.1013, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 0.1706, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 0.2798, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 0.1041, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 0.1500, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 0.2580, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 0.1938, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 0.1559, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 0.1444, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 0.19311736524105072, accuracy: 92.8 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 1.1119027137756348, accuracy: 74.9 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 0.20160691440105438, accuracy: 93.7 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 0.2206110656261444, accuracy: 91.2 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 0.1761195808649063, accuracy: 92.9 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 0.17821186780929565, accuracy: 93.0 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 0.17719583213329315, accuracy: 93.0 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 0.2069741040468216, accuracy: 92.8 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 0.2748241126537323, accuracy: 90.6 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 0.16993285715579987, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 0.1674, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 0.1565, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 0.3084, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 0.1637, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 0.1310, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 0.2102, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 0.1001, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 0.2692, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 0.1389, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 0.2002, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 0.14531388878822327, accuracy: 94.9 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 0.14654125273227692, accuracy: 95.4 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 0.14182637631893158, accuracy: 95.6 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 0.1390603631734848, accuracy: 95.7 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 0.1504983752965927, accuracy: 95.3 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 0.13733647763729095, accuracy: 96.0 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 0.1346232146024704, accuracy: 96.0 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 0.13215774297714233, accuracy: 96.1 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 0.13195279240608215, accuracy: 96.3 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 0.13070730865001678, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 0.1895, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 0.1961, batch time: 0.28, accuracy:  93.75%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 0.1348, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 0.3725, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 0.0730, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 0.1741, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 0.1762, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 0.1225, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 0.1899, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 0.0968, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 0.17009316384792328, accuracy: 94.8 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 1.188442587852478, accuracy: 76.6 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 0.16671524941921234, accuracy: 95.5 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 0.16589795053005219, accuracy: 95.3 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 0.20519210398197174, accuracy: 93.6 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 0.20486019551753998, accuracy: 93.3 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 0.15851344168186188, accuracy: 95.4 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 0.156678706407547, accuracy: 95.6 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 0.15424057841300964, accuracy: 95.7 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 0.15316276252269745, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 0.2624, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 0.2932, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 0.2003, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 0.1839, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 0.2134, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 0.2282, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 0.1777, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 0.1262, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 0.2823, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 0.1952, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 0.23563475906848907, accuracy: 92.7 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 0.94440096616745, accuracy: 80.0 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 0.22367845475673676, accuracy: 92.7 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 0.21469898521900177, accuracy: 93.2 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 0.21284450590610504, accuracy: 93.5 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 0.2085847407579422, accuracy: 93.6 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 0.25128889083862305, accuracy: 92.5 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 0.18836337327957153, accuracy: 94.0 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 0.18616026639938354, accuracy: 94.5 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 0.1841563731431961, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 0.2378, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 0.0622, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 0.1413, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 0.0925, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 0.1728, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 0.2155, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 0.1792, batch time: 0.06, accuracy:  92.19%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 0.2069, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 0.1184, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 0.2328, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 0.15630477666854858, accuracy: 95.0 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 0.1712447702884674, accuracy: 94.6 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 0.14647138118743896, accuracy: 95.2 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 0.14359697699546814, accuracy: 95.4 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 0.1568240523338318, accuracy: 94.5 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 0.14352090656757355, accuracy: 95.7 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 0.14212584495544434, accuracy: 95.9 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 0.140361949801445, accuracy: 95.9 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 0.1397741436958313, accuracy: 95.9 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 0.1396697759628296, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 0.1220, batch time: 0.07, accuracy:  96.09%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 0.1787, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 0.1673, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 0.3274, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 0.1654, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 0.2411, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 0.1588, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 0.2828, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 0.1368, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 0.3402, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 0.18537820875644684, accuracy: 94.3 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 0.191635400056839, accuracy: 93.5 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 0.21742676198482513, accuracy: 93.4 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 0.19123367965221405, accuracy: 93.9 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 0.22034350037574768, accuracy: 93.0 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 0.17414462566375732, accuracy: 94.6 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 0.1742393523454666, accuracy: 94.9 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 0.1683860719203949, accuracy: 94.8 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 0.16604790091514587, accuracy: 95.1 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 0.16558679938316345, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 0.0907, batch time: 0.06, accuracy:  95.31%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 0.1275, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 0.1158, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 0.2864, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 0.2531, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 0.1910, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 0.2038, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 0.1144, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 0.1330, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 0.1951, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 0.1624249964952469, accuracy: 94.9 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 0.16685277223587036, accuracy: 94.7 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 0.1772678941488266, accuracy: 94.4 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 0.15805834531784058, accuracy: 95.2 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 0.155955508351326, accuracy: 95.3 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 0.17073757946491241, accuracy: 94.4 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 0.155069962143898, accuracy: 95.3 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 0.1542631983757019, accuracy: 94.9 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 0.15329644083976746, accuracy: 95.6 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 0.151944100856781, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 0.1973, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 0.1047, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 0.1709, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 0.1707, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 0.2148, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 0.1730, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 0.1714, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 0.2400, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 0.3291, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 0.1233, batch time: 0.09, accuracy:  93.75%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 0.149156853556633, accuracy: 95.0 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 0.1606888473033905, accuracy: 94.6 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 0.14485451579093933, accuracy: 94.9 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 0.14460276067256927, accuracy: 95.1 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 0.16821490228176117, accuracy: 93.9 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 0.1837034374475479, accuracy: 93.9 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 0.13970911502838135, accuracy: 95.1 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 0.14304693043231964, accuracy: 95.3 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 0.1357821375131607, accuracy: 95.3 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 0.13462556898593903, accuracy: 95.1 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 0.0943, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 0.1338, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 0.1219, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 0.1185, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 0.1580, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 0.1981, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 0.2050, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 0.2466, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 0.3169, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 0.1396, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 0.14743132889270782, accuracy: 95.2 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 0.16923372447490692, accuracy: 94.2 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 0.14665988087654114, accuracy: 95.2 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 0.14499227702617645, accuracy: 95.7 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 0.3233928084373474, accuracy: 89.4 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 0.17250123620033264, accuracy: 94.6 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 0.1466560959815979, accuracy: 95.4 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 0.14300857484340668, accuracy: 95.3 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 0.1431303322315216, accuracy: 95.4 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 0.13993169367313385, accuracy: 95.5 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 0.1151, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 0.2680, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 0.2026, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 0.2863, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 0.1160, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 0.1178, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 0.2134, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 0.1524, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 0.2863, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 0.1300, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 0.17263057827949524, accuracy: 94.1 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 0.19138377904891968, accuracy: 93.4 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 0.15957415103912354, accuracy: 95.4 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 0.15568366646766663, accuracy: 94.9 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 0.17721904814243317, accuracy: 94.9 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 0.15693986415863037, accuracy: 95.2 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 0.17224492132663727, accuracy: 94.3 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 0.1702454537153244, accuracy: 94.3 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 0.15226048231124878, accuracy: 95.3 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 0.14738458395004272, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 0.2549, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 0.2693, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 0.1913, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 0.1440, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 0.2159, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 0.2014, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 0.1366, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 0.2693, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 0.1520, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 0.1400, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 0.1479181945323944, accuracy: 94.8 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 0.16481895744800568, accuracy: 94.8 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 0.142753466963768, accuracy: 95.2 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 0.14198990166187286, accuracy: 95.1 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 0.17975668609142303, accuracy: 93.9 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 0.1412467360496521, accuracy: 95.2 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 0.13930344581604004, accuracy: 95.1 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 0.1414443999528885, accuracy: 95.3 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 0.13900695741176605, accuracy: 95.1 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 0.14039911329746246, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 0.1224, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 0.1045, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 0.1823, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 0.1605, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 0.0906, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 0.2391, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 0.0961, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 0.1576, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 0.2805, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 0.1550, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 0.15079104900360107, accuracy: 95.5 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 0.17481361329555511, accuracy: 94.2 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 0.14999541640281677, accuracy: 95.5 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 0.14442667365074158, accuracy: 95.8 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 0.15041080117225647, accuracy: 95.0 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 0.19838382303714752, accuracy: 93.3 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 0.13740096986293793, accuracy: 95.4 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 0.1379202902317047, accuracy: 95.4 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 0.13876140117645264, accuracy: 95.6 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 0.13603511452674866, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 0.3448, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 0.1383, batch time: 0.06, accuracy:  95.31%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 0.1888, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 0.1667, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 0.1757, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 0.1640, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 0.1421, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 0.1530, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 0.0997, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 0.4252, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 0.19078512489795685, accuracy: 93.6 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 0.19147062301635742, accuracy: 93.5 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 0.17626066505908966, accuracy: 94.6 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 0.17478370666503906, accuracy: 94.2 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 0.17937533557415009, accuracy: 94.5 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 0.1727709174156189, accuracy: 94.6 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 0.1652727872133255, accuracy: 94.4 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 0.1636403203010559, accuracy: 94.5 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 0.16401368379592896, accuracy: 94.7 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 0.16320952773094177, accuracy: 94.5 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 0.2608, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 0.2161, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 0.2549, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 0.2740, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 0.3294, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 0.1740, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 0.2700, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 0.1829, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 0.1245, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 0.2604, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 0.1530700922012329, accuracy: 94.5 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 0.15904434025287628, accuracy: 94.5 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 0.1308412104845047, accuracy: 95.5 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 0.1284223347902298, accuracy: 95.5 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 0.13979674875736237, accuracy: 94.9 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 0.13975350558757782, accuracy: 96.0 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 0.152055025100708, accuracy: 94.8 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 0.12519203126430511, accuracy: 95.5 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 0.1232694759964943, accuracy: 95.8 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 0.12715086340904236, accuracy: 95.6 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 0.1681, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 0.2423, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 0.2518, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 0.2052, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 0.1450, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 0.2106, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 0.2955, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 0.1688, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 0.1801, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 0.1271, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 0.14469751715660095, accuracy: 95.2 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 0.16599024832248688, accuracy: 95.1 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 0.15340055525302887, accuracy: 95.0 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 0.179659903049469, accuracy: 94.2 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 0.14213204383850098, accuracy: 95.8 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 0.15102489292621613, accuracy: 94.7 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 0.13338656723499298, accuracy: 95.7 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 0.1324625164270401, accuracy: 96.0 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 0.13259515166282654, accuracy: 95.7 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 0.13213501870632172, accuracy: 95.7 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 0.0664, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 0.1199, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 0.1684, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 0.2580, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 0.1534, batch time: 0.09, accuracy:  92.97%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 0.1330, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 0.0982, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 0.3536, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 0.2195, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 0.1134, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 0.17572322487831116, accuracy: 95.7 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 0.17250822484493256, accuracy: 95.8 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 0.16031061112880707, accuracy: 96.0 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 0.15856821835041046, accuracy: 96.0 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 0.17389531433582306, accuracy: 94.7 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 0.16571232676506042, accuracy: 95.4 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 0.17839811742305756, accuracy: 94.8 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 0.15206536650657654, accuracy: 95.8 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 0.15135356783866882, accuracy: 95.8 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 0.14964397251605988, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 0.1752, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 0.1711, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 0.0637, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 0.2080, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 0.2557, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 0.1051, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 0.1194, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 0.0881, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 0.2383, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 0.1323, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 0.21865491569042206, accuracy: 94.0 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 0.23709800839424133, accuracy: 92.8 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 0.22119803726673126, accuracy: 93.7 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 0.20925091207027435, accuracy: 94.4 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 0.21071191132068634, accuracy: 93.6 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 0.23525886237621307, accuracy: 92.4 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 0.2049696296453476, accuracy: 94.4 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 0.2646366059780121, accuracy: 91.6 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 0.1957387626171112, accuracy: 94.1 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 0.19438669085502625, accuracy: 94.1 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 0.1692, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 0.1791, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 0.1803, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 0.2752, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 0.2173, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 0.0956, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 0.1633, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 0.2903, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 0.1770, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 0.2125, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 0.1636105328798294, accuracy: 95.0 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 0.16934902966022491, accuracy: 95.1 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 0.16383656859397888, accuracy: 94.8 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 0.18301719427108765, accuracy: 93.6 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 0.15675289928913116, accuracy: 95.3 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 0.15574604272842407, accuracy: 95.4 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 0.1565280556678772, accuracy: 95.8 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 0.1577543020248413, accuracy: 94.7 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 0.15405875444412231, accuracy: 94.7 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 0.15524885058403015, accuracy: 95.5 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 0.2301, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 0.1406, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 0.0948, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 0.2110, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 0.1143, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 0.1139, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 0.1398, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 0.1755, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 0.1864, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 0.2306, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 0.14279092848300934, accuracy: 95.7 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 0.14233586192131042, accuracy: 95.2 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 0.13615216314792633, accuracy: 95.5 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 0.1238991916179657, accuracy: 96.3 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 0.12716740369796753, accuracy: 96.0 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 0.19487056136131287, accuracy: 93.0 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 0.12174034118652344, accuracy: 95.9 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 0.11540117859840393, accuracy: 96.1 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 0.11493954807519913, accuracy: 96.2 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 0.11470957100391388, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 0.2022, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 0.1805, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 0.1390, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 0.1606, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 0.2326, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 0.1848, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 0.1625, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 0.2572, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 0.1795, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 0.1861, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 0.14697983860969543, accuracy: 95.4 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 0.14469264447689056, accuracy: 95.8 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 0.1361560821533203, accuracy: 96.4 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 0.13385091722011566, accuracy: 96.3 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 0.15048059821128845, accuracy: 96.4 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 0.13414378464221954, accuracy: 95.9 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 0.1297842413187027, accuracy: 95.8 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 0.13099157810211182, accuracy: 95.8 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 0.12943533062934875, accuracy: 96.2 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 0.12862595915794373, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 0.2979, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 0.2683, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 0.2550, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 0.2751, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 0.0672, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 0.1652, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 0.1860, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 0.1354, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 0.1855, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 0.1107, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 0.15186840295791626, accuracy: 95.5 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 0.15506324172019958, accuracy: 95.5 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 0.1642078310251236, accuracy: 95.3 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 0.15893331170082092, accuracy: 95.1 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 0.16508381068706512, accuracy: 95.2 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 0.14440754055976868, accuracy: 95.7 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 0.14360427856445312, accuracy: 96.1 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 0.1463768184185028, accuracy: 95.5 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 0.1413627713918686, accuracy: 95.9 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 0.14080455899238586, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 0.1503, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 0.1036, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 0.1191, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 0.1901, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 0.0949, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 0.0760, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 0.2779, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 0.1222, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 0.2376, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 0.1477, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 0.14641162753105164, accuracy: 95.9 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 0.19417434930801392, accuracy: 93.6 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 0.13531117141246796, accuracy: 96.3 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 0.1341215968132019, accuracy: 96.3 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 0.1362326294183731, accuracy: 96.1 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 0.13221582770347595, accuracy: 96.5 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 0.13024720549583435, accuracy: 96.7 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 0.12920831143856049, accuracy: 96.4 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 0.12835481762886047, accuracy: 96.4 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 0.12803590297698975, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 0.1784, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 0.1742, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 0.1483, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 0.2744, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 0.1901, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 0.1286, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 0.2579, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 0.1732, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 0.1085, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 0.0620, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 0.17435050010681152, accuracy: 95.1 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 0.17990227043628693, accuracy: 94.4 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 0.18049055337905884, accuracy: 94.5 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 0.1903340220451355, accuracy: 94.6 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 0.21915587782859802, accuracy: 93.0 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 0.1618177890777588, accuracy: 94.9 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 0.15980705618858337, accuracy: 95.3 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 0.15762890875339508, accuracy: 94.9 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 0.1589081883430481, accuracy: 94.8 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 0.15704992413520813, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 0.1930, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 0.0827, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 0.1707, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 0.1630, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 0.1311, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 0.2339, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 0.1637, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 0.2141, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 0.1415, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 0.0777, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 0.163429394364357, accuracy: 94.9 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 3.0365586280822754, accuracy: 65.2 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 0.15534339845180511, accuracy: 95.5 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 0.15532751381397247, accuracy: 95.5 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 0.359861820936203, accuracy: 90.4 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 0.1481693834066391, accuracy: 95.5 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 0.1479092240333557, accuracy: 95.8 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 0.14271338284015656, accuracy: 95.9 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 0.14298009872436523, accuracy: 95.5 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 0.14242348074913025, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 0.0967, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 0.1579, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 0.2516, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 0.1021, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 0.1134, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 0.1819, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 0.1307, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 0.2331, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 0.1716, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 0.1181, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 0.1688007414340973, accuracy: 95.2 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 0.19406023621559143, accuracy: 94.0 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 0.1594882309436798, accuracy: 95.4 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 0.15942242741584778, accuracy: 95.4 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 0.1535211205482483, accuracy: 95.4 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 0.17314760386943817, accuracy: 94.6 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 0.16904738545417786, accuracy: 94.3 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 0.14596641063690186, accuracy: 95.9 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 0.1444728970527649, accuracy: 96.0 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 0.1430901288986206, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 0.1168, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 0.1737, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 0.0589, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 0.1674, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 0.1365, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 0.1507, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 0.1465, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 0.1376, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 0.1490, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 0.1912, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 0.18158642947673798, accuracy: 93.6 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 3.806267023086548, accuracy: 46.5 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 0.18471066653728485, accuracy: 94.0 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 0.170337975025177, accuracy: 94.0 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 0.17545408010482788, accuracy: 94.6 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 0.23684276640415192, accuracy: 92.4 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 0.16941241919994354, accuracy: 94.4 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 0.16610637307167053, accuracy: 94.4 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 0.165014386177063, accuracy: 94.0 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 0.16399835050106049, accuracy: 94.1 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 0.1407, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 0.1592, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 0.0766, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 0.1341, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 0.1323, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 0.1157, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 0.1370, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 0.1692, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 0.1484, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 0.3212, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 0.17158126831054688, accuracy: 94.9 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 0.17403748631477356, accuracy: 95.0 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 0.16540564596652985, accuracy: 95.0 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 0.1638365238904953, accuracy: 95.3 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 0.26764556765556335, accuracy: 92.0 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 0.1597091257572174, accuracy: 95.7 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 0.16325533390045166, accuracy: 95.3 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 0.15502722561359406, accuracy: 95.5 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 0.17046695947647095, accuracy: 94.4 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 0.15313388407230377, accuracy: 95.6 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 0.1899, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 0.1957, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 0.2076, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 0.3160, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 0.1693, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 0.1156, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 0.1162, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 0.1297, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 0.1758, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 0.1517, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 0.16925087571144104, accuracy: 95.0 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 1.3319941759109497, accuracy: 69.8 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 0.16538412868976593, accuracy: 95.1 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 0.16119341552257538, accuracy: 95.1 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 0.17350618541240692, accuracy: 94.9 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 0.21835219860076904, accuracy: 94.0 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 0.15534637868404388, accuracy: 95.2 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 0.1540636271238327, accuracy: 95.4 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 0.1523791402578354, accuracy: 95.5 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 0.15197992324829102, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 0.2728, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 0.1412, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 0.1471, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 0.2022, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 0.2083, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 0.1409, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 0.3495, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 0.1069, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 0.1190, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 0.2429, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 0.1633453667163849, accuracy: 94.5 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 0.17766280472278595, accuracy: 95.1 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 0.15372835099697113, accuracy: 95.0 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 0.20179994404315948, accuracy: 93.7 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 0.14937448501586914, accuracy: 95.2 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 0.14730265736579895, accuracy: 95.3 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 0.1566804200410843, accuracy: 94.8 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 0.1461835652589798, accuracy: 95.8 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 0.1442050337791443, accuracy: 95.7 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 0.144083172082901, accuracy: 95.7 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 0.1902, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 0.0958, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 0.1496, batch time: 0.06, accuracy:  94.53%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 0.1094, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 0.1521, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 0.1234, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 0.2796, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 0.2054, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 0.1832, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 0.3304, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 0.16038836538791656, accuracy: 95.7 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 0.17436139285564423, accuracy: 94.8 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 0.1580316722393036, accuracy: 95.7 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 0.18069913983345032, accuracy: 95.0 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 0.15151438117027283, accuracy: 95.5 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 0.14772053062915802, accuracy: 96.0 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 0.14733187854290009, accuracy: 95.9 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 0.14691931009292603, accuracy: 95.8 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 0.1436356008052826, accuracy: 95.7 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 0.14177966117858887, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 0.1660, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 0.2374, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 0.0896, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 0.0898, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 0.1933, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 0.2325, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 0.1690, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 0.2066, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 0.1001, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 0.2342, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 0.17780202627182007, accuracy: 95.1 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 0.19413943588733673, accuracy: 94.3 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 0.17481568455696106, accuracy: 95.1 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 0.1973801553249359, accuracy: 94.3 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 0.17133069038391113, accuracy: 95.0 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 0.17060507833957672, accuracy: 95.4 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 0.17096957564353943, accuracy: 95.2 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 0.17076817154884338, accuracy: 95.8 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 0.16921286284923553, accuracy: 95.1 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 0.1681540608406067, accuracy: 95.1 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 0.0980, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 0.2400, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 0.1934, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 0.2988, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 0.1461, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 0.1229, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 0.0876, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 0.0924, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 0.2087, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 0.1111, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 0.2130938619375229, accuracy: 93.9 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 0.47605788707733154, accuracy: 85.9 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 0.20085564255714417, accuracy: 94.5 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 0.1951567828655243, accuracy: 94.4 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 0.2039702981710434, accuracy: 94.6 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 0.18088848888874054, accuracy: 95.1 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 0.179962158203125, accuracy: 94.6 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 0.18026284873485565, accuracy: 95.0 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 0.20265868306159973, accuracy: 93.5 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 0.2360311895608902, accuracy: 93.2 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 0.2342, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 0.2147, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 0.1609, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 0.1223, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 0.0826, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 0.1234, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 0.1306, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 0.0887, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 0.1086, batch time: 0.07, accuracy:  96.09%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 0.1726, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 0.18633919954299927, accuracy: 94.1 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 0.2072327733039856, accuracy: 93.5 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 0.18537268042564392, accuracy: 94.3 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 0.1773139238357544, accuracy: 94.4 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 0.19017954170703888, accuracy: 93.3 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 0.18873503804206848, accuracy: 93.3 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 0.17031191289424896, accuracy: 94.4 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 0.17518065869808197, accuracy: 93.6 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 0.19229580461978912, accuracy: 94.0 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 0.17232996225357056, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 0.0882, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 0.3072, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 0.2512, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 0.1734, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 0.1522, batch time: 0.33, accuracy:  94.53%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 0.1312, batch time: 0.09, accuracy:  95.31%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 0.1546, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 0.2433, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 0.1687, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 0.1757, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 0.1345425397157669, accuracy: 95.9 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 0.1473465859889984, accuracy: 95.2 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 0.13827058672904968, accuracy: 95.6 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 0.1313389092683792, accuracy: 95.4 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 0.14414416253566742, accuracy: 95.2 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 0.17205794155597687, accuracy: 94.5 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 0.12385722249746323, accuracy: 96.0 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 0.12067433446645737, accuracy: 95.9 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 0.12040919810533524, accuracy: 95.6 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 0.11879478394985199, accuracy: 95.7 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 0.1464, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 0.1771, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 0.2002, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 0.2322, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 0.1062, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 0.1705, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 0.1903, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 0.1776, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 0.2431, batch time: 0.09, accuracy:  92.97%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 0.2292, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 0.15724940598011017, accuracy: 95.1 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 0.18357695639133453, accuracy: 94.0 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 0.15270020067691803, accuracy: 94.8 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 0.19271396100521088, accuracy: 94.0 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 0.143880695104599, accuracy: 95.9 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 0.14265203475952148, accuracy: 95.6 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 0.14333657920360565, accuracy: 96.2 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 0.14091333746910095, accuracy: 96.2 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 0.14033010601997375, accuracy: 96.0 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 0.14060856401920319, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 0.2547, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 0.1667, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 0.1663, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 0.0861, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 0.0694, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 0.2184, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 0.1405, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 0.1309, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 0.1388, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 0.1512, batch time: 0.08, accuracy:  96.09%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 0.1714918464422226, accuracy: 94.8 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 0.18251056969165802, accuracy: 94.6 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 0.16916221380233765, accuracy: 94.8 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 0.1659262478351593, accuracy: 95.1 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 0.21495404839515686, accuracy: 94.1 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 0.18238310515880585, accuracy: 94.0 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 0.24211789667606354, accuracy: 92.1 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 0.15608471632003784, accuracy: 95.4 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 0.15333569049835205, accuracy: 95.3 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 0.15252135694026947, accuracy: 95.5 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 0.2165, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 0.0918, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 0.1983, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 0.1316, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 0.1147, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 0.1011, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 0.1482, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 0.1505, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 0.2337, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 0.2238, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 0.1555750072002411, accuracy: 94.9 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 0.15833769738674164, accuracy: 95.2 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 0.16235846281051636, accuracy: 94.6 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 0.16936548054218292, accuracy: 94.8 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 0.1697179526090622, accuracy: 94.5 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 0.14225175976753235, accuracy: 95.5 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 0.14123304188251495, accuracy: 95.4 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 0.1403180956840515, accuracy: 95.3 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 0.13865014910697937, accuracy: 95.5 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 0.13878761231899261, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 0.1991, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 0.2064, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 0.1287, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 0.2441, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 0.1559, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 0.1867, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 0.1087, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 0.1522, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 0.2980, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 0.2214, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 0.15899302065372467, accuracy: 94.9 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 0.1745031476020813, accuracy: 94.5 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 0.15639516711235046, accuracy: 94.3 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 0.15207384526729584, accuracy: 95.2 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 0.14793138206005096, accuracy: 95.6 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 0.18737739324569702, accuracy: 94.4 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 0.1418764889240265, accuracy: 95.3 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 0.1387528032064438, accuracy: 95.8 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 0.13678918778896332, accuracy: 96.0 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 0.13576577603816986, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 0.0854, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 0.1452, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 0.2196, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 0.0803, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 0.1886, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 0.1442, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 0.1173, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 0.0699, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 0.2037, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 0.1397, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 0.21385672688484192, accuracy: 93.7 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 3.970001459121704, accuracy: 45.4 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 0.21243412792682648, accuracy: 93.3 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 0.19138982892036438, accuracy: 94.1 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 0.19914329051971436, accuracy: 94.3 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 0.17987914383411407, accuracy: 94.8 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 0.1816292703151703, accuracy: 94.6 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 0.1803995817899704, accuracy: 94.5 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 0.21492718160152435, accuracy: 93.2 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 0.19124488532543182, accuracy: 94.0 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 0.1462, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 0.1294, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 0.1420, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 0.1498, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 0.1482, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 0.2903, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 0.1770, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 0.1284, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 0.1824, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 0.2155, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 0.13779211044311523, accuracy: 94.9 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 0.1524871587753296, accuracy: 94.6 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 0.14712010324001312, accuracy: 95.2 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 0.13527192175388336, accuracy: 95.5 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 0.17127090692520142, accuracy: 94.6 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 0.14591354131698608, accuracy: 95.0 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 0.14133591949939728, accuracy: 94.6 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 0.12332021445035934, accuracy: 96.1 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 0.12257229536771774, accuracy: 96.0 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 0.12204878032207489, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 0.0908, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 0.1615, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 0.0717, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 0.1964, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 0.3020, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 0.1498, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 0.0867, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 0.1519, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 0.1305, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 0.1983, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 0.17256861925125122, accuracy: 93.9 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 0.19341722130775452, accuracy: 93.0 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 0.15672363340854645, accuracy: 94.4 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 0.14772067964076996, accuracy: 94.6 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 0.1468110829591751, accuracy: 94.6 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 0.1588204950094223, accuracy: 94.2 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 0.1661197990179062, accuracy: 93.9 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 0.14232055842876434, accuracy: 94.9 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 0.1406038999557495, accuracy: 95.1 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 0.1382443755865097, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 0.1250, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 0.1969, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 0.1580, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 0.1913, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 0.0829, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 0.2322, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 0.0704, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 0.2207, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 0.2049, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 0.1004, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 0.14058950543403625, accuracy: 95.0 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 0.16386394202709198, accuracy: 93.8 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 0.14549583196640015, accuracy: 94.7 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 0.17658731341362, accuracy: 94.2 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 0.13246552646160126, accuracy: 95.5 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 0.12978969514369965, accuracy: 95.5 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 0.13062241673469543, accuracy: 95.5 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 0.12948407232761383, accuracy: 95.5 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 0.13537684082984924, accuracy: 95.3 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 0.1278502643108368, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 0.2258, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 0.2255, batch time: 0.08, accuracy:  92.19%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 0.2000, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 0.1254, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 0.1063, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 0.1266, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 0.1671, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 0.1566, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 0.0765, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 0.0832, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 0.14217200875282288, accuracy: 95.7 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 0.15234464406967163, accuracy: 94.9 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 0.13460585474967957, accuracy: 95.6 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 0.1345217227935791, accuracy: 95.3 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 0.2731100916862488, accuracy: 90.2 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 0.12978407740592957, accuracy: 95.7 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 0.12801839411258698, accuracy: 95.9 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 0.1265832632780075, accuracy: 96.0 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 0.1252814680337906, accuracy: 95.9 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 0.1323103904724121, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 0.2245, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 0.2621, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 0.1450, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 0.1394, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 0.1354, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 0.2342, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 0.2410, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 0.1162, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 0.2429, batch time: 0.07, accuracy:  92.97%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 0.1862, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 0.14909447729587555, accuracy: 95.1 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 0.13639730215072632, accuracy: 95.3 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 0.1326771378517151, accuracy: 95.6 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 0.13208255171775818, accuracy: 95.7 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 0.17209355533123016, accuracy: 95.0 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 0.24080534279346466, accuracy: 93.1 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 0.12298678606748581, accuracy: 96.6 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 0.11927484720945358, accuracy: 96.7 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 0.12021287530660629, accuracy: 96.1 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 0.11809071898460388, accuracy: 96.4 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 0.1586, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 0.1868, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 0.1599, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 0.1315, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 0.0633, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 0.1543, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 0.1562, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 0.2456, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 0.2435, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 0.2307, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 0.13348320126533508, accuracy: 95.9 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 0.1456131935119629, accuracy: 95.2 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 0.1508316844701767, accuracy: 94.6 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 0.13240814208984375, accuracy: 95.8 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 0.12473584711551666, accuracy: 96.0 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 0.12362487614154816, accuracy: 96.1 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 0.12909436225891113, accuracy: 95.9 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 0.12343721091747284, accuracy: 96.2 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 0.12625344097614288, accuracy: 96.1 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 0.12188708782196045, accuracy: 95.7 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 0.2619, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 0.1626, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 0.2397, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 0.1332, batch time: 0.06, accuracy:  95.31%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 0.1949, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 0.2393, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 0.3804, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 0.1945, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 0.0963, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 0.2454, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 0.15101617574691772, accuracy: 95.1 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 5.258546829223633, accuracy: 27.5 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 0.1444539874792099, accuracy: 95.5 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 0.14267782866954803, accuracy: 95.6 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 0.14831990003585815, accuracy: 95.4 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 0.18879728019237518, accuracy: 93.5 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 0.15607468783855438, accuracy: 95.3 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 0.15531601011753082, accuracy: 95.6 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 0.13233691453933716, accuracy: 96.0 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 0.12946763634681702, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 0.1607, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 0.1583, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 0.2123, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 0.2090, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 0.2244, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 0.2115, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 0.2555, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 0.2049, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 0.2337, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 0.1878, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 0.1638108491897583, accuracy: 94.2 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 0.172391876578331, accuracy: 94.3 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 0.16238486766815186, accuracy: 94.4 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 0.15662269294261932, accuracy: 94.5 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 0.16705526411533356, accuracy: 93.8 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 0.22477151453495026, accuracy: 92.7 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 0.14869870245456696, accuracy: 95.0 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 0.1435289978981018, accuracy: 94.9 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 0.14173008501529694, accuracy: 95.1 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 0.13914023339748383, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 0.2028, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 0.2664, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 0.1646, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 0.1376, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 0.1416, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 0.1767, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 0.1166, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 0.0868, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 0.2805, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 0.2183, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 0.15060947835445404, accuracy: 95.5 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 0.17946231365203857, accuracy: 94.8 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 0.15740421414375305, accuracy: 95.1 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 0.1452905386686325, accuracy: 95.4 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 0.15725724399089813, accuracy: 94.9 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 0.16595512628555298, accuracy: 94.6 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 0.13936568796634674, accuracy: 95.4 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 0.13751456141471863, accuracy: 95.5 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 0.13690285384655, accuracy: 96.0 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 0.1399422585964203, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 0.1565, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 0.1765, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 0.2087, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 0.1966, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 0.2369, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 0.1775, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 0.1443, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 0.2276, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 0.2593, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 0.2008, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 0.1431017518043518, accuracy: 96.2 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 0.17032934725284576, accuracy: 95.7 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 0.16138015687465668, accuracy: 94.8 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 0.14043192565441132, accuracy: 96.2 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 0.14892001450061798, accuracy: 95.8 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 0.15318922698497772, accuracy: 95.7 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 0.1397992968559265, accuracy: 95.8 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 0.13557352125644684, accuracy: 96.0 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 0.13954301178455353, accuracy: 96.2 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 0.13694719970226288, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 0.1392, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 0.1967, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 0.1772, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 0.1955, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 0.2064, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 0.1628, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 0.1332, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 0.2255, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 0.1705, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 0.2621, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 0.15459299087524414, accuracy: 95.2 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 0.16471952199935913, accuracy: 94.8 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 0.15049216151237488, accuracy: 95.1 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 0.15007120370864868, accuracy: 95.5 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 0.14855338633060455, accuracy: 95.3 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 0.14738474786281586, accuracy: 95.1 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 0.16369777917861938, accuracy: 93.9 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 0.146238774061203, accuracy: 95.5 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 0.2443496137857437, accuracy: 91.5 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 0.45492392778396606, accuracy: 85.9 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 0.1593, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 0.0780, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 0.2042, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 0.2453, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 0.1401, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 0.1967, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 0.2133, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 0.1098, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 0.1674, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 0.1864, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 0.19995827972888947, accuracy: 94.3 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 0.20393671095371246, accuracy: 94.0 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 0.19810321927070618, accuracy: 94.5 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 0.19709201157093048, accuracy: 94.3 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 0.278333842754364, accuracy: 91.2 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 0.20227783918380737, accuracy: 94.7 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 0.22197820246219635, accuracy: 93.3 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 0.18928100168704987, accuracy: 94.4 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 0.1863124668598175, accuracy: 94.6 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 0.18637631833553314, accuracy: 94.5 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 0.1968, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 0.0838, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 0.1546, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 0.1166, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 0.1105, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 0.3530, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 0.1677, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 0.1303, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 0.1482, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 0.1319, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 0.178574338555336, accuracy: 93.7 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 5.769662380218506, accuracy: 32.2 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 0.16766509413719177, accuracy: 94.6 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 0.15883156657218933, accuracy: 94.3 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 0.2138582170009613, accuracy: 92.7 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 0.20693349838256836, accuracy: 93.0 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 0.24160508811473846, accuracy: 92.1 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 0.22337433695793152, accuracy: 92.0 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 0.2340109497308731, accuracy: 92.5 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 0.13979747891426086, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 0.1509, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 0.2379, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 0.1693, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 0.2279, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 0.2467, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 0.1367, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 0.2992, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 0.0758, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 0.0777, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 0.2172, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 0.18548963963985443, accuracy: 94.4 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 0.1920604109764099, accuracy: 94.2 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 0.17846189439296722, accuracy: 94.8 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 0.21707385778427124, accuracy: 93.2 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 0.16880983114242554, accuracy: 95.4 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 0.20051132142543793, accuracy: 93.8 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 0.18066862225532532, accuracy: 94.9 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 0.21101044118404388, accuracy: 93.2 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 0.16769224405288696, accuracy: 95.7 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 0.16844242811203003, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 0.1125, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 0.1628, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 0.2421, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 0.2771, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 0.1638, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 0.2580, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 0.1252, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 0.1561, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 0.2665, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 0.1504, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 0.18003767728805542, accuracy: 94.3 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 1.9223921298980713, accuracy: 60.1 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 0.1666490137577057, accuracy: 94.5 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 0.216338649392128, accuracy: 93.0 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 0.1887608915567398, accuracy: 93.9 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 0.15710361301898956, accuracy: 94.6 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 0.15090909600257874, accuracy: 94.8 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 0.14616727828979492, accuracy: 94.9 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 0.18607904016971588, accuracy: 94.2 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 0.1423816978931427, accuracy: 95.2 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 0.3475, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 0.0739, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 0.1999, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 0.1874, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 0.2586, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 0.2877, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 0.2260, batch time: 0.09, accuracy:  95.31%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 0.1337, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 0.1788, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 0.2060, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 0.14958994090557098, accuracy: 95.7 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 0.15518400073051453, accuracy: 95.3 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 0.15832966566085815, accuracy: 95.7 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 0.1551678627729416, accuracy: 95.1 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 0.16952179372310638, accuracy: 94.7 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 0.1340012401342392, accuracy: 95.8 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 0.13310925662517548, accuracy: 96.0 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 0.13183645904064178, accuracy: 96.0 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 0.13112646341323853, accuracy: 96.3 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 0.13087889552116394, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 0.2113, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 0.1939, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 0.1073, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 0.2050, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 0.2313, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 0.1920, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 0.1593, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 0.1630, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 0.1858, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 0.1477, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 0.1924392729997635, accuracy: 93.7 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 2.1542601585388184, accuracy: 56.9 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 0.18689078092575073, accuracy: 93.8 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 0.18073150515556335, accuracy: 94.2 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 0.17933714389801025, accuracy: 94.1 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 0.24559056758880615, accuracy: 93.3 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 0.1967952698469162, accuracy: 93.8 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 0.17193922400474548, accuracy: 94.6 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 0.16997863352298737, accuracy: 94.1 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 0.17204876244068146, accuracy: 94.4 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 0.2753, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 0.0808, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 0.2796, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 0.2787, batch time: 0.06, accuracy:  92.97%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 0.1966, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 0.2457, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 0.2091, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 0.1669, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 0.1847, batch time: 0.06, accuracy:  94.53%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 0.2163, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 0.18952292203903198, accuracy: 93.9 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 0.273982971906662, accuracy: 90.6 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 0.1979159414768219, accuracy: 93.4 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 0.18433883786201477, accuracy: 94.4 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 0.27570825815200806, accuracy: 91.3 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 0.2305235117673874, accuracy: 92.6 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 0.20877349376678467, accuracy: 93.1 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 0.17739541828632355, accuracy: 94.4 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 0.17732307314872742, accuracy: 94.5 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 0.17724260687828064, accuracy: 94.7 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 0.0606, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 0.1565, batch time: 0.07, accuracy:  95.31%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 0.1476, batch time: 0.07, accuracy:  96.88%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 0.2515, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 0.2064, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 0.2058, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 0.1258, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 0.1056, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 0.1724, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 0.0905, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 0.18056292831897736, accuracy: 95.3 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 1.8549706935882568, accuracy: 57.4 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 0.1678510159254074, accuracy: 95.3 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 0.16691802442073822, accuracy: 95.3 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 0.16590383648872375, accuracy: 95.6 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 0.23198255896568298, accuracy: 92.5 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 0.18394067883491516, accuracy: 94.9 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 0.1829148828983307, accuracy: 94.7 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 0.16417038440704346, accuracy: 95.1 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 0.15472474694252014, accuracy: 95.7 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 0.1158, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 0.2342, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 0.2581, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 0.1232, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 0.2194, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 0.2363, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 0.1385, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 0.1696, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 0.1297, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 0.2042, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 0.1595304012298584, accuracy: 94.6 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 0.15949998795986176, accuracy: 94.5 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 0.15717574954032898, accuracy: 95.1 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 0.1560821831226349, accuracy: 95.0 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 0.1600714921951294, accuracy: 94.9 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 0.18914134800434113, accuracy: 94.2 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 0.14716596901416779, accuracy: 95.7 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 0.14466488361358643, accuracy: 95.6 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 0.14354608952999115, accuracy: 95.8 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 0.14404471218585968, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 0.1720, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 0.1318, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 0.1874, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 0.1377, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 0.1370, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 0.1227, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 0.2184, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 0.1173, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 0.1693, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 0.2763, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 0.16103848814964294, accuracy: 95.5 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 0.16832542419433594, accuracy: 94.9 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 0.19692930579185486, accuracy: 93.9 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 0.1567377746105194, accuracy: 95.9 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 0.1459793895483017, accuracy: 96.3 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 0.14575475454330444, accuracy: 96.4 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 0.14423733949661255, accuracy: 96.1 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 0.14341263473033905, accuracy: 96.0 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 0.1429515928030014, accuracy: 95.8 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 0.14252205193042755, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 0.1063, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 0.1072, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 0.3034, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 0.1202, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 0.1465, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 0.1482, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 0.3028, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 0.1329, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 0.2303, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 0.2544, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 0.16119612753391266, accuracy: 95.5 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 26.774019241333008, accuracy: 21.3 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 0.16606250405311584, accuracy: 95.2 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 0.15657362341880798, accuracy: 95.2 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 0.1669209748506546, accuracy: 94.3 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 0.15151989459991455, accuracy: 95.3 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 0.15041767060756683, accuracy: 95.1 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 0.14926530420780182, accuracy: 95.7 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 0.15314249694347382, accuracy: 95.0 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 0.14759057760238647, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 0.1114, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 0.2831, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 0.2240, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 0.1475, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 0.2148, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 0.1642, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 0.1284, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 0.1211, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 0.1045, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 0.2268, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 0.20425420999526978, accuracy: 93.6 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 4.847183704376221, accuracy: 41.7 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 0.20190437138080597, accuracy: 93.6 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 0.2529178559780121, accuracy: 92.1 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 0.25713977217674255, accuracy: 92.0 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 0.217265784740448, accuracy: 93.5 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 2.1351144313812256, accuracy: 58.6 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 0.18326905369758606, accuracy: 94.9 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 0.17713244259357452, accuracy: 94.8 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 0.17536039650440216, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 0.2365, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 0.2115, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 0.2048, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 0.1502, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 0.2984, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 0.1379, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 0.1755, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 0.2104, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 0.1708, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 0.1408, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 0.15222524106502533, accuracy: 94.6 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 0.15289542078971863, accuracy: 94.6 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 0.1591038554906845, accuracy: 94.4 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 0.14799202978610992, accuracy: 95.0 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 0.17464253306388855, accuracy: 94.1 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 0.1421346217393875, accuracy: 95.0 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 0.1707058697938919, accuracy: 94.2 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 0.14348016679286957, accuracy: 95.2 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 0.14243341982364655, accuracy: 95.6 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 0.138802632689476, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 0.1486, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 0.1092, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 0.0879, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 0.2060, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 0.1360, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 0.2687, batch time: 0.08, accuracy:  92.97%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 0.0823, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 0.1874, batch time: 0.06, accuracy:  93.75%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 0.0971, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 0.1815, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 0.14551551640033722, accuracy: 95.5 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 0.1911955177783966, accuracy: 93.1 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 0.16022418439388275, accuracy: 94.9 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 0.140598326921463, accuracy: 95.3 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 0.1552790403366089, accuracy: 95.1 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 0.1353277564048767, accuracy: 95.9 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 0.13393856585025787, accuracy: 96.1 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 0.13281677663326263, accuracy: 95.9 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 0.13381153345108032, accuracy: 96.1 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 0.13341058790683746, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 0.2072, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 0.1755, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 0.1394, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 0.1768, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 0.1795, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 0.1436, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 0.2339, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 0.1263, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 0.2954, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 0.1423, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 0.16816002130508423, accuracy: 94.3 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 0.7201897501945496, accuracy: 79.7 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 0.1610255390405655, accuracy: 95.1 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 0.15923337638378143, accuracy: 95.3 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 0.1648448407649994, accuracy: 95.0 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 0.17560850083827972, accuracy: 94.5 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 0.16349469125270844, accuracy: 95.5 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 0.1556190848350525, accuracy: 94.9 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 0.15550151467323303, accuracy: 95.3 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 0.14868956804275513, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 0.1238, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 0.1221, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 0.2639, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 0.1464, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 0.1187, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 0.2871, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 0.2070, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 0.1429, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 0.2061, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 0.1605, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 0.1327378898859024, accuracy: 95.7 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 0.16148746013641357, accuracy: 94.6 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 0.15314167737960815, accuracy: 95.0 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 0.15401415526866913, accuracy: 95.1 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 0.1290408819913864, accuracy: 95.8 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 0.12742896378040314, accuracy: 95.7 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 0.12690240144729614, accuracy: 95.8 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 0.12575219571590424, accuracy: 95.8 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 0.12565560638904572, accuracy: 95.9 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 0.12539179623126984, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 0.1478, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 0.1295, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 0.1744, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 0.1817, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 0.1759, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 0.1697, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 0.1551, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 0.0887, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 0.2654, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 0.1544, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 0.13808363676071167, accuracy: 95.6 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 0.13070687651634216, accuracy: 96.3 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 0.1255394071340561, accuracy: 95.9 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 0.12553630769252777, accuracy: 95.9 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 0.15633206069469452, accuracy: 94.6 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 0.12102952599525452, accuracy: 95.9 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 0.1193452849984169, accuracy: 96.0 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 0.11913636326789856, accuracy: 96.1 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 0.1176891103386879, accuracy: 95.9 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 0.1180112212896347, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 0.2807, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 0.0913, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 0.2157, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 0.1868, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 0.2007, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 0.1292, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 0.1890, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 0.1797, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 0.2448, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 0.1628, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 0.15119101107120514, accuracy: 95.5 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 0.15414534509181976, accuracy: 95.0 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 0.1509704440832138, accuracy: 95.7 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 0.18201419711112976, accuracy: 94.3 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 0.14641325175762177, accuracy: 95.2 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 0.14228792488574982, accuracy: 95.5 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 0.14249613881111145, accuracy: 95.8 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 0.14315380156040192, accuracy: 95.8 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 0.1417723447084427, accuracy: 95.5 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 0.14265058934688568, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 0.2195, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 0.1458, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 0.1514, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 0.1893, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 0.0601, batch time: 0.06, accuracy:  99.22%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 0.1434, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 0.1682, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 0.2272, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 0.1201, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 0.1490, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 0.17776668071746826, accuracy: 93.9 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 0.1763627678155899, accuracy: 93.5 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 0.16959184408187866, accuracy: 94.3 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 0.16650407016277313, accuracy: 94.3 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 0.19001829624176025, accuracy: 93.5 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 0.23548060655593872, accuracy: 91.8 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 0.16875188052654266, accuracy: 94.6 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 0.18124163150787354, accuracy: 93.7 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 0.2723310887813568, accuracy: 91.3 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 0.1989583671092987, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 0.2324, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 0.1995, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 0.1829, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 0.1130, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 0.0983, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 0.2657, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 0.1853, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 0.2293, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 0.1295, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 0.2751, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 0.1512371003627777, accuracy: 94.8 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 0.16851919889450073, accuracy: 94.0 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 0.1493937373161316, accuracy: 94.7 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 0.14168445765972137, accuracy: 94.5 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 0.1539987027645111, accuracy: 94.8 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 0.6553115248680115, accuracy: 81.0 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 0.21132531762123108, accuracy: 92.3 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 0.1349729597568512, accuracy: 94.8 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 0.13565920293331146, accuracy: 95.5 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 0.13237938284873962, accuracy: 95.1 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 0.2149, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 0.1332, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 0.0939, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 0.2271, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 0.1110, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 0.1700, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 0.2993, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 0.0782, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 0.1510, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 0.1145, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 0.12129111588001251, accuracy: 96.1 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 0.13585074245929718, accuracy: 94.8 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 0.12531445920467377, accuracy: 95.7 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 0.11745964735746384, accuracy: 96.2 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 0.12281201034784317, accuracy: 95.6 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 0.10983740538358688, accuracy: 96.3 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 0.10812068730592728, accuracy: 96.4 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 0.10681796073913574, accuracy: 96.5 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 0.10569798946380615, accuracy: 96.5 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 0.10512745380401611, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 0.2667, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 0.2648, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 0.1229, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 0.2444, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 0.0903, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 0.1896, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 0.2528, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 0.1824, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 0.1765, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 0.1744, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 0.1152237057685852, accuracy: 96.6 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 0.18878643214702606, accuracy: 93.5 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 0.11721237748861313, accuracy: 96.0 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 0.15720629692077637, accuracy: 95.0 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 0.11500562727451324, accuracy: 95.8 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 0.12200253456830978, accuracy: 95.9 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 0.11334553360939026, accuracy: 96.4 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 0.11191864311695099, accuracy: 96.2 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 0.10842122882604599, accuracy: 96.9 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 0.11065787822008133, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 0.0783, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 0.1319, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 0.1216, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 0.1549, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 0.1247, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 0.1179, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 0.1463, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 0.1347, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 0.1324, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 0.1427, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 0.1491236388683319, accuracy: 95.6 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 0.15133759379386902, accuracy: 95.2 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 0.1634240448474884, accuracy: 94.6 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 0.14455080032348633, accuracy: 96.2 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 0.18196018040180206, accuracy: 93.8 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 0.13400834798812866, accuracy: 96.0 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 0.1331862360239029, accuracy: 95.8 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 0.13120917975902557, accuracy: 96.1 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 0.13318447768688202, accuracy: 95.6 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 0.13072368502616882, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 0.1399, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 0.2953, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 0.2443, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 0.1699, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 0.1411, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 0.0877, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 0.2062, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 0.1522, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 0.1370, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 0.0883, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 0.18189705908298492, accuracy: 94.8 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 1.6536810398101807, accuracy: 66.3 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 0.17280754446983337, accuracy: 95.2 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 0.17246784269809723, accuracy: 95.3 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 0.22942481935024261, accuracy: 92.9 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 0.20580965280532837, accuracy: 94.2 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 0.16638828814029694, accuracy: 95.2 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 0.17643381655216217, accuracy: 95.2 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 0.358172208070755, accuracy: 88.9 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 0.18087658286094666, accuracy: 94.2 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 0.2535, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 0.1194, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 0.1628, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 0.2339, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 0.1138, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 0.2266, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 0.1777, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 0.1761, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 0.2994, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 0.1422, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 0.1547868549823761, accuracy: 94.7 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 1.593428611755371, accuracy: 65.5 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 0.15821389853954315, accuracy: 94.4 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 0.15078644454479218, accuracy: 95.2 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 0.15200667083263397, accuracy: 94.7 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 0.1802135854959488, accuracy: 92.4 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 0.182423934340477, accuracy: 93.7 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 0.6137559413909912, accuracy: 84.7 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 0.137271448969841, accuracy: 95.5 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 0.13531510531902313, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 0.2734, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 0.2890, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 0.1212, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 0.2208, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 0.0993, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 0.1962, batch time: 0.07, accuracy:  92.97%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 0.1678, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 0.1315, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 0.2579, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 0.2209, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 0.1804286241531372, accuracy: 94.3 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 1.525860071182251, accuracy: 66.1 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 0.1644509881734848, accuracy: 94.4 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 0.1622459441423416, accuracy: 94.4 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 0.16011114418506622, accuracy: 94.4 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 0.22497332096099854, accuracy: 92.4 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 0.15544337034225464, accuracy: 94.7 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 0.1524774730205536, accuracy: 94.9 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 0.15194441378116608, accuracy: 95.0 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 0.15261484682559967, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 0.1504, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 0.1340, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 0.2388, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 0.1828, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 0.2127, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 0.1617, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 0.1472, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 0.1066, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 0.1969, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 0.0605, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 0.19053584337234497, accuracy: 93.5 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 4.135798931121826, accuracy: 47.0 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 0.173402801156044, accuracy: 94.5 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 0.1602175086736679, accuracy: 94.9 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 0.1588195413351059, accuracy: 95.0 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 0.1612389236688614, accuracy: 94.7 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 0.3323543965816498, accuracy: 89.4 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 0.1480729579925537, accuracy: 94.7 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 0.1582251936197281, accuracy: 94.9 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 0.17136628925800323, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 0.2668, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 0.1916, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 0.2935, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 0.1893, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 0.1545, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 0.0670, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 0.2057, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 0.2256, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 0.1200, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 0.1732, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 0.12260138988494873, accuracy: 96.1 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 0.13447852432727814, accuracy: 95.7 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 0.11866477131843567, accuracy: 95.8 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 0.11530902236700058, accuracy: 96.4 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 0.12395108491182327, accuracy: 96.1 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 0.20556026697158813, accuracy: 93.3 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 0.10692247003316879, accuracy: 96.8 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 0.10552424937486649, accuracy: 97.0 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 0.10570035129785538, accuracy: 96.8 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 0.10500690340995789, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 0.2117, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 0.2229, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 0.1789, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 0.1891, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 0.1184, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 0.2450, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 0.0725, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 0.1690, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 0.1258, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 0.2150, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 0.1279909461736679, accuracy: 95.7 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 0.14110736548900604, accuracy: 95.4 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 0.1276557296514511, accuracy: 96.0 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 0.1456488072872162, accuracy: 94.9 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 0.11470106244087219, accuracy: 96.6 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 0.11128892749547958, accuracy: 96.3 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 0.11119356751441956, accuracy: 96.8 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 0.11111683398485184, accuracy: 96.9 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 0.10783819109201431, accuracy: 96.8 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 0.10540718585252762, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 0.1120, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 0.2117, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 0.1754, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 0.1754, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 0.1586, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 0.1642, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 0.1337, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 0.1456, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 0.1484, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 0.1881, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 0.14108474552631378, accuracy: 96.4 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 0.14679013192653656, accuracy: 95.8 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 0.1557403951883316, accuracy: 95.1 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 0.14873948693275452, accuracy: 95.7 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 0.13772240281105042, accuracy: 96.4 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 0.13633780181407928, accuracy: 96.4 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 0.13629040122032166, accuracy: 96.2 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 0.13482683897018433, accuracy: 96.4 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 0.13487058877944946, accuracy: 96.4 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 0.13604764640331268, accuracy: 96.4 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 0.1057, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 0.1895, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 0.1164, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 0.1537, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 0.1619, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 0.0661, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 0.0611, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 0.2517, batch time: 0.09, accuracy:  92.97%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 0.1109, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 0.1496, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 0.18542525172233582, accuracy: 93.8 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 5.728399276733398, accuracy: 41.6 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 0.179087296128273, accuracy: 93.8 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 0.1763094812631607, accuracy: 94.4 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 0.18839189410209656, accuracy: 93.6 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 0.16398502886295319, accuracy: 94.3 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 0.165663942694664, accuracy: 94.3 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 0.17967073619365692, accuracy: 94.0 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 0.15960346162319183, accuracy: 94.7 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 0.15933647751808167, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 0.2066, batch time: 0.48, accuracy:  94.53%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 0.1784, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 0.2315, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 0.1396, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 0.2181, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 0.1345, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 0.1021, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 0.2142, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 0.1981, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 0.1197, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 0.16672667860984802, accuracy: 95.0 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 0.17107200622558594, accuracy: 94.7 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 0.1793702393770218, accuracy: 94.5 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 0.15454985201358795, accuracy: 94.9 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 0.15385712683200836, accuracy: 94.7 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 0.15395700931549072, accuracy: 95.6 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 0.16359002888202667, accuracy: 94.6 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 0.14448437094688416, accuracy: 95.8 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 0.14186348021030426, accuracy: 95.6 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 0.14055654406547546, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 0.1935, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 0.1917, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 0.1341, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 0.1449, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 0.1642, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 0.1403, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 0.1734, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 0.0712, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 0.1245, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 0.2194, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 0.16314823925495148, accuracy: 95.6 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 0.1597370207309723, accuracy: 95.6 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 0.15611205995082855, accuracy: 95.7 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 0.15326811373233795, accuracy: 95.8 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 0.15404069423675537, accuracy: 95.7 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 0.1511240452528, accuracy: 95.7 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 0.14933213591575623, accuracy: 96.0 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 0.15049801766872406, accuracy: 95.9 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 0.14729538559913635, accuracy: 95.8 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 0.14528632164001465, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 0.2568, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 0.2142, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 0.0970, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 0.1405, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 0.2718, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 0.2129, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 0.3047, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 0.0679, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 0.1677, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 0.2151, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 0.17657430469989777, accuracy: 95.0 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 0.17742609977722168, accuracy: 95.3 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 0.16564778983592987, accuracy: 95.2 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 0.16526639461517334, accuracy: 95.1 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 0.3030829131603241, accuracy: 90.5 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 0.16342318058013916, accuracy: 95.6 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 0.17251621186733246, accuracy: 94.6 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 0.21487000584602356, accuracy: 93.7 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 0.1505994349718094, accuracy: 95.6 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 0.1517041027545929, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 0.0979, batch time: 0.08, accuracy:  96.09%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 0.1828, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 0.1502, batch time: 0.08, accuracy:  96.09%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 0.1815, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 0.1766, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 0.1555, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 0.1698, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 0.1222, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 0.2026, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 0.1305, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 0.17516088485717773, accuracy: 93.8 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 1.0479377508163452, accuracy: 72.5 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 0.7113766670227051, accuracy: 82.1 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 0.14038318395614624, accuracy: 96.2 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 0.14618895947933197, accuracy: 95.4 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 0.13645625114440918, accuracy: 95.3 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 0.13801470398902893, accuracy: 95.6 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 0.1850721836090088, accuracy: 93.3 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 0.979810357093811, accuracy: 78.5 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 0.1289260983467102, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 0.2871, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 0.2601, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 0.1256, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 0.1324, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 0.2547, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 0.2187, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 0.1529, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 0.1487, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 0.1305, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 0.1603, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 0.12974010407924652, accuracy: 96.1 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 0.14408352971076965, accuracy: 95.4 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 0.12728561460971832, accuracy: 96.1 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 0.12698496878147125, accuracy: 96.4 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 2.075852155685425, accuracy: 63.1 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 0.12404115498065948, accuracy: 96.5 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 0.11885708570480347, accuracy: 96.7 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 0.11801370978355408, accuracy: 96.6 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 0.11749391257762909, accuracy: 96.5 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 0.11617258936166763, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 0.1625, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 0.1158, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 0.1565, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 0.1941, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 0.2035, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 0.1863, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 0.1160, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 0.1743, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 0.1456, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 0.2387, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 0.15920168161392212, accuracy: 95.1 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 0.1727631837129593, accuracy: 95.0 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 0.17931732535362244, accuracy: 94.2 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 0.25298598408699036, accuracy: 90.9 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 0.14351539313793182, accuracy: 95.7 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 0.14154431223869324, accuracy: 95.7 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 0.14142923057079315, accuracy: 95.9 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 0.14046348631381989, accuracy: 95.9 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 0.13893648982048035, accuracy: 96.0 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 0.14056213200092316, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 0.1774, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 0.3089, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 0.2175, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 0.0807, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 0.1444, batch time: 0.39, accuracy:  96.09%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 0.2045, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 0.2326, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 0.1306, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 0.1764, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 0.1743, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 0.15134292840957642, accuracy: 95.7 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 0.17329825460910797, accuracy: 94.4 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 0.15264466404914856, accuracy: 95.7 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 0.19359198212623596, accuracy: 93.9 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 0.1987035870552063, accuracy: 93.7 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 0.13422705233097076, accuracy: 96.3 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 0.14104551076889038, accuracy: 96.0 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 0.1308336853981018, accuracy: 96.6 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 0.12850049138069153, accuracy: 96.5 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 0.12909454107284546, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 0.1010, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 0.1831, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 0.2120, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 0.1654, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 0.1466, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 0.0849, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 0.0987, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 0.1707, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 0.1650, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 0.1112, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 0.1535196155309677, accuracy: 94.8 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 0.1569235622882843, accuracy: 94.7 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 0.15677975118160248, accuracy: 94.7 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 0.14405544102191925, accuracy: 95.4 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 0.15038694441318512, accuracy: 95.3 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 0.5927742123603821, accuracy: 82.6 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 0.1366329789161682, accuracy: 95.5 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 0.1356079876422882, accuracy: 95.4 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 0.13360954821109772, accuracy: 95.8 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 0.13354305922985077, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 0.0685, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 0.2015, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 0.1070, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 0.1464, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 0.1722, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 0.0968, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 0.1326, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 0.1148, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 0.1511, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 0.3125, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 0.16623102128505707, accuracy: 94.6 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 0.19784700870513916, accuracy: 94.1 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 0.22428852319717407, accuracy: 92.9 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 0.29210880398750305, accuracy: 90.5 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 0.15518371760845184, accuracy: 95.2 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 0.1522969752550125, accuracy: 94.8 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 0.15174520015716553, accuracy: 95.3 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 0.15072302520275116, accuracy: 95.4 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 0.15056097507476807, accuracy: 95.4 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 0.1497119963169098, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 0.1546, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 0.1956, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 0.2588, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 0.1233, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 0.1320, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 0.1174, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 0.1024, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 0.1656, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 0.1160, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 0.2031, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 0.1260392665863037, accuracy: 96.6 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 0.12774716317653656, accuracy: 96.2 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 0.12515053153038025, accuracy: 96.3 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 0.12268228828907013, accuracy: 97.1 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 0.19187436997890472, accuracy: 94.1 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 0.11911938339471817, accuracy: 96.7 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 0.11836320161819458, accuracy: 96.7 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 0.11810263991355896, accuracy: 97.1 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 0.11891382932662964, accuracy: 96.8 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 0.1205291748046875, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 0.1962, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 0.2506, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 0.1273, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 0.1842, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 0.2444, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 0.0531, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 0.1714, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 0.1699, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 0.0705, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 0.1367, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 0.15213917195796967, accuracy: 94.6 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 0.2809590995311737, accuracy: 91.7 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 0.18189184367656708, accuracy: 93.7 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 0.27777761220932007, accuracy: 91.4 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 0.14627057313919067, accuracy: 95.0 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 0.14698511362075806, accuracy: 95.2 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 0.1429024487733841, accuracy: 95.4 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 0.1431250125169754, accuracy: 95.1 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 0.14071214199066162, accuracy: 95.2 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 0.13971258699893951, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 0.1816, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 0.0791, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 0.2283, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 0.1882, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 0.1709, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 0.2379, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 0.1979, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 0.1767, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 0.1951, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 0.2309, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 0.18649189174175262, accuracy: 93.1 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 0.18977884948253632, accuracy: 93.0 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 0.1580863893032074, accuracy: 94.4 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 0.1525711715221405, accuracy: 94.0 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 0.15903563797473907, accuracy: 94.0 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 0.17906005680561066, accuracy: 93.4 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 0.1810179203748703, accuracy: 93.7 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 0.16784437000751495, accuracy: 94.3 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 0.14263711869716644, accuracy: 95.0 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 0.14065252244472504, accuracy: 95.2 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "loss_list_epoch = []\n",
    "acc_list_epoch = []\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0\n",
    "\n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter)\n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "\n",
    "            qnn_train_step += 1\n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\"\n",
    "                )\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA\n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(\n",
    "            qnn_minimize_loss,\n",
    "            init_param,\n",
    "            method=\"COBYLA\",\n",
    "            options={\"maxiter\": 1000, \"adaptive\": True},\n",
    "        )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0661898851394653, 0.7507606148719788, 0.5989087224006653, 0.633633017539978, 0.47166281938552856, 0.45886996388435364, 0.3921310603618622, 0.43734362721443176, 0.3284077048301697, 0.3622278869152069, 0.3930349349975586, 0.2391790896654129, 0.4402824342250824, 0.4895300269126892, 0.5134456753730774, 0.23342756927013397, 0.37748581171035767, 0.2686986029148102, 0.38695573806762695, 0.4229569733142853, 0.37711143493652344, 0.3873443305492401, 0.285991370677948, 0.22473512589931488, 0.2995794713497162, 0.23309828341007233, 0.188291534781456, 0.3217942714691162, 0.32730355858802795, 0.21776334941387177, 0.23653806746006012, 0.35574859380722046, 0.22746942937374115, 0.24879038333892822, 0.3430560529232025, 0.15242978930473328, 0.28499361872673035, 0.12260650098323822, 0.3241499364376068, 0.24210120737552643, 0.2335374802350998, 0.20256777107715607, 0.29862353205680847, 0.1429588794708252, 0.19770605862140656, 0.21229782700538635, 0.19824481010437012, 0.24238833785057068, 0.35887667536735535, 0.28507834672927856, 0.3104630410671234, 0.3254348635673523, 0.3332264721393585, 0.22860634326934814, 0.2372259944677353, 0.22202856838703156, 0.12587304413318634, 0.20335422456264496, 0.29378417134284973, 0.3053952753543854, 0.31603553891181946, 0.13491830229759216, 0.1651710420846939, 0.1755772978067398, 0.18752095103263855, 0.13652962446212769, 0.18022899329662323, 0.3029007315635681, 0.1335020810365677, 0.31183233857154846, 0.131211057305336, 0.14125050604343414, 0.25385814905166626, 0.30927109718322754, 0.14499302208423615, 0.19524750113487244, 0.25263795256614685, 0.26559168100357056, 0.2824394404888153, 0.3094813823699951, 0.09531668573617935, 0.27901023626327515, 0.23184993863105774, 0.15880882740020752, 0.19042609632015228, 0.11493010073900223, 0.3815709054470062, 0.2407032549381256, 0.41956236958503723, 0.12879101932048798, 0.14321795105934143, 0.2651348412036896, 0.27884629368782043, 0.18804670870304108, 0.23009561002254486, 0.2657542824745178, 0.12595520913600922, 0.1668274700641632, 0.2320403903722763, 0.2103032022714615, 0.18846721947193146, 0.1527233123779297, 0.3409702181816101, 0.1654050350189209, 0.1664094775915146, 0.10601488500833511, 0.12873785197734833, 0.31554147601127625, 0.11157263070344925, 0.15842808783054352, 0.1716243177652359, 0.4064013361930847, 0.0923776626586914, 0.27312642335891724, 0.1173044815659523, 0.24918583035469055, 0.2874618172645569, 0.23179058730602264, 0.20332685112953186, 0.3170498311519623, 0.18003375828266144, 0.152329683303833, 0.1438068300485611, 0.1648348867893219, 0.12943965196609497, 0.06070125102996826, 0.16605010628700256, 0.06541868299245834, 0.1663217842578888, 0.25814583897590637, 0.11046219617128372, 0.141012504696846, 0.20721326768398285, 0.18881432712078094, 0.09228844940662384, 0.1388685554265976, 0.0721491351723671, 0.21146883070468903, 0.20665763318538666, 0.19426748156547546, 0.22764699161052704, 0.12430571764707565, 0.33664819598197937, 0.21782851219177246, 0.18976466357707977, 0.11462096124887466, 0.10220924764871597, 0.13907815515995026, 0.129812091588974, 0.20648367702960968, 0.2031792253255844, 0.1450311839580536, 0.1414250284433365, 0.1788518726825714, 0.11587192863225937, 0.2600918710231781, 0.1733766794204712, 0.13300564885139465, 0.28470325469970703, 0.15254615247249603, 0.2128555327653885, 0.22093792259693146, 0.15391720831394196, 0.12025242298841476, 0.1513584703207016, 0.09386494010686874, 0.09818706661462784, 0.16307418048381805, 0.35088568925857544, 0.125337615609169, 0.1602546125650406, 0.0989963561296463, 0.2385602742433548, 0.22933079302310944, 0.2518118917942047, 0.2589997351169586, 0.12029057741165161, 0.13411369919776917, 0.2905847728252411, 0.2843552529811859, 0.18899501860141754, 0.11454851180315018, 0.2970588803291321, 0.07063852995634079, 0.09220466762781143, 0.21531888842582703, 0.14951011538505554, 0.10874245315790176, 0.17116330564022064, 0.2103566974401474, 0.05071137472987175, 0.19837185740470886, 0.10149697959423065, 0.20101824402809143, 0.1671048253774643, 0.3121104836463928, 0.15885531902313232, 0.12260203808546066, 0.10661868005990982, 0.1335342675447464]\n",
      "[66.07142857142857, 80.35714285714286, 81.25, 80.35714285714286, 84.82142857142857, 84.82142857142857, 89.28571428571429, 89.28571428571429, 90.17857142857143, 86.60714285714286, 89.28571428571429, 91.96428571428571, 84.82142857142857, 87.5, 87.5, 92.85714285714286, 88.39285714285714, 94.64285714285714, 89.28571428571429, 88.39285714285714, 89.28571428571429, 87.5, 89.28571428571429, 91.96428571428571, 87.5, 91.96428571428571, 92.85714285714286, 91.07142857142857, 88.39285714285714, 91.07142857142857, 93.75, 87.5, 93.75, 91.07142857142857, 89.28571428571429, 95.53571428571429, 88.39285714285714, 94.64285714285714, 89.28571428571429, 92.85714285714286, 91.96428571428571, 95.53571428571429, 88.39285714285714, 93.75, 92.85714285714286, 91.96428571428571, 93.75, 90.17857142857143, 91.07142857142857, 92.85714285714286, 92.85714285714286, 91.07142857142857, 91.96428571428571, 91.96428571428571, 90.17857142857143, 95.53571428571429, 96.42857142857143, 93.75, 95.53571428571429, 89.28571428571429, 91.07142857142857, 93.75, 93.75, 91.96428571428571, 94.64285714285714, 96.42857142857143, 93.75, 92.85714285714286, 97.32142857142857, 88.39285714285714, 97.32142857142857, 93.75, 93.75, 88.39285714285714, 95.53571428571429, 94.64285714285714, 93.75, 91.96428571428571, 91.96428571428571, 89.28571428571429, 97.32142857142857, 91.96428571428571, 91.07142857142857, 92.85714285714286, 94.64285714285714, 96.42857142857143, 91.07142857142857, 91.96428571428571, 89.28571428571429, 95.53571428571429, 93.75, 94.64285714285714, 91.96428571428571, 94.64285714285714, 93.75, 92.85714285714286, 94.64285714285714, 95.53571428571429, 92.85714285714286, 91.07142857142857, 92.85714285714286, 95.53571428571429, 90.17857142857143, 94.64285714285714, 96.42857142857143, 95.53571428571429, 94.64285714285714, 91.96428571428571, 95.53571428571429, 94.64285714285714, 93.75, 87.5, 97.32142857142857, 90.17857142857143, 96.42857142857143, 94.64285714285714, 92.85714285714286, 93.75, 96.42857142857143, 89.28571428571429, 96.42857142857143, 95.53571428571429, 93.75, 94.64285714285714, 96.42857142857143, 98.21428571428571, 95.53571428571429, 98.21428571428571, 94.64285714285714, 93.75, 97.32142857142857, 94.64285714285714, 92.85714285714286, 94.64285714285714, 99.10714285714286, 95.53571428571429, 97.32142857142857, 94.64285714285714, 92.85714285714286, 92.85714285714286, 93.75, 96.42857142857143, 89.28571428571429, 92.85714285714286, 94.64285714285714, 97.32142857142857, 95.53571428571429, 94.64285714285714, 96.42857142857143, 93.75, 93.75, 94.64285714285714, 97.32142857142857, 97.32142857142857, 94.64285714285714, 92.85714285714286, 94.64285714285714, 93.75, 89.28571428571429, 96.42857142857143, 93.75, 94.64285714285714, 94.64285714285714, 97.32142857142857, 96.42857142857143, 96.42857142857143, 97.32142857142857, 96.42857142857143, 88.39285714285714, 94.64285714285714, 94.64285714285714, 95.53571428571429, 94.64285714285714, 91.96428571428571, 92.85714285714286, 91.96428571428571, 95.53571428571429, 93.75, 92.85714285714286, 91.07142857142857, 92.85714285714286, 94.64285714285714, 90.17857142857143, 97.32142857142857, 96.42857142857143, 93.75, 92.85714285714286, 97.32142857142857, 92.85714285714286, 93.75, 100.0, 94.64285714285714, 97.32142857142857, 93.75, 95.53571428571429, 93.75, 93.75, 98.21428571428571, 96.42857142857143, 96.42857142857143]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [1.3870084285736084, 0.6991583704948425, 0.6557806134223938, 0.6003235578536987, 0.4904267191886902, 0.41167858242988586, 0.3621465563774109, 0.2956938147544861, 0.43345287442207336, 0.2028428018093109, 0.2948610782623291, 0.300305038690567, 0.30067354440689087, 0.44806796312332153, 0.32258230447769165, 0.2517075836658478, 0.48606351017951965, 0.4323854446411133, 0.23882059752941132, 0.26116013526916504, 0.17792776226997375, 0.35908937454223633, 0.3656379282474518, 0.347771018743515, 0.27548912167549133, 0.5449920892715454, 0.33069345355033875, 0.2408454269170761, 0.2740141749382019, 0.2577061951160431, 0.17333494126796722, 0.3343537747859955, 0.34670644998550415, 0.4432329833507538, 0.2004930078983307, 0.2610030770301819, 0.30592674016952515, 0.3676773011684418, 0.3216950595378876, 0.2602854073047638, 0.30373120307922363, 0.4010297954082489, 0.24727164208889008, 0.4820893406867981, 0.15849323570728302, 0.17714974284172058, 0.20941992104053497, 0.4296279847621918, 0.3523687422275543, 0.18873463571071625, 0.30125027894973755, 0.11929945647716522, 0.2122134268283844, 0.14934520423412323, 0.20107567310333252, 0.30135688185691833, 0.3170686364173889, 0.25368982553482056, 0.20887498557567596, 0.2094680219888687, 0.22645576298236847, 0.10948438197374344, 0.3722243010997772, 0.14579525589942932, 0.20733097195625305, 0.34446796774864197, 0.3051183819770813, 0.30597972869873047, 0.167926624417305, 0.2277422845363617, 0.14916954934597015, 0.16632536053657532, 0.22087298333644867, 0.17390814423561096, 0.20291768014431, 0.1430780589580536, 0.24173465371131897, 0.213233083486557, 0.16945837438106537, 0.28222039341926575, 0.15734899044036865, 0.1447068601846695, 0.10288884490728378, 0.2412315160036087, 0.22761334478855133, 0.2153642475605011, 0.20425991714000702, 0.37232306599617004, 0.16936935484409332, 0.19896166026592255, 0.14040164649486542, 0.23020575940608978, 0.16159901022911072, 0.21537823975086212, 0.20864827930927277, 0.22858257591724396, 0.17163433134555817, 0.1996825933456421, 0.20554618537425995, 0.10287745296955109, 0.3856341540813446, 0.10633138567209244, 0.3697875142097473, 0.11287257820367813, 0.15440426766872406, 0.11025888472795486, 0.27951738238334656, 0.18703998625278473, 0.19477017223834991, 0.15554924309253693, 0.15415477752685547, 0.1987999975681305, 0.14436228573322296, 0.09584732353687286, 0.3456529676914215, 0.12239094078540802, 0.16531240940093994, 0.17434993386268616, 0.16234467923641205, 0.18833966553211212, 0.21996548771858215, 0.16038548946380615, 0.1905326545238495, 0.17159004509449005, 0.3004598617553711, 0.24713429808616638, 0.1066448763012886, 0.2117924690246582, 0.32183220982551575, 0.2276122272014618, 0.3362005054950714, 0.21566522121429443, 0.11032409220933914, 0.1506928652524948, 0.16838417947292328, 0.11077571660280228, 0.235648050904274, 0.2582506239414215, 0.1513008028268814, 0.20685498416423798, 0.17755019664764404, 0.2051171064376831, 0.13045531511306763, 0.1713060438632965, 0.1703200787305832, 0.18530236184597015, 0.338411808013916, 0.2629712224006653, 0.24028684198856354, 0.2729059159755707, 0.3156414031982422, 0.19929447770118713, 0.2229912132024765, 0.30721238255500793, 0.11765925586223602, 0.21589818596839905, 0.0628092885017395, 0.15827476978302002, 0.1859511137008667, 0.15484951436519623, 0.11551111936569214, 0.28234562277793884, 0.1311696618795395, 0.16428972780704498, 0.16091859340667725, 0.2739619314670563, 0.11167754977941513, 0.1940009891986847, 0.14395901560783386, 0.14610286056995392, 0.11581405252218246, 0.17506812512874603, 0.1808168739080429, 0.30403855443000793, 0.14125928282737732, 0.19608470797538757, 0.19800910353660583, 0.14969025552272797, 0.08566897362470627, 0.16953733563423157, 0.3980105221271515, 0.16475877165794373, 0.16414079070091248, 0.12853166460990906, 0.2388945072889328, 0.11745438724756241, 0.08329419046640396, 0.13703204691410065, 0.1824786365032196, 0.21120509505271912, 0.3084655702114105, 0.29353779554367065, 0.12804535031318665, 0.2261459082365036, 0.19222593307495117, 0.34956076741218567, 0.15602755546569824, 0.21899846196174622, 0.11072198301553726, 0.20658540725708008]\n",
    "# acc_list_epoch_ = [53.57142857142857, 77.67857142857143, 78.57142857142857, 83.03571428571429, 88.39285714285714, 87.5, 87.5, 92.85714285714286, 87.5, 92.85714285714286, 91.96428571428571, 87.5, 91.07142857142857, 86.60714285714286, 91.96428571428571, 91.96428571428571, 85.71428571428571, 91.07142857142857, 91.96428571428571, 91.96428571428571, 92.85714285714286, 89.28571428571429, 87.5, 89.28571428571429, 92.85714285714286, 84.82142857142857, 90.17857142857143, 94.64285714285714, 92.85714285714286, 90.17857142857143, 95.53571428571429, 89.28571428571429, 89.28571428571429, 90.17857142857143, 97.32142857142857, 91.07142857142857, 91.07142857142857, 89.28571428571429, 92.85714285714286, 91.07142857142857, 93.75, 88.39285714285714, 91.07142857142857, 89.28571428571429, 95.53571428571429, 96.42857142857143, 91.96428571428571, 89.28571428571429, 92.85714285714286, 93.75, 90.17857142857143, 95.53571428571429, 92.85714285714286, 97.32142857142857, 93.75, 94.64285714285714, 91.07142857142857, 90.17857142857143, 94.64285714285714, 92.85714285714286, 94.64285714285714, 96.42857142857143, 87.5, 96.42857142857143, 91.07142857142857, 93.75, 91.07142857142857, 89.28571428571429, 92.85714285714286, 94.64285714285714, 92.85714285714286, 93.75, 94.64285714285714, 93.75, 92.85714285714286, 94.64285714285714, 91.96428571428571, 90.17857142857143, 94.64285714285714, 91.96428571428571, 96.42857142857143, 96.42857142857143, 96.42857142857143, 94.64285714285714, 90.17857142857143, 91.96428571428571, 93.75, 86.60714285714286, 91.07142857142857, 92.85714285714286, 97.32142857142857, 93.75, 96.42857142857143, 91.96428571428571, 91.07142857142857, 92.85714285714286, 96.42857142857143, 92.85714285714286, 91.96428571428571, 95.53571428571429, 87.5, 96.42857142857143, 92.85714285714286, 97.32142857142857, 95.53571428571429, 96.42857142857143, 94.64285714285714, 96.42857142857143, 94.64285714285714, 94.64285714285714, 92.85714285714286, 94.64285714285714, 91.96428571428571, 98.21428571428571, 92.85714285714286, 96.42857142857143, 96.42857142857143, 95.53571428571429, 93.75, 95.53571428571429, 91.96428571428571, 91.96428571428571, 92.85714285714286, 91.96428571428571, 92.85714285714286, 91.96428571428571, 97.32142857142857, 96.42857142857143, 89.28571428571429, 93.75, 92.85714285714286, 92.85714285714286, 95.53571428571429, 96.42857142857143, 95.53571428571429, 97.32142857142857, 91.07142857142857, 95.53571428571429, 94.64285714285714, 95.53571428571429, 94.64285714285714, 93.75, 96.42857142857143, 95.53571428571429, 94.64285714285714, 92.85714285714286, 92.85714285714286, 92.85714285714286, 93.75, 88.39285714285714, 91.07142857142857, 93.75, 91.07142857142857, 90.17857142857143, 95.53571428571429, 91.96428571428571, 99.10714285714286, 96.42857142857143, 92.85714285714286, 94.64285714285714, 96.42857142857143, 93.75, 95.53571428571429, 95.53571428571429, 97.32142857142857, 89.28571428571429, 96.42857142857143, 91.96428571428571, 92.85714285714286, 92.85714285714286, 96.42857142857143, 93.75, 93.75, 87.5, 97.32142857142857, 93.75, 96.42857142857143, 94.64285714285714, 97.32142857142857, 95.53571428571429, 88.39285714285714, 95.53571428571429, 93.75, 95.53571428571429, 91.96428571428571, 97.32142857142857, 97.32142857142857, 97.32142857142857, 94.64285714285714, 96.42857142857143, 91.96428571428571, 92.85714285714286, 95.53571428571429, 93.75, 95.53571428571429, 91.96428571428571, 94.64285714285714, 92.85714285714286, 93.75, 93.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 94.95%\n",
      "Loss on the train set: 0.15\n",
      "Accuracy on the test set: 93.17%\n",
      "Loss on the test set: 0.23\n",
      "Generalization error: 0.081270546\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
