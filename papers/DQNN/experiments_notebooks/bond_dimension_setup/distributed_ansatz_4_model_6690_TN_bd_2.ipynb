{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1637.5\" height=\"593.75\" viewBox=\"-30.0 0 1310.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.024377</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.56141</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.670284</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.161036</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.2968</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.77004</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.342048</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.58082</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.732373</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.116147</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.942431</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.815481</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.336928</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.095103</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.479936</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.024985</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.482692</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.211702</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.463422</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.183123</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.782928</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.178475</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.21048</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.880985</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.549281</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.391674</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.092691</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.497574</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.44773</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.823029</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.362676</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.795692</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.610538</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.491646</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.081221</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.156369</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.721998</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.825137</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.811312</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.720007</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.018222</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.80966</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.055709</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.637516</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.942535</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.11546</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.53409</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.163976</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.430415</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.785437</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.984279</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.562501</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.622224</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.241058</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.210455</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.208671</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.011658</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.083224</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.014819</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.801119</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.43196</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.959382</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.777198</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.034668</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.407572</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.066847</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.802543</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.920646</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.546407</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.231918</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.493027</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.193878</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.495213</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.431848</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.73081</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.965358</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.854667</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.184264</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.57127</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.487098</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.275252</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.930029</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.840151</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.57141</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.552813</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.497273</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.241208</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.060953</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.049703</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.166682</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.783036</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.997965</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.090343</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.878376</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.257798</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.786415</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25.0 L1240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,125.0 L1240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,175.0 L1240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,225.0 L1240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,275.0 L1240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,325.0 L1240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,375.0 L1240,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,425.0 L1240,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1250\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1250\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1250\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1250\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1250\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1250\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1250\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1250\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1250\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x798d6fdfb4f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m=9, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.88187</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.60543</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.195439</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.562017</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.805568</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.558219</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.276558</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.127375</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.379797</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.99375</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.124653</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.871787</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.218825</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.065024</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.350135</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.305968</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.69627</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.92815</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.640491</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.081343</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.228535</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.232711</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.20548</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.701325</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.970518</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.057633</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.462747</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.740141</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.495965</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.388511</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.627655</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.594772</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.936028</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.851611</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.785485</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.679068</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.341098</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.982223</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.259292</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.279262</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.311672</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.127283</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.414114</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.528951</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.061581</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.015711</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.169952</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.588805</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.922669</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.794811</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.829468</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.883835</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.022846</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.037628</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.017237</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.121025</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.468014</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.091543</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.830741</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.304075</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.377843</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.56955</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.058842</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.097308</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.692331</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.56748</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.611274</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.774343</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.185104</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.527161</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.621254</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.63523</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.284895</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.177215</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.05241</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x798d6fd14940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m=8, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        #     super(CNNModel, self).__init__()\n",
    "        #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "        #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "        #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "        #     self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "        # def forward(self, x):\n",
    "        #     x = self.pool(self.conv1(x))\n",
    "        #     x = self.pool(self.conv2(x))\n",
    "        #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        #     x = self.fc1(x)\n",
    "        #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 70.67%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    # class MappingModel(nn.Module):\n",
    "    #     def __init__(self, input_size, hidden_sizes, output_size):\n",
    "    #         super().__init__()\n",
    "    #         # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "    #         self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "    #         self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "    #         self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    #     def forward(self, X):\n",
    "    #         # Ensure the input tensor is the same type as the weights\n",
    "    #         X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "    #         # Input layer with ReLU activation\n",
    "    #         X = self.input_layer(X)\n",
    "\n",
    "    #         # Hidden layers with ReLU activation\n",
    "    #         for hidden in self.hidden_layers:\n",
    "    #             X = hidden(X)\n",
    "\n",
    "    #         # Output layer with linear activation\n",
    "    #         output = self.output_layer(X)\n",
    "    #         # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "    #         return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "        # self.MappingNetwork = self.MappingModel(n_qubit+1, [8], 1).to(device)\n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit + 1, output_dim=1, bond_dim=2)\n",
    "\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        # self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[\n",
    "            :108\n",
    "        ]  # nn.Parameter(q_delta * torch.randn(135)).to(device)\n",
    "        self.q_params_2 = qnn_parameters[108:]\n",
    "        device = x.device\n",
    "\n",
    "        res_1 = bs_1.run(parameters=self.q_params_1, samples=100000)\n",
    "        trans_res_1 = bs_1.translate_results(res=res_1)\n",
    "        trans_res_1 = trans_res_1 / torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)\n",
    "\n",
    "        res_2 = bs_2.run(parameters=self.q_params_2, samples=100000)\n",
    "        trans_res_2 = bs_2.translate_results(res=res_2)\n",
    "        trans_res_2 = trans_res_2 / torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)\n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(126 * 70, 1)\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[: len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  124\n",
      "# of trainable parameter in QNN model:  192\n",
      "# of trainable parameter in full model:  316\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108 + 84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\n",
    "    \"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters\n",
    ")\n",
    "print(\n",
    "    \"# of trainable parameter in full model: \",\n",
    "    num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.3032, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.2991, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.1349, batch time: 0.22, accuracy:  21.09%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.0478, batch time: 0.25, accuracy:  24.22%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 1.9297, batch time: 0.08, accuracy:  21.88%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 1.9887, batch time: 0.23, accuracy:  17.19%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 1.8824, batch time: 0.12, accuracy:  27.34%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 1.8590, batch time: 0.17, accuracy:  29.69%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 1.7339, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 1.7687, batch time: 0.21, accuracy:  32.03%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 1.694429636001587, accuracy: 37.0 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 1.6930514574050903, accuracy: 36.2 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 1.6884591579437256, accuracy: 38.5 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 1.65101158618927, accuracy: 40.1 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 1.645856499671936, accuracy: 41.6 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 1.7822582721710205, accuracy: 36.9 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 1.780051350593567, accuracy: 36.9 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 1.6263808012008667, accuracy: 44.0 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 1.6445341110229492, accuracy: 42.3 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 1.6108185052871704, accuracy: 41.9 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 1.3793, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 1.5960, batch time: 0.11, accuracy:  43.75%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 1.4247, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 1.3804, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 1.3615, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 1.4161, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 1.2882, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 1.2335, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 1.3312, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 1.2593, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 1.2910817861557007, accuracy: 54.5 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 1.3309876918792725, accuracy: 52.7 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 1.3102651834487915, accuracy: 54.9 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 1.2539277076721191, accuracy: 57.0 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 1.2972798347473145, accuracy: 55.0 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 1.6315546035766602, accuracy: 45.7 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 1.226211667060852, accuracy: 58.9 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 1.226152777671814, accuracy: 57.2 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 1.214167833328247, accuracy: 58.5 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 1.2092244625091553, accuracy: 58.3 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 1.0699, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 1.1857, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 1.2285, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 1.0493, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 1.1996, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 1.0963, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 1.1665, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 1.2415, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 1.1557, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 1.1861, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 1.143718957901001, accuracy: 59.7 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 1.1980072259902954, accuracy: 58.5 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 1.1591050624847412, accuracy: 60.4 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 1.0884685516357422, accuracy: 63.3 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 1.178494930267334, accuracy: 60.6 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 1.1719826459884644, accuracy: 62.0 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 1.1865458488464355, accuracy: 59.1 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 1.0614864826202393, accuracy: 64.6 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 1.0471516847610474, accuracy: 64.4 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 1.0405845642089844, accuracy: 65.5 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 1.1350, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 1.1768, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 1.2665, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 1.2289, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 1.1571, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 1.2034, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 1.0691, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 0.9526, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 1.1237, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 0.9265, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 0.9589443802833557, accuracy: 67.3 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 1.4675363302230835, accuracy: 48.9 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 1.1360470056533813, accuracy: 60.9 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 0.939217746257782, accuracy: 67.8 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 0.9422616362571716, accuracy: 66.1 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 0.9203699231147766, accuracy: 67.5 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 0.9181088209152222, accuracy: 67.9 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 0.9168444871902466, accuracy: 68.9 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 0.9148349761962891, accuracy: 66.7 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 0.9037147760391235, accuracy: 68.5 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 0.8791, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 1.0325, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 1.1091, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 1.0262, batch time: 0.04, accuracy:  68.75%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 0.9384, batch time: 0.10, accuracy:  73.44%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 0.8665, batch time: 0.10, accuracy:  75.78%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 1.1762, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 1.2529, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 1.1680, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 1.0061, batch time: 0.11, accuracy:  66.41%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 0.9875062108039856, accuracy: 67.9 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 1.2814240455627441, accuracy: 59.7 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 1.0222140550613403, accuracy: 65.4 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 1.0856618881225586, accuracy: 63.1 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 0.9382469654083252, accuracy: 67.3 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 0.9122752547264099, accuracy: 69.7 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 0.9087285399436951, accuracy: 69.4 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 0.9527104496955872, accuracy: 66.5 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 0.9014166593551636, accuracy: 69.8 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 0.8927782773971558, accuracy: 71.2 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 0.7762, batch time: 0.11, accuracy:  71.88%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 1.1315, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 1.0138, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 1.0301, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 1.0242, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 1.1073, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 0.9837, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 1.1431, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 1.1273, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 1.0050, batch time: 0.11, accuracy:  66.41%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 0.9252187013626099, accuracy: 69.3 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 1.7355589866638184, accuracy: 52.7 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 1.7490750551223755, accuracy: 53.0 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 1.1632897853851318, accuracy: 62.4 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 0.9159165620803833, accuracy: 70.2 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 0.9188311100006104, accuracy: 70.0 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 0.9425439238548279, accuracy: 69.4 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 0.9019866585731506, accuracy: 70.1 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 0.8979854583740234, accuracy: 70.8 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 0.8962777256965637, accuracy: 70.5 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 0.8876, batch time: 0.04, accuracy:  67.97%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 0.9817, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 0.9132, batch time: 0.10, accuracy:  70.31%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 0.9539, batch time: 0.11, accuracy:  66.41%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 1.0766, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 0.9115, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 0.7879, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 0.9745, batch time: 0.04, accuracy:  69.53%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 0.9196, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 0.7722, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 0.9046291708946228, accuracy: 69.5 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 1.6782026290893555, accuracy: 51.8 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 1.1063789129257202, accuracy: 64.8 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 3.6351468563079834, accuracy: 36.0 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 0.8973110914230347, accuracy: 70.7 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 0.9068676829338074, accuracy: 69.7 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 0.9392991662025452, accuracy: 69.1 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 0.884763240814209, accuracy: 72.5 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 0.9122509360313416, accuracy: 71.1 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 0.88614821434021, accuracy: 71.4 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 1.0225, batch time: 0.11, accuracy:  67.19%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 0.8792, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 0.7393, batch time: 0.10, accuracy:  74.22%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 0.9974, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 0.8150, batch time: 0.09, accuracy:  71.88%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 0.8028, batch time: 0.11, accuracy:  74.22%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 0.8250, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 0.7989, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 0.8493, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 0.8655, batch time: 0.04, accuracy:  72.66%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 0.9952042698860168, accuracy: 66.6 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 2.0504136085510254, accuracy: 46.2 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 1.8841853141784668, accuracy: 50.0 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 1.3644506931304932, accuracy: 55.7 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 1.0085649490356445, accuracy: 69.0 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 0.9948821067810059, accuracy: 67.4 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 0.9860174059867859, accuracy: 69.4 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 0.9920106530189514, accuracy: 67.7 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 0.9820478558540344, accuracy: 67.9 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 0.9841046929359436, accuracy: 67.6 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 0.8327, batch time: 0.05, accuracy:  72.66%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 0.9174, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 0.7725, batch time: 0.11, accuracy:  75.78%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 0.8580, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 0.8383, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 0.7413, batch time: 0.09, accuracy:  75.00%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 0.8888, batch time: 0.04, accuracy:  68.75%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 0.6438, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 0.8919, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 0.9319, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 0.8751293420791626, accuracy: 69.6 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 1.6184980869293213, accuracy: 52.1 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 1.0388426780700684, accuracy: 64.4 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 0.8381751775741577, accuracy: 71.0 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 0.855827271938324, accuracy: 71.1 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 0.824705958366394, accuracy: 71.7 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 0.8204250335693359, accuracy: 72.0 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 0.8304920792579651, accuracy: 71.7 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 0.824829638004303, accuracy: 71.0 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 0.8265476822853088, accuracy: 70.3 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 0.8827, batch time: 0.11, accuracy:  71.09%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 1.0579, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 0.6883, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 0.8033, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 0.7511, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 1.0222, batch time: 0.10, accuracy:  69.53%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 1.0074, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 0.7491, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 0.8321, batch time: 0.11, accuracy:  75.78%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 0.8975, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 0.816068708896637, accuracy: 73.7 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 1.408240795135498, accuracy: 54.6 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 2.368591785430908, accuracy: 47.0 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 1.093245029449463, accuracy: 64.7 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 0.7977952361106873, accuracy: 72.9 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 0.7960359454154968, accuracy: 73.5 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 0.8239150047302246, accuracy: 70.8 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 0.7887966632843018, accuracy: 73.5 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 0.7860229015350342, accuracy: 73.4 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 0.785042405128479, accuracy: 74.1 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 0.9499, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 0.7453, batch time: 0.11, accuracy:  72.66%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 0.8015, batch time: 0.10, accuracy:  74.22%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 0.9255, batch time: 0.08, accuracy:  69.53%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 0.9474, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 0.8309, batch time: 0.10, accuracy:  69.53%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 0.6609, batch time: 0.10, accuracy:  76.56%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 0.6841, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 0.6646, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 1.0374, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 0.9136418104171753, accuracy: 69.1 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 1.457742691040039, accuracy: 53.0 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 1.0094363689422607, accuracy: 65.2 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 1.5153270959854126, accuracy: 54.6 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 0.9902425408363342, accuracy: 66.5 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 1.060507893562317, accuracy: 66.1 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 0.880940318107605, accuracy: 71.0 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 0.866436779499054, accuracy: 71.7 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 0.8888387084007263, accuracy: 69.1 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 0.8636044859886169, accuracy: 72.2 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 1.0324, batch time: 0.05, accuracy:  71.88%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 0.8156, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 0.9243, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 0.8308, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 0.8218, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 0.9864, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 0.6743, batch time: 0.10, accuracy:  75.00%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 1.0218, batch time: 0.10, accuracy:  71.88%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 0.9531, batch time: 0.10, accuracy:  71.88%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 0.8892, batch time: 0.10, accuracy:  75.00%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 0.9238297939300537, accuracy: 70.8 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 1.567929744720459, accuracy: 55.7 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 0.9633602499961853, accuracy: 65.8 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 0.9880865812301636, accuracy: 67.2 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 0.9073787331581116, accuracy: 69.9 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 0.8839631080627441, accuracy: 71.0 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 0.8852927088737488, accuracy: 71.4 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 0.8891832232475281, accuracy: 71.1 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 0.889360785484314, accuracy: 70.2 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 0.8834326863288879, accuracy: 71.8 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 0.9601, batch time: 0.11, accuracy:  71.88%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 0.9302, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 0.9111, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 0.8081, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 0.8076, batch time: 0.04, accuracy:  71.88%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 0.8987, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 0.8271, batch time: 0.05, accuracy:  72.66%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 0.9187, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 0.8670, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 0.8590, batch time: 0.05, accuracy:  72.66%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 0.8222774863243103, accuracy: 71.2 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 0.8942327499389648, accuracy: 69.6 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 0.8122597932815552, accuracy: 71.1 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 0.7875882983207703, accuracy: 72.6 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 1.086685061454773, accuracy: 62.5 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 0.781097412109375, accuracy: 72.3 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 0.7785609364509583, accuracy: 72.5 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 0.7701579332351685, accuracy: 73.0 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 0.7669928669929504, accuracy: 73.5 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 0.7687483429908752, accuracy: 73.2 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 0.5951, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 0.7736, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 0.8412, batch time: 0.10, accuracy:  74.22%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 0.6196, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 0.9129, batch time: 0.11, accuracy:  70.31%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 0.8030, batch time: 0.10, accuracy:  75.00%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 0.8579, batch time: 0.10, accuracy:  67.97%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 0.9507, batch time: 0.11, accuracy:  69.53%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 0.9227, batch time: 0.10, accuracy:  71.88%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 0.7392, batch time: 0.11, accuracy:  75.78%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 0.8168928623199463, accuracy: 74.8 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 0.9237117767333984, accuracy: 72.4 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 0.8024571537971497, accuracy: 75.8 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 0.800582230091095, accuracy: 75.5 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 0.8671716451644897, accuracy: 72.1 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 1.0350492000579834, accuracy: 66.9 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 0.8329326510429382, accuracy: 73.6 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 0.7733847498893738, accuracy: 75.2 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 0.7700569033622742, accuracy: 74.9 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 0.7743028402328491, accuracy: 75.7 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 0.7075, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 0.7522, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 0.6367, batch time: 0.04, accuracy:  81.25%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 1.1068, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 0.6672, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 0.7626, batch time: 0.04, accuracy:  74.22%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 0.7783, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 0.8508, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 0.8268, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 0.9460, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 0.7845420241355896, accuracy: 75.2 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 0.856869101524353, accuracy: 72.1 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 0.8396250605583191, accuracy: 72.9 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 0.7617595195770264, accuracy: 77.0 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 0.847663402557373, accuracy: 71.2 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 0.745793342590332, accuracy: 77.0 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 0.7393510937690735, accuracy: 77.5 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 0.737771213054657, accuracy: 76.9 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 0.7274380326271057, accuracy: 77.4 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 0.7973308563232422, accuracy: 74.7 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 0.9219, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 0.9104, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 0.9704, batch time: 0.10, accuracy:  71.09%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 0.6696, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 0.8936, batch time: 0.11, accuracy:  71.09%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 0.7235, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 0.6838, batch time: 0.10, accuracy:  75.00%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 0.8685, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 0.6938, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 0.7045, batch time: 0.10, accuracy:  73.44%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 0.7535165548324585, accuracy: 75.6 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 1.2741625308990479, accuracy: 57.9 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 0.8538370132446289, accuracy: 71.6 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 0.8097113370895386, accuracy: 72.9 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 0.7535118460655212, accuracy: 75.4 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 0.7366369366645813, accuracy: 76.1 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 0.7534378170967102, accuracy: 76.8 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 0.7596344351768494, accuracy: 74.7 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 0.7457401156425476, accuracy: 75.8 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 0.7197479605674744, accuracy: 77.0 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 0.7230, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 0.6553, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 0.7310, batch time: 0.10, accuracy:  73.44%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 0.7130, batch time: 0.10, accuracy:  74.22%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 0.7802, batch time: 0.11, accuracy:  75.78%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 0.6301, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 0.7606, batch time: 0.04, accuracy:  73.44%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 0.7550, batch time: 0.04, accuracy:  77.34%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 0.6004, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 0.7174, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 0.8133103251457214, accuracy: 74.7 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 0.8818864226341248, accuracy: 71.7 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 0.7992055416107178, accuracy: 76.1 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 0.774890661239624, accuracy: 76.8 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 1.3074356317520142, accuracy: 61.7 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 0.7714930176734924, accuracy: 76.8 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 0.7222658395767212, accuracy: 78.3 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 0.720900297164917, accuracy: 78.5 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 0.7212768793106079, accuracy: 77.9 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 0.7257628440856934, accuracy: 78.5 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 0.8638, batch time: 0.10, accuracy:  73.44%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 0.6276, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 0.6917, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 0.7502, batch time: 0.11, accuracy:  74.22%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 0.9301, batch time: 0.11, accuracy:  71.88%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 0.7082, batch time: 0.05, accuracy:  72.66%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 0.6593, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 0.7547, batch time: 0.05, accuracy:  72.66%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 0.7088, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 0.5869, batch time: 0.08, accuracy:  84.38%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 0.754155695438385, accuracy: 76.9 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 1.3779582977294922, accuracy: 58.0 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 0.8890473246574402, accuracy: 71.3 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 0.8885056972503662, accuracy: 71.5 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 0.7447109222412109, accuracy: 77.0 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 0.7717936038970947, accuracy: 76.4 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 0.761115312576294, accuracy: 76.6 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 0.7285212278366089, accuracy: 77.8 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 0.7248787879943848, accuracy: 77.9 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 0.7247777581214905, accuracy: 78.2 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 0.5716, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 0.7082, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 0.7617, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 0.5809, batch time: 0.04, accuracy:  82.03%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 0.8558, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 0.7637, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 0.7674, batch time: 0.04, accuracy:  77.34%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 0.6937, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 0.7442, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 0.9161, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 0.7351627945899963, accuracy: 78.5 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 1.1222680807113647, accuracy: 63.1 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 1.1802860498428345, accuracy: 67.3 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 0.7951781749725342, accuracy: 73.8 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 0.7534423470497131, accuracy: 77.8 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 0.7184725999832153, accuracy: 78.2 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 0.7242216467857361, accuracy: 78.4 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 0.7331215143203735, accuracy: 77.0 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 0.7268843650817871, accuracy: 77.5 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 0.7558248043060303, accuracy: 75.3 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 0.6293, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 0.6904, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 0.8658, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 0.9480, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 0.7478, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 0.9263, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 0.6965, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 0.6160, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 0.7588, batch time: 0.04, accuracy:  72.66%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 0.4974, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 0.6822591423988342, accuracy: 77.8 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 1.4036511182785034, accuracy: 54.8 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 1.2354477643966675, accuracy: 67.7 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 1.1709885597229004, accuracy: 60.5 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 0.6708714365959167, accuracy: 77.9 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 0.6688893437385559, accuracy: 78.4 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 0.687175989151001, accuracy: 77.1 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 0.6771158576011658, accuracy: 76.4 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 0.7775234580039978, accuracy: 75.8 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 0.6618905067443848, accuracy: 78.2 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 0.5597, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 0.5776, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 0.7370, batch time: 0.10, accuracy:  74.22%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 0.8851, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 0.8072, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 0.6617, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 0.5471, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 0.8469, batch time: 0.10, accuracy:  75.00%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 0.7257, batch time: 0.10, accuracy:  73.44%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 0.7748, batch time: 0.10, accuracy:  75.78%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 0.6665635704994202, accuracy: 79.4 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 1.1431397199630737, accuracy: 61.2 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 0.7543227672576904, accuracy: 76.8 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 0.877761721611023, accuracy: 70.6 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 0.7015434503555298, accuracy: 79.1 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 0.6768252849578857, accuracy: 79.3 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 0.665901780128479, accuracy: 78.9 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 0.6488323211669922, accuracy: 80.3 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 0.648703396320343, accuracy: 80.0 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 0.6454896926879883, accuracy: 79.9 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 0.6100, batch time: 0.10, accuracy:  76.56%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 0.9033, batch time: 0.11, accuracy:  69.53%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 0.6057, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 0.6954, batch time: 0.11, accuracy:  77.34%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 0.8206, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 0.6963, batch time: 0.09, accuracy:  74.22%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 0.5410, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 0.6187, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 0.8275, batch time: 0.10, accuracy:  74.22%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 0.7650, batch time: 0.10, accuracy:  70.31%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 0.7236933708190918, accuracy: 77.7 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 1.284557819366455, accuracy: 58.6 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 1.1690080165863037, accuracy: 69.0 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 0.8435508608818054, accuracy: 74.4 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 0.7262837290763855, accuracy: 77.4 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 0.868013858795166, accuracy: 69.4 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 0.7120198607444763, accuracy: 78.4 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 0.788072407245636, accuracy: 74.0 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 0.7152470350265503, accuracy: 79.1 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 0.6901507377624512, accuracy: 79.6 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 0.6059, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 0.6301, batch time: 0.10, accuracy:  75.00%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 0.6534, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 0.6458, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 0.5608, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 0.6911, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 0.6355, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 0.8191, batch time: 0.04, accuracy:  75.78%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 0.7057, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 0.7276, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 0.7126659154891968, accuracy: 75.7 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 1.4254777431488037, accuracy: 55.6 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 1.1709580421447754, accuracy: 68.4 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 0.6769871711730957, accuracy: 78.4 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 0.6764599084854126, accuracy: 78.1 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 0.6753681302070618, accuracy: 78.0 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 0.7088494300842285, accuracy: 76.1 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 0.7110153436660767, accuracy: 76.7 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 0.6806674003601074, accuracy: 77.4 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 0.7355037927627563, accuracy: 75.8 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 0.7530, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 0.5622, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 0.5270, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 0.7791, batch time: 0.04, accuracy:  72.66%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 0.8276, batch time: 0.04, accuracy:  75.00%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 0.6849, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 0.6233, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 0.6497, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 0.7950, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 0.5493, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 0.6522307991981506, accuracy: 80.0 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 3.6014275550842285, accuracy: 38.4 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 1.2292518615722656, accuracy: 68.6 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 1.0288770198822021, accuracy: 71.5 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 0.6357877254486084, accuracy: 79.3 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 0.6602053046226501, accuracy: 78.3 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 0.6534518003463745, accuracy: 79.8 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 0.6213216781616211, accuracy: 80.0 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 0.6283599138259888, accuracy: 79.8 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 0.6206632852554321, accuracy: 80.2 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 0.6534, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 0.7216, batch time: 0.05, accuracy:  71.88%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 0.7371, batch time: 0.04, accuracy:  78.12%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 0.5972, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 0.8954, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 0.6642, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 0.6002, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 0.5198, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 0.7849, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 0.7449, batch time: 0.04, accuracy:  75.00%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 0.6613592505455017, accuracy: 78.5 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 1.2297089099884033, accuracy: 57.6 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 0.7495301365852356, accuracy: 75.2 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 0.9116706252098083, accuracy: 69.5 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 0.6631776094436646, accuracy: 77.1 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 0.6337526440620422, accuracy: 79.8 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 0.6362524032592773, accuracy: 80.1 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 0.6721718907356262, accuracy: 78.2 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 0.6433684229850769, accuracy: 79.8 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 0.6222977042198181, accuracy: 80.6 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 0.8067, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 0.5687, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 0.5625, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 0.9483, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 0.5099, batch time: 0.09, accuracy:  83.59%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 0.5942, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 0.6221, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 0.8510, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 0.5845, batch time: 0.04, accuracy:  80.47%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 0.5922, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 0.6460250616073608, accuracy: 79.7 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 3.35125994682312, accuracy: 42.1 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 1.215620994567871, accuracy: 69.0 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 1.1479789018630981, accuracy: 64.6 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 0.6652451157569885, accuracy: 78.9 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 0.7314594388008118, accuracy: 75.8 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 0.6698034405708313, accuracy: 77.2 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 0.6146050095558167, accuracy: 79.9 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 0.6485502123832703, accuracy: 77.7 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 0.6107431650161743, accuracy: 80.1 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 0.6787, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 0.6925, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 0.6423, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 0.6343, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 0.6682, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 0.5329, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 0.8520, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 0.6090, batch time: 0.11, accuracy:  78.12%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 0.5325, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 0.6987, batch time: 0.10, accuracy:  74.22%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 0.6562474966049194, accuracy: 78.9 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 1.5305646657943726, accuracy: 51.1 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 0.8333343863487244, accuracy: 72.5 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 0.9802781343460083, accuracy: 63.7 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 0.6299468278884888, accuracy: 80.9 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 0.6200516223907471, accuracy: 80.7 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 0.6201623678207397, accuracy: 80.6 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 0.6181825995445251, accuracy: 81.3 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 0.6161897778511047, accuracy: 80.8 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 0.6162202954292297, accuracy: 80.5 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 0.7050, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 0.6550, batch time: 0.10, accuracy:  76.56%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 0.6777, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 0.7126, batch time: 0.11, accuracy:  76.56%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 0.6265, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 0.7891, batch time: 0.11, accuracy:  78.12%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 0.6681, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 0.9304, batch time: 0.05, accuracy:  72.66%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 0.6010, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 0.5739, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 0.6493667960166931, accuracy: 79.8 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 0.9420041441917419, accuracy: 69.4 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 0.6469030380249023, accuracy: 80.9 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 0.6463809609413147, accuracy: 80.5 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 0.7014048099517822, accuracy: 78.7 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 0.6447014212608337, accuracy: 80.9 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 0.6463342905044556, accuracy: 80.0 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 0.6498240232467651, accuracy: 80.1 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 0.6387583613395691, accuracy: 80.4 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 0.6393055319786072, accuracy: 80.1 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 0.6438, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 0.6905, batch time: 0.06, accuracy:  78.91%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 0.7755, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 0.8656, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 0.6308, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 0.6612, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 0.6278, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 0.8198, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 0.7272, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 0.4827, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 0.5758822560310364, accuracy: 80.8 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 1.2358698844909668, accuracy: 59.1 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 0.6684485077857971, accuracy: 79.1 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 1.0689725875854492, accuracy: 65.9 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 0.7203108668327332, accuracy: 74.7 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 0.578244686126709, accuracy: 81.1 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 0.5741251111030579, accuracy: 81.2 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 0.5698550939559937, accuracy: 80.6 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 0.5583412647247314, accuracy: 81.7 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 0.556462287902832, accuracy: 82.3 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 0.7776, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 0.4813, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 0.7459, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 0.6134, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 0.6003, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 0.7000, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 0.7263, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 0.6164, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 0.5509, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 0.6712, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 0.6652166247367859, accuracy: 79.0 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 1.3568781614303589, accuracy: 56.1 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 0.688555896282196, accuracy: 78.2 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 0.7609474658966064, accuracy: 75.6 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 0.6697866320610046, accuracy: 79.6 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 0.6759036779403687, accuracy: 78.8 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 0.666273832321167, accuracy: 79.0 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 0.6718266606330872, accuracy: 78.9 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 0.6543725728988647, accuracy: 79.6 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 0.7188637852668762, accuracy: 76.7 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 0.6407, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 0.6249, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 0.7588, batch time: 0.04, accuracy:  77.34%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 0.6290, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 0.7815, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 0.8294, batch time: 0.07, accuracy:  75.78%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 0.6848, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 0.6141, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 0.7374, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 0.7174, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 0.6484233736991882, accuracy: 77.7 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 1.3618919849395752, accuracy: 59.7 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 0.6404051780700684, accuracy: 78.5 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 0.6355533599853516, accuracy: 78.6 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 0.8797522783279419, accuracy: 69.0 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 0.6316497325897217, accuracy: 78.4 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 0.6281622648239136, accuracy: 79.2 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 0.6134570240974426, accuracy: 79.5 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 0.6308858394622803, accuracy: 79.0 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 0.658486545085907, accuracy: 77.7 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 0.6110, batch time: 0.09, accuracy:  80.47%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 0.6289, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 0.5701, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 0.6738, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 0.4468, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 0.6049, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 0.7465, batch time: 0.10, accuracy:  76.56%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 0.7116, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 0.5708, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 0.5712, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 0.6071626543998718, accuracy: 79.8 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 0.9677168726921082, accuracy: 69.7 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 0.6064722537994385, accuracy: 80.3 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 1.0075522661209106, accuracy: 69.2 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 0.6010814905166626, accuracy: 80.2 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 0.5967608094215393, accuracy: 81.5 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 0.6064764857292175, accuracy: 80.0 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 0.5928301215171814, accuracy: 80.7 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 0.830157458782196, accuracy: 70.2 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 0.5826414823532104, accuracy: 80.9 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 0.7595, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 0.6417, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 0.6492, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 0.4717, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 0.5714, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 0.6856, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 0.5899, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 0.6325, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 0.7723, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 0.6488, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 0.6113813519477844, accuracy: 80.9 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 1.1126962900161743, accuracy: 63.3 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 1.0428345203399658, accuracy: 69.5 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 0.7245829701423645, accuracy: 77.6 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 0.6311472654342651, accuracy: 78.8 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 0.6084295511245728, accuracy: 80.0 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 0.5844970941543579, accuracy: 81.4 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 0.6071059107780457, accuracy: 80.4 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 0.6078494191169739, accuracy: 80.8 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 0.6013909578323364, accuracy: 80.3 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 0.6679, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 0.6601, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 0.6988, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 0.5449, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 0.7335, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 0.8086, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 0.5687, batch time: 0.04, accuracy:  82.03%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 0.7561, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 0.4826, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 0.8237, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 0.6297592520713806, accuracy: 79.6 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 0.8362293243408203, accuracy: 71.9 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 0.6293824911117554, accuracy: 79.2 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 0.6160373687744141, accuracy: 79.5 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 0.7358030676841736, accuracy: 74.9 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 0.6906548142433167, accuracy: 75.9 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 0.6117221117019653, accuracy: 80.9 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 0.5939218997955322, accuracy: 81.5 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 0.5932943224906921, accuracy: 81.8 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 0.5890107154846191, accuracy: 81.9 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 0.5602, batch time: 0.04, accuracy:  81.25%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 0.8100, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 0.5483, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 0.6149, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 0.7207, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 0.9044, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 0.5857, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 0.7205, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 0.6207, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 0.7024, batch time: 0.04, accuracy:  78.12%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 0.581296443939209, accuracy: 81.0 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 1.2647196054458618, accuracy: 58.4 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 0.7166555523872375, accuracy: 76.7 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 0.7405974268913269, accuracy: 75.7 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 0.5803363919258118, accuracy: 81.4 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 0.5578592419624329, accuracy: 82.8 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 0.5819725394248962, accuracy: 80.5 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 0.5545759201049805, accuracy: 83.1 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 0.5618110299110413, accuracy: 82.9 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 0.5564255714416504, accuracy: 82.0 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 0.4664, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 0.6540, batch time: 0.04, accuracy:  76.56%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 0.5863, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 0.6619, batch time: 0.04, accuracy:  75.78%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 0.5785, batch time: 0.04, accuracy:  82.03%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 0.6803, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 0.5833, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 0.7205, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 0.8434, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 0.6294, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 0.6976974010467529, accuracy: 77.6 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 1.1366597414016724, accuracy: 62.9 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 0.7801746129989624, accuracy: 75.0 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 0.6512818336486816, accuracy: 80.1 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 0.6381945610046387, accuracy: 80.4 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 0.6399892568588257, accuracy: 80.6 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 0.6370813846588135, accuracy: 81.0 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 0.6319490671157837, accuracy: 81.1 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 0.616871178150177, accuracy: 81.2 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 0.6527464389801025, accuracy: 79.8 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 0.7101, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 0.8953, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 0.6202, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 0.4531, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 0.6236, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 0.5702, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 0.7307, batch time: 0.05, accuracy:  71.88%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 0.5162, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 0.5452, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 0.9030, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 0.6507017016410828, accuracy: 79.7 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 1.3208096027374268, accuracy: 59.6 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 0.8294758200645447, accuracy: 74.0 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 0.8170998692512512, accuracy: 74.6 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 0.6650742292404175, accuracy: 78.5 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 0.6487188935279846, accuracy: 78.1 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 0.6437975168228149, accuracy: 79.0 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 0.6306985020637512, accuracy: 79.1 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 0.6305390000343323, accuracy: 79.5 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 0.6276288628578186, accuracy: 79.1 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 0.6984, batch time: 0.11, accuracy:  78.12%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 0.5166, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 0.5816, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 0.6501, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 0.5657, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 0.7306, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 0.8286, batch time: 0.04, accuracy:  73.44%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 0.5116, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 0.7747, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 0.7085, batch time: 0.04, accuracy:  74.22%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 0.6815213561058044, accuracy: 79.7 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 1.217107892036438, accuracy: 61.2 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 0.6813079714775085, accuracy: 79.6 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 0.6790767312049866, accuracy: 79.8 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 0.7728091478347778, accuracy: 74.6 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 0.6648803353309631, accuracy: 79.6 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 0.6661157011985779, accuracy: 79.5 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 0.6781495809555054, accuracy: 79.4 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 0.6655834317207336, accuracy: 79.3 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 0.7196096181869507, accuracy: 77.6 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 0.5844, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 0.5107, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 0.6438, batch time: 0.04, accuracy:  79.69%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 0.4683, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 0.5760, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 0.6439, batch time: 0.04, accuracy:  75.00%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 0.6019, batch time: 0.04, accuracy:  79.69%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 0.7727, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 0.4903, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 0.5716, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 0.6467788219451904, accuracy: 79.6 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 5.588230609893799, accuracy: 30.5 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 0.8089029788970947, accuracy: 76.4 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 1.5098137855529785, accuracy: 54.4 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 0.667868971824646, accuracy: 79.4 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 0.6781426668167114, accuracy: 78.2 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 0.6400575041770935, accuracy: 80.0 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 0.6382747888565063, accuracy: 80.3 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 0.6370376944541931, accuracy: 79.9 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 0.6415822505950928, accuracy: 79.6 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 0.5849, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 0.7506, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 0.7404, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 0.5898, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 0.7511, batch time: 0.11, accuracy:  75.00%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 0.6546, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 0.7626, batch time: 0.04, accuracy:  73.44%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 0.5439, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 0.5928, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 0.6684, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 0.5923126935958862, accuracy: 80.9 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 1.3136032819747925, accuracy: 61.7 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 0.5786803364753723, accuracy: 82.0 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 0.5785869359970093, accuracy: 82.0 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 0.6299505233764648, accuracy: 79.9 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 0.6604040861129761, accuracy: 78.7 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 0.6590825319290161, accuracy: 76.1 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 0.5676857233047485, accuracy: 82.3 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 0.5610666275024414, accuracy: 82.1 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 0.5687074065208435, accuracy: 82.2 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 0.7782, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 0.4945, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 0.6431, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 0.6029, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 0.5564, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 0.5379, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 0.7569, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 0.5154, batch time: 0.04, accuracy:  83.59%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 0.5400, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 0.5371, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 0.582923948764801, accuracy: 81.1 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 1.375588059425354, accuracy: 56.7 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 0.7483696937561035, accuracy: 73.7 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 0.9155614376068115, accuracy: 71.4 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 0.5889300107955933, accuracy: 80.9 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 0.6051715016365051, accuracy: 78.9 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 0.8568575978279114, accuracy: 72.0 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 0.562981367111206, accuracy: 81.5 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 0.5607450604438782, accuracy: 81.6 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 0.5601315498352051, accuracy: 82.3 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 0.5934, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 0.6896, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 0.7289, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 0.7877, batch time: 0.11, accuracy:  73.44%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 0.5370, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 0.5192, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 0.8374, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 0.5426, batch time: 0.11, accuracy:  78.12%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 0.6581, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 0.5905, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 0.5625933408737183, accuracy: 82.6 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 1.450918436050415, accuracy: 62.4 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 0.5610570907592773, accuracy: 81.3 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 2.1753714084625244, accuracy: 51.6 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 1.167236328125, accuracy: 65.2 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 0.5447216629981995, accuracy: 82.7 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 0.5566824078559875, accuracy: 82.2 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 0.5532869696617126, accuracy: 82.0 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 0.5530768632888794, accuracy: 82.1 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 0.5306214690208435, accuracy: 82.9 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 0.8497, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 0.6185, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 0.6552, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 0.5708, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 0.7130, batch time: 0.09, accuracy:  75.00%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 0.7207, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 0.7212, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 0.7611, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 0.6089, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 0.4349, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 0.5913022756576538, accuracy: 82.6 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 1.292937994003296, accuracy: 60.7 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 0.5900777578353882, accuracy: 82.9 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 0.5899487137794495, accuracy: 82.9 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 3.7391574382781982, accuracy: 31.8 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 0.5828406810760498, accuracy: 81.8 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 0.5979875326156616, accuracy: 80.6 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 0.6023016571998596, accuracy: 81.7 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 0.5903575420379639, accuracy: 81.1 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 0.6152321696281433, accuracy: 80.9 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 0.4824, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 0.4575, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 0.6916, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 0.6066, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 0.7579, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 0.7096, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 0.6671, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 0.5713, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 0.5073, batch time: 0.07, accuracy:  80.47%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 0.5463, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 0.645595133304596, accuracy: 79.3 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 4.3083343505859375, accuracy: 32.4 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 1.0477899312973022, accuracy: 69.5 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 1.1378839015960693, accuracy: 65.5 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 0.6334681510925293, accuracy: 79.9 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 0.6708670258522034, accuracy: 78.5 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 0.7149369716644287, accuracy: 76.2 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 0.6206031441688538, accuracy: 81.2 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 0.6171770691871643, accuracy: 80.9 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 0.6138220429420471, accuracy: 81.4 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 0.6067, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 0.7045, batch time: 0.11, accuracy:  75.00%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 0.4877, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 0.8245, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 0.7437, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 0.6321, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 0.4628, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 0.6944, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 0.5854, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 0.5394, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 0.5492090582847595, accuracy: 81.9 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 1.2734112739562988, accuracy: 59.9 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 0.712261974811554, accuracy: 75.7 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 0.7661116123199463, accuracy: 73.5 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 0.5704869627952576, accuracy: 80.2 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 0.574465274810791, accuracy: 80.2 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 0.5459269285202026, accuracy: 81.6 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 0.6091495752334595, accuracy: 78.2 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 0.6035800576210022, accuracy: 78.4 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 0.5683727264404297, accuracy: 79.9 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 0.7557, batch time: 0.11, accuracy:  76.56%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 0.6091, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 0.4801, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 0.7965, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 0.4801, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 0.4129, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 0.6511, batch time: 0.06, accuracy:  80.47%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 0.5017, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 0.4111, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 0.7810, batch time: 0.04, accuracy:  80.47%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 0.5781210660934448, accuracy: 81.8 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 1.1834955215454102, accuracy: 62.8 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 0.7138109803199768, accuracy: 78.5 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 0.7736018896102905, accuracy: 74.3 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 0.6039650440216064, accuracy: 80.6 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 0.5831834077835083, accuracy: 80.9 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 0.7080299258232117, accuracy: 77.2 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 0.6075756549835205, accuracy: 80.6 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 0.5984663367271423, accuracy: 80.8 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 0.553733229637146, accuracy: 81.6 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 0.5820, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 0.4322, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 0.5393, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 0.5892, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 0.5966, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 0.6242, batch time: 0.04, accuracy:  83.59%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 0.4512, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 0.5586, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 0.6203, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 0.5036, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 0.5524570345878601, accuracy: 82.0 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 1.2549914121627808, accuracy: 59.2 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 0.6219936013221741, accuracy: 79.2 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 0.9482285380363464, accuracy: 68.6 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 0.548109769821167, accuracy: 81.7 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 0.570943295955658, accuracy: 81.1 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 0.5921275615692139, accuracy: 80.7 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 0.5499831438064575, accuracy: 80.9 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 0.5354751348495483, accuracy: 81.1 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 0.5326783061027527, accuracy: 81.4 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 0.5561, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 0.5744, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 0.5176, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 0.6806, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 0.6266, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 0.5849, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 0.5389, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 0.5293, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 0.7136, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 0.4230, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 0.6092813611030579, accuracy: 80.2 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 1.5544220209121704, accuracy: 54.1 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 1.0859588384628296, accuracy: 63.5 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 0.7431734204292297, accuracy: 75.1 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 0.5669878721237183, accuracy: 82.5 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 0.5504705309867859, accuracy: 83.0 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 1.0329577922821045, accuracy: 67.4 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 0.5504170656204224, accuracy: 82.7 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 0.5893371105194092, accuracy: 81.3 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 0.5539833307266235, accuracy: 82.9 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 0.8274, batch time: 0.05, accuracy:  71.88%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 0.5309, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 0.5155, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 0.5165, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 0.5545, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 0.8259, batch time: 0.04, accuracy:  75.78%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 0.4756, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 0.5870, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 0.6038, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 0.6025, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 0.5657519102096558, accuracy: 81.1 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 1.495602011680603, accuracy: 53.6 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 1.2625070810317993, accuracy: 63.3 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 1.33211088180542, accuracy: 58.5 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 0.5397071242332458, accuracy: 81.7 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 0.5525368452072144, accuracy: 80.5 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 0.5361289381980896, accuracy: 81.4 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 0.5191838145256042, accuracy: 82.7 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 0.5071551203727722, accuracy: 83.0 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 0.5055017471313477, accuracy: 83.4 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 0.6892, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 0.4631, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 0.7309, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 0.4769, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 0.5461, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 0.6143, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 0.4591, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 0.7299, batch time: 0.11, accuracy:  77.34%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 0.6138, batch time: 0.11, accuracy:  78.12%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 0.5362, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 0.6602250337600708, accuracy: 80.2 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 1.8718914985656738, accuracy: 49.0 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 1.2215019464492798, accuracy: 63.0 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 0.9413206577301025, accuracy: 69.1 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 0.614014208316803, accuracy: 81.5 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 0.5986601114273071, accuracy: 81.9 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 0.6473143100738525, accuracy: 79.1 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 0.6072254776954651, accuracy: 81.5 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 1.1726642847061157, accuracy: 63.6 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 0.5889855623245239, accuracy: 82.2 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 0.5179, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 0.5073, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 0.6425, batch time: 0.11, accuracy:  76.56%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 0.5160, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 0.4341, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 0.5268, batch time: 0.23, accuracy:  82.03%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 0.7095, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 0.7020, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 0.4458, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 0.4915, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 0.668118417263031, accuracy: 79.1 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 2.2517805099487305, accuracy: 42.6 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 1.023305058479309, accuracy: 70.1 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 0.859977126121521, accuracy: 74.6 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 0.6140323877334595, accuracy: 79.8 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 0.6587648391723633, accuracy: 77.2 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 0.6233317852020264, accuracy: 80.2 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 0.5969635248184204, accuracy: 80.8 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 0.5951946973800659, accuracy: 81.2 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 0.5920186042785645, accuracy: 81.7 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 0.4994, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 0.6017, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 0.4540, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 0.6524, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 0.7172, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 0.6300, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 0.4634, batch time: 0.06, accuracy:  85.94%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 0.5471, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 0.6938, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 0.4742, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 0.6007810831069946, accuracy: 82.5 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 2.3503878116607666, accuracy: 44.9 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 1.208235740661621, accuracy: 65.1 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 0.7175374627113342, accuracy: 77.0 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 0.7461673617362976, accuracy: 76.7 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 0.5902178883552551, accuracy: 81.5 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 0.5882666707038879, accuracy: 82.4 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 0.5937981009483337, accuracy: 82.0 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 0.57680743932724, accuracy: 82.7 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 0.5747544169425964, accuracy: 82.8 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 0.5884, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 0.6311, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 0.5507, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 0.5163, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 0.6853, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 0.6457, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 0.6688, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 0.6711, batch time: 0.11, accuracy:  76.56%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 0.4133, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 0.6217, batch time: 0.04, accuracy:  83.59%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 0.5185394287109375, accuracy: 84.2 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 1.8136712312698364, accuracy: 47.4 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 0.7126044034957886, accuracy: 76.4 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 0.881594181060791, accuracy: 71.7 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 0.5388845801353455, accuracy: 83.9 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 0.5297078490257263, accuracy: 83.6 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 0.5376284718513489, accuracy: 84.4 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 0.5958210229873657, accuracy: 80.6 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 0.503665566444397, accuracy: 84.7 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 0.5031046271324158, accuracy: 84.4 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 0.6228, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 0.5148, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 0.6582, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 0.4794, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 0.8475, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 0.5746, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 0.6829, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 0.4822, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 0.3708, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 0.6635, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 0.5225538015365601, accuracy: 83.9 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 1.8355587720870972, accuracy: 47.1 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 0.9192966818809509, accuracy: 71.7 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 0.9017165899276733, accuracy: 71.3 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 0.5236066579818726, accuracy: 83.8 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 0.5231817364692688, accuracy: 83.9 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 0.5203322172164917, accuracy: 84.7 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 0.5739519596099854, accuracy: 80.7 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 0.5044851899147034, accuracy: 84.5 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 0.5044733285903931, accuracy: 84.9 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 0.6492, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 0.4568, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 0.4792, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 0.6412, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 0.6104, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 0.4477, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 0.4835, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 0.5261, batch time: 0.04, accuracy:  82.03%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 0.6116, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 0.5124, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 0.5930164456367493, accuracy: 81.4 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 2.020545721054077, accuracy: 44.5 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 1.1821740865707397, accuracy: 63.9 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 0.7069317102432251, accuracy: 79.4 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 0.5833591222763062, accuracy: 81.1 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 0.6331831216812134, accuracy: 79.4 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 0.5791172385215759, accuracy: 81.5 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 0.5780268311500549, accuracy: 81.0 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 0.5752140283584595, accuracy: 81.8 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 0.5698882341384888, accuracy: 81.7 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 0.5933, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 0.3935, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 0.4887, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 0.7007, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 0.4538, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 0.5172, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 0.5847, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 0.5231, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 0.6322, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 0.5433, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 0.5710445046424866, accuracy: 81.1 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 2.089754581451416, accuracy: 47.4 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 1.8805067539215088, accuracy: 55.2 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 0.6919423341751099, accuracy: 77.8 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 0.610314130783081, accuracy: 79.7 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 0.5531243681907654, accuracy: 80.6 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 0.5442513227462769, accuracy: 81.3 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 0.5324010252952576, accuracy: 81.7 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 0.5319144129753113, accuracy: 81.7 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 0.5294860601425171, accuracy: 81.9 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 0.4789, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 0.4242, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 0.6093, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 0.6861, batch time: 0.10, accuracy:  76.56%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 0.5033, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 0.4983, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 0.4519, batch time: 0.07, accuracy:  84.38%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 0.5134, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 0.6600, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 0.6029, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 0.7976817488670349, accuracy: 75.0 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 0.7518876194953918, accuracy: 76.8 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 0.7493464350700378, accuracy: 75.9 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 0.6950932741165161, accuracy: 80.2 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 0.6938347220420837, accuracy: 79.7 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 1.6666513681411743, accuracy: 55.9 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 0.8266458511352539, accuracy: 74.9 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 0.9626950621604919, accuracy: 69.4 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 2.2341859340667725, accuracy: 42.6 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 0.9099867939949036, accuracy: 70.2 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 0.6522, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 0.6262, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 0.7137, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 0.8799, batch time: 0.10, accuracy:  75.78%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 0.6099, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 0.6117, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 0.5423, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 0.7369, batch time: 0.10, accuracy:  73.44%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 0.9274, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 0.4763, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 0.5971072912216187, accuracy: 84.3 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 1.862070083618164, accuracy: 48.8 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 0.997529149055481, accuracy: 72.6 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 8.395913124084473, accuracy: 25.1 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 0.6934710144996643, accuracy: 79.3 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 0.6390126943588257, accuracy: 81.5 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 0.5710741281509399, accuracy: 83.6 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 0.5657538771629333, accuracy: 83.5 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 0.5668556690216064, accuracy: 83.6 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 0.5655252933502197, accuracy: 83.2 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 0.7819, batch time: 0.10, accuracy:  75.78%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 0.5843, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 0.6914, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 0.4547, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 0.4770, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 0.6060, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 0.5026, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 0.6417, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 0.7323, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 0.5421, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 0.5185877084732056, accuracy: 83.0 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 0.8031560778617859, accuracy: 76.0 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 0.5175299048423767, accuracy: 83.0 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 2.025660991668701, accuracy: 45.6 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 0.5585618615150452, accuracy: 81.7 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 0.51396244764328, accuracy: 82.9 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 0.5015199780464172, accuracy: 83.3 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 0.5103071928024292, accuracy: 83.1 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 0.5045649409294128, accuracy: 82.9 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 0.49958524107933044, accuracy: 83.1 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 0.6663, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 0.7881, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 0.7795, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 0.4890, batch time: 0.04, accuracy:  83.59%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 0.4670, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 0.4818, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 0.4916, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 0.6035, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 0.6038, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 0.6023, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 0.5704988837242126, accuracy: 82.4 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 0.7974262833595276, accuracy: 73.1 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 0.5689519047737122, accuracy: 82.1 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 1.1929290294647217, accuracy: 62.5 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 0.5557470917701721, accuracy: 81.2 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 0.5206881165504456, accuracy: 83.5 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 0.6351810097694397, accuracy: 80.0 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 0.5155310034751892, accuracy: 83.5 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 0.5169607996940613, accuracy: 82.9 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 0.5055793523788452, accuracy: 83.6 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 0.9075, batch time: 0.11, accuracy:  75.00%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 0.4733, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 0.6233, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 0.6504, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 0.7238, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 0.5151, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 0.6950, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 0.7629, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 0.6947, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 0.5032, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 0.5696995854377747, accuracy: 82.5 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 0.7429320812225342, accuracy: 74.2 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 1.0728899240493774, accuracy: 63.8 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 0.5104748606681824, accuracy: 85.2 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 0.9522504210472107, accuracy: 70.2 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 0.5020732283592224, accuracy: 85.7 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 0.5336238145828247, accuracy: 84.3 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 0.5294120907783508, accuracy: 83.1 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 0.503782331943512, accuracy: 85.8 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 0.5182129144668579, accuracy: 84.8 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 0.6046, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 0.5438, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 0.5057, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 0.5618, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 0.4685, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 0.5152, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 0.5639, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 0.4460, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 0.5706, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 0.7305, batch time: 0.11, accuracy:  76.56%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 0.5659805536270142, accuracy: 83.5 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 1.5224864482879639, accuracy: 50.9 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 0.7863366603851318, accuracy: 77.0 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 0.6929031610488892, accuracy: 78.3 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 0.6022179126739502, accuracy: 80.9 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 0.5586355924606323, accuracy: 83.2 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 0.5917304754257202, accuracy: 82.5 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 0.5667821168899536, accuracy: 82.6 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 0.57414710521698, accuracy: 83.0 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 0.622745156288147, accuracy: 80.0 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 0.5224, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 0.4775, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 0.5922, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 0.5554, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 0.7200, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 0.5277, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 0.4175, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 0.5321, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 0.5865, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 0.6827, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 0.5778027176856995, accuracy: 81.9 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 1.4441254138946533, accuracy: 55.2 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 0.6737191081047058, accuracy: 78.8 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 0.6995808482170105, accuracy: 78.8 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 0.5891193747520447, accuracy: 82.3 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 0.6176931858062744, accuracy: 81.3 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 0.5573654770851135, accuracy: 83.5 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 0.5539677143096924, accuracy: 83.7 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 0.5521509051322937, accuracy: 83.7 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 0.5520685911178589, accuracy: 83.6 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 0.4844, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 0.6069, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 0.5510, batch time: 0.04, accuracy:  82.81%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 0.7720, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 0.4550, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 0.5581, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 0.5199, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 0.4784, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 0.6191, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 0.5112, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 0.5597853660583496, accuracy: 82.1 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 1.7727348804473877, accuracy: 47.2 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 0.8420911431312561, accuracy: 75.0 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 1.1739996671676636, accuracy: 62.0 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 0.5266942381858826, accuracy: 83.3 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 0.5253260731697083, accuracy: 83.7 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 0.5208488702774048, accuracy: 83.4 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 0.5791693925857544, accuracy: 81.3 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 0.5378080606460571, accuracy: 81.6 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 0.513139545917511, accuracy: 84.7 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 0.6778, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 0.5846, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 0.5228, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 0.5899, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 0.5808, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 0.4262, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 0.6397, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 0.5756, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 0.5369, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 0.4844, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 0.606996476650238, accuracy: 81.5 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 2.0529706478118896, accuracy: 44.5 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 0.770408034324646, accuracy: 77.8 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 1.2620688676834106, accuracy: 60.9 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 0.6052485704421997, accuracy: 81.5 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 0.6166707277297974, accuracy: 80.8 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 0.5770505666732788, accuracy: 82.4 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 0.56562340259552, accuracy: 82.8 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 0.5749852061271667, accuracy: 81.5 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 0.5611111521720886, accuracy: 82.8 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 0.6968, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 0.5939, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 0.7952, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 0.7409, batch time: 0.11, accuracy:  77.34%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 0.5645, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 0.4777, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 0.7157, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 0.3472, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 0.4845, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 0.7346, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 0.5875473618507385, accuracy: 80.6 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 1.2914131879806519, accuracy: 58.3 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 0.6502922773361206, accuracy: 81.3 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 0.9916418790817261, accuracy: 69.8 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 0.5551735162734985, accuracy: 82.0 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 0.5238709449768066, accuracy: 83.2 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 0.5478103160858154, accuracy: 82.8 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 0.517402172088623, accuracy: 83.7 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 0.51786208152771, accuracy: 83.7 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 0.5157970786094666, accuracy: 83.6 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 0.5182, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 0.7364, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 0.5704, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 0.7180, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 0.4611, batch time: 0.09, accuracy:  84.38%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 0.7128, batch time: 0.08, accuracy:  82.81%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 0.5930, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 0.4635, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 0.4713, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 0.5614, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 0.5522148609161377, accuracy: 81.7 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 1.2087147235870361, accuracy: 63.7 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 0.7096988558769226, accuracy: 75.8 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 1.0080149173736572, accuracy: 66.4 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 0.5329005718231201, accuracy: 82.0 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 0.5790356993675232, accuracy: 81.3 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 0.5817559957504272, accuracy: 80.5 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 0.5290545225143433, accuracy: 82.6 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 0.5252321362495422, accuracy: 82.9 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 0.5268135666847229, accuracy: 83.0 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 0.5627, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 0.6760, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 0.5002, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 0.6070, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 0.4131, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 0.8204, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 0.6333, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 0.5408, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 0.5730, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 0.6059, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 0.5904788970947266, accuracy: 83.1 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 1.3403303623199463, accuracy: 59.5 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 0.8463529348373413, accuracy: 76.1 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 0.8440432548522949, accuracy: 71.0 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 0.5846124291419983, accuracy: 82.8 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 0.5846988558769226, accuracy: 82.8 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 0.6086143851280212, accuracy: 82.2 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 0.5859475135803223, accuracy: 83.0 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 0.5917325615882874, accuracy: 82.5 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 0.5775805711746216, accuracy: 82.8 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 0.5581, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 0.6514, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 0.3712, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 0.4993, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 0.7918, batch time: 0.04, accuracy:  78.91%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 0.6136, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 0.5182, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 0.6099, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 0.4724, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 0.4917, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 0.5139695405960083, accuracy: 84.0 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 1.1339002847671509, accuracy: 63.2 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 0.835306704044342, accuracy: 71.6 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 0.5846651196479797, accuracy: 82.4 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 0.503045380115509, accuracy: 84.7 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 0.5105472207069397, accuracy: 84.7 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 0.5747174024581909, accuracy: 82.0 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 0.49543631076812744, accuracy: 84.5 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 0.49213239550590515, accuracy: 85.2 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 0.49543529748916626, accuracy: 86.0 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 0.5539, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 0.4849, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 0.6629, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 0.7580, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 0.4291, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 0.7241, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 0.4713, batch time: 0.04, accuracy:  79.69%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 0.3823, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 0.4561, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 0.6529, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 0.5773298144340515, accuracy: 81.8 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 0.7306858897209167, accuracy: 76.1 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 0.7351372241973877, accuracy: 76.9 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 0.5601059198379517, accuracy: 83.2 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 1.097206950187683, accuracy: 65.8 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 0.5407115817070007, accuracy: 84.5 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 0.5635963082313538, accuracy: 84.4 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 0.534608781337738, accuracy: 84.9 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 0.6098890900611877, accuracy: 81.3 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 0.5625759959220886, accuracy: 82.5 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 0.4615, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 0.7189, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 0.5655, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 0.5511, batch time: 0.34, accuracy:  82.81%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 0.4594, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 0.4870, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 0.5255, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 0.6006, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 0.5564, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 0.3727, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 0.527145266532898, accuracy: 84.5 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 1.3367899656295776, accuracy: 58.6 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 0.9062991738319397, accuracy: 76.3 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 0.7781834602355957, accuracy: 75.8 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 0.5305169820785522, accuracy: 84.4 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 0.5178204774856567, accuracy: 85.4 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 0.5149786472320557, accuracy: 84.9 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 0.5137822031974792, accuracy: 85.1 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 0.5145764350891113, accuracy: 85.4 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 0.5128130912780762, accuracy: 85.0 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 0.4711, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 0.3974, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 0.6389, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 0.7142, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 0.4533, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 0.8795, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 0.8283, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 0.4751, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 0.5501, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 0.6171, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 0.5395920276641846, accuracy: 81.8 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 1.5347468852996826, accuracy: 53.9 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 0.8824665546417236, accuracy: 75.5 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 0.8148153424263, accuracy: 72.6 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 0.5412957072257996, accuracy: 82.3 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 0.5245291590690613, accuracy: 82.1 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 0.528221845626831, accuracy: 82.7 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 0.6529474854469299, accuracy: 79.5 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 0.5174182057380676, accuracy: 82.6 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 0.516393780708313, accuracy: 82.5 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 0.4896, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 0.4870, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 0.5950, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 0.5031, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 0.5815, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 0.6008, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 0.5735, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 0.5093, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 0.5948, batch time: 0.04, accuracy:  81.25%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 0.4299, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 0.5983395576477051, accuracy: 81.7 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 2.0675628185272217, accuracy: 44.3 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 0.8796509504318237, accuracy: 77.0 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 0.9792414903640747, accuracy: 69.8 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 0.5681012868881226, accuracy: 83.7 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 0.5421029925346375, accuracy: 84.3 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 0.5695993304252625, accuracy: 82.6 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 0.5560923218727112, accuracy: 83.7 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 0.5362992286682129, accuracy: 83.9 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 0.5397186279296875, accuracy: 84.5 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 0.7162, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 0.5110, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 0.4589, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 0.9287, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 0.6974, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 0.3899, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 0.6290, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 0.6369, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 0.5574, batch time: 0.04, accuracy:  80.47%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 0.4898, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 0.5173562169075012, accuracy: 82.8 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 1.63162100315094, accuracy: 52.8 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 0.8796547651290894, accuracy: 75.0 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 0.5333027243614197, accuracy: 82.9 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 0.5665122270584106, accuracy: 81.6 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 0.5308197140693665, accuracy: 82.6 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 0.5177328586578369, accuracy: 83.4 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 0.4975515604019165, accuracy: 83.3 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 0.49653008580207825, accuracy: 84.1 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 0.4938899278640747, accuracy: 83.9 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 0.6671, batch time: 0.10, accuracy:  74.22%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 0.5202, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 0.5458, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 0.5496, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 0.5051, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 0.6863, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 0.4627, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 0.7453, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 0.5507, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 0.5762, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 0.6004186868667603, accuracy: 82.2 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 1.7496036291122437, accuracy: 49.9 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 0.9314728379249573, accuracy: 73.1 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 0.7599868774414062, accuracy: 76.5 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 0.5787150859832764, accuracy: 83.4 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 0.6327834725379944, accuracy: 80.4 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 0.64757239818573, accuracy: 79.7 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 0.572652280330658, accuracy: 83.0 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 0.5691707134246826, accuracy: 83.2 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 0.568524181842804, accuracy: 83.3 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 0.4718, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 0.7526, batch time: 0.04, accuracy:  76.56%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 0.5679, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 0.5398, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 0.4899, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 0.5302, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 0.5299, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 0.4578, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 0.6215, batch time: 0.06, accuracy:  80.47%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 0.4505, batch time: 0.08, accuracy:  87.50%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 0.630307674407959, accuracy: 82.3 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 1.3958605527877808, accuracy: 59.1 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 0.8101775646209717, accuracy: 75.8 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 3.8578174114227295, accuracy: 36.5 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 0.6235339641571045, accuracy: 81.7 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 0.6017654538154602, accuracy: 81.8 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 0.6010040640830994, accuracy: 82.6 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 0.5871389508247375, accuracy: 83.4 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 0.5836344361305237, accuracy: 83.2 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 0.5819376707077026, accuracy: 83.3 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 0.4820, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 0.6826, batch time: 0.11, accuracy:  78.12%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 0.4245, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 0.6077, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 0.6795, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 0.5558, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 0.5570, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 0.6405, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 0.6098, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 0.6082, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 0.6055325269699097, accuracy: 82.5 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 1.640417218208313, accuracy: 55.5 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 0.646199643611908, accuracy: 80.7 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 1.3869636058807373, accuracy: 65.4 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 0.5944942831993103, accuracy: 83.7 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 0.5910152792930603, accuracy: 83.8 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 0.6030387282371521, accuracy: 83.7 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 0.5869224071502686, accuracy: 83.9 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 0.588882327079773, accuracy: 84.1 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 0.6025061011314392, accuracy: 83.0 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 0.5275, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 0.5126, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 0.4681, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 0.6828, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 0.5081, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 0.4403, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 0.7847, batch time: 0.04, accuracy:  78.12%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 0.6004, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 0.4148, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 0.5598, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 0.5232040882110596, accuracy: 82.5 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 1.5185890197753906, accuracy: 54.2 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 0.6880598664283752, accuracy: 74.9 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 1.4637212753295898, accuracy: 58.0 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 0.5131661295890808, accuracy: 82.6 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 0.5838328003883362, accuracy: 80.6 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 0.557876467704773, accuracy: 81.2 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 0.4993356764316559, accuracy: 82.7 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 0.49637719988822937, accuracy: 83.2 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 0.4957639276981354, accuracy: 83.4 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 0.5982, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 0.5396, batch time: 0.04, accuracy:  81.25%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 0.5373, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 0.5661, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 0.5678, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 0.4639, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 0.5892, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 0.5130, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 0.4735, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 0.4156, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 0.5703991055488586, accuracy: 83.5 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 2.027104377746582, accuracy: 48.5 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 0.7419930696487427, accuracy: 78.1 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 0.9636446237564087, accuracy: 71.0 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 0.6281055212020874, accuracy: 79.9 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 0.578622579574585, accuracy: 83.0 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 0.626513659954071, accuracy: 79.9 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 0.5357300639152527, accuracy: 84.0 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 0.5289895534515381, accuracy: 84.7 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 0.526643693447113, accuracy: 85.1 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 0.6471, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 0.5806, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 0.5940, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 0.6798, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 0.4690, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 0.5543, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 0.6231, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 0.4733, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 0.5215, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 0.7011, batch time: 0.11, accuracy:  77.34%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 0.5931974649429321, accuracy: 82.0 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 1.2171660661697388, accuracy: 60.8 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 1.0097812414169312, accuracy: 69.3 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 1.1349818706512451, accuracy: 68.5 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 0.5718519687652588, accuracy: 82.2 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 0.5694876313209534, accuracy: 82.4 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 0.592901349067688, accuracy: 82.0 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 0.5581798553466797, accuracy: 82.9 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 0.5557991862297058, accuracy: 83.6 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 0.5512945055961609, accuracy: 83.3 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 0.5682, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 0.5553, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 0.5475, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 0.5088, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 0.4742, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 0.4764, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 0.5387, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 0.5623, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 0.5314, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 0.4723, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 0.5268067121505737, accuracy: 82.7 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 1.032158613204956, accuracy: 66.7 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 0.7214678525924683, accuracy: 77.2 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 0.9551976919174194, accuracy: 67.4 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 0.5101671814918518, accuracy: 84.0 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 0.5428335070610046, accuracy: 83.6 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 0.5555813312530518, accuracy: 81.4 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 0.5065190196037292, accuracy: 85.1 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 0.5107611417770386, accuracy: 83.7 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 0.5897884368896484, accuracy: 82.2 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 0.4581, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 0.5829, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 0.4182, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 0.5101, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 0.4269, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 0.6643, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 0.6490, batch time: 0.06, accuracy:  80.47%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 0.5473, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 0.5035, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 0.6979, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 0.5157070159912109, accuracy: 83.8 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 0.9487891793251038, accuracy: 66.9 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 0.6268099546432495, accuracy: 79.2 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 0.734796404838562, accuracy: 74.2 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 0.5016379356384277, accuracy: 83.9 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 0.5244344472885132, accuracy: 82.7 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 0.49647921323776245, accuracy: 85.0 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 0.47922664880752563, accuracy: 85.7 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 0.477651447057724, accuracy: 85.7 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 0.4764324426651001, accuracy: 86.1 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 0.5922, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 0.5698, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 0.6279, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 0.4810, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 0.3852, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 0.4570, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 0.4180, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 0.3392, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 0.3792, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 0.6258, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 0.5883272886276245, accuracy: 82.6 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 1.0114506483078003, accuracy: 66.9 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 0.6481842398643494, accuracy: 79.2 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 0.9795617461204529, accuracy: 67.8 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 0.6154156923294067, accuracy: 81.2 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 0.6183592081069946, accuracy: 80.4 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 0.5770354270935059, accuracy: 83.5 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 0.5791206955909729, accuracy: 81.9 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 0.553253710269928, accuracy: 83.5 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 0.5514039397239685, accuracy: 84.3 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 0.5328, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 0.4977, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 0.5606, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 0.7038, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 0.4054, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 0.5117, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 0.6401, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 0.4920, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 0.4204, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 0.3257, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 0.5113558173179626, accuracy: 84.1 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 1.0662920475006104, accuracy: 68.3 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 0.565687894821167, accuracy: 82.2 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 8.314068794250488, accuracy: 18.5 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 0.521211564540863, accuracy: 84.5 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 0.5363760590553284, accuracy: 83.2 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 0.49037861824035645, accuracy: 86.0 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 0.487389475107193, accuracy: 86.2 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 0.48865261673927307, accuracy: 85.8 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 0.4863159656524658, accuracy: 86.8 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 0.4863, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 0.5079, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 0.5822, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 0.3747, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 0.4418, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 0.6743, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 0.5052, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 0.5657, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 0.3843, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 0.6805, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 0.5598368644714355, accuracy: 82.8 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 0.8529849052429199, accuracy: 73.1 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 0.5797069668769836, accuracy: 81.6 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 1.060949444770813, accuracy: 69.1 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 0.533201277256012, accuracy: 83.9 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 0.5178728103637695, accuracy: 84.3 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 0.5581673383712769, accuracy: 83.3 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 0.5117680430412292, accuracy: 84.4 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 0.5122672319412231, accuracy: 84.2 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 0.5089961886405945, accuracy: 84.1 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 0.4607, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 0.4027, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 0.4952, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 0.5741, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 0.5980, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 0.3546, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 0.4424, batch time: 0.08, accuracy:  89.06%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 0.6473, batch time: 0.05, accuracy:  71.88%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 0.5479, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 0.6356, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 0.4731903672218323, accuracy: 85.6 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 1.299860954284668, accuracy: 61.8 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 0.4842536151409149, accuracy: 85.5 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 1.6461029052734375, accuracy: 52.4 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 0.4703761041164398, accuracy: 85.3 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 0.48846256732940674, accuracy: 84.6 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 0.4765635132789612, accuracy: 84.4 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 0.4468894600868225, accuracy: 86.1 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 0.4460199177265167, accuracy: 86.0 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 0.44435977935791016, accuracy: 86.0 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 0.5694, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 0.6395, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 0.4951, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 0.5355, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 0.7056, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 0.8397, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 0.3456, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 0.5583, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 0.4320, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 0.4547, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 0.5475339293479919, accuracy: 83.9 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 1.4034498929977417, accuracy: 60.2 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 0.5920457243919373, accuracy: 81.5 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 5.27234411239624, accuracy: 21.4 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 0.5448419451713562, accuracy: 82.9 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 0.5121861696243286, accuracy: 85.7 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 0.5078965425491333, accuracy: 85.7 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 0.5058092474937439, accuracy: 85.1 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 0.5043193697929382, accuracy: 85.6 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 0.5022827386856079, accuracy: 85.9 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 0.4295, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 0.5897, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 0.5267, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 0.4426, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 0.5491, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 0.3631, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 0.3804, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 0.4820, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 0.5095, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 0.7590, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 0.5222490429878235, accuracy: 83.9 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 0.8834136128425598, accuracy: 72.1 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 0.8085760474205017, accuracy: 72.0 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 1.894628882408142, accuracy: 57.1 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 0.5070303678512573, accuracy: 83.6 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 0.5351521968841553, accuracy: 82.7 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 0.5141122937202454, accuracy: 83.8 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 0.4980686604976654, accuracy: 84.7 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 0.49568262696266174, accuracy: 85.0 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 0.4949418306350708, accuracy: 85.2 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 0.4017, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 0.3464, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 0.5146, batch time: 0.04, accuracy:  79.69%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 0.4862, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 0.3891, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 0.5558, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 0.4676, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 0.4473, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 0.4894, batch time: 0.06, accuracy:  85.94%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 0.5974, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 0.5209997296333313, accuracy: 84.9 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 1.1261273622512817, accuracy: 62.1 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 0.5337911248207092, accuracy: 83.9 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 0.6834235191345215, accuracy: 79.1 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 0.5673403143882751, accuracy: 81.9 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 0.5571815967559814, accuracy: 84.6 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 0.5536656975746155, accuracy: 83.9 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 0.5122717022895813, accuracy: 85.4 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 0.5150516629219055, accuracy: 84.6 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 0.5083632469177246, accuracy: 85.4 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 0.5770, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 0.4940, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 0.6034, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 0.6672, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 0.5740, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 0.5279, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 0.4774, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 0.5686, batch time: 0.08, accuracy:  85.16%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 0.6911, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 0.3205, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 0.5085166096687317, accuracy: 85.3 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 1.23018217086792, accuracy: 63.6 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 0.8473566770553589, accuracy: 74.0 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 0.9074830412864685, accuracy: 73.1 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 0.5414062142372131, accuracy: 84.0 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 0.5304796695709229, accuracy: 84.0 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 0.5178768038749695, accuracy: 84.8 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 0.48894935846328735, accuracy: 86.0 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 0.4879244565963745, accuracy: 85.6 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 0.48777613043785095, accuracy: 85.8 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 0.4862, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 0.4938, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 0.5248, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 0.7006, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 0.4391, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 0.4057, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 0.4215, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 0.5577, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 0.4598, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 0.4580, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 0.495089054107666, accuracy: 85.3 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 1.211545467376709, accuracy: 59.8 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 0.7738244533538818, accuracy: 74.6 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 2.121067523956299, accuracy: 38.9 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 0.5488560795783997, accuracy: 81.8 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 0.5356355905532837, accuracy: 83.2 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 0.48551803827285767, accuracy: 85.2 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 0.4812600314617157, accuracy: 85.7 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 0.4809078276157379, accuracy: 85.5 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 0.4798392653465271, accuracy: 85.8 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 0.4641, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 0.4869, batch time: 0.09, accuracy:  84.38%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 0.4085, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 0.5150, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 0.4813, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 0.7076, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 0.6389, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 0.4359, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 0.6212, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 0.5193, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 0.5326730012893677, accuracy: 83.5 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 1.391221046447754, accuracy: 58.4 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 0.5604596734046936, accuracy: 84.1 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 0.5958768725395203, accuracy: 80.6 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 0.5353091359138489, accuracy: 84.0 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 0.5136815309524536, accuracy: 84.0 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 0.5344018936157227, accuracy: 84.2 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 0.5096126794815063, accuracy: 84.4 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 0.5087857246398926, accuracy: 84.7 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 0.508023738861084, accuracy: 84.4 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 0.6804, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 0.4663, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 0.3254, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 0.5361, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 0.4535, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 0.4061, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 0.4419, batch time: 0.06, accuracy:  85.16%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 0.4536, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 0.6127, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 0.3956, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 0.5126076340675354, accuracy: 85.4 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 0.9817016124725342, accuracy: 68.4 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 0.7168557047843933, accuracy: 76.6 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 1.1450549364089966, accuracy: 68.7 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 0.4716792702674866, accuracy: 84.3 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 0.4560678005218506, accuracy: 85.8 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 0.4594605565071106, accuracy: 85.2 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 0.47021621465682983, accuracy: 84.9 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 0.47843074798583984, accuracy: 84.0 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 0.45157676935195923, accuracy: 85.2 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 0.4807, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 0.6209, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 0.4813, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 0.4252, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 0.6490, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 0.3695, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 0.5652, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 0.5143, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 0.6966, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 0.4129, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 0.49651625752449036, accuracy: 85.0 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 0.9853731393814087, accuracy: 69.5 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 0.7463789582252502, accuracy: 76.6 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 1.4832285642623901, accuracy: 63.9 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 0.48766303062438965, accuracy: 84.7 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 0.4803118109703064, accuracy: 85.1 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 0.4821285605430603, accuracy: 85.8 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 0.5044166445732117, accuracy: 84.2 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 0.5420919060707092, accuracy: 82.9 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 0.4744310677051544, accuracy: 85.3 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 0.5313, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 0.5390, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 0.4742, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 0.6196, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 0.4248, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 0.4689, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 0.5328, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 0.5798, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 0.4894, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 0.5207, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 0.5540347099304199, accuracy: 85.0 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 1.0343753099441528, accuracy: 65.9 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 0.800905168056488, accuracy: 75.4 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 0.7060166597366333, accuracy: 78.2 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 0.5715435743331909, accuracy: 83.8 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 0.5503759980201721, accuracy: 84.1 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 0.5409278273582458, accuracy: 84.6 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 0.5512939691543579, accuracy: 83.4 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 0.5427461266517639, accuracy: 84.3 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 0.5319033265113831, accuracy: 85.0 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 0.6391, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 0.4793, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 0.7251, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 0.4808, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 0.4912, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 0.4545, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 0.3578, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 0.4874, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 0.5230, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 0.4264, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 0.49306565523147583, accuracy: 84.9 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 0.9962306022644043, accuracy: 68.7 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 0.7716493606567383, accuracy: 76.0 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 2.3285489082336426, accuracy: 39.5 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 0.506488025188446, accuracy: 83.5 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 0.5098651647567749, accuracy: 83.2 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 0.48192334175109863, accuracy: 85.1 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 0.4789022207260132, accuracy: 84.9 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 0.4812461733818054, accuracy: 84.7 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 0.4807215929031372, accuracy: 85.0 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 0.6034, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 0.4878, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 0.5619, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 0.4332, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 0.3886, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 0.7627, batch time: 0.10, accuracy:  75.78%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 0.5016, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 0.3461, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 0.3953, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 0.5122, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 0.4997881054878235, accuracy: 85.6 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 1.5373591184616089, accuracy: 57.3 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 0.5706746578216553, accuracy: 82.0 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 0.9124171137809753, accuracy: 69.7 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 0.4629702568054199, accuracy: 86.6 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 0.4922495484352112, accuracy: 85.4 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 0.45828574895858765, accuracy: 86.3 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 0.44700509309768677, accuracy: 87.2 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 0.4457177519798279, accuracy: 87.5 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 0.4445161521434784, accuracy: 87.5 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 0.5183, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 0.3884, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 0.4791, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 0.6784, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 0.4708, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 0.6366, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 0.4920, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 0.4183, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 0.4633, batch time: 0.04, accuracy:  83.59%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 0.4633, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 0.5136730670928955, accuracy: 84.8 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 1.3819773197174072, accuracy: 60.6 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 0.7631949186325073, accuracy: 76.5 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 1.3539265394210815, accuracy: 59.1 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 0.4941733777523041, accuracy: 86.0 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 0.4884314239025116, accuracy: 86.3 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 0.5006848573684692, accuracy: 85.6 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 0.5341688394546509, accuracy: 83.7 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 0.4863416850566864, accuracy: 86.0 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 0.4816574454307556, accuracy: 86.8 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 0.4125, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 0.5102, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 0.4261, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 0.4615, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 0.4851, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 0.4064, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 0.4438, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 0.4987, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 0.6684, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 0.6236, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 0.4837201237678528, accuracy: 84.7 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 1.0983461141586304, accuracy: 67.4 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 0.7454230189323425, accuracy: 76.5 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 1.2844206094741821, accuracy: 61.6 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 0.49092280864715576, accuracy: 83.8 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 0.5065664649009705, accuracy: 83.0 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 0.48002201318740845, accuracy: 84.5 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 0.4688745439052582, accuracy: 85.1 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 0.47333604097366333, accuracy: 84.3 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 0.4728771150112152, accuracy: 84.9 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 0.6413, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 0.4686, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 0.4911, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 0.6099, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 0.5707, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 0.6742, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 0.5345, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 0.6674, batch time: 0.04, accuracy:  82.81%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 0.4549, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 0.4522, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 0.5315044522285461, accuracy: 84.8 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 1.183961272239685, accuracy: 66.0 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 0.8424142003059387, accuracy: 74.5 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 2.43315052986145, accuracy: 37.4 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 0.5569222569465637, accuracy: 84.3 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 0.5557945370674133, accuracy: 83.5 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 0.5265120267868042, accuracy: 84.9 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 0.5250595808029175, accuracy: 85.0 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 0.5229561924934387, accuracy: 84.9 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 0.5232715606689453, accuracy: 85.8 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 0.3925, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 0.4734, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 0.4807, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 0.5214, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 0.5473, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 0.4855, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 0.4515, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 0.3945, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 0.6444, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 0.3798, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 0.6061820387840271, accuracy: 81.8 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 2.065366268157959, accuracy: 45.5 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 0.5835083723068237, accuracy: 83.0 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 0.5802367329597473, accuracy: 81.8 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 0.5368177890777588, accuracy: 84.4 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 0.5288070440292358, accuracy: 84.1 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 0.5031337738037109, accuracy: 85.5 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 0.5175685286521912, accuracy: 84.3 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 0.6381466388702393, accuracy: 79.8 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 0.4992116093635559, accuracy: 86.1 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 0.5861, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 0.4019, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 0.6243, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 0.8684, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 0.6812, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 0.4087, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 0.4520, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 0.5056, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 0.5196, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 0.3562, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 0.5398904085159302, accuracy: 82.0 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 1.1711887121200562, accuracy: 63.4 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 0.7459248900413513, accuracy: 74.4 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 1.237153172492981, accuracy: 67.6 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 0.5095442533493042, accuracy: 82.8 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 0.5396572947502136, accuracy: 81.9 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 0.526638388633728, accuracy: 80.7 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 0.49719884991645813, accuracy: 83.1 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 0.5007241368293762, accuracy: 82.8 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 0.47600704431533813, accuracy: 83.8 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 0.3248, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 0.6760, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 0.5696, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 0.5951, batch time: 0.38, accuracy:  78.91%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 0.3982, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 0.6740, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 0.5056, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 0.6038, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 0.5259, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 0.7454, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 0.5429739356040955, accuracy: 83.7 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 1.112770915031433, accuracy: 63.5 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 0.8110836148262024, accuracy: 74.6 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 1.3388898372650146, accuracy: 60.6 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 0.538853108882904, accuracy: 84.0 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 0.5303661823272705, accuracy: 84.4 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 0.5319913625717163, accuracy: 84.0 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 0.5803351998329163, accuracy: 81.8 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 0.5234656929969788, accuracy: 84.9 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 0.5211357474327087, accuracy: 85.1 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 0.5252, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 0.5500, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 0.5061, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 0.4802, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 0.4727, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 0.7801, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 0.4606, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 0.4788, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 0.5512, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 0.4074, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 0.48478570580482483, accuracy: 85.5 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 1.0257326364517212, accuracy: 67.9 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 0.7867359519004822, accuracy: 76.1 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 0.8515623211860657, accuracy: 72.3 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 0.5151382684707642, accuracy: 83.6 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 0.5230222344398499, accuracy: 83.4 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 0.47719916701316833, accuracy: 85.4 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 0.47040024399757385, accuracy: 85.9 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 0.4704108238220215, accuracy: 86.1 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 0.46760720014572144, accuracy: 86.3 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 0.3954, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 0.5503, batch time: 0.38, accuracy:  82.81%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 0.4999, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 0.5429, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 0.5333, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 0.4001, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 0.5077, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 0.5306, batch time: 0.04, accuracy:  82.81%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 0.4919, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 0.4712, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 0.5027215480804443, accuracy: 84.7 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 1.7387012243270874, accuracy: 51.0 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 0.5293149352073669, accuracy: 84.3 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 0.8581886887550354, accuracy: 75.8 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 0.4747889041900635, accuracy: 85.3 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 0.522406816482544, accuracy: 84.3 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 0.5450407862663269, accuracy: 82.7 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 0.47114595770835876, accuracy: 85.8 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 0.46862906217575073, accuracy: 85.5 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 0.46799758076667786, accuracy: 85.5 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 0.5748, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 0.4884, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 0.5144, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 0.5896, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 0.5092, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 0.5599, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 0.6223, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 0.5315, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 0.5609, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 0.5177, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 0.5364595651626587, accuracy: 83.1 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 1.4403401613235474, accuracy: 59.0 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 1.2010142803192139, accuracy: 65.6 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 0.9773141741752625, accuracy: 69.1 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 0.5159958004951477, accuracy: 83.5 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 0.523635983467102, accuracy: 84.5 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 0.5577622056007385, accuracy: 82.1 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 0.5112013220787048, accuracy: 83.4 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 0.5073986649513245, accuracy: 83.3 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 0.5218151211738586, accuracy: 82.8 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 0.5342, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 0.5483, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 0.5964, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 0.6393, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 0.5307, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 0.6715, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 0.6321, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 0.4673, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 0.3764, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 0.6114, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 0.5167054533958435, accuracy: 84.6 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 0.9647696614265442, accuracy: 69.0 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 0.7647020816802979, accuracy: 74.8 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 1.202585220336914, accuracy: 70.0 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 0.520248532295227, accuracy: 84.4 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 0.5407295823097229, accuracy: 83.7 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 0.4985804259777069, accuracy: 85.9 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 0.49432146549224854, accuracy: 85.9 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 0.49444565176963806, accuracy: 85.7 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 0.49164313077926636, accuracy: 86.1 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 0.6998, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 0.5625, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 0.4100, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 0.4986, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 0.5324, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 0.5575, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 0.4859, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 0.4220, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 0.4043, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 0.3479, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 0.5522456169128418, accuracy: 84.2 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 1.2102901935577393, accuracy: 63.6 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 0.7801896929740906, accuracy: 76.1 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 1.4981564283370972, accuracy: 63.9 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 0.5465238094329834, accuracy: 83.8 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 0.5394563674926758, accuracy: 84.6 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 0.5775129199028015, accuracy: 81.8 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 0.5743212699890137, accuracy: 82.5 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 0.5193327069282532, accuracy: 84.7 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 0.515835165977478, accuracy: 84.7 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 0.4599, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 0.6042, batch time: 0.11, accuracy:  77.34%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 0.6088, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 0.5129, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 0.4417, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 0.6457, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 0.3939, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 0.8167, batch time: 0.10, accuracy:  74.22%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 0.3872, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 0.5177, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 0.539487898349762, accuracy: 83.2 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 1.8258944749832153, accuracy: 52.8 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 0.7665325403213501, accuracy: 76.4 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 0.7418422102928162, accuracy: 76.3 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 0.5098316073417664, accuracy: 83.9 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 0.5108281970024109, accuracy: 84.4 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 0.5043088793754578, accuracy: 84.6 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 0.5002836585044861, accuracy: 84.5 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 0.4992392361164093, accuracy: 84.6 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 0.49704548716545105, accuracy: 84.7 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 0.6132, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 0.6073, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 0.5975, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 0.4686, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 0.4745, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 0.5016, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 0.5372, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 0.5493, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 0.6870, batch time: 0.06, accuracy:  78.12%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 0.4169, batch time: 0.07, accuracy:  85.94%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 0.48028939962387085, accuracy: 84.7 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 2.014777898788452, accuracy: 47.5 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 0.5052420496940613, accuracy: 84.0 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 0.8094402551651001, accuracy: 77.5 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 0.5122603178024292, accuracy: 84.9 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 0.4555051326751709, accuracy: 86.0 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 0.45348092913627625, accuracy: 85.7 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 0.4516943395137787, accuracy: 85.7 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 0.45224428176879883, accuracy: 85.9 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 0.45096513628959656, accuracy: 86.0 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 0.4143, batch time: 0.08, accuracy:  87.50%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 0.4568, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 0.4824, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 0.4790, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 0.6295, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 0.4679, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 0.5511, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 0.4522, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 0.4618, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 0.4797, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 0.5166752934455872, accuracy: 84.2 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 1.9252209663391113, accuracy: 48.7 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 0.5607265830039978, accuracy: 83.4 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 1.1963915824890137, accuracy: 62.1 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 0.5115463733673096, accuracy: 85.3 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 0.4737212657928467, accuracy: 86.2 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 0.4749090075492859, accuracy: 86.8 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 0.5367163419723511, accuracy: 83.5 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 0.4827744960784912, accuracy: 85.6 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 0.5133523344993591, accuracy: 84.4 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 0.3624, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 0.4664, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 0.4992, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 0.4308, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 0.5998, batch time: 0.04, accuracy:  78.91%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 0.5101, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 0.3668, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 0.5505, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 0.4940, batch time: 0.04, accuracy:  83.59%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 0.3939, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 0.49557578563690186, accuracy: 85.9 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 1.4557125568389893, accuracy: 54.1 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 0.6715856194496155, accuracy: 78.0 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 1.628113865852356, accuracy: 53.4 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 0.48918288946151733, accuracy: 86.5 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 0.4765443205833435, accuracy: 86.9 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 0.4862602651119232, accuracy: 85.7 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 0.4865596890449524, accuracy: 86.4 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 0.4803982973098755, accuracy: 86.7 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 0.46582847833633423, accuracy: 87.4 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 0.6145, batch time: 0.09, accuracy:  80.47%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 0.4781, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 0.4729, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 0.6793, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 0.4247, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 0.5259, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 0.4339, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 0.3168, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 0.5488, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 0.4019, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 0.47718867659568787, accuracy: 84.5 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 1.9363149404525757, accuracy: 46.5 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 0.6907348036766052, accuracy: 76.0 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 1.2600200176239014, accuracy: 62.2 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 0.4512096345424652, accuracy: 85.7 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 0.44670262932777405, accuracy: 85.7 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 0.46512895822525024, accuracy: 84.2 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 0.47927379608154297, accuracy: 84.7 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 0.4397183656692505, accuracy: 86.1 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 0.43413105607032776, accuracy: 86.7 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 0.3806, batch time: 0.06, accuracy:  87.50%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 0.5425, batch time: 0.08, accuracy:  89.06%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 0.5433, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 0.4516, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 0.5374, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 0.5304, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 0.8313, batch time: 0.10, accuracy:  75.78%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 0.3694, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 0.4727, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 0.4384, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 0.4942905008792877, accuracy: 85.0 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 1.6344685554504395, accuracy: 52.2 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 0.6354431509971619, accuracy: 79.7 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 1.1919724941253662, accuracy: 67.7 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 0.48806247115135193, accuracy: 84.2 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 0.4805108606815338, accuracy: 85.4 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 0.5047609806060791, accuracy: 83.9 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 0.47477951645851135, accuracy: 84.8 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 0.47249943017959595, accuracy: 84.8 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 0.4710448384284973, accuracy: 85.4 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 0.4127, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 0.4364, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 0.5434, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 0.6328, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 0.5687, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 0.2925, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 0.3915, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 0.5421, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 0.6049, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 0.3871, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 0.5563902854919434, accuracy: 83.7 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 2.4287502765655518, accuracy: 42.5 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 0.7182642817497253, accuracy: 77.7 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 2.2209932804107666, accuracy: 47.6 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 0.5070507526397705, accuracy: 85.4 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 0.5219477415084839, accuracy: 85.0 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 0.5158172845840454, accuracy: 85.5 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 0.5275776386260986, accuracy: 83.9 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 0.5322116613388062, accuracy: 84.5 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 0.502633810043335, accuracy: 84.6 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 0.4841, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 0.6800, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 0.5787, batch time: 0.09, accuracy:  78.12%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 0.3276, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 0.5495, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 0.5568, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 0.4794, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 0.8694, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 0.5499, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 0.4232, batch time: 0.06, accuracy:  87.50%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 0.5790611505508423, accuracy: 83.5 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 0.7828720211982727, accuracy: 75.4 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 0.5515352487564087, accuracy: 84.3 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 0.9551937580108643, accuracy: 68.1 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 0.5505412220954895, accuracy: 84.1 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 0.513472318649292, accuracy: 85.5 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 0.5197750329971313, accuracy: 85.1 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 0.5192950963973999, accuracy: 84.9 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 0.5585713982582092, accuracy: 83.1 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 0.5095508694648743, accuracy: 85.5 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 0.6400, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 0.5063, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 0.7026, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 0.5113, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 0.5209, batch time: 0.04, accuracy:  82.03%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 0.5140, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 0.4248, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 0.4901, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 0.4860, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 0.4031, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 0.5116205215454102, accuracy: 85.0 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 1.456378698348999, accuracy: 56.0 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 1.7252556085586548, accuracy: 55.9 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 1.7210768461227417, accuracy: 61.9 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 0.5098233222961426, accuracy: 84.6 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 0.5396108627319336, accuracy: 83.0 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 0.5052942633628845, accuracy: 85.0 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 0.5021724104881287, accuracy: 85.0 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 0.5008713006973267, accuracy: 85.1 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 0.5008295178413391, accuracy: 85.5 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 0.5460, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 0.4833, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 0.6803, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 0.4357, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 0.3591, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 0.5666, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 0.4018, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 0.5600, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 0.6379, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 0.4051, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 0.4885416626930237, accuracy: 85.3 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 1.4332380294799805, accuracy: 60.4 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 0.5807353854179382, accuracy: 81.8 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 1.1546119451522827, accuracy: 66.3 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 0.4876303970813751, accuracy: 85.4 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 0.5277882814407349, accuracy: 82.4 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 0.47105008363723755, accuracy: 85.3 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 0.4697103202342987, accuracy: 85.3 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 0.5198379755020142, accuracy: 82.2 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 0.5634856224060059, accuracy: 81.2 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 0.4643, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 0.5677, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 0.6631, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 0.4031, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 0.4109, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 0.6895, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 0.6165, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 0.6989, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 0.4812, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 0.4581, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 0.49125394225120544, accuracy: 85.0 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 1.5473896265029907, accuracy: 55.4 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 0.7960308790206909, accuracy: 77.0 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 1.2676222324371338, accuracy: 68.0 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 0.5192779898643494, accuracy: 84.2 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 0.4818306565284729, accuracy: 85.4 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 0.4859856963157654, accuracy: 84.9 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 0.465650349855423, accuracy: 85.2 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 0.4670354127883911, accuracy: 85.7 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 0.4612104892730713, accuracy: 86.0 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 0.4104, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 0.5616, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 0.4620, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 0.6642, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 0.7258, batch time: 0.11, accuracy:  78.12%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 0.4128, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 0.3749, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 0.5430, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 0.6163, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 0.5157, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 0.4983292818069458, accuracy: 85.5 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 1.3952187299728394, accuracy: 56.0 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 0.7097304463386536, accuracy: 77.4 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 1.4849865436553955, accuracy: 58.0 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 0.4991072714328766, accuracy: 84.7 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 0.49929893016815186, accuracy: 84.6 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 0.5798177123069763, accuracy: 80.5 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 0.5034832954406738, accuracy: 84.5 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 0.4779447317123413, accuracy: 86.0 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 0.47562503814697266, accuracy: 86.0 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 0.5661, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 0.4214, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 0.6608, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 0.3654, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 0.4432, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 0.5036, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 0.3787, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 0.4713, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 0.5168, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 0.6912, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 0.5001246929168701, accuracy: 85.3 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 1.2955656051635742, accuracy: 58.3 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 0.6587234735488892, accuracy: 79.8 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 1.0080841779708862, accuracy: 66.0 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 0.5236047506332397, accuracy: 83.8 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 0.5233268141746521, accuracy: 85.0 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 0.484341025352478, accuracy: 85.9 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 0.4803495407104492, accuracy: 86.1 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 0.48014548420906067, accuracy: 86.2 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 0.4780765771865845, accuracy: 86.1 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 0.6161, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 0.5378, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 0.6762, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 0.5336, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 0.5477, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 0.5450, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 0.6306, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 0.6684, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 0.5539, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 0.4588, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 0.5068115592002869, accuracy: 85.1 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 1.5886919498443604, accuracy: 51.6 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 0.7676125168800354, accuracy: 76.2 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 1.57354736328125, accuracy: 58.9 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 0.5389540195465088, accuracy: 83.8 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 0.5299495458602905, accuracy: 82.9 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 0.5457114577293396, accuracy: 83.0 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 0.4946862757205963, accuracy: 85.9 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 0.4927827715873718, accuracy: 85.7 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 0.4953760504722595, accuracy: 85.6 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 0.5063, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 0.4709, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 0.6819, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 0.4249, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 0.5238, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 0.3791, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 0.3883, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 0.3970, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 0.6053, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 0.4780, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 0.5047341585159302, accuracy: 84.0 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 1.578139066696167, accuracy: 57.8 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 0.7751496434211731, accuracy: 77.1 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 0.62114417552948, accuracy: 81.7 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 0.5414926409721375, accuracy: 82.3 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 0.5090490579605103, accuracy: 83.7 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 0.4966486096382141, accuracy: 84.4 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 0.4928280711174011, accuracy: 84.5 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 0.491904616355896, accuracy: 84.3 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 0.4918133318424225, accuracy: 84.8 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 0.6442, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 0.4484, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 0.3822, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 0.5112, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 0.5664, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 0.4591, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 0.3938, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 0.3321, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 0.4629, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 0.5071, batch time: 0.08, accuracy:  87.50%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 0.5266735553741455, accuracy: 83.6 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 1.026091456413269, accuracy: 66.8 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 0.6893960237503052, accuracy: 77.4 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 1.157752275466919, accuracy: 63.4 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 0.545791745185852, accuracy: 82.5 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 0.5615254640579224, accuracy: 81.3 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 0.5491131544113159, accuracy: 83.3 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 0.4941810965538025, accuracy: 85.3 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 0.4852084815502167, accuracy: 85.2 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 0.46951213479042053, accuracy: 85.6 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 0.3654, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 0.5974, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 0.5309, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 0.3896, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 0.6002, batch time: 0.07, accuracy:  85.16%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 0.4616, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 0.5582, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 0.6247, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 0.4175, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 0.6360, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 0.4365531802177429, accuracy: 87.1 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 1.6802351474761963, accuracy: 52.9 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 0.6519389152526855, accuracy: 79.5 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 0.46393638849258423, accuracy: 85.3 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 0.4946887493133545, accuracy: 84.8 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 0.4517001509666443, accuracy: 86.2 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 0.5368991494178772, accuracy: 82.2 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 0.4264014661312103, accuracy: 87.5 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 0.4215664267539978, accuracy: 87.5 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 0.42530134320259094, accuracy: 87.8 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 0.3973, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 0.6004, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 0.3915, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 0.5515, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 0.6034, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 0.5941, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 0.4343, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 0.5610, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 0.5250, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 0.4224, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 0.5146291851997375, accuracy: 85.4 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 1.6725449562072754, accuracy: 50.1 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 0.7491110563278198, accuracy: 76.7 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 2.41294002532959, accuracy: 56.4 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 0.5093650221824646, accuracy: 85.7 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 0.5606763362884521, accuracy: 83.7 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 0.5063316226005554, accuracy: 85.8 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 0.5040963888168335, accuracy: 85.5 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 0.5045093297958374, accuracy: 86.0 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 0.4987941086292267, accuracy: 85.1 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 0.7079, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 0.5268, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 0.6070, batch time: 0.04, accuracy:  81.25%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 0.4068, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 0.5569, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 0.4434, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 0.4025, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 0.3739, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 0.5843, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 0.5543, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 0.48750942945480347, accuracy: 84.4 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 1.688685655593872, accuracy: 50.4 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 0.796253502368927, accuracy: 75.9 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 2.824131488800049, accuracy: 51.5 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 0.5209187269210815, accuracy: 84.0 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 0.5368533134460449, accuracy: 83.4 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 0.4732113480567932, accuracy: 84.8 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 0.4688481092453003, accuracy: 85.1 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 0.47233930230140686, accuracy: 85.4 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 0.46653372049331665, accuracy: 86.0 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 0.3580, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 0.4065, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 0.3724, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 0.4542, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 0.4038, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 0.4525, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 0.4051, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 0.4258, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 0.3278, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 0.5479, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 0.5145032405853271, accuracy: 85.8 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 1.3212791681289673, accuracy: 61.4 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 0.7534107565879822, accuracy: 77.6 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 3.1909475326538086, accuracy: 47.3 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 0.4993613362312317, accuracy: 85.6 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 0.5076015591621399, accuracy: 86.0 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 0.5166622400283813, accuracy: 84.4 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 0.49230682849884033, accuracy: 86.4 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 0.4893161654472351, accuracy: 86.8 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 0.48719075322151184, accuracy: 86.5 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 0.5606, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 0.3502, batch time: 0.12, accuracy:  89.84%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 0.9246, batch time: 0.11, accuracy:  71.88%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 0.4518, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 0.5147, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 0.5382, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 0.6157, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 0.4552, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 0.3622, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 0.3539, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 0.4741038978099823, accuracy: 85.1 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 2.0853657722473145, accuracy: 45.1 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 0.8073627352714539, accuracy: 75.5 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 1.6727687120437622, accuracy: 52.2 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 0.5094946622848511, accuracy: 84.0 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 0.46308284997940063, accuracy: 85.7 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 0.5513429641723633, accuracy: 81.2 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 0.45987027883529663, accuracy: 85.5 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 0.45840078592300415, accuracy: 86.4 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 0.46203938126564026, accuracy: 85.5 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 0.4885, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 0.5245, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 0.3530, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 0.4461, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 0.5754, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 0.4489, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 0.5405, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 0.4044, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 0.5249, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 0.5864, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 0.5249550938606262, accuracy: 84.8 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 1.699648141860962, accuracy: 51.8 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 0.9842420816421509, accuracy: 72.2 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 1.7504420280456543, accuracy: 58.6 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 0.6628722548484802, accuracy: 80.0 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 0.5919846296310425, accuracy: 82.0 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 0.5097677707672119, accuracy: 85.3 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 0.5077454447746277, accuracy: 85.9 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 0.5053537487983704, accuracy: 85.8 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 0.5020918846130371, accuracy: 85.9 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 0.3396, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 0.4148, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 0.6091, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 0.4618, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 0.4113, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 0.4956, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 0.6136, batch time: 0.07, accuracy:  79.69%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 0.4894, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 0.4835, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 0.4008, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 0.48215994238853455, accuracy: 84.9 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 1.5512160062789917, accuracy: 53.7 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 0.7051040530204773, accuracy: 78.1 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 2.443511962890625, accuracy: 51.7 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 0.5566741824150085, accuracy: 82.6 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 0.49063923954963684, accuracy: 84.6 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 0.46821701526641846, accuracy: 84.9 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 0.46693629026412964, accuracy: 85.4 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 0.4682512581348419, accuracy: 85.1 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 0.4667251706123352, accuracy: 85.5 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 0.3897, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 0.4295, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 0.4963, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 0.4125, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 0.4910, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 0.6295, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 0.3824, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 0.5003, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 0.3822, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 0.4023, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 0.45173728466033936, accuracy: 86.7 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 1.8896905183792114, accuracy: 46.9 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 0.7544312477111816, accuracy: 75.7 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 0.7761805057525635, accuracy: 77.9 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 0.4494803547859192, accuracy: 86.8 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 0.4581867456436157, accuracy: 86.8 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 0.44909054040908813, accuracy: 87.0 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 0.4349974989891052, accuracy: 87.4 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 0.4302416741847992, accuracy: 87.5 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 0.42972198128700256, accuracy: 87.4 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 0.4168, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 0.5976, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 0.4397, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 0.4967, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 0.5494, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 0.4986, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 0.5309, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 0.3638, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 0.6781, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 0.3376, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 0.48406943678855896, accuracy: 85.7 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 1.167779564857483, accuracy: 62.1 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 0.6148443818092346, accuracy: 80.3 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 0.6312205791473389, accuracy: 79.7 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 0.4802391529083252, accuracy: 85.6 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 0.5664212703704834, accuracy: 81.6 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 0.49835219979286194, accuracy: 84.5 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 0.45662781596183777, accuracy: 86.4 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 0.4476180970668793, accuracy: 86.8 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 0.4418553411960602, accuracy: 86.2 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 0.3937, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 0.5160, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 0.5152, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 0.5203, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 0.4504, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 0.6328, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 0.4603, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 0.3798, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 0.3903, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 0.6089, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 0.5353959202766418, accuracy: 84.8 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 1.7218767404556274, accuracy: 48.1 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 0.7994881868362427, accuracy: 75.4 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 1.084373950958252, accuracy: 74.3 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 0.5771507024765015, accuracy: 83.1 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 0.5215177536010742, accuracy: 84.5 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 0.5420478582382202, accuracy: 84.8 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 0.5914450287818909, accuracy: 82.4 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 0.5123265385627747, accuracy: 85.6 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 0.5088751316070557, accuracy: 85.2 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 0.3363, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 0.4507, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 0.4169, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 0.4295, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 0.6370, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 0.3491, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 0.3133, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 0.6172, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 0.6921, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 0.5738, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 0.42691364884376526, accuracy: 87.8 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 2.045274496078491, accuracy: 44.1 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 0.9006288647651672, accuracy: 70.2 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 1.872941255569458, accuracy: 49.3 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 0.42112308740615845, accuracy: 87.9 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 0.4808913767337799, accuracy: 84.8 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 0.4168127179145813, accuracy: 87.7 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 0.4162564277648926, accuracy: 88.1 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 0.41234129667282104, accuracy: 88.1 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 0.407758891582489, accuracy: 87.7 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 0.5061, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 0.4733, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 0.6126, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 0.4173, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 0.5040, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 0.3962, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 0.6469, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 0.4295, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 0.5557, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 0.4189, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 0.5189462304115295, accuracy: 84.2 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 1.6494932174682617, accuracy: 50.7 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 1.2717124223709106, accuracy: 65.6 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 0.9306466579437256, accuracy: 70.6 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 0.5048564076423645, accuracy: 84.1 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 0.4866386353969574, accuracy: 84.6 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 0.4817148745059967, accuracy: 85.1 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 0.4811078608036041, accuracy: 84.8 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 0.47356244921684265, accuracy: 85.5 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 0.5426473617553711, accuracy: 81.1 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 0.4478, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 0.4033, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 0.4104, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 0.4958, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 0.4729, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 0.3759, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 0.3482, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 0.4290, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 0.4108, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 0.5669, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 0.46085816621780396, accuracy: 88.0 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 2.1359918117523193, accuracy: 43.7 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 0.49609702825546265, accuracy: 86.2 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 0.5417978167533875, accuracy: 85.7 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 0.5046572685241699, accuracy: 85.3 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 0.4443822205066681, accuracy: 88.0 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 0.505429208278656, accuracy: 85.9 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 0.4485725164413452, accuracy: 87.2 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 0.4359267055988312, accuracy: 87.8 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 0.4327147305011749, accuracy: 87.8 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 0.4565, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 0.4473, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 0.5617, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 0.4074, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 0.4815, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 0.3804, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 0.5301, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 0.4516, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 0.3009, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 0.5822, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 0.4627529978752136, accuracy: 86.0 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 1.6609692573547363, accuracy: 50.8 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 0.5142876505851746, accuracy: 83.6 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 0.5771900415420532, accuracy: 81.5 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 0.7355895638465881, accuracy: 74.6 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 0.45443060994148254, accuracy: 86.3 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 0.4465938210487366, accuracy: 86.7 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 0.4415420591831207, accuracy: 87.0 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 0.4445721507072449, accuracy: 87.1 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 0.4409375786781311, accuracy: 87.5 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 0.4920, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 0.4281, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 0.7037, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 0.5003, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 0.5799, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 0.5892, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 0.4410, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 0.5683, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 0.5323, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 0.5927, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 0.46401408314704895, accuracy: 85.7 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 2.243636131286621, accuracy: 43.9 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 0.49781668186187744, accuracy: 84.2 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 1.1471445560455322, accuracy: 69.6 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 0.4973098039627075, accuracy: 83.8 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 0.6498318314552307, accuracy: 78.7 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 0.4467966556549072, accuracy: 85.9 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 0.4455808699131012, accuracy: 86.5 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 0.4424937665462494, accuracy: 86.2 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 0.44564446806907654, accuracy: 85.3 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 0.2952, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 0.6085, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 0.4876, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 0.4291, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 0.4845, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 0.3444, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 0.5864, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 0.5534, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 0.3836, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 0.4417, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 0.5024778842926025, accuracy: 85.0 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 1.7338409423828125, accuracy: 52.1 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 1.0218915939331055, accuracy: 67.1 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 5.295348644256592, accuracy: 46.2 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 0.5181443095207214, accuracy: 84.3 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 0.4971836805343628, accuracy: 85.7 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 0.48612165451049805, accuracy: 85.6 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 0.4842011034488678, accuracy: 85.6 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 0.4870655834674835, accuracy: 85.9 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 0.48173561692237854, accuracy: 86.6 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 0.6924, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 0.5354, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 0.4798, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 0.4876, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 0.5368, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 0.3707, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 0.4731, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 0.4422, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 0.4332, batch time: 0.06, accuracy:  84.38%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 0.3263, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 0.47506484389305115, accuracy: 85.0 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 1.4560476541519165, accuracy: 55.9 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 0.7403174638748169, accuracy: 77.3 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 1.232543706893921, accuracy: 63.5 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 0.5601884722709656, accuracy: 82.6 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 0.4992021322250366, accuracy: 85.3 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 0.4879113435745239, accuracy: 84.6 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 0.4547044634819031, accuracy: 86.1 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 0.4493962526321411, accuracy: 86.9 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 0.4496064782142639, accuracy: 86.7 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 0.4512, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 0.3770, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 0.5444, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 0.4277, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 0.5861, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 0.4614, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 0.3599, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 0.3764, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 0.5624, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 0.4388, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 0.5082057118415833, accuracy: 87.4 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 1.6766045093536377, accuracy: 53.0 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 0.5811935067176819, accuracy: 84.4 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 2.6886162757873535, accuracy: 53.5 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 0.5285945534706116, accuracy: 85.8 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 0.5250247120857239, accuracy: 86.7 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 0.4951450824737549, accuracy: 87.6 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 0.4909225404262543, accuracy: 87.5 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 0.489441454410553, accuracy: 87.5 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 0.49067145586013794, accuracy: 87.9 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 0.3777, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 0.4986, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 0.4804, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 0.6248, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 0.5114, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 0.4919, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 0.5507, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 0.5599, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 0.5458, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 0.5624, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 0.45830145478248596, accuracy: 85.6 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 1.9301201105117798, accuracy: 45.4 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 1.1162272691726685, accuracy: 67.2 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 1.6747958660125732, accuracy: 51.9 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 0.4778158664703369, accuracy: 84.3 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 0.4503369927406311, accuracy: 85.8 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 0.4643954932689667, accuracy: 85.1 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 0.4375957250595093, accuracy: 86.1 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 0.4348132610321045, accuracy: 85.7 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 0.44217923283576965, accuracy: 86.1 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 0.8904, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 0.3776, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 0.3811, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 0.2907, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 0.4286, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 0.4135, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 0.3022, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 0.5076, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 0.3624, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 0.8176, batch time: 0.10, accuracy:  75.78%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 0.41991570591926575, accuracy: 87.4 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 1.8476905822753906, accuracy: 47.2 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 0.7077924013137817, accuracy: 77.2 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 1.3180264234542847, accuracy: 69.5 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 0.4102019667625427, accuracy: 87.5 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 0.47514358162879944, accuracy: 84.2 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 0.4967796206474304, accuracy: 83.6 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 0.4030153453350067, accuracy: 87.9 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 0.4010658860206604, accuracy: 87.5 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 0.3942834138870239, accuracy: 88.4 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 0.4112, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 0.2940, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 0.5416, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 0.4178, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 0.3495, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 0.4062, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 0.3253, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 0.5652, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 0.3884, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 0.4289, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 0.47468602657318115, accuracy: 86.7 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 1.4794819355010986, accuracy: 56.6 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 0.5934339165687561, accuracy: 80.7 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 1.1844197511672974, accuracy: 74.4 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 0.473496675491333, accuracy: 85.3 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 0.4595871567726135, accuracy: 86.3 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 0.6192968487739563, accuracy: 81.9 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 0.45303821563720703, accuracy: 86.7 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 0.4476298689842224, accuracy: 87.0 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 0.4437081217765808, accuracy: 87.4 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 0.4599, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 0.3940, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 0.3942, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 0.4862, batch time: 0.07, accuracy:  82.81%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 0.3891, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 0.5198, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 0.5207, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 0.5787, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 0.4838, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 0.5319, batch time: 0.04, accuracy:  81.25%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 0.43837234377861023, accuracy: 85.6 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 1.7712219953536987, accuracy: 49.8 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 0.5024675726890564, accuracy: 83.5 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 3.4917609691619873, accuracy: 40.1 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 0.4340122938156128, accuracy: 86.2 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 0.4484732747077942, accuracy: 84.7 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 0.4025648832321167, accuracy: 87.4 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 0.4029677212238312, accuracy: 87.4 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 0.40144872665405273, accuracy: 86.6 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 0.4001663625240326, accuracy: 87.2 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 0.4209, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 0.4776, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 0.4922, batch time: 0.04, accuracy:  82.81%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 0.3792, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 0.3921, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 0.3473, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 0.5318, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 0.3395, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 0.5137, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 0.4461, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 0.5179067850112915, accuracy: 85.3 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 1.0681594610214233, accuracy: 67.1 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 0.854718804359436, accuracy: 75.4 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 1.2009230852127075, accuracy: 66.4 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 0.5514020919799805, accuracy: 82.3 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 0.5208779573440552, accuracy: 84.0 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 0.5075548887252808, accuracy: 85.4 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 0.5204344987869263, accuracy: 84.3 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 0.5023399591445923, accuracy: 85.4 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 0.4770781397819519, accuracy: 86.3 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 0.2857, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 0.4678, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 0.4822, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 0.4480, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 0.5468, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 0.5725, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 0.4417, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 0.6023, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 0.4382, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 0.4532, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 0.424483060836792, accuracy: 86.3 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 1.3557595014572144, accuracy: 57.7 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 0.5423612594604492, accuracy: 81.6 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 3.152967691421509, accuracy: 47.8 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 0.48936396837234497, accuracy: 83.6 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 0.43650028109550476, accuracy: 86.9 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 0.4145053029060364, accuracy: 87.4 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 0.4148024916648865, accuracy: 87.7 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 0.41350337862968445, accuracy: 87.0 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 0.41295892000198364, accuracy: 87.5 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 0.4183, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 0.5164, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 0.4877, batch time: 0.07, accuracy:  83.59%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 0.6073, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 0.3139, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 0.4234, batch time: 0.08, accuracy:  87.50%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 0.4126, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 0.4161, batch time: 0.08, accuracy:  85.94%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 0.5606, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 0.5203, batch time: 0.07, accuracy:  84.38%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 0.4398079812526703, accuracy: 87.7 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 1.521175503730774, accuracy: 52.1 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 0.54422926902771, accuracy: 82.4 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 1.54035222530365, accuracy: 53.2 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 0.48386093974113464, accuracy: 85.1 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 0.456003338098526, accuracy: 86.6 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 0.4164028465747833, accuracy: 87.5 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 0.41297048330307007, accuracy: 88.6 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 0.4091540277004242, accuracy: 87.9 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 0.4124528765678406, accuracy: 88.3 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 0.3806, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 0.2857, batch time: 0.44, accuracy:  92.19%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 0.5097, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 0.4948, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 0.3757, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 0.2993, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 0.5808, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 0.4012, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 0.5992, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 0.4851, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 0.46278440952301025, accuracy: 86.8 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 1.207643747329712, accuracy: 58.6 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 0.5649927854537964, accuracy: 80.7 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 3.367823839187622, accuracy: 43.2 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 0.5331341624259949, accuracy: 82.4 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 0.48507368564605713, accuracy: 84.3 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 0.43857210874557495, accuracy: 87.3 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 0.43532794713974, accuracy: 87.4 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 0.4319535493850708, accuracy: 87.7 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 0.4319368004798889, accuracy: 87.7 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 0.4928, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 0.4657, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 0.4280, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 0.5004, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 0.4389, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 0.3631, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 0.6631, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 0.6797, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 0.5318, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 0.4448, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 0.4132922887802124, accuracy: 87.1 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 1.2733250856399536, accuracy: 57.8 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 0.5580335855484009, accuracy: 80.6 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 2.6543240547180176, accuracy: 45.0 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 0.40878379344940186, accuracy: 87.5 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 0.4074965715408325, accuracy: 87.9 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 0.3914291560649872, accuracy: 87.8 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 0.3873637020587921, accuracy: 88.3 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 0.3816547989845276, accuracy: 88.2 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 0.37850961089134216, accuracy: 88.6 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 0.3598, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 0.5056, batch time: 0.04, accuracy:  83.59%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 0.5819, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 0.4455, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 0.4097, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 0.5063, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 0.3902, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 0.6638, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 0.5756, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 0.6173, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 0.4914006292819977, accuracy: 85.0 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 1.4234654903411865, accuracy: 55.7 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 0.579478919506073, accuracy: 81.6 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 1.3245892524719238, accuracy: 58.5 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 0.4728042781352997, accuracy: 86.3 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 0.47549229860305786, accuracy: 84.9 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 0.497287780046463, accuracy: 85.1 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 0.46327459812164307, accuracy: 85.7 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 0.4577139616012573, accuracy: 85.7 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 0.4542664885520935, accuracy: 85.8 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 0.5371, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 0.4828, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 0.6527, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 0.3197, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 0.5099, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 0.4081, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 0.5782, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 0.5830, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 0.5078, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 0.5629, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 0.443899542093277, accuracy: 86.8 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 1.925344705581665, accuracy: 44.2 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 0.6684309840202332, accuracy: 79.8 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 0.5238994359970093, accuracy: 83.7 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 0.4557884633541107, accuracy: 86.0 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 0.4213283061981201, accuracy: 86.1 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 0.4231022894382477, accuracy: 86.2 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 0.4162878096103668, accuracy: 86.6 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 0.41494330763816833, accuracy: 86.7 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 0.4106198847293854, accuracy: 86.7 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 0.3467, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 0.5168, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 0.4405, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 0.4630, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 0.4097, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 0.5244, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 0.4194, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 0.5021, batch time: 0.06, accuracy:  88.28%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 0.4336, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 0.3920, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 0.4311496913433075, accuracy: 87.3 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 1.3931665420532227, accuracy: 53.9 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 0.5323914289474487, accuracy: 81.7 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 3.33217716217041, accuracy: 44.6 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 0.4748326539993286, accuracy: 86.6 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 0.5198323726654053, accuracy: 83.2 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 0.4283409118652344, accuracy: 87.9 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 0.4386233985424042, accuracy: 87.1 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 0.4257684051990509, accuracy: 88.0 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 0.42496615648269653, accuracy: 88.0 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 0.6186, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 0.4896, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 0.3770, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 0.2896, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 0.4717, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 0.4274, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 0.5481, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 0.3686, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 0.4114, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 0.3629, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 0.45831364393234253, accuracy: 85.7 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 1.8674006462097168, accuracy: 48.3 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 0.48349666595458984, accuracy: 84.4 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 0.7914022207260132, accuracy: 75.7 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 0.4809251129627228, accuracy: 85.0 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 0.47261059284210205, accuracy: 85.5 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 0.42590245604515076, accuracy: 87.4 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 0.42273783683776855, accuracy: 87.4 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 0.4199197292327881, accuracy: 87.7 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 0.4172504246234894, accuracy: 87.1 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 0.4418, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 0.4458, batch time: 0.08, accuracy:  87.50%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 0.4957, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 0.6224, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 0.3830, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 0.3689, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 0.3943, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 0.5263, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 0.3011, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 0.3816, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 0.5071665048599243, accuracy: 85.0 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 3.6519575119018555, accuracy: 30.4 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 1.0561747550964355, accuracy: 65.2 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 0.5971096158027649, accuracy: 82.1 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 0.5553147196769714, accuracy: 84.0 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 0.520444393157959, accuracy: 85.4 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 0.4790259897708893, accuracy: 85.6 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 0.47155463695526123, accuracy: 85.9 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 0.47174081206321716, accuracy: 86.4 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 0.46898308396339417, accuracy: 86.2 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 0.4443, batch time: 0.04, accuracy:  82.81%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 0.3849, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 0.5420, batch time: 0.04, accuracy:  83.59%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 0.4999, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 0.4596, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 0.8032, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 0.6014, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 0.4466, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 0.5662, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 0.5955, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 0.4508626163005829, accuracy: 87.2 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 1.1836446523666382, accuracy: 61.6 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 0.52964186668396, accuracy: 83.8 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 4.278932094573975, accuracy: 38.9 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 0.4610207676887512, accuracy: 87.3 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 0.44470641016960144, accuracy: 87.1 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 0.43482813239097595, accuracy: 87.7 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 0.4331185817718506, accuracy: 87.8 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 0.4302624762058258, accuracy: 88.1 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 0.4280472993850708, accuracy: 88.2 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 0.4329, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 0.4776, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 0.5835, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 0.3791, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 0.5216, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 0.3331, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 0.5488, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 0.3427, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 0.3820, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 0.6475, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 0.5096386671066284, accuracy: 84.3 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 1.5017505884170532, accuracy: 54.7 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 0.776289701461792, accuracy: 76.8 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 0.5371724963188171, accuracy: 83.9 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 0.6077078580856323, accuracy: 81.1 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 0.5707910060882568, accuracy: 81.0 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 0.5254690051078796, accuracy: 83.2 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 0.4989178478717804, accuracy: 84.5 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 0.496246874332428, accuracy: 84.5 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 0.49386847019195557, accuracy: 84.8 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 0.2939, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 0.4130, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 0.5484, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 0.5601, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 0.4113, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 0.5637, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 0.4693, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 0.3876, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 0.4628, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 0.3916, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 0.41682279109954834, accuracy: 85.9 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 2.0756916999816895, accuracy: 45.1 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 0.7423264384269714, accuracy: 78.5 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 3.0300261974334717, accuracy: 43.3 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 0.4415147304534912, accuracy: 84.2 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 0.3850039839744568, accuracy: 87.2 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 0.4385928809642792, accuracy: 85.7 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 0.38129085302352905, accuracy: 87.6 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 0.3781064748764038, accuracy: 87.0 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 0.37707117199897766, accuracy: 87.5 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 0.4872, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 0.5145, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 0.4304, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 0.6699, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 0.4366, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 0.4371, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 0.5860, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 0.5709, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 0.4999, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 0.3700, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 0.4750206172466278, accuracy: 84.9 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 1.596423625946045, accuracy: 52.0 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 0.7367680668830872, accuracy: 78.6 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 5.253754615783691, accuracy: 28.3 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 0.5251131653785706, accuracy: 84.3 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 0.4953346252441406, accuracy: 83.9 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 0.46643397212028503, accuracy: 85.1 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 0.45798954367637634, accuracy: 86.3 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 0.4695102870464325, accuracy: 85.9 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 0.4563044309616089, accuracy: 85.9 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 0.7337, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 0.4353, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 0.3291, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 0.6210, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 0.4188, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 0.6199, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 0.4471, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 0.3794, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 0.4436, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 0.5889, batch time: 0.04, accuracy:  82.03%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 0.4957299530506134, accuracy: 86.5 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 1.6872336864471436, accuracy: 50.7 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 0.7888138294219971, accuracy: 78.1 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 0.5587431788444519, accuracy: 82.4 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 0.5011741518974304, accuracy: 85.9 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 0.6213562488555908, accuracy: 80.7 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 0.5049898624420166, accuracy: 86.2 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 0.46175283193588257, accuracy: 86.7 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 0.4595138430595398, accuracy: 86.7 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 0.4567161500453949, accuracy: 86.8 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 0.4329, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 0.3541, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 0.5926, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 0.4203, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 0.3677, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 0.4910, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 0.5102, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 0.7392, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 0.4246, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 0.5387, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 0.5297580361366272, accuracy: 85.3 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 1.5796297788619995, accuracy: 55.0 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 0.7634842395782471, accuracy: 78.2 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 1.1136420965194702, accuracy: 69.5 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 0.544487476348877, accuracy: 84.3 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 0.6442755460739136, accuracy: 80.2 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 0.5044375061988831, accuracy: 85.8 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 0.503878116607666, accuracy: 85.1 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 0.5029453039169312, accuracy: 85.4 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 0.5057553648948669, accuracy: 86.2 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 0.4245, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 0.3388, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 0.3558, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 0.4863, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 0.4604, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 0.5749, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 0.4333, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 0.6542, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 0.5004, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 0.5529, batch time: 0.08, accuracy:  80.47%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 0.48215624690055847, accuracy: 85.5 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 1.6356006860733032, accuracy: 52.0 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 0.7844114303588867, accuracy: 77.9 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 1.2832142114639282, accuracy: 66.3 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 0.5364910960197449, accuracy: 83.5 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 0.4768463969230652, accuracy: 86.4 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 0.47199296951293945, accuracy: 86.0 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 0.4725942313671112, accuracy: 86.1 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 0.47603175044059753, accuracy: 85.7 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 0.46931856870651245, accuracy: 86.2 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 0.5397, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 0.4163, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 0.3361, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 0.3335, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 0.5506, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 0.3853, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 0.6105, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 0.3690, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 0.5430, batch time: 0.44, accuracy:  82.81%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 0.4368, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 0.44768619537353516, accuracy: 84.9 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 1.7193952798843384, accuracy: 51.3 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 0.698611855506897, accuracy: 79.8 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 1.1118427515029907, accuracy: 62.8 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 0.4536499083042145, accuracy: 85.0 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 0.4167817234992981, accuracy: 85.8 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 0.456886351108551, accuracy: 84.8 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 0.4084540903568268, accuracy: 86.0 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 0.40761661529541016, accuracy: 86.5 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 0.4062962532043457, accuracy: 86.5 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 0.4007, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 0.4945, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 0.2833, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 0.4355, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 0.4029, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 0.4733, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 0.5105, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 0.4651, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 0.5205, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 0.3796, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 0.4933888912200928, accuracy: 84.7 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 3.059828996658325, accuracy: 38.5 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 1.1283509731292725, accuracy: 67.5 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 1.3087642192840576, accuracy: 59.2 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 0.46507954597473145, accuracy: 85.5 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 0.5052034854888916, accuracy: 85.5 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 0.4432136118412018, accuracy: 86.7 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 0.5775607228279114, accuracy: 80.2 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 0.425424724817276, accuracy: 87.1 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 0.4240342676639557, accuracy: 87.3 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 0.4444, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 0.6044, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 0.4134, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 0.5224, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 0.4674, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 0.3264, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 0.3025, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 0.4797, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 0.3726, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 0.4692, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 0.4914885461330414, accuracy: 85.7 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 1.3329323530197144, accuracy: 56.1 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 0.6752903461456299, accuracy: 78.3 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 0.8650147318840027, accuracy: 74.1 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 0.5386084914207458, accuracy: 82.1 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 0.5578793287277222, accuracy: 80.6 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 0.43981412053108215, accuracy: 86.3 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 0.43415719270706177, accuracy: 86.6 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 0.4294250011444092, accuracy: 86.9 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 0.42629754543304443, accuracy: 86.3 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 0.4633, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 0.3662, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 0.3559, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 0.4819, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 0.3181, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 0.5287, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 0.5061, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 0.4335, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 0.5559, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 0.4571, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 0.39409908652305603, accuracy: 88.7 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 1.6372054815292358, accuracy: 49.2 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 0.6699973344802856, accuracy: 81.8 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 0.8300093412399292, accuracy: 72.1 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 0.4639407694339752, accuracy: 85.7 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 0.3872067928314209, accuracy: 88.6 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 0.3916715383529663, accuracy: 88.6 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 0.3899621069431305, accuracy: 89.3 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 0.3827684819698334, accuracy: 88.6 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 0.38020890951156616, accuracy: 88.8 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 0.3155, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 0.4059, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 0.4338, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 0.4147, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 0.5143, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 0.4338, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 0.4356, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 0.5152, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 0.3875, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 0.3284, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 0.41108566522598267, accuracy: 87.2 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 1.7159106731414795, accuracy: 49.8 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 0.6432995200157166, accuracy: 78.8 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 4.290865421295166, accuracy: 40.9 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 0.41560739278793335, accuracy: 86.4 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 0.476936399936676, accuracy: 85.8 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 0.403577595949173, accuracy: 86.9 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 0.39616265892982483, accuracy: 87.7 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 0.3957021236419678, accuracy: 87.8 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 0.39286157488822937, accuracy: 88.0 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 0.4400, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 0.5352, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 0.5039, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 0.3446, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 0.5018, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 0.3555, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 0.4136, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 0.4399, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 0.2700, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 0.5156, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 0.4755552411079407, accuracy: 85.8 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 1.695372223854065, accuracy: 50.1 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 0.6475517153739929, accuracy: 79.3 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 4.397052764892578, accuracy: 40.7 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 0.5368577241897583, accuracy: 82.8 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 0.49577587842941284, accuracy: 84.3 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 0.471660315990448, accuracy: 85.5 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 0.4678772985935211, accuracy: 86.0 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 0.46734780073165894, accuracy: 86.0 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 0.46755069494247437, accuracy: 85.7 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 0.3954, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 0.4010, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 0.4861, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 0.3410, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 0.4202, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 0.3941, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 0.5734, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 0.4632, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 0.4802, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 0.4232, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 0.4625636637210846, accuracy: 85.1 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 1.8797409534454346, accuracy: 45.9 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 0.59284907579422, accuracy: 80.3 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 1.6200757026672363, accuracy: 52.4 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 0.4409114718437195, accuracy: 86.4 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 0.43952232599258423, accuracy: 86.2 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 0.47705692052841187, accuracy: 84.9 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 0.45144498348236084, accuracy: 85.8 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 0.526823103427887, accuracy: 82.9 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 0.44580352306365967, accuracy: 85.5 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 0.3746, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 0.5538, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 0.4041, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 0.4770, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 0.5509, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 0.3841, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 0.5398, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 0.4085, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 0.4486, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 0.5018, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 0.43742504715919495, accuracy: 87.1 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 1.6873425245285034, accuracy: 51.3 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 0.6146838665008545, accuracy: 79.4 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 0.7413446307182312, accuracy: 74.9 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 0.5060304999351501, accuracy: 84.6 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 0.5488654971122742, accuracy: 81.9 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 0.4199634790420532, accuracy: 88.4 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 0.41776666045188904, accuracy: 88.1 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 0.41695669293403625, accuracy: 88.3 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 0.41736242175102234, accuracy: 88.2 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 0.4700, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 0.4160, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 0.4335, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 0.4917, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 0.2773, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 0.4920, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 0.4574, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 0.5183, batch time: 0.04, accuracy:  82.03%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 0.4103, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 0.6739, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 0.4354326128959656, accuracy: 87.2 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 1.2242530584335327, accuracy: 59.7 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 0.677415132522583, accuracy: 79.9 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 3.7747175693511963, accuracy: 41.8 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 0.49078360199928284, accuracy: 83.5 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 0.4280860126018524, accuracy: 87.5 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 0.4114472270011902, accuracy: 87.6 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 0.4152604341506958, accuracy: 87.0 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 0.4078752100467682, accuracy: 87.8 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 0.40541428327560425, accuracy: 87.7 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 0.3768, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 0.3760, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 0.4842, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 0.5021, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 0.3755, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 0.4415, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 0.4081, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 0.5879, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 0.4550, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 0.3104, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 0.42019665241241455, accuracy: 87.6 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 1.4382678270339966, accuracy: 56.2 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 0.7322399020195007, accuracy: 80.8 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 4.920960426330566, accuracy: 37.9 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 0.49392229318618774, accuracy: 83.0 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 0.5063962936401367, accuracy: 84.4 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 0.3991393446922302, accuracy: 88.3 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 0.3973502516746521, accuracy: 87.8 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 0.3951427936553955, accuracy: 88.2 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 0.396438866853714, accuracy: 87.9 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 0.4702, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 0.5593, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 0.6287, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 0.5780, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 0.4202, batch time: 0.06, accuracy:  89.06%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 0.3562, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 0.4380, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 0.4248, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 0.4170, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 0.3405, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 0.46101436018943787, accuracy: 86.8 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 1.2661077976226807, accuracy: 57.7 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 0.7588893175125122, accuracy: 79.0 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 0.7461084127426147, accuracy: 77.0 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 0.5106884837150574, accuracy: 83.2 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 0.6082515716552734, accuracy: 81.1 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 0.424714058637619, accuracy: 87.7 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 0.4242801070213318, accuracy: 86.8 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 0.4195600152015686, accuracy: 87.7 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 0.4268381595611572, accuracy: 87.4 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 0.6231, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 0.5564, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 0.6205, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 0.4774, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 0.5854, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 0.4531, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 0.4184, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 0.5291, batch time: 0.06, accuracy:  87.50%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 0.4034, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 0.4582, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 0.4693163335323334, accuracy: 86.0 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 1.5763782262802124, accuracy: 50.4 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 0.7075935006141663, accuracy: 79.5 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 4.8355712890625, accuracy: 37.1 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 0.501112699508667, accuracy: 85.0 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 0.5035580992698669, accuracy: 83.9 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 0.4624882936477661, accuracy: 86.2 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 0.4597211480140686, accuracy: 86.4 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 0.4599802494049072, accuracy: 86.2 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 0.4555011987686157, accuracy: 86.3 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 0.4008, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 0.4241, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 0.4389, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 0.7426, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 0.4461, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 0.3783, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 0.4494, batch time: 0.07, accuracy:  85.94%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 0.5048, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 0.3646, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 0.5233, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 0.4258391857147217, accuracy: 88.1 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 1.5039663314819336, accuracy: 53.3 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 0.6114755868911743, accuracy: 79.8 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 0.4616265892982483, accuracy: 86.3 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 0.5826626420021057, accuracy: 83.4 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 0.42809340357780457, accuracy: 87.1 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 0.42002153396606445, accuracy: 88.4 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 0.4210512936115265, accuracy: 88.2 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 0.4160991609096527, accuracy: 88.4 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 0.41577231884002686, accuracy: 88.2 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 0.4021, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 0.4344, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 0.4250, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 0.4646, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 0.4167, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 0.5645, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 0.4589, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 0.4857, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 0.3995, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 0.5859, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 0.426298052072525, accuracy: 87.9 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 1.226894736289978, accuracy: 58.8 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 0.6564397811889648, accuracy: 79.5 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 1.8192448616027832, accuracy: 56.1 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 0.41628873348236084, accuracy: 88.5 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 0.42976364493370056, accuracy: 87.5 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 0.44350433349609375, accuracy: 87.2 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 0.5042359232902527, accuracy: 85.5 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 0.4166403114795685, accuracy: 87.9 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 0.5527571439743042, accuracy: 82.0 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 0.5151, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 0.3686, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 0.3555, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 0.3463, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 0.4009, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 0.4640, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 0.4254, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 0.4331, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 0.3610, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 0.3746, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 0.4019418954849243, accuracy: 88.2 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 1.381494402885437, accuracy: 56.1 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 0.552113950252533, accuracy: 81.5 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 4.3456830978393555, accuracy: 41.3 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 0.4421311914920807, accuracy: 87.2 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 0.4441312551498413, accuracy: 87.4 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 0.3880825340747833, accuracy: 88.2 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 0.384152889251709, accuracy: 88.5 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 0.38187655806541443, accuracy: 89.3 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 0.3806702494621277, accuracy: 88.8 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 0.6324, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 0.3807, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 0.6679, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 0.2531, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 0.5994, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 0.3227, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 0.6224, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 0.3815, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 0.5346, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 0.4051, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 0.42063674330711365, accuracy: 88.3 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 1.2609899044036865, accuracy: 58.3 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 0.6050076484680176, accuracy: 79.8 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 2.4049787521362305, accuracy: 44.2 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 0.4333110749721527, accuracy: 87.5 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 0.5636622309684753, accuracy: 80.9 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 0.4110150635242462, accuracy: 88.8 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 0.4051876962184906, accuracy: 89.0 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 0.4046303629875183, accuracy: 89.4 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 0.4138728082180023, accuracy: 88.1 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 0.4430, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 0.3543, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 0.4446, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 0.4626, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 0.4602, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 0.4116, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 0.3961, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 0.4611, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 0.7114, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 0.4434, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 0.42166441679000854, accuracy: 86.5 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 1.4356064796447754, accuracy: 55.9 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 0.5448191165924072, accuracy: 82.3 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 5.478291034698486, accuracy: 33.6 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 0.4354479908943176, accuracy: 85.9 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 0.502036452293396, accuracy: 83.3 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 0.41194164752960205, accuracy: 86.6 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 0.41064468026161194, accuracy: 86.9 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 0.4112739861011505, accuracy: 86.8 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 0.40965819358825684, accuracy: 86.9 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 0.2741, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 0.3180, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 0.5367, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 0.5836, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 0.3934, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 0.4888, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 0.5876, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 0.4535, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 0.3635, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 0.5186, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 0.46762901544570923, accuracy: 85.3 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 1.1323646306991577, accuracy: 60.7 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 0.7090261578559875, accuracy: 78.1 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 5.935022354125977, accuracy: 27.7 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 0.5079649686813354, accuracy: 83.8 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 0.4808312952518463, accuracy: 84.4 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 0.4543643295764923, accuracy: 85.9 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 0.4460732638835907, accuracy: 86.2 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 0.44241130352020264, accuracy: 86.2 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 0.4404359757900238, accuracy: 86.5 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 0.4311, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 0.4904, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 0.5578, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 0.4512, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 0.6936, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 0.3454, batch time: 0.07, accuracy:  91.41%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 0.3529, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 0.3809, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 0.5588, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 0.4263, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 0.44024622440338135, accuracy: 86.5 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 1.0876060724258423, accuracy: 63.2 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 0.7350224852561951, accuracy: 80.4 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 0.9698981642723083, accuracy: 66.3 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 0.4389328062534332, accuracy: 87.4 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 0.4266015589237213, accuracy: 88.2 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 0.4218156933784485, accuracy: 88.2 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 0.4173683822154999, accuracy: 88.1 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 0.4181593656539917, accuracy: 88.1 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 0.41777530312538147, accuracy: 87.9 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 0.5337, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 0.4773, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 0.4189, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 0.4360, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 0.4549, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 0.5191, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 0.4954, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 0.4993, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 0.3125, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 0.3277, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 0.4678494930267334, accuracy: 84.8 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 2.2151408195495605, accuracy: 42.0 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 0.6127874255180359, accuracy: 81.3 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 2.600616931915283, accuracy: 51.2 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 0.5076274275779724, accuracy: 82.8 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 0.4387543797492981, accuracy: 86.2 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 0.46371084451675415, accuracy: 85.2 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 0.4273175001144409, accuracy: 86.4 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 0.4257085919380188, accuracy: 86.5 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 0.4238705635070801, accuracy: 86.4 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 0.4289, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 0.5039, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 0.4557, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 0.3679, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 0.3989, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 0.4084, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 0.6454, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 0.5307, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 0.3660, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 0.4862, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 0.46505194902420044, accuracy: 85.7 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 1.2805794477462769, accuracy: 58.0 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 0.644514262676239, accuracy: 80.2 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 5.759737491607666, accuracy: 29.9 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 0.5025818347930908, accuracy: 85.7 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 0.5606400370597839, accuracy: 81.9 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 0.45324447751045227, accuracy: 86.5 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 0.4525045156478882, accuracy: 86.2 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 0.45248323678970337, accuracy: 86.4 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 0.4533889889717102, accuracy: 86.3 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 0.6426, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 0.5665, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 0.3575, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 0.4236, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 0.3953, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 0.4878, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 0.5245, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 0.5659, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 0.4884, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 0.3456, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 0.46741771697998047, accuracy: 84.2 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 1.1134670972824097, accuracy: 63.3 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 0.7052342295646667, accuracy: 77.4 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 2.342529058456421, accuracy: 57.4 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 0.4819059371948242, accuracy: 83.9 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 0.6713122129440308, accuracy: 79.6 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 0.4494556188583374, accuracy: 85.0 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 0.4425947666168213, accuracy: 85.4 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 0.43992504477500916, accuracy: 85.3 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 0.43889477849006653, accuracy: 85.2 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 0.3638, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 0.3829, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 0.7441, batch time: 0.10, accuracy:  76.56%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 0.5357, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 0.3964, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 0.3922, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 0.6388, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 0.3791, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 0.5743, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 0.3889, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 0.5393141508102417, accuracy: 84.4 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 1.7833753824234009, accuracy: 48.5 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 0.7987532019615173, accuracy: 77.4 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 4.918396949768066, accuracy: 37.4 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 0.5411688685417175, accuracy: 83.3 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 0.5426003932952881, accuracy: 84.1 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 0.5233085751533508, accuracy: 84.1 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 0.5131774544715881, accuracy: 84.6 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 0.5153202414512634, accuracy: 84.4 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 0.517077624797821, accuracy: 83.5 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 0.3048, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 0.5574, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 0.4772, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 0.4032, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 0.5615, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 0.4774, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 0.4873, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 0.4116, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 0.4224, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 0.3018, batch time: 0.08, accuracy:  89.84%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 0.4915340542793274, accuracy: 86.6 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 1.4163312911987305, accuracy: 54.4 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 0.7145214676856995, accuracy: 80.4 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 1.5365879535675049, accuracy: 62.8 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 0.4773445427417755, accuracy: 87.2 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 0.5531156063079834, accuracy: 84.6 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 0.4753968119621277, accuracy: 86.9 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 0.47110599279403687, accuracy: 86.9 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 0.47182488441467285, accuracy: 87.2 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 0.47068193554878235, accuracy: 87.6 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 0.4914, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 0.3126, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 0.4575, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 0.4242, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 0.4014, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 0.5609, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 0.4451, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 0.5533, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 0.4894, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 0.6864, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 0.4899244010448456, accuracy: 85.7 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 1.5823372602462769, accuracy: 48.3 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 0.668787956237793, accuracy: 77.2 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 0.676176130771637, accuracy: 79.5 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 0.5759247541427612, accuracy: 82.5 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 0.4725258946418762, accuracy: 86.6 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 0.5026739835739136, accuracy: 85.4 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 0.4677390158176422, accuracy: 86.8 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 0.4640413224697113, accuracy: 86.9 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 0.463241308927536, accuracy: 86.4 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 0.3931, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 0.3363, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 0.4139, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 0.4569, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 0.3074, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 0.4297, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 0.3810, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 0.5389, batch time: 0.08, accuracy:  79.69%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 0.5119, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 0.3694, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 0.4756197929382324, accuracy: 85.9 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 1.4771037101745605, accuracy: 55.8 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 0.6474607586860657, accuracy: 80.5 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 5.90090799331665, accuracy: 36.2 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 0.4678216576576233, accuracy: 85.9 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 0.5873868465423584, accuracy: 80.1 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 0.4469030499458313, accuracy: 87.3 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 0.44134190678596497, accuracy: 87.1 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 0.44027501344680786, accuracy: 86.9 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 0.4381049871444702, accuracy: 86.6 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 0.6586, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 0.4626, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 0.5174, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 0.5020, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 0.5590, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 0.7061, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 0.5289, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 0.5851, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 0.4727, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 0.6550, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 0.3814888596534729, accuracy: 88.1 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 1.2127522230148315, accuracy: 60.1 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 0.6019311547279358, accuracy: 80.0 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 6.958592414855957, accuracy: 29.2 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 0.40069761872291565, accuracy: 86.3 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 0.38639095425605774, accuracy: 87.5 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 0.3648402690887451, accuracy: 88.8 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 0.3626863658428192, accuracy: 89.1 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 0.3618943691253662, accuracy: 89.2 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 0.3608942925930023, accuracy: 89.1 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 0.4866, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 0.4001, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 0.7207, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 0.5584, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 0.4855, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 0.5131, batch time: 0.04, accuracy:  82.81%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 0.4094, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 0.4471, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 0.4091, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 0.3022, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 0.42977654933929443, accuracy: 87.0 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 1.5551904439926147, accuracy: 52.9 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 0.6769107580184937, accuracy: 80.7 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 0.4570655822753906, accuracy: 85.1 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 0.4729328751564026, accuracy: 84.0 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 0.45885396003723145, accuracy: 85.4 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 0.4293254315853119, accuracy: 86.6 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 0.4125421345233917, accuracy: 87.8 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 0.411297082901001, accuracy: 88.0 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 0.40929052233695984, accuracy: 88.4 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 0.4955, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 0.5009, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 0.4079, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 0.5205, batch time: 0.06, accuracy:  83.59%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 0.3825, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 0.6507, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 0.4282, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 0.3645, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 0.5020, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 0.3964, batch time: 0.09, accuracy:  88.28%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 0.4278222918510437, accuracy: 86.3 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 1.4654500484466553, accuracy: 57.5 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 0.6038649082183838, accuracy: 81.0 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 6.607719421386719, accuracy: 30.8 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 0.43344348669052124, accuracy: 87.4 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 0.4483889937400818, accuracy: 85.7 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 0.4087340831756592, accuracy: 87.9 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 0.40664783120155334, accuracy: 87.9 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 0.41171398758888245, accuracy: 88.3 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 0.4155551493167877, accuracy: 88.1 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 0.3181, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 0.5148, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 0.5777, batch time: 0.09, accuracy:  84.38%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 0.5196, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 0.5546, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 0.5293, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 0.4034, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 0.6970, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 0.3239, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 0.4327, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 0.4751574695110321, accuracy: 84.1 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 1.1581976413726807, accuracy: 63.4 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 0.7129978537559509, accuracy: 79.0 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 0.7391469478607178, accuracy: 78.6 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 0.4700203239917755, accuracy: 84.5 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 0.48967233300209045, accuracy: 84.3 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 0.46190187335014343, accuracy: 85.1 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 0.46703335642814636, accuracy: 85.3 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 0.4559886157512665, accuracy: 84.8 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 0.45592036843299866, accuracy: 85.8 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 0.6322, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 0.5637, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 0.3744, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 0.3930, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 0.5331, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 0.4433, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 0.5511, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 0.4460, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 0.4338, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 0.4378, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 0.5457118153572083, accuracy: 83.2 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 1.222350835800171, accuracy: 60.5 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 0.7270314693450928, accuracy: 77.4 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 0.8653450608253479, accuracy: 74.2 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 0.7303480505943298, accuracy: 76.9 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 0.5116069316864014, accuracy: 83.8 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 0.5009580850601196, accuracy: 84.9 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 0.4795987904071808, accuracy: 85.0 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 0.4780624210834503, accuracy: 85.8 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 0.47409623861312866, accuracy: 85.0 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 0.4119, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 0.4218, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 0.4434, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 0.5566, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 0.4648, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 0.3613, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 0.3659, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 0.4821, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 0.5842, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 0.4090, batch time: 0.04, accuracy:  80.47%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 0.40548068284988403, accuracy: 85.9 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 1.1317800283432007, accuracy: 63.0 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 0.5651053786277771, accuracy: 81.4 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 1.4713681936264038, accuracy: 65.7 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 0.41105687618255615, accuracy: 85.6 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 0.39857572317123413, accuracy: 86.7 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 0.41158607602119446, accuracy: 86.5 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 0.38182276487350464, accuracy: 88.0 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 0.38168206810951233, accuracy: 87.9 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 0.3800795376300812, accuracy: 87.7 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 0.3785, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 0.5130, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 0.5485, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 0.3913, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 0.3895, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 0.4182, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 0.5244, batch time: 0.47, accuracy:  88.28%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 0.3923, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 0.3720, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 0.8234, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 0.44766998291015625, accuracy: 86.4 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 1.2065556049346924, accuracy: 58.7 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 0.6397081613540649, accuracy: 79.2 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 5.7382917404174805, accuracy: 30.2 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 0.4881688058376312, accuracy: 83.8 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 0.45608705282211304, accuracy: 86.1 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 0.4426647424697876, accuracy: 86.1 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 0.4391442537307739, accuracy: 86.2 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 0.43889981508255005, accuracy: 86.2 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 0.4385656714439392, accuracy: 86.6 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 0.5388, batch time: 0.09, accuracy:  79.69%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 0.4411, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 0.5040, batch time: 0.09, accuracy:  88.28%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 0.4814, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 0.4284, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 0.5502, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 0.5975, batch time: 0.09, accuracy:  86.72%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 0.3968, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 0.5933, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 0.5801, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 0.4457683265209198, accuracy: 85.5 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 1.0781264305114746, accuracy: 63.3 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 0.69659423828125, accuracy: 78.8 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 6.265322685241699, accuracy: 31.0 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 0.554926872253418, accuracy: 80.8 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 0.6679788827896118, accuracy: 78.0 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 0.41896381974220276, accuracy: 86.6 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 0.414228230714798, accuracy: 87.0 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 0.4120487868785858, accuracy: 86.8 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 0.4109397232532501, accuracy: 86.7 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 0.3543, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 0.4989, batch time: 0.04, accuracy:  80.47%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 0.4107, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 0.4370, batch time: 0.09, accuracy:  86.72%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 0.5654, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 0.4550, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 0.3883, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 0.3274, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 0.5008, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 0.3566, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 0.4827432930469513, accuracy: 85.2 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 1.4425932168960571, accuracy: 57.1 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 0.6908981800079346, accuracy: 79.8 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 7.853092670440674, accuracy: 29.7 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 0.6768094897270203, accuracy: 78.5 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 0.5277109146118164, accuracy: 83.6 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 0.47038882970809937, accuracy: 85.3 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 0.4692549407482147, accuracy: 85.3 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 0.46950018405914307, accuracy: 85.1 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 0.4679694175720215, accuracy: 84.9 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 0.7404, batch time: 0.04, accuracy:  82.81%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 0.4628, batch time: 0.04, accuracy:  80.47%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 0.4197, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 0.4845, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 0.2990, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 0.4516, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 0.6009, batch time: 0.04, accuracy:  79.69%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 0.5525, batch time: 0.04, accuracy:  83.59%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 0.3829, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 0.3854, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 0.3992530405521393, accuracy: 87.7 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 0.41173604130744934, accuracy: 87.5 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 0.5956548452377319, accuracy: 79.5 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 2.0482006072998047, accuracy: 41.3 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 0.41869786381721497, accuracy: 87.4 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 0.45918479561805725, accuracy: 85.5 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 0.40480124950408936, accuracy: 87.8 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 0.3903641998767853, accuracy: 88.8 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 0.40486204624176025, accuracy: 87.8 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 0.39119675755500793, accuracy: 88.4 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 0.4481, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 0.3908, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 0.4050, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 0.3901, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 0.4606, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 0.5361, batch time: 0.04, accuracy:  82.81%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 0.3257, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 0.6288, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 0.3527, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 0.3852, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 0.4575129747390747, accuracy: 86.0 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 1.1727094650268555, accuracy: 60.3 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 0.7415604591369629, accuracy: 77.3 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 7.145132064819336, accuracy: 26.6 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 0.5112050175666809, accuracy: 82.5 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 0.5108984112739563, accuracy: 84.5 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 0.4534578025341034, accuracy: 86.1 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 0.44885241985321045, accuracy: 86.2 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 0.4503108263015747, accuracy: 85.9 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 0.4547724425792694, accuracy: 85.8 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "loss_list_epoch = []\n",
    "acc_list_epoch = []\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0\n",
    "\n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter)\n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "\n",
    "            qnn_train_step += 1\n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\"\n",
    "                )\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA\n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(\n",
    "            qnn_minimize_loss,\n",
    "            init_param,\n",
    "            method=\"COBYLA\",\n",
    "            options={\"maxiter\": 1000, \"adaptive\": True},\n",
    "        )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8046414852142334, 1.2641280889511108, 1.2859655618667603, 1.0496301651000977, 0.9362042546272278, 0.8676818013191223, 0.9569591879844666, 0.7715725898742676, 0.9116650819778442, 0.9635618329048157, 0.8525230288505554, 0.8430970311164856, 0.9368236660957336, 0.7401107549667358, 0.8657477498054504, 0.8918811678886414, 0.7682813405990601, 0.5774379372596741, 0.9035229086875916, 0.6725139617919922, 0.6299500465393066, 0.7620798349380493, 0.7443290948867798, 0.6200401186943054, 0.6822200417518616, 0.9393066167831421, 0.7938050031661987, 0.4780030846595764, 0.49172133207321167, 0.9182097315788269, 0.3748317360877991, 0.5420784950256348, 0.6770682334899902, 0.509314239025116, 0.5028019547462463, 0.887073814868927, 0.7728724479675293, 0.6460521817207336, 0.46058389544487, 0.8265007734298706, 0.8498244881629944, 0.4662321209907532, 0.3992021381855011, 0.5237343907356262, 0.6555148363113403, 0.6163662672042847, 0.5110224485397339, 0.5838679075241089, 0.6440642476081848, 0.46232959628105164, 0.6243820786476135, 0.5270194411277771, 0.5167950391769409, 0.6311960220336914, 0.49108457565307617, 0.5181630253791809, 0.7893117666244507, 0.4819090664386749, 0.5990372896194458, 0.5249038934707642, 0.6396151781082153, 0.5231276154518127, 0.5741967558860779, 0.5694447755813599, 0.3240717351436615, 0.5054572820663452, 0.5880002975463867, 0.5453080534934998, 0.5377033352851868, 0.4436531066894531, 0.5978865623474121, 0.5899022221565247, 0.5506317615509033, 0.6659792065620422, 0.628433108329773, 0.5859616994857788, 0.4985887408256531, 0.5758411288261414, 0.634597897529602, 0.6164602637290955, 0.41371646523475647, 0.4818948209285736, 0.6166688203811646, 0.5315372347831726, 0.47276780009269714, 0.43513551354408264, 0.6855097413063049, 0.4874381721019745, 0.5024558901786804, 0.5324296355247498, 0.42953211069107056, 0.5462561249732971, 0.6456076502799988, 0.47149625420570374, 0.43378910422325134, 0.30168232321739197, 0.43353596329689026, 0.5015247464179993, 0.5971461534500122, 0.5112065672874451, 0.47943976521492004, 0.41840091347694397, 0.6632745862007141, 0.5091564059257507, 0.39651039242744446, 0.5107536911964417, 0.7227597236633301, 0.6820744872093201, 0.5041602253913879, 0.378050833940506, 0.44926872849464417, 0.5880927443504333, 0.5819754004478455, 0.5472490191459656, 0.49400344491004944, 0.4871031641960144, 0.380892276763916, 0.5466156601905823, 0.4045086205005646, 0.5129532814025879, 0.48972031474113464, 0.43383100628852844, 0.34441182017326355, 0.5367205739021301, 0.45009085536003113, 0.3865014612674713, 0.4474160373210907, 0.45280352234840393, 0.5108487010002136, 0.474333792924881, 0.5580255389213562, 0.7004604339599609, 0.791135847568512, 0.8184512257575989, 0.5212712287902832, 0.46529918909072876, 0.625236451625824, 0.48694509267807007, 0.5985843539237976, 0.459882527589798, 0.38551029562950134, 0.4726884365081787, 0.526716411113739, 0.3330287039279938, 0.39513692259788513, 0.36036863923072815, 0.48140019178390503, 0.5352090001106262, 0.5424795746803284, 0.34859713912010193, 0.5191621780395508, 0.41341400146484375, 0.589088499546051, 0.4307525157928467, 0.4770581126213074, 0.3550501763820648, 0.4371263384819031, 0.4318115711212158, 0.4287767708301544, 0.2749716341495514, 0.4135434627532959, 0.49390068650245667, 0.44551321864128113, 0.3956008851528168, 0.43040356040000916, 0.4342321455478668, 0.45324182510375977, 0.4981977939605713, 0.5133609175682068, 0.4503210484981537, 0.5202038884162903, 0.689775824546814, 0.4116797149181366, 0.6011285781860352, 0.42074960470199585, 0.4902482330799103, 0.38920775055885315, 0.27388784289360046, 0.6601228713989258, 0.8213801980018616, 0.4915931820869446, 0.5084255337715149, 0.4264492094516754, 0.4570368230342865, 0.6139389276504517, 0.44317764043807983, 0.376125305891037, 0.4231606125831604, 0.5807668566703796, 0.46452268958091736, 0.4915330410003662, 0.45434141159057617, 0.5089138746261597, 0.5561726093292236, 0.4565294086933136, 0.5287250876426697, 0.5478845834732056, 0.514184832572937, 0.4216245114803314, 0.454841673374176]\n",
      "[36.607142857142854, 55.357142857142854, 51.785714285714285, 63.392857142857146, 69.64285714285714, 71.42857142857143, 69.64285714285714, 80.35714285714286, 69.64285714285714, 66.96428571428571, 72.32142857142857, 74.10714285714286, 71.42857142857143, 77.67857142857143, 73.21428571428571, 73.21428571428571, 78.57142857142857, 81.25, 68.75, 78.57142857142857, 78.57142857142857, 71.42857142857143, 75.89285714285714, 76.78571428571429, 82.14285714285714, 78.57142857142857, 74.10714285714286, 81.25, 79.46428571428571, 79.46428571428571, 91.96428571428571, 83.03571428571429, 75.89285714285714, 84.82142857142857, 84.82142857142857, 78.57142857142857, 74.10714285714286, 78.57142857142857, 87.5, 79.46428571428571, 75.89285714285714, 87.5, 88.39285714285714, 80.35714285714286, 75.89285714285714, 75.89285714285714, 84.82142857142857, 81.25, 79.46428571428571, 85.71428571428571, 80.35714285714286, 81.25, 78.57142857142857, 82.14285714285714, 85.71428571428571, 82.14285714285714, 79.46428571428571, 85.71428571428571, 83.03571428571429, 83.03571428571429, 77.67857142857143, 83.92857142857143, 81.25, 80.35714285714286, 86.60714285714286, 84.82142857142857, 83.92857142857143, 88.39285714285714, 88.39285714285714, 86.60714285714286, 84.82142857142857, 78.57142857142857, 88.39285714285714, 80.35714285714286, 79.46428571428571, 81.25, 83.03571428571429, 82.14285714285714, 81.25, 85.71428571428571, 86.60714285714286, 85.71428571428571, 88.39285714285714, 84.82142857142857, 81.25, 86.60714285714286, 84.82142857142857, 79.46428571428571, 83.92857142857143, 82.14285714285714, 85.71428571428571, 83.03571428571429, 85.71428571428571, 84.82142857142857, 88.39285714285714, 91.07142857142857, 86.60714285714286, 86.60714285714286, 79.46428571428571, 84.82142857142857, 85.71428571428571, 87.5, 83.92857142857143, 85.71428571428571, 88.39285714285714, 83.03571428571429, 81.25, 83.03571428571429, 84.82142857142857, 83.03571428571429, 83.03571428571429, 78.57142857142857, 83.92857142857143, 81.25, 85.71428571428571, 84.82142857142857, 85.71428571428571, 87.5, 86.60714285714286, 84.82142857142857, 88.39285714285714, 86.60714285714286, 90.17857142857143, 84.82142857142857, 85.71428571428571, 87.5, 83.92857142857143, 85.71428571428571, 83.92857142857143, 84.82142857142857, 80.35714285714286, 85.71428571428571, 78.57142857142857, 83.92857142857143, 83.03571428571429, 84.82142857142857, 79.46428571428571, 84.82142857142857, 81.25, 81.25, 86.60714285714286, 83.03571428571429, 77.67857142857143, 90.17857142857143, 85.71428571428571, 88.39285714285714, 84.82142857142857, 83.03571428571429, 83.92857142857143, 91.96428571428571, 84.82142857142857, 86.60714285714286, 85.71428571428571, 88.39285714285714, 89.28571428571429, 87.5, 86.60714285714286, 86.60714285714286, 85.71428571428571, 92.85714285714286, 87.5, 87.5, 90.17857142857143, 85.71428571428571, 89.28571428571429, 88.39285714285714, 83.92857142857143, 87.5, 83.03571428571429, 85.71428571428571, 84.82142857142857, 82.14285714285714, 84.82142857142857, 80.35714285714286, 91.96428571428571, 80.35714285714286, 89.28571428571429, 90.17857142857143, 84.82142857142857, 79.46428571428571, 84.82142857142857, 84.82142857142857, 84.82142857142857, 86.60714285714286, 77.67857142857143, 88.39285714285714, 84.82142857142857, 86.60714285714286, 81.25, 87.5, 83.92857142857143, 86.60714285714286, 88.39285714285714, 87.5, 83.92857142857143, 84.82142857142857, 83.92857142857143, 85.71428571428571, 83.03571428571429, 83.03571428571429]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [1.5793536901474, 1.3606070280075073, 1.130916714668274, 0.9989752173423767, 0.9545585513114929, 1.1199911832809448, 1.0151442289352417, 0.9778190851211548, 0.9833410978317261, 1.1850727796554565, 0.9182454347610474, 0.9837549924850464, 0.9604334235191345, 0.6698225736618042, 0.751673698425293, 1.007665753364563, 1.160025954246521, 0.8619522452354431, 0.8433149456977844, 0.8246124982833862, 0.8606038093566895, 1.0869405269622803, 0.9537059664726257, 0.7021923065185547, 0.7802230715751648, 0.8184767961502075, 0.9030352234840393, 0.7981778979301453, 0.7833312749862671, 0.8599045872688293, 0.8948111534118652, 0.727757453918457, 0.7932426333427429, 0.7295569181442261, 0.986294686794281, 0.6350662112236023, 0.7199816703796387, 0.8913276791572571, 1.1148616075515747, 0.8293507695198059, 1.0744084119796753, 0.745124876499176, 0.8596287369728088, 0.9139259457588196, 0.7071499228477478, 0.7921417951583862, 0.6558728814125061, 0.772249698638916, 0.8534156084060669, 0.907215416431427, 0.7737399339675903, 0.712461531162262, 0.7494677901268005, 0.7870087027549744, 0.8082929849624634, 0.745728611946106, 0.7523451447486877, 0.7147486805915833, 0.78651362657547, 0.8992504477500916, 0.7892569899559021, 0.7550878524780273, 0.7658811807632446, 0.8490017056465149, 0.959765613079071, 0.7820084691047668, 0.6501368880271912, 0.7570801973342896, 0.9709364771842957, 0.6098541021347046, 0.7790269255638123, 0.8817018270492554, 0.85728520154953, 0.900725245475769, 0.829018235206604, 0.6568363904953003, 0.6410073637962341, 0.5601121187210083, 0.76897132396698, 1.0815727710723877, 0.7475864291191101, 0.6004422903060913, 0.876167893409729, 0.606316864490509, 0.7410712242126465, 0.7287538647651672, 0.8134070634841919, 0.6443325877189636, 0.8812237977981567, 0.7514147758483887, 0.7131314277648926, 0.6659108400344849, 0.6383360624313354, 0.8750385046005249, 0.8867655992507935, 0.6827479600906372, 0.7249776721000671, 0.7865398526191711, 0.7235835194587708, 0.8575131297111511, 0.6154326796531677, 0.7094230651855469, 0.7980932593345642, 0.7010515332221985, 0.7405763268470764, 0.9069867730140686, 0.6694186925888062, 0.8375507593154907, 0.8568762540817261, 0.8423210382461548, 0.7724611163139343, 0.837544322013855, 0.8297337889671326, 0.6602716445922852, 0.8344845175743103, 0.7484064102172852, 0.7404674291610718, 1.0753333568572998, 0.7490978837013245, 0.8344626426696777, 0.5768626928329468, 0.9590297937393188, 0.7686606645584106, 0.5701773762702942, 0.6277446746826172, 0.7306930422782898, 0.6937421560287476, 0.8811662793159485, 0.7523276209831238, 0.7533654570579529, 0.6755979657173157, 0.6792980432510376, 0.722080647945404, 0.7043147087097168, 0.6248584985733032, 0.6540809273719788, 0.8498005270957947, 0.8007411360740662, 0.6750391721725464, 0.8026666641235352, 0.7838580012321472, 0.8294153809547424, 0.7564182281494141, 0.702299952507019, 0.9228783249855042, 0.9126005172729492, 0.7239255309104919, 0.7555379271507263, 0.6098979115486145, 0.8946110606193542, 0.812968373298645, 0.902546226978302, 0.7545722126960754, 0.6873642802238464, 0.7369376420974731, 0.7704716920852661, 0.8251942992210388, 0.8384639620780945, 0.8961890935897827, 0.652102530002594, 0.615848183631897, 0.7671064734458923, 0.7310209274291992, 0.7747597694396973, 0.658784806728363, 0.7052134871482849, 0.7465609312057495, 0.8962215185165405, 0.7306972742080688, 0.7461091876029968, 0.8381564021110535, 0.7776342034339905, 0.7901638746261597, 0.7141352891921997, 0.7647926211357117, 0.8210469484329224, 0.9547142386436462, 0.7776121497154236, 0.7210837006568909, 0.8263674378395081, 0.632298469543457, 0.8313926458358765, 0.654488205909729, 0.6604153513908386, 0.7392787933349609, 0.8495975136756897, 0.8109437823295593, 1.0810184478759766, 0.8097628355026245, 0.9136065244674683, 0.6615161299705505, 0.6230474710464478, 0.6614557504653931, 0.624165952205658, 0.727571964263916, 0.8123169541358948, 0.8038389086723328, 0.8972457647323608, 0.7926344871520996, 0.5853199362754822]\n",
    "# acc_list_epoch_ = [44.642857142857146, 52.67857142857143, 58.92857142857143, 64.28571428571429, 66.96428571428571, 63.392857142857146, 67.85714285714286, 67.85714285714286, 63.392857142857146, 62.5, 72.32142857142857, 66.07142857142857, 68.75, 75.0, 70.53571428571429, 66.07142857142857, 64.28571428571429, 72.32142857142857, 68.75, 74.10714285714286, 71.42857142857143, 66.07142857142857, 68.75, 81.25, 72.32142857142857, 71.42857142857143, 66.96428571428571, 75.0, 68.75, 72.32142857142857, 66.96428571428571, 72.32142857142857, 67.85714285714286, 73.21428571428571, 65.17857142857143, 74.10714285714286, 69.64285714285714, 71.42857142857143, 67.85714285714286, 76.78571428571429, 67.85714285714286, 74.10714285714286, 74.10714285714286, 75.0, 70.53571428571429, 68.75, 75.89285714285714, 72.32142857142857, 69.64285714285714, 69.64285714285714, 72.32142857142857, 75.0, 77.67857142857143, 75.0, 74.10714285714286, 73.21428571428571, 74.10714285714286, 80.35714285714286, 72.32142857142857, 68.75, 76.78571428571429, 72.32142857142857, 77.67857142857143, 69.64285714285714, 65.17857142857143, 74.10714285714286, 76.78571428571429, 71.42857142857143, 73.21428571428571, 83.03571428571429, 70.53571428571429, 75.89285714285714, 75.89285714285714, 75.89285714285714, 75.0, 79.46428571428571, 75.89285714285714, 80.35714285714286, 74.10714285714286, 66.96428571428571, 76.78571428571429, 74.10714285714286, 74.10714285714286, 81.25, 78.57142857142857, 81.25, 75.0, 75.89285714285714, 70.53571428571429, 72.32142857142857, 78.57142857142857, 73.21428571428571, 80.35714285714286, 75.0, 65.17857142857143, 77.67857142857143, 73.21428571428571, 74.10714285714286, 73.21428571428571, 76.78571428571429, 76.78571428571429, 77.67857142857143, 78.57142857142857, 79.46428571428571, 76.78571428571429, 70.53571428571429, 79.46428571428571, 78.57142857142857, 72.32142857142857, 72.32142857142857, 74.10714285714286, 70.53571428571429, 69.64285714285714, 80.35714285714286, 75.89285714285714, 74.10714285714286, 70.53571428571429, 68.75, 78.57142857142857, 74.10714285714286, 81.25, 70.53571428571429, 73.21428571428571, 82.14285714285714, 79.46428571428571, 75.0, 75.0, 73.21428571428571, 73.21428571428571, 69.64285714285714, 76.78571428571429, 79.46428571428571, 74.10714285714286, 75.89285714285714, 76.78571428571429, 78.57142857142857, 76.78571428571429, 73.21428571428571, 75.89285714285714, 71.42857142857143, 74.10714285714286, 75.89285714285714, 74.10714285714286, 74.10714285714286, 73.21428571428571, 66.96428571428571, 81.25, 71.42857142857143, 78.57142857142857, 72.32142857142857, 75.0, 75.0, 72.32142857142857, 74.10714285714286, 73.21428571428571, 82.14285714285714, 70.53571428571429, 78.57142857142857, 74.10714285714286, 81.25, 80.35714285714286, 77.67857142857143, 71.42857142857143, 76.78571428571429, 75.0, 75.89285714285714, 73.21428571428571, 71.42857142857143, 77.67857142857143, 76.78571428571429, 75.89285714285714, 75.89285714285714, 71.42857142857143, 72.32142857142857, 69.64285714285714, 72.32142857142857, 71.42857142857143, 77.67857142857143, 75.89285714285714, 72.32142857142857, 77.67857142857143, 74.10714285714286, 74.10714285714286, 79.46428571428571, 75.89285714285714, 74.10714285714286, 75.89285714285714, 65.17857142857143, 71.42857142857143, 74.10714285714286, 79.46428571428571, 83.03571428571429, 78.57142857142857, 83.92857142857143, 79.46428571428571, 69.64285714285714, 74.10714285714286, 69.64285714285714, 74.10714285714286, 77.67857142857143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 86.93%\n",
      "Loss on the train set: 0.43\n",
      "Accuracy on the test set: 84.67%\n",
      "Loss on the test set: 0.51\n",
      "Generalization error: 0.07919645\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
