{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1637.5\" height=\"593.75\" viewBox=\"-30.0 0 1310.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.129123</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.578826</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.487571</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.673157</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.263712</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.131439</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.203076</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.813396</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.396973</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.171533</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.451811</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.402385</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.345748</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.273453</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.211267</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.281872</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.518896</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.371977</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.339908</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.733145</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.73239</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.279718</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.21618</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.597355</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.35157</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.054113</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.826816</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.23582</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.444621</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.28793</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.900315</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.438951</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.190542</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.642538</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.37416</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.511303</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.816017</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.137663</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.690642</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.789666</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.761087</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.07603</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.342958</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.435404</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.514865</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.180346</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.553873</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.074711</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.440446</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.082547</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.171973</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.881881</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.524852</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.728723</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.873789</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.475631</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.18645</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.175638</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.763968</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.08686</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.845514</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.070605</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.794198</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.743119</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.408893</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.573804</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.677573</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.890781</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.187239</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.382337</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.982822</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.027647</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.855358</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.451481</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.927847</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.28992</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.952466</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.801589</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.882801</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.605292</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.219045</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.37059</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.2432</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.125611</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.356291</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.355664</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.943301</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.202591</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.658412</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.278987</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.695332</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.210944</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.78273</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.064512</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.327491</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.346447</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25.0 L1240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,125.0 L1240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,175.0 L1240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,225.0 L1240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,275.0 L1240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,325.0 L1240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,375.0 L1240,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,425.0 L1240,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1250\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1250\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1250\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1250\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1250\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1250\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1250\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1250\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1250\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7dd8d65c1370>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m=9, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.997523</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.160102</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.812568</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.976411</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.782537</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.504115</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.087343</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.131808</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.591564</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.956178</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.478851</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.445789</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.589527</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.371901</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.889638</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.814935</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.568892</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.823892</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.383715</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.68727</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.244748</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.751319</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.763518</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.606415</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.447045</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.581161</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.668428</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.635388</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.520673</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.925376</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.913367</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.194278</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.162326</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.293312</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.279657</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.789191</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.764353</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.325717</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.962494</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.257947</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.200857</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.309995</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.308657</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.078233</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.785071</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.090225</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.892403</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.31983</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.464793</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.611745</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.995617</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.669019</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.80482</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.126832</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.585257</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.229881</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.145665</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.437337</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.74075</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.64971</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.819408</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.811826</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.441992</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.273647</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.800159</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.37677</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.366763</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.745674</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.341452</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.473083</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.005975</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.934686</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.010407</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.244888</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.007479</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7dd8d65559a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m=8, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        #     super(CNNModel, self).__init__()\n",
    "        #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "        #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "        #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "        #     self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "        # def forward(self, x):\n",
    "        #     x = self.pool(self.conv1(x))\n",
    "        #     x = self.pool(self.conv2(x))\n",
    "        #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        #     x = self.fc1(x)\n",
    "        #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 76.67%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    # class MappingModel(nn.Module):\n",
    "    #     def __init__(self, input_size, hidden_sizes, output_size):\n",
    "    #         super().__init__()\n",
    "    #         # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "    #         self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "    #         self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "    #         self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    #     def forward(self, X):\n",
    "    #         # Ensure the input tensor is the same type as the weights\n",
    "    #         X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "    #         # Input layer with ReLU activation\n",
    "    #         X = self.input_layer(X)\n",
    "\n",
    "    #         # Hidden layers with ReLU activation\n",
    "    #         for hidden in self.hidden_layers:\n",
    "    #             X = hidden(X)\n",
    "\n",
    "    #         # Output layer with linear activation\n",
    "    #         output = self.output_layer(X)\n",
    "    #         # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "    #         return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "        # self.MappingNetwork = self.MappingModel(n_qubit+1, [8], 1).to(device)\n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit + 1, output_dim=1, bond_dim=3)\n",
    "\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        # self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[\n",
    "            :108\n",
    "        ]  # nn.Parameter(q_delta * torch.randn(135)).to(device)\n",
    "        self.q_params_2 = qnn_parameters[108:]\n",
    "        device = x.device\n",
    "\n",
    "        res_1 = bs_1.run(parameters=self.q_params_1, samples=100000)\n",
    "        trans_res_1 = bs_1.translate_results(res=res_1)\n",
    "        trans_res_1 = trans_res_1 / torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)\n",
    "\n",
    "        res_2 = bs_2.run(parameters=self.q_params_2, samples=100000)\n",
    "        trans_res_2 = bs_2.translate_results(res=res_2)\n",
    "        trans_res_2 = trans_res_2 / torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)\n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(126 * 70, 1)\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[: len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  279\n",
      "# of trainable parameter in QNN model:  192\n",
      "# of trainable parameter in full model:  471\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108 + 84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\n",
    "    \"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters\n",
    ")\n",
    "print(\n",
    "    \"# of trainable parameter in full model: \",\n",
    "    num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.2835, batch time: 0.20, accuracy:  6.25%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.2985, batch time: 0.25, accuracy:  9.38%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.1954, batch time: 0.18, accuracy:  16.41%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.1419, batch time: 0.15, accuracy:  20.31%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 1.8498, batch time: 0.22, accuracy:  26.56%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 1.8358, batch time: 0.33, accuracy:  21.88%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 1.7009, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 1.7450, batch time: 0.16, accuracy:  35.94%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 1.6281, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 1.5243, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 1.537905216217041, accuracy: 43.4 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 1.8019843101501465, accuracy: 35.8 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 1.506646990776062, accuracy: 45.1 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 1.4713449478149414, accuracy: 45.8 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 1.4923310279846191, accuracy: 45.8 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 1.7259308099746704, accuracy: 36.8 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 1.4727619886398315, accuracy: 46.3 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 1.4590731859207153, accuracy: 46.4 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 1.4559741020202637, accuracy: 46.7 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 1.4550294876098633, accuracy: 47.3 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 1.5182, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 1.5318, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 1.1088, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 1.2267, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 1.0637, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 1.2913, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 1.0149, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 0.9700, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 1.1115, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 1.0539, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 1.067028284072876, accuracy: 60.7 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 5.778119087219238, accuracy: 29.9 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 0.9971829056739807, accuracy: 63.6 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 1.3333730697631836, accuracy: 55.4 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 1.12440025806427, accuracy: 60.3 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 1.3631869554519653, accuracy: 56.0 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 0.9536336660385132, accuracy: 67.2 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 0.9450299739837646, accuracy: 67.7 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 0.9416691064834595, accuracy: 68.2 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 0.9372297525405884, accuracy: 67.6 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 0.9643, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 1.0452, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 0.8829, batch time: 0.04, accuracy:  71.88%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 1.0375, batch time: 0.07, accuracy:  64.84%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 0.9153, batch time: 0.04, accuracy:  71.09%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 0.9942, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 1.1002, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 1.0629, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 1.1357, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 0.9896, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 0.8600058555603027, accuracy: 70.9 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 2.2965104579925537, accuracy: 37.6 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 0.8435089588165283, accuracy: 69.4 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 0.8371251821517944, accuracy: 70.8 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 0.8364344239234924, accuracy: 71.4 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 1.1879971027374268, accuracy: 68.5 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 0.8238421678543091, accuracy: 70.6 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 0.833304226398468, accuracy: 70.0 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 0.8198484182357788, accuracy: 71.1 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 0.819173276424408, accuracy: 71.7 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 0.8351, batch time: 0.10, accuracy:  71.09%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 0.7164, batch time: 0.10, accuracy:  71.88%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 0.8439, batch time: 0.07, accuracy:  72.66%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 1.0102, batch time: 0.10, accuracy:  69.53%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 0.7547, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 0.8800, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 0.7984, batch time: 0.09, accuracy:  71.88%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 0.8877, batch time: 0.11, accuracy:  70.31%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 0.9383, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 0.8089, batch time: 0.10, accuracy:  69.53%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 0.8086093068122864, accuracy: 73.8 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 3.1514179706573486, accuracy: 42.4 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 0.8020620942115784, accuracy: 73.7 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 0.8010950684547424, accuracy: 74.3 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 1.0469661951065063, accuracy: 62.2 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 0.7861941456794739, accuracy: 76.3 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 0.7834265828132629, accuracy: 75.7 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 0.7817316651344299, accuracy: 75.9 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 0.7781796455383301, accuracy: 76.2 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 0.7758709788322449, accuracy: 75.7 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 0.6501, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 0.6435, batch time: 0.10, accuracy:  75.78%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 0.7947, batch time: 0.11, accuracy:  75.00%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 0.7526, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 0.7514, batch time: 0.04, accuracy:  70.31%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 0.7348, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 0.8093, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 0.6095, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 1.0672, batch time: 0.04, accuracy:  68.75%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 1.1281, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 0.8317936062812805, accuracy: 72.2 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 3.75777006149292, accuracy: 34.8 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 0.7857661843299866, accuracy: 75.0 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 0.7832590341567993, accuracy: 74.9 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 0.7681329250335693, accuracy: 75.5 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 0.7854318022727966, accuracy: 74.8 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 0.8883534073829651, accuracy: 72.9 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 0.7528955340385437, accuracy: 78.2 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 0.7487350106239319, accuracy: 76.7 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 0.762370765209198, accuracy: 76.3 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 0.7931, batch time: 0.11, accuracy:  73.44%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 0.7272, batch time: 0.06, accuracy:  75.00%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 0.7644, batch time: 0.08, accuracy:  73.44%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 0.6682, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 0.8293, batch time: 0.05, accuracy:  72.66%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 0.7324, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 0.9062, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 0.7035, batch time: 0.05, accuracy:  72.66%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 0.7319, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 0.6645, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 0.7301023006439209, accuracy: 78.6 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 3.1845688819885254, accuracy: 43.9 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 0.7156071066856384, accuracy: 78.9 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 0.7121092081069946, accuracy: 79.3 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 0.8973823189735413, accuracy: 70.5 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 0.7065623998641968, accuracy: 79.6 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 0.7194588780403137, accuracy: 76.3 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 0.6995660662651062, accuracy: 80.0 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 0.7014982104301453, accuracy: 79.5 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 0.6978842616081238, accuracy: 80.0 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 0.7840, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 0.7291, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 0.7186, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 0.6318, batch time: 0.11, accuracy:  75.78%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 0.7777, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 0.7174, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 0.7794, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 0.7199, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 0.9089, batch time: 0.04, accuracy:  71.88%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 0.6133, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 0.7097588181495667, accuracy: 78.9 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 0.7066839933395386, accuracy: 79.0 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 1.293799638748169, accuracy: 59.0 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 0.6963744163513184, accuracy: 79.9 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 1.1735918521881104, accuracy: 65.7 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 0.6887600421905518, accuracy: 80.2 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 0.6886497139930725, accuracy: 80.4 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 0.7074427008628845, accuracy: 78.4 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 0.6864660978317261, accuracy: 80.0 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 0.6880130767822266, accuracy: 80.2 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 0.7758, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 0.7249, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 0.7945, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 0.7489, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 0.8321, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 0.7693, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 0.6032, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 0.7397, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 0.7092, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 0.6792, batch time: 0.06, accuracy:  80.47%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 0.6588821411132812, accuracy: 76.7 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 0.67950838804245, accuracy: 76.2 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 0.6437798142433167, accuracy: 77.4 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 0.6402807831764221, accuracy: 77.1 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 0.9237277507781982, accuracy: 69.7 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 0.6325843334197998, accuracy: 77.6 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 4.291149139404297, accuracy: 34.7 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 0.6155312657356262, accuracy: 79.2 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 0.6589635610580444, accuracy: 75.7 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 0.6094455122947693, accuracy: 79.6 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 0.6844, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 0.5619, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 0.5998, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 0.8431, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 0.5037, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 0.7211, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 0.8537, batch time: 0.11, accuracy:  70.31%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 0.6995, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 0.7613, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 0.6815, batch time: 0.11, accuracy:  75.78%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 0.6935757398605347, accuracy: 78.8 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 5.399486541748047, accuracy: 29.0 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 0.6884893774986267, accuracy: 78.6 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 0.6883476376533508, accuracy: 78.7 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 0.6940080523490906, accuracy: 79.4 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 0.6849261522293091, accuracy: 79.8 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 0.6901362538337708, accuracy: 79.0 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 0.6811287999153137, accuracy: 79.7 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 0.6824440956115723, accuracy: 79.3 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 0.6888366937637329, accuracy: 80.1 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 0.7756, batch time: 0.10, accuracy:  71.88%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 0.7344, batch time: 0.11, accuracy:  75.00%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 0.7048, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 0.6999, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 0.6146, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 0.6300, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 0.9347, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 0.5978, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 0.7256, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 0.7359, batch time: 0.11, accuracy:  75.78%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 0.6561741232872009, accuracy: 77.2 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 9.600996971130371, accuracy: 25.0 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 0.6873453259468079, accuracy: 77.8 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 0.6358112096786499, accuracy: 78.9 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 0.6333156824111938, accuracy: 79.7 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 0.6433895230293274, accuracy: 77.9 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 1.7763484716415405, accuracy: 53.9 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 0.6225159764289856, accuracy: 80.3 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 0.623567521572113, accuracy: 79.0 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 0.6183963418006897, accuracy: 80.2 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 0.9079, batch time: 0.10, accuracy:  70.31%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 0.7285, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 0.7411, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 0.6723, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 0.6448, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 0.5634, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 0.6813, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 0.6655, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 0.7362, batch time: 0.05, accuracy:  72.66%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 0.9418, batch time: 0.06, accuracy:  74.22%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 0.6546053886413574, accuracy: 79.9 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 38.21987533569336, accuracy: 9.6 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 0.6529912948608398, accuracy: 79.2 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 0.6440246105194092, accuracy: 79.8 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 0.6476537585258484, accuracy: 79.8 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 0.6332687735557556, accuracy: 80.6 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 0.6326879262924194, accuracy: 80.3 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 0.6294093132019043, accuracy: 80.8 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 0.7100867033004761, accuracy: 77.5 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 0.6313445568084717, accuracy: 80.1 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 0.5079, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 0.8194, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 0.5707, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 0.6743, batch time: 0.05, accuracy:  72.66%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 0.6041, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 0.7986, batch time: 0.11, accuracy:  73.44%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 0.8330, batch time: 0.11, accuracy:  75.78%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 0.5235, batch time: 0.07, accuracy:  82.81%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 0.6948, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 0.6685, batch time: 0.10, accuracy:  75.78%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 0.6027028560638428, accuracy: 81.2 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 1.8165720701217651, accuracy: 52.4 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 0.613925576210022, accuracy: 80.6 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 0.7661882638931274, accuracy: 73.6 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 0.5865515470504761, accuracy: 82.5 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 0.5829607248306274, accuracy: 83.0 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 0.5821768641471863, accuracy: 83.3 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 0.5805211663246155, accuracy: 83.1 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 0.581322431564331, accuracy: 83.0 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 0.5861753821372986, accuracy: 82.8 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 0.5529, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 0.6321, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 0.5654, batch time: 0.04, accuracy:  80.47%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 0.8871, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 0.4250, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 0.5212, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 0.6629, batch time: 0.04, accuracy:  79.69%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 0.7409, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 0.7314, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 0.6374, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 0.5846008062362671, accuracy: 81.6 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 8.505940437316895, accuracy: 22.2 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 0.6512240171432495, accuracy: 76.7 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 0.5722479820251465, accuracy: 82.4 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 0.6427422165870667, accuracy: 80.4 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 0.8134141564369202, accuracy: 72.8 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 0.8218387365341187, accuracy: 72.6 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 0.6495346426963806, accuracy: 77.3 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 1.0309679508209229, accuracy: 66.3 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 0.6047998070716858, accuracy: 80.2 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 0.9302, batch time: 0.10, accuracy:  71.88%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 0.6819, batch time: 0.10, accuracy:  76.56%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 0.5135, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 0.8551, batch time: 0.10, accuracy:  76.56%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 0.6057, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 0.5252, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 0.5847, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 0.5042, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 0.6954, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 0.5279, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 0.5350736975669861, accuracy: 83.5 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 1.8893957138061523, accuracy: 53.8 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 0.5538552403450012, accuracy: 83.3 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 0.8952367901802063, accuracy: 73.6 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 0.5282373428344727, accuracy: 84.8 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 0.5222683548927307, accuracy: 84.8 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 0.5348836183547974, accuracy: 84.2 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 0.5208253264427185, accuracy: 84.6 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 0.6039130091667175, accuracy: 82.7 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 0.534637987613678, accuracy: 84.8 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 0.6423, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 0.4770, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 0.6570, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 0.5810, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 0.7030, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 0.4760, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 0.5877, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 0.8697, batch time: 0.10, accuracy:  72.66%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 0.7976, batch time: 0.10, accuracy:  75.00%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 0.5995, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 0.5807811617851257, accuracy: 81.5 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 0.5836211442947388, accuracy: 81.3 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 0.5789976119995117, accuracy: 81.1 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 0.5560473799705505, accuracy: 82.1 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 0.645550012588501, accuracy: 80.3 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 1.0082266330718994, accuracy: 66.5 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 0.8283445835113525, accuracy: 72.7 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 0.5499532222747803, accuracy: 81.3 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 0.5191673636436462, accuracy: 83.8 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 0.5205854773521423, accuracy: 83.4 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 0.6817, batch time: 0.04, accuracy:  75.78%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 0.6040, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 0.6315, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 0.5602, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 0.5116, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 0.4489, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 0.5053, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 0.4418, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 0.5845, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 0.4160, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 0.5413164496421814, accuracy: 81.1 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 0.5390749573707581, accuracy: 80.6 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 1.005100965499878, accuracy: 66.8 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 0.9516817331314087, accuracy: 69.1 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 0.4936177432537079, accuracy: 82.7 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 0.496364027261734, accuracy: 83.1 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 0.5702831149101257, accuracy: 82.7 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 0.5142633318901062, accuracy: 82.8 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 0.48909127712249756, accuracy: 83.7 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 0.4910516142845154, accuracy: 84.2 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 0.5411, batch time: 0.04, accuracy:  81.25%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 0.6397, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 0.6609, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 0.8104, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 0.5107, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 0.5556, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 0.4647, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 0.6212, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 0.6498, batch time: 0.04, accuracy:  81.25%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 0.4847, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 0.5737175941467285, accuracy: 82.7 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 0.5886452198028564, accuracy: 82.4 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 0.5694901943206787, accuracy: 82.6 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 0.5683410167694092, accuracy: 83.0 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 0.60770183801651, accuracy: 80.4 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 0.571597158908844, accuracy: 83.5 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 0.5861233472824097, accuracy: 81.7 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 0.7065330743789673, accuracy: 77.0 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 0.5724008679389954, accuracy: 80.9 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 0.564225971698761, accuracy: 81.5 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 0.7572, batch time: 0.04, accuracy:  82.03%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 0.6069, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 0.5186, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 0.5657, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 0.7663, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 0.6773, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 0.2997, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 0.6662, batch time: 0.09, accuracy:  79.69%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 0.6728, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 0.6110, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 0.6338969469070435, accuracy: 80.2 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 0.6383672952651978, accuracy: 79.6 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 0.6209642887115479, accuracy: 81.0 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 0.8323708176612854, accuracy: 71.8 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 0.6788057088851929, accuracy: 79.8 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 0.5999464988708496, accuracy: 83.2 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 0.5894899368286133, accuracy: 83.0 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 0.5877948999404907, accuracy: 83.7 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 0.585515022277832, accuracy: 83.4 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 0.5938345789909363, accuracy: 82.7 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 0.4456, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 0.5618, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 0.5609, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 0.6926, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 0.6786, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 0.6174, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 0.5260, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 0.4683, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 0.4552, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 0.5735, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 0.5324036478996277, accuracy: 82.6 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 75.65786743164062, accuracy: 9.3 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 0.5353503823280334, accuracy: 83.3 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 0.7957888841629028, accuracy: 71.5 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 0.5666888356208801, accuracy: 81.6 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 0.5722740292549133, accuracy: 81.7 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 0.5161339640617371, accuracy: 82.6 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 0.5326160192489624, accuracy: 82.5 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 0.5193058848381042, accuracy: 83.1 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 0.5810731649398804, accuracy: 80.8 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 0.3277, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 0.6152, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 0.4861, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 0.4474, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 0.5678, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 0.4730, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 0.6997, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 0.5506, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 0.6285, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 0.6772, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 0.528075098991394, accuracy: 83.8 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 0.5410802364349365, accuracy: 83.7 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 0.5134562849998474, accuracy: 85.9 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 0.5134562849998474, accuracy: 85.9 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 0.5141764879226685, accuracy: 84.6 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 0.49852725863456726, accuracy: 85.9 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 0.4991060793399811, accuracy: 85.6 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 0.49515455961227417, accuracy: 85.8 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 0.49435654282569885, accuracy: 86.3 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 0.501826286315918, accuracy: 85.8 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 0.6186, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 0.4920, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 0.7389, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 0.3943, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 0.4556, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 0.4368, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 0.4951, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 0.6483, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 0.4033, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 0.5767, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 0.5693994760513306, accuracy: 81.4 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 0.5668338537216187, accuracy: 81.6 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 0.6295590996742249, accuracy: 79.3 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 0.5188448429107666, accuracy: 82.9 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 0.5153489708900452, accuracy: 82.9 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 0.8024888634681702, accuracy: 75.8 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 0.5139151215553284, accuracy: 83.4 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 0.49747976660728455, accuracy: 82.7 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 0.4919547438621521, accuracy: 83.7 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 0.4895934462547302, accuracy: 83.1 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 0.4272, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 0.6133, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 0.5994, batch time: 0.06, accuracy:  75.78%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 0.5817, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 0.5384, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 0.4722, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 0.7169, batch time: 0.10, accuracy:  80.47%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 0.4445, batch time: 0.09, accuracy:  84.38%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 0.6426, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 0.5440, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 0.5262949466705322, accuracy: 84.2 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 8.185478210449219, accuracy: 23.9 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 0.6632137298583984, accuracy: 79.7 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 0.522113561630249, accuracy: 83.1 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 0.5826557278633118, accuracy: 82.7 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 0.5029221773147583, accuracy: 85.0 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 0.49965909123420715, accuracy: 85.6 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 0.49609705805778503, accuracy: 85.8 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 0.5013250708580017, accuracy: 85.5 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 0.49500754475593567, accuracy: 85.6 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 0.4792, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 0.4080, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 0.3396, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 0.7107, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 0.4376, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 0.4913, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 0.6017, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 0.7318, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 0.6823, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 0.5653, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 0.5242117047309875, accuracy: 85.6 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 0.5266136527061462, accuracy: 85.4 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 0.5186969041824341, accuracy: 86.5 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 0.5124138593673706, accuracy: 86.5 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 0.75522780418396, accuracy: 76.6 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 2.7531988620758057, accuracy: 44.6 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 0.4924829304218292, accuracy: 86.1 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 0.4923008680343628, accuracy: 86.2 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 0.4969414472579956, accuracy: 86.2 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 0.4921375811100006, accuracy: 86.5 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 0.4382, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 0.4558, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 0.6208, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 0.5516, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 0.4279, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 0.5537, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 0.5390, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 0.3665, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 0.4750, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 0.6221, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 0.4531991183757782, accuracy: 84.6 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 0.4522576630115509, accuracy: 85.0 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 0.5013960599899292, accuracy: 83.5 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 0.44567349553108215, accuracy: 85.8 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 0.5000450611114502, accuracy: 82.8 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 0.4387315809726715, accuracy: 85.9 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 0.43966296315193176, accuracy: 85.7 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 0.4481351971626282, accuracy: 84.1 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 0.43499401211738586, accuracy: 85.5 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 0.4501270353794098, accuracy: 85.4 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 0.5060, batch time: 0.07, accuracy:  88.28%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 0.3264, batch time: 0.08, accuracy:  91.41%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 0.6288, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 0.4349, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 0.7548, batch time: 0.04, accuracy:  76.56%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 0.4801, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 0.5895, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 0.6389, batch time: 0.04, accuracy:  79.69%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 0.3093, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 0.4771, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 0.4466598927974701, accuracy: 88.5 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 0.4445098340511322, accuracy: 88.0 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 0.4445098340511322, accuracy: 88.0 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 2.5542118549346924, accuracy: 47.5 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 0.4395279288291931, accuracy: 86.9 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 0.4236898422241211, accuracy: 87.5 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 0.4536013901233673, accuracy: 86.3 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 0.427127867937088, accuracy: 87.7 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 0.43129032850265503, accuracy: 87.1 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 0.4177725613117218, accuracy: 88.0 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 0.7414, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 0.6291, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 0.4858, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 0.4042, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 0.4695, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 0.3802, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 0.4979, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 0.4029, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 0.4462, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 0.5106, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 0.48232829570770264, accuracy: 87.0 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 0.9177998304367065, accuracy: 70.8 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 0.5768911242485046, accuracy: 83.0 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 0.4735396206378937, accuracy: 87.3 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 0.5875504612922668, accuracy: 81.9 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 0.9181035161018372, accuracy: 74.5 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 0.4724631905555725, accuracy: 86.7 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 0.4595317244529724, accuracy: 88.0 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 0.476148784160614, accuracy: 85.9 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 0.45589110255241394, accuracy: 87.7 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 0.6041, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 0.4421, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 0.4462, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 0.5493, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 0.6385, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 0.4241, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 0.4473, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 0.4507, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 0.6270, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 0.5912, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 0.5031951069831848, accuracy: 83.3 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 0.5028640627861023, accuracy: 83.3 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 0.48677095770835876, accuracy: 83.2 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 0.4764367938041687, accuracy: 85.4 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 1.133017659187317, accuracy: 69.7 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 0.4698032736778259, accuracy: 85.2 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 0.46954599022865295, accuracy: 85.1 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 0.47166770696640015, accuracy: 85.0 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 0.5296615958213806, accuracy: 81.8 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 0.521359920501709, accuracy: 83.1 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 0.5561, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 0.6455, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 0.4992, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 0.5768, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 0.4836, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 0.3668, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 0.4447, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 0.3902, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 0.7138, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 0.5383, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 0.48771294951438904, accuracy: 83.1 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 11.129963874816895, accuracy: 25.5 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 2.380216121673584, accuracy: 52.7 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 1.8964647054672241, accuracy: 49.6 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 0.494268000125885, accuracy: 83.6 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 0.48019468784332275, accuracy: 84.9 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 0.5089128613471985, accuracy: 83.3 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 0.5451747179031372, accuracy: 82.1 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 0.5032228827476501, accuracy: 82.9 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 0.4442512094974518, accuracy: 85.1 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 0.4878, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 0.6532, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 0.4884, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 0.6051, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 0.4377, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 0.6517, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 0.4507, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 0.4453, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 0.4782, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 0.3191, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 0.44588765501976013, accuracy: 86.9 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 0.4238741397857666, accuracy: 86.9 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 0.41156432032585144, accuracy: 87.3 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 0.40797802805900574, accuracy: 88.3 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 0.4406930208206177, accuracy: 86.3 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 0.9456468224525452, accuracy: 70.2 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 2.59588360786438, accuracy: 50.0 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 0.37552669644355774, accuracy: 88.7 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 0.37184983491897583, accuracy: 88.9 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 0.3739857077598572, accuracy: 88.8 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 0.6160, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 0.4061, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 0.6196, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 0.3355, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 0.5133, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 0.4044, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 0.5384, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 0.4489, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 0.5341, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 0.5577, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 0.565095841884613, accuracy: 82.4 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 0.6642255783081055, accuracy: 78.2 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 0.5633485317230225, accuracy: 82.4 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 1.4687503576278687, accuracy: 61.7 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 0.5563262701034546, accuracy: 82.8 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 0.5433369278907776, accuracy: 84.0 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 0.5394056439399719, accuracy: 84.1 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 0.5240018367767334, accuracy: 84.9 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 0.551458477973938, accuracy: 83.6 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 0.5144028067588806, accuracy: 85.6 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 0.5052, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 0.4648, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 0.6170, batch time: 0.04, accuracy:  78.91%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 0.5444, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 0.4117, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 0.5807, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 0.4628, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 0.5396, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 0.4747, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 0.3472, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 0.5381126999855042, accuracy: 84.2 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 0.5582602620124817, accuracy: 83.2 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 0.6664125323295593, accuracy: 79.5 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 0.6640671491622925, accuracy: 77.6 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 0.5127995014190674, accuracy: 83.9 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 0.48309317231178284, accuracy: 86.4 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 0.4816893935203552, accuracy: 86.5 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 0.4929637312889099, accuracy: 85.0 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 0.4773472845554352, accuracy: 86.6 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 0.4784161150455475, accuracy: 86.1 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 0.5822, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 0.5285, batch time: 0.09, accuracy:  81.25%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 0.2940, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 0.5205, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 0.3828, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 0.4369, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 0.4205, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 0.5630, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 0.3876, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 0.6595, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 0.39769724011421204, accuracy: 87.5 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 0.49329227209091187, accuracy: 83.7 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 0.40095219016075134, accuracy: 87.5 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 0.395801842212677, accuracy: 87.7 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 0.6446569561958313, accuracy: 76.9 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 0.423117995262146, accuracy: 87.6 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 0.3973619341850281, accuracy: 87.2 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 0.3977977931499481, accuracy: 87.7 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 0.418874591588974, accuracy: 87.1 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 0.3915881812572479, accuracy: 87.6 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 0.5814, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 0.3825, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 0.7005, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 0.4626, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 0.4168, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 0.4306, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 0.4340, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 0.3779, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 0.4070, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 0.5001, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 0.5607740879058838, accuracy: 82.3 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 0.8131691813468933, accuracy: 73.6 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 0.4907819330692291, accuracy: 86.1 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 0.4821237325668335, accuracy: 86.4 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 0.44694021344184875, accuracy: 87.0 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 0.6078657507896423, accuracy: 78.9 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 3.1184468269348145, accuracy: 50.2 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 0.4336399435997009, accuracy: 87.4 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 0.43156763911247253, accuracy: 87.2 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 0.45162537693977356, accuracy: 86.4 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 0.5492, batch time: 0.12, accuracy:  85.16%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 0.4691, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 0.2844, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 0.4651, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 0.3407, batch time: 0.08, accuracy:  90.62%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 0.5488, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 0.6285, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 0.6933, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 0.5351, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 0.3476, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 0.45494213700294495, accuracy: 87.4 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 2.7718307971954346, accuracy: 48.6 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 0.4340437650680542, accuracy: 86.0 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 1.1148866415023804, accuracy: 64.5 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 0.4182772934436798, accuracy: 87.4 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 0.48042139410972595, accuracy: 85.0 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 0.4108717441558838, accuracy: 87.5 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 0.43741971254348755, accuracy: 85.8 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 0.4431760907173157, accuracy: 86.2 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 0.4115702211856842, accuracy: 87.4 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 0.4856, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 0.5004, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 0.5560, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 0.4733, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 0.6507, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 0.5533, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 0.6870, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 0.3387, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 0.4338, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 0.4331, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 0.4173945188522339, accuracy: 88.1 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 0.4267003536224365, accuracy: 87.6 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 0.40479105710983276, accuracy: 89.1 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 0.4013565480709076, accuracy: 89.2 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 0.4959513247013092, accuracy: 85.7 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 0.4035594165325165, accuracy: 88.7 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 0.392660915851593, accuracy: 89.0 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 0.39104437828063965, accuracy: 89.0 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 0.3909488320350647, accuracy: 88.7 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 0.3977262079715729, accuracy: 89.4 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 0.6033, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 0.3925, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 0.4930, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 0.5330, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 0.3882, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 0.4180, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 0.5741, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 0.4521, batch time: 0.09, accuracy:  87.50%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 0.4937, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 0.5121, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 0.5677000880241394, accuracy: 83.2 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 0.5638670325279236, accuracy: 83.5 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 0.5195774435997009, accuracy: 85.8 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 0.5167123675346375, accuracy: 86.0 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 0.6654760241508484, accuracy: 81.3 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 0.507302463054657, accuracy: 85.6 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 0.5007678270339966, accuracy: 86.0 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 0.486214816570282, accuracy: 86.7 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 0.48353978991508484, accuracy: 87.3 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 0.48099225759506226, accuracy: 86.9 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 0.4510, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 0.3437, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 0.4622, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 0.4960, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 0.4783, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 0.3328, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 0.6178, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 0.3451, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 0.3595, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 0.3642, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 0.4060214161872864, accuracy: 88.6 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 0.6089981198310852, accuracy: 82.4 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 0.4412427842617035, accuracy: 87.2 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 0.8577171564102173, accuracy: 76.0 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 0.6628711223602295, accuracy: 79.6 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 0.6043540239334106, accuracy: 81.5 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 0.39945074915885925, accuracy: 88.2 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 0.40096503496170044, accuracy: 88.6 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 0.39929813146591187, accuracy: 88.5 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 0.3947402834892273, accuracy: 88.9 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 0.4301, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 0.2768, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 0.4580, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 0.4046, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 0.5235, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 0.4711, batch time: 0.06, accuracy:  86.72%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 0.3503, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 0.4670, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 0.6004, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 0.4039, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 0.4258481562137604, accuracy: 87.3 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 0.42341217398643494, accuracy: 87.0 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 0.4538947343826294, accuracy: 86.4 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 0.41646674275398254, accuracy: 87.2 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 0.41382744908332825, accuracy: 87.5 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 1.612024188041687, accuracy: 67.2 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 0.4339512586593628, accuracy: 86.9 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 0.8479430079460144, accuracy: 73.3 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 0.4134142994880676, accuracy: 87.2 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 0.4021341800689697, accuracy: 87.4 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 0.4281, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 0.2626, batch time: 0.21, accuracy:  90.62%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 0.3961, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 0.6518, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 0.4372, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 0.4481, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 0.4286, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 0.3484, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 0.3666, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 0.5673, batch time: 0.08, accuracy:  85.16%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 0.4303135573863983, accuracy: 87.7 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 11.458169937133789, accuracy: 22.4 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 0.7430251836776733, accuracy: 78.7 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 18.66762924194336, accuracy: 20.2 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 0.4007112979888916, accuracy: 88.2 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 0.39431166648864746, accuracy: 87.2 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 0.39122673869132996, accuracy: 88.1 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 0.37286248803138733, accuracy: 88.7 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 0.36713024973869324, accuracy: 88.7 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 0.36240383982658386, accuracy: 88.5 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 0.6278, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 0.3731, batch time: 0.06, accuracy:  92.97%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 0.5581, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 0.6169, batch time: 0.07, accuracy:  82.81%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 0.4727, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 0.5172, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 0.4164, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 0.3894, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 0.5959, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 0.5675, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 0.5021403431892395, accuracy: 83.8 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 0.5008246898651123, accuracy: 83.1 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 0.4858120083808899, accuracy: 84.9 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 0.48432740569114685, accuracy: 85.0 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 0.6006231904029846, accuracy: 80.9 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 1.0380158424377441, accuracy: 73.1 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 0.4707880914211273, accuracy: 85.4 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 0.4707859456539154, accuracy: 85.3 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 0.45795607566833496, accuracy: 85.2 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 0.4842413067817688, accuracy: 84.3 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 0.4540, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 0.3329, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 0.3916, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 0.4060, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 0.3229, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 0.6262, batch time: 0.11, accuracy:  79.69%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 0.4990, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 0.4654, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 0.4633, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 0.3951, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 0.4485399127006531, accuracy: 86.2 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 0.44628527760505676, accuracy: 86.6 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 0.4520951211452484, accuracy: 87.0 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 0.7960734367370605, accuracy: 75.4 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 0.4288948178291321, accuracy: 87.6 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 0.4286563992500305, accuracy: 87.8 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 0.48947155475616455, accuracy: 86.0 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 0.4251742660999298, accuracy: 87.6 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 0.43293997645378113, accuracy: 87.0 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 0.6045556664466858, accuracy: 81.1 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 0.6630, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 0.4898, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 0.3826, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 0.3579, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 0.3816, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 0.4851, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 0.4605, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 0.7576, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 0.4400, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 0.5791, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 0.39565905928611755, accuracy: 88.7 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 0.41209402680397034, accuracy: 88.2 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 0.4604262411594391, accuracy: 86.6 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 0.872025728225708, accuracy: 70.1 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 0.39238977432250977, accuracy: 89.4 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 0.3842902183532715, accuracy: 89.1 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 0.3904893100261688, accuracy: 89.2 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 0.38094213604927063, accuracy: 89.3 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 0.3794064223766327, accuracy: 90.4 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 0.38158342242240906, accuracy: 89.1 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 0.3964, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 0.4489, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 0.2565, batch time: 0.08, accuracy:  92.19%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 0.4328, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 0.7405, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 0.3818, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 0.4667, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 0.3904, batch time: 0.08, accuracy:  88.28%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 0.4281, batch time: 0.31, accuracy:  83.59%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 0.3897, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 0.4402576982975006, accuracy: 86.5 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 0.44804638624191284, accuracy: 86.3 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 0.47743016481399536, accuracy: 85.6 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 0.8573038578033447, accuracy: 75.9 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 0.42400771379470825, accuracy: 87.5 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 0.4184832274913788, accuracy: 87.4 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 0.4225100576877594, accuracy: 87.8 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 0.41581296920776367, accuracy: 87.8 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 0.41629523038864136, accuracy: 87.9 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 0.41438108682632446, accuracy: 87.8 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 0.3062, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 0.6922, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 0.5802, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 0.6865, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 0.4167, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 0.4394, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 0.4986, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 0.3939, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 0.4613, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 0.4379, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 0.40297791361808777, accuracy: 87.1 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 0.4128125309944153, accuracy: 87.0 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 0.4577594995498657, accuracy: 85.7 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 0.7634950876235962, accuracy: 75.9 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 0.3963339924812317, accuracy: 87.1 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 0.3920570909976959, accuracy: 87.3 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 0.39051949977874756, accuracy: 87.7 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 0.39472857117652893, accuracy: 88.0 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 0.4201624095439911, accuracy: 87.3 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 0.4334523677825928, accuracy: 87.3 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 0.3530, batch time: 0.09, accuracy:  89.84%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 0.4329, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 0.3011, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 0.3576, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 0.3101, batch time: 0.07, accuracy:  88.28%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 0.4215, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 0.4029, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 0.5908, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 0.3303, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 0.5290, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 0.3901907801628113, accuracy: 88.1 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 0.40380537509918213, accuracy: 87.4 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 0.49874216318130493, accuracy: 85.0 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 0.6560818552970886, accuracy: 80.4 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 0.37535399198532104, accuracy: 88.4 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 0.3655206561088562, accuracy: 88.5 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 0.3626614511013031, accuracy: 89.0 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 0.37006959319114685, accuracy: 88.8 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 0.36179566383361816, accuracy: 89.1 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 0.36558935046195984, accuracy: 89.1 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 0.5616, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 0.4923, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 0.7992, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 0.3871, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 0.5946, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 0.4427, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 0.5011, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 0.2170, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 0.2965, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 0.4034, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 0.41911938786506653, accuracy: 87.6 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 0.8576505780220032, accuracy: 72.2 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 0.46459341049194336, accuracy: 85.1 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 28.011302947998047, accuracy: 12.2 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 0.41662949323654175, accuracy: 87.2 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 0.4293747544288635, accuracy: 87.8 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 0.4259544312953949, accuracy: 86.5 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 0.4048219621181488, accuracy: 88.2 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 0.40498071908950806, accuracy: 87.8 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 0.4028084874153137, accuracy: 88.1 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 0.3490, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 0.2791, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 0.4985, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 0.4330, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 0.4845, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 0.3893, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 0.3482, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 0.4905, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 0.3135, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 0.5622, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 0.41840723156929016, accuracy: 87.4 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 0.7064096927642822, accuracy: 77.4 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 0.406669944524765, accuracy: 87.9 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 0.40645459294319153, accuracy: 87.9 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 0.8542428612709045, accuracy: 73.5 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 0.4887291193008423, accuracy: 85.4 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 0.39706674218177795, accuracy: 87.9 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 0.39162901043891907, accuracy: 88.6 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 0.40355196595191956, accuracy: 88.1 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 0.3896450400352478, accuracy: 89.2 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 0.3159, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 0.4716, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 0.5581, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 0.3238, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 0.5239, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 0.2755, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 0.3529, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 0.3101, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 0.5134, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 0.4536, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 0.36969658732414246, accuracy: 88.0 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 5.252182960510254, accuracy: 39.3 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 0.3609793186187744, accuracy: 88.9 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 0.3609793186187744, accuracy: 88.9 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 0.3550727069377899, accuracy: 89.3 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 0.3488224148750305, accuracy: 88.9 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 0.35887640714645386, accuracy: 88.9 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 0.3528887927532196, accuracy: 90.2 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 0.3446776568889618, accuracy: 89.8 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 0.3442554175853729, accuracy: 90.0 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 0.5659, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 0.4011, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 0.3784, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 0.7012, batch time: 0.10, accuracy:  76.56%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 0.4620, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 0.4365, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 0.6590, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 0.3811, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 0.6374, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 0.3720, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 0.3927173316478729, accuracy: 89.0 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 0.7356233596801758, accuracy: 78.3 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 0.38162627816200256, accuracy: 90.1 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 0.3814687728881836, accuracy: 90.0 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 0.49718305468559265, accuracy: 85.2 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 0.37850871682167053, accuracy: 90.0 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 0.39956578612327576, accuracy: 89.4 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 0.37457627058029175, accuracy: 89.5 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 0.382524698972702, accuracy: 89.2 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 0.4268667995929718, accuracy: 87.3 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 0.4758, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 0.3935, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 0.4304, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 0.3135, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 0.4621, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 0.5472, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 0.3754, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 0.4625, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 0.4616, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 0.4013, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 0.425141841173172, accuracy: 87.9 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 0.42477643489837646, accuracy: 88.0 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 0.4155958592891693, accuracy: 87.6 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 0.4089426100254059, accuracy: 87.5 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 1.2343165874481201, accuracy: 77.3 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 0.4013214409351349, accuracy: 87.7 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 0.40505921840667725, accuracy: 87.9 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 0.3970591425895691, accuracy: 87.5 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 0.42248132824897766, accuracy: 87.5 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 0.4015869200229645, accuracy: 88.2 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 0.4602, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 0.3334, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 0.4336, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 0.3112, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 0.3963, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 0.4681, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 0.4520, batch time: 0.07, accuracy:  89.06%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 0.4020, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 0.5210, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 0.3924, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 0.4109281003475189, accuracy: 88.3 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 0.9226179718971252, accuracy: 73.0 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 0.3981742858886719, accuracy: 89.1 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 0.39777061343193054, accuracy: 89.1 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 0.40521135926246643, accuracy: 89.0 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 0.39094215631484985, accuracy: 88.2 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 0.4026232063770294, accuracy: 88.4 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 0.3846200108528137, accuracy: 88.5 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 0.3872066140174866, accuracy: 88.7 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 0.3808594346046448, accuracy: 89.3 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 0.3999, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 0.4501, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 0.4826, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 0.3262, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 0.3478, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 0.3222, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 0.3347, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 0.5087, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 0.4029, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 0.5711, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 0.4382938742637634, accuracy: 86.6 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 0.4339227080345154, accuracy: 86.8 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 0.43306809663772583, accuracy: 86.6 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 0.4324730634689331, accuracy: 86.7 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 0.44702449440956116, accuracy: 85.6 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 0.41539517045021057, accuracy: 86.7 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 0.41294384002685547, accuracy: 86.9 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 0.45196741819381714, accuracy: 86.1 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 0.40494412183761597, accuracy: 87.1 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 0.4239403307437897, accuracy: 86.5 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 0.4293, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 0.4753, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 0.4831, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 0.4030, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 0.4610, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 0.2933, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 0.4620, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 0.3366, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 0.2944, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 0.3539, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 0.3683491349220276, accuracy: 87.9 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 0.3699896037578583, accuracy: 88.1 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 0.5041635632514954, accuracy: 83.1 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 48.93363952636719, accuracy: 9.8 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 0.38623300194740295, accuracy: 86.9 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 0.3516440689563751, accuracy: 88.7 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 0.3631528913974762, accuracy: 87.5 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 0.34550508856773376, accuracy: 89.0 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 0.3445568382740021, accuracy: 88.7 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 0.3498390316963196, accuracy: 88.4 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 0.3674, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 0.4931, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 0.5049, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 0.3607, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 0.4675, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 0.6268, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 0.3528, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 0.6204, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 0.3376, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 0.4230, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 0.4336601495742798, accuracy: 87.4 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 38.09909439086914, accuracy: 11.9 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 0.4254322350025177, accuracy: 87.6 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 0.4303896427154541, accuracy: 87.5 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 0.42128506302833557, accuracy: 87.8 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 0.41944223642349243, accuracy: 87.6 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 0.4558488130569458, accuracy: 86.6 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 0.41619229316711426, accuracy: 88.4 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 0.4254012107849121, accuracy: 89.0 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 0.8909230828285217, accuracy: 72.1 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 0.4963, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 0.4583, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 0.4620, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 0.4170, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 0.4715, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 0.3361, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 0.7722, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 0.3928, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 0.5266, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 0.4327, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 0.4693043529987335, accuracy: 86.0 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 22.579116821289062, accuracy: 12.9 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 0.4550742208957672, accuracy: 85.2 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 0.44773268699645996, accuracy: 85.1 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 1.0637363195419312, accuracy: 71.8 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 1.0177197456359863, accuracy: 71.0 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 0.459031343460083, accuracy: 86.3 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 0.5427356362342834, accuracy: 83.7 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 60.77228546142578, accuracy: 9.0 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 0.4119744896888733, accuracy: 88.0 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 0.5141, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 0.3693, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 0.2966, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 0.3053, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 0.4025, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 0.3721, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 0.3460, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 0.3452, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 0.5684, batch time: 0.04, accuracy:  82.03%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 0.5178, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 0.4038505554199219, accuracy: 88.1 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 0.4023875594139099, accuracy: 88.2 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 0.40912237763404846, accuracy: 87.7 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 23.884349822998047, accuracy: 13.9 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 0.39696353673934937, accuracy: 88.8 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 0.4200059473514557, accuracy: 87.6 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 0.381166011095047, accuracy: 89.6 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 0.367779940366745, accuracy: 89.7 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 0.36982670426368713, accuracy: 90.0 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 0.36948537826538086, accuracy: 89.0 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 0.4640, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 0.3591, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 0.4863, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 0.3622, batch time: 0.23, accuracy:  89.06%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 0.4100, batch time: 0.09, accuracy:  88.28%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 0.3254, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 0.5158, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 0.3722, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 0.3456, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 0.3189, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 0.4679597020149231, accuracy: 86.8 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 3.7218739986419678, accuracy: 39.7 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 0.6770203113555908, accuracy: 78.7 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 0.4777214229106903, accuracy: 84.9 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 0.41133683919906616, accuracy: 88.1 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 0.40048670768737793, accuracy: 89.4 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 0.4132975935935974, accuracy: 88.8 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 0.401283860206604, accuracy: 88.9 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 0.4018959701061249, accuracy: 88.9 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 0.3916004002094269, accuracy: 89.3 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 0.4322, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 0.2682, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 0.3743, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 0.4025, batch time: 0.07, accuracy:  89.84%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 0.4117, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 0.4820, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 0.3276, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 0.3957, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 0.4110, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 0.2582, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 0.37894541025161743, accuracy: 88.5 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 3.0805916786193848, accuracy: 38.3 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 0.5884040594100952, accuracy: 80.1 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 0.5403077602386475, accuracy: 81.6 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 0.3856625556945801, accuracy: 87.5 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 0.3618652820587158, accuracy: 88.9 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 0.3648569881916046, accuracy: 88.3 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 0.35210222005844116, accuracy: 89.0 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 0.3497036099433899, accuracy: 89.0 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 0.34652724862098694, accuracy: 89.1 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 0.4682, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 0.4695, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 0.3294, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 0.3200, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 0.5076, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 0.5192, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 0.6302, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 0.3184, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 0.5137, batch time: 0.06, accuracy:  82.81%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 0.4044, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 0.3838382959365845, accuracy: 87.6 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 0.3838297426700592, accuracy: 87.7 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 0.38484126329421997, accuracy: 88.0 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 0.3800657391548157, accuracy: 88.0 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 0.373180091381073, accuracy: 88.0 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 0.36928078532218933, accuracy: 88.4 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 0.3674197196960449, accuracy: 88.3 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 0.3720129132270813, accuracy: 88.6 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 0.36551353335380554, accuracy: 88.6 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 0.371491014957428, accuracy: 88.6 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 0.5166, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 0.4209, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 0.4705, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 0.5608, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 0.4211, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 0.3017, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 0.3474, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 0.3658, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 0.4025, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 0.4382, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 0.4015892446041107, accuracy: 87.4 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 0.4336133599281311, accuracy: 86.4 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 0.5418647527694702, accuracy: 81.9 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 9.339581489562988, accuracy: 31.1 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 0.4015091061592102, accuracy: 87.6 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 0.36772623658180237, accuracy: 88.8 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 0.3684077560901642, accuracy: 88.5 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 0.3668619394302368, accuracy: 88.8 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 0.3939288258552551, accuracy: 88.7 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 0.3834761679172516, accuracy: 88.4 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 0.5591, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 0.2861, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 0.5002, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 0.3911, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 0.3665, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 0.2350, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 0.2901, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 0.3988, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 0.5147, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 0.2977, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 0.3691446781158447, accuracy: 90.2 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 2.555356025695801, accuracy: 49.4 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 0.8890236616134644, accuracy: 74.1 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 0.6796784996986389, accuracy: 78.3 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 0.36367377638816833, accuracy: 88.9 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 0.35839328169822693, accuracy: 89.8 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 0.36008480191230774, accuracy: 89.2 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 0.37536466121673584, accuracy: 89.2 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 0.3609485328197479, accuracy: 89.8 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 0.35444018244743347, accuracy: 89.7 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 0.5076, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 0.4866, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 0.4823, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 0.4470, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 0.4036, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 0.5137, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 0.4976, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 0.3145, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 0.4025, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 0.3470, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 0.3240644037723541, accuracy: 91.0 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 0.3356178104877472, accuracy: 89.8 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 0.3237820267677307, accuracy: 90.4 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 108.7761459350586, accuracy: 8.9 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 0.296199232339859, accuracy: 91.0 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 0.30091288685798645, accuracy: 90.4 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 0.3444185256958008, accuracy: 89.3 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 0.2947518229484558, accuracy: 91.5 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 0.2911001443862915, accuracy: 90.9 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 0.33761096000671387, accuracy: 89.0 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 0.3319, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 0.3766, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 0.3593, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 0.3469, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 0.4093, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 0.4220, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 0.3348, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 0.3195, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 0.3856, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 0.4282, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 0.36455851793289185, accuracy: 89.6 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 0.7750105261802673, accuracy: 73.6 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 0.36944064497947693, accuracy: 89.3 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 0.38607874512672424, accuracy: 87.9 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 0.3501241207122803, accuracy: 89.4 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 0.3802134692668915, accuracy: 88.4 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 23.45627784729004, accuracy: 8.1 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 0.3588838577270508, accuracy: 89.3 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 0.3378300666809082, accuracy: 90.6 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 0.4391247630119324, accuracy: 85.2 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 0.5701, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 0.4591, batch time: 0.09, accuracy:  83.59%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 0.4271, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 0.3764, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 0.3779, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 0.4449, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 0.5367, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 0.4174, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 0.4149, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 0.4376, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 0.43713173270225525, accuracy: 86.9 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 25.09404754638672, accuracy: 12.3 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 0.39608460664749146, accuracy: 87.9 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 0.39523303508758545, accuracy: 88.0 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 0.39725759625434875, accuracy: 87.5 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 0.825934886932373, accuracy: 75.7 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 0.3704458177089691, accuracy: 88.6 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 0.3641236424446106, accuracy: 89.2 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 0.36297985911369324, accuracy: 88.4 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 0.35875752568244934, accuracy: 89.0 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 0.3674, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 0.3218, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 0.3005, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 0.4316, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 0.2989, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 0.5949, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 0.5065, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 0.4325, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 0.3395, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 0.4500, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 0.3938499391078949, accuracy: 87.3 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 0.6016055345535278, accuracy: 79.0 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 0.3885689377784729, accuracy: 87.2 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 0.38699811697006226, accuracy: 87.6 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 0.38749223947525024, accuracy: 87.4 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 0.37365037202835083, accuracy: 88.2 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 0.36754295229911804, accuracy: 88.0 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 0.3638686239719391, accuracy: 88.6 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 0.4273722469806671, accuracy: 86.0 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 0.3625493049621582, accuracy: 88.8 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 0.3347, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 0.3186, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 0.5051, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 0.5938, batch time: 0.09, accuracy:  82.81%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 0.4227, batch time: 0.07, accuracy:  85.16%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 0.2481, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 0.3489, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 0.3365, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 0.5080, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 0.3136, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 0.3772027790546417, accuracy: 88.5 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 2.310791015625, accuracy: 52.7 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 0.45400792360305786, accuracy: 84.1 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 0.5910607576370239, accuracy: 81.2 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 0.39031311869621277, accuracy: 88.0 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 0.3714739680290222, accuracy: 88.6 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 0.4210318624973297, accuracy: 86.9 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 0.37248000502586365, accuracy: 88.7 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 0.3651556372642517, accuracy: 88.7 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 0.36188724637031555, accuracy: 88.8 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 0.3320, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 0.3172, batch time: 0.08, accuracy:  90.62%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 0.3778, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 0.3934, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 0.4665, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 0.3757, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 0.4461, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 0.4672, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 0.3771, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 0.3833, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 0.38938701152801514, accuracy: 88.9 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 0.3908720910549164, accuracy: 89.0 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 0.4574147164821625, accuracy: 85.3 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 0.5361414551734924, accuracy: 83.8 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 0.403412401676178, accuracy: 87.8 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 0.3743590712547302, accuracy: 88.9 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 0.374088853597641, accuracy: 89.7 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 0.37458285689353943, accuracy: 89.2 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 0.3732471168041229, accuracy: 89.5 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 2.9202606678009033, accuracy: 39.1 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 0.5491, batch time: 0.06, accuracy:  78.91%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 0.3535, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 0.3641, batch time: 0.27, accuracy:  88.28%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 0.4796, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 0.3080, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 0.3648, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 0.6908, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 0.3757, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 0.4845, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 0.2590, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 0.40725409984588623, accuracy: 87.8 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 0.40939512848854065, accuracy: 87.7 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 0.4653499722480774, accuracy: 85.0 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 35.887367248535156, accuracy: 14.4 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 0.385778546333313, accuracy: 87.6 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 0.3804468512535095, accuracy: 87.9 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 0.3810882866382599, accuracy: 87.8 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 0.39774447679519653, accuracy: 87.3 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 0.4041920006275177, accuracy: 87.3 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 0.37446117401123047, accuracy: 88.9 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 0.4231, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 0.3607, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 0.3327, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 0.2720, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 0.3149, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 0.2263, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 0.4503, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 0.3225, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 0.4755, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 0.3039, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 0.3495609760284424, accuracy: 89.2 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 9.482723236083984, accuracy: 17.6 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 0.40088024735450745, accuracy: 86.5 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 127.1142807006836, accuracy: 10.1 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 0.3394618332386017, accuracy: 90.3 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 0.33640924096107483, accuracy: 90.8 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 0.3648849129676819, accuracy: 89.9 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 0.35398659110069275, accuracy: 89.2 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 0.33733513951301575, accuracy: 91.1 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 0.3324248790740967, accuracy: 90.5 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 0.3520, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 0.3540, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 0.3902, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 0.5592, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 0.5598, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 0.4709, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 0.2998, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 0.4865, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 0.4874, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 0.3805, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 0.3847655653953552, accuracy: 87.1 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 1.1706736087799072, accuracy: 66.9 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 0.3823016881942749, accuracy: 87.4 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 3.0190913677215576, accuracy: 41.7 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 0.5285151600837708, accuracy: 83.9 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 34.07060623168945, accuracy: 12.1 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 0.35457587242126465, accuracy: 87.9 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 0.35195010900497437, accuracy: 87.9 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 0.35053640604019165, accuracy: 88.1 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 0.3595585227012634, accuracy: 88.1 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 0.3418, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 0.3922, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 0.3442, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 0.3560, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 0.4581, batch time: 0.04, accuracy:  83.59%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 0.3453, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 0.4227, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 0.4938, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 0.3453, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 0.3252, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 0.3810335397720337, accuracy: 87.1 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 12.276799201965332, accuracy: 18.9 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 0.44610247015953064, accuracy: 86.0 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 0.962799608707428, accuracy: 68.7 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 0.3847484290599823, accuracy: 88.3 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 0.614539384841919, accuracy: 78.8 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 0.3820008337497711, accuracy: 87.2 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 0.6473838686943054, accuracy: 77.5 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 0.3687170445919037, accuracy: 88.7 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 0.37663742899894714, accuracy: 88.2 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 0.4049, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 0.3881, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 0.4547, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 0.5866, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 0.3378, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 0.5486, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 0.1666, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 0.4279, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 0.3358, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 0.3889, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 0.279491662979126, accuracy: 91.3 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 12.287970542907715, accuracy: 17.6 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 0.6583319306373596, accuracy: 80.5 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 0.6418652534484863, accuracy: 78.8 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 0.28036728501319885, accuracy: 90.9 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 0.2760133147239685, accuracy: 90.6 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 0.2906278073787689, accuracy: 90.3 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 0.27712148427963257, accuracy: 90.8 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 0.3036133348941803, accuracy: 89.2 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 0.26750507950782776, accuracy: 91.0 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 0.3490, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 0.3946, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 0.3526, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 0.2987, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 0.4334, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 0.2527, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 0.2912, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 0.4178, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 0.5360, batch time: 0.08, accuracy:  82.81%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 0.3832, batch time: 0.09, accuracy:  89.06%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 0.34954145550727844, accuracy: 89.1 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 0.34989234805107117, accuracy: 89.5 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 0.3461771309375763, accuracy: 89.5 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 1.7789316177368164, accuracy: 54.0 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 0.3491450250148773, accuracy: 89.6 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 0.3306097686290741, accuracy: 90.5 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 0.35566815733909607, accuracy: 89.2 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 0.3352234959602356, accuracy: 89.6 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 0.3286888301372528, accuracy: 90.3 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 0.44286108016967773, accuracy: 86.0 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 0.4100, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 0.4515, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 0.5189, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 0.3999, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 0.2799, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 0.4438, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 0.4223, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 0.2792, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 0.3303, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 0.5002, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 0.38865476846694946, accuracy: 87.5 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 0.5146774649620056, accuracy: 84.0 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 0.37498390674591064, accuracy: 87.6 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 0.36715957522392273, accuracy: 87.8 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 0.7808273434638977, accuracy: 77.2 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 0.36779364943504333, accuracy: 87.5 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 0.3661215901374817, accuracy: 88.0 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 0.3749994933605194, accuracy: 87.5 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 0.3622909486293793, accuracy: 88.1 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 0.35982584953308105, accuracy: 88.3 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 0.4153, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 0.4025, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 0.3182, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 0.3466, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 0.2471, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 0.3538, batch time: 0.06, accuracy:  89.84%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 0.3192, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 0.5124, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 0.3004, batch time: 0.06, accuracy:  91.41%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 0.3911, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 0.3296756446361542, accuracy: 89.0 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 0.35021382570266724, accuracy: 88.7 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 0.41097286343574524, accuracy: 88.2 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 0.892204999923706, accuracy: 73.4 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 0.3142763376235962, accuracy: 90.3 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 0.3105384111404419, accuracy: 90.0 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 0.3167979121208191, accuracy: 89.3 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 0.3096376955509186, accuracy: 89.8 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 0.3065439760684967, accuracy: 89.8 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 0.30503618717193604, accuracy: 89.8 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 0.5483, batch time: 0.10, accuracy:  81.25%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 0.3538, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 0.3877, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 0.4635, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 0.4399, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 0.3776, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 0.4373, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 0.3541, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 0.4884, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 0.4734, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 0.3876468241214752, accuracy: 87.6 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 0.8512541651725769, accuracy: 74.8 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 0.40607088804244995, accuracy: 87.2 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 0.37367570400238037, accuracy: 88.7 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 0.5592368841171265, accuracy: 80.5 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 0.3646862506866455, accuracy: 88.6 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 0.40488070249557495, accuracy: 86.4 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 0.36036065220832825, accuracy: 89.0 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 0.4095783531665802, accuracy: 87.9 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 0.36179181933403015, accuracy: 89.2 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 0.3547, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 0.2893, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 0.3930, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 0.4364, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 0.3329, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 0.3804, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 0.3889, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 0.3630, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 0.3290, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 0.6621, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 0.33623045682907104, accuracy: 91.0 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 0.3983948826789856, accuracy: 88.7 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 0.33410462737083435, accuracy: 91.0 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 0.8096919655799866, accuracy: 77.3 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 0.3397018611431122, accuracy: 90.4 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 0.32699552178382874, accuracy: 90.8 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 0.326785147190094, accuracy: 90.2 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 0.3242471516132355, accuracy: 90.7 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 0.3395911157131195, accuracy: 90.5 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 0.3980942666530609, accuracy: 88.1 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 0.3462, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 0.4560, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 0.3859, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 0.4916, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 0.3745, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 0.4102, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 0.2978, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 0.5938, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 0.2778, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 0.4838, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 0.365041583776474, accuracy: 88.5 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 0.8183627724647522, accuracy: 75.8 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 0.36481618881225586, accuracy: 88.6 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 0.4006486237049103, accuracy: 87.4 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 0.37367746233940125, accuracy: 88.0 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 0.373258113861084, accuracy: 88.0 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 0.36777156591415405, accuracy: 88.9 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 0.35660120844841003, accuracy: 88.4 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 0.35618001222610474, accuracy: 88.8 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 0.3546648919582367, accuracy: 88.7 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 0.2988, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 0.3985, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 0.4143, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 0.4396, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 0.4437, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 0.3732, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 0.4203, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 0.4248, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 0.4457, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 0.3035, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 0.37532591819763184, accuracy: 89.0 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 13.199581146240234, accuracy: 17.9 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 0.5484007000923157, accuracy: 83.0 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 0.4353989064693451, accuracy: 86.9 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 0.3628963828086853, accuracy: 89.3 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 0.35779502987861633, accuracy: 89.9 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 0.3624430000782013, accuracy: 89.7 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 0.40051472187042236, accuracy: 87.9 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 0.36562684178352356, accuracy: 89.3 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 0.37379544973373413, accuracy: 88.7 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 0.3522, batch time: 0.12, accuracy:  87.50%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 0.4153, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 0.3666, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 0.3559, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 0.3830, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 0.3262, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 0.4680, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 0.4966, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 0.6285, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 0.4447, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 0.3974683880805969, accuracy: 88.4 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 0.3908179998397827, accuracy: 88.4 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 0.47553110122680664, accuracy: 83.9 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 0.378197580575943, accuracy: 89.3 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 1.2903023958206177, accuracy: 64.8 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 0.7513729333877563, accuracy: 77.3 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 0.37361738085746765, accuracy: 89.0 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 0.36275050044059753, accuracy: 89.9 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 0.3572651147842407, accuracy: 89.7 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 0.3577394187450409, accuracy: 89.6 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 0.2848, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 0.3558, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 0.4719, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 0.2972, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 0.3745, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 0.4725, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 0.5360, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 0.3991, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 0.2653, batch time: 0.07, accuracy:  91.41%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 0.3166, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 0.35227692127227783, accuracy: 88.0 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 13.08574390411377, accuracy: 18.5 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 0.6320923566818237, accuracy: 80.3 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 0.43248251080513, accuracy: 84.6 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 0.38761377334594727, accuracy: 87.5 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 18.130029678344727, accuracy: 24.5 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 0.3272593915462494, accuracy: 89.7 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 0.3309531807899475, accuracy: 88.5 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 0.32470059394836426, accuracy: 90.1 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 0.3285817801952362, accuracy: 89.6 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 0.3034, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 0.3465, batch time: 0.08, accuracy:  91.41%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 0.3367, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 0.4592, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 0.3634, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 0.4014, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 0.4224, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 0.2946, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 0.3307, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 0.3485, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 0.380266010761261, accuracy: 87.7 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 0.5954514741897583, accuracy: 82.0 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 0.4762361943721771, accuracy: 83.9 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 1.5867656469345093, accuracy: 56.2 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 0.38314488530158997, accuracy: 87.5 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 0.36180567741394043, accuracy: 87.9 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 0.35760411620140076, accuracy: 88.5 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 0.35748204588890076, accuracy: 88.0 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 0.35163894295692444, accuracy: 88.0 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 0.37098291516304016, accuracy: 89.3 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 0.3032, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 0.3876, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 0.3823, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 0.3944, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 0.3457, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 0.4506, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 0.5145, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 0.4006, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 0.3248, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 0.4770, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 0.3184736967086792, accuracy: 90.2 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 0.32967647910118103, accuracy: 90.6 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 0.7057207226753235, accuracy: 77.9 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 0.7792671918869019, accuracy: 75.4 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 0.31476178765296936, accuracy: 90.2 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 0.30909422039985657, accuracy: 90.4 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 0.30635884404182434, accuracy: 90.6 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 0.33344846963882446, accuracy: 90.0 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 0.306770920753479, accuracy: 90.8 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 0.30290383100509644, accuracy: 90.7 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 0.3482, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 0.3084, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 0.4386, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 0.2851, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 0.3366, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 0.2642, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 0.5445, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 0.4046, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 0.3073, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 0.3127, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 0.3867388665676117, accuracy: 87.6 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 2.145792007446289, accuracy: 56.3 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 0.4954673945903778, accuracy: 83.2 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 38.11867141723633, accuracy: 12.1 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 0.37493443489074707, accuracy: 88.4 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 0.3722805380821228, accuracy: 88.3 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 0.37029939889907837, accuracy: 88.8 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 0.3701825737953186, accuracy: 88.9 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 0.36927711963653564, accuracy: 88.7 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 0.3854009509086609, accuracy: 87.8 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 0.3783, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 0.3490, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 0.4788, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 0.2870, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 0.3893, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 0.3407, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 0.3296, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 0.4256, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 0.4078, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 0.2326, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 0.3059263527393341, accuracy: 89.9 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 0.3088027536869049, accuracy: 89.6 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 0.3053736090660095, accuracy: 89.7 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 5.309384822845459, accuracy: 33.9 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 0.2999464273452759, accuracy: 90.7 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 0.3042364716529846, accuracy: 90.2 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 0.29730725288391113, accuracy: 90.2 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 0.31289729475975037, accuracy: 90.1 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 0.7234271168708801, accuracy: 73.4 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 0.28899696469306946, accuracy: 91.0 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 0.3490, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 0.3098, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 0.4182, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 0.4042, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 0.2790, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 0.3941, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 0.3191, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 0.5968, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 0.2642, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 0.3405, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 0.31771010160446167, accuracy: 89.6 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 0.3244645297527313, accuracy: 89.6 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 0.4293694794178009, accuracy: 87.5 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 0.3126479685306549, accuracy: 90.2 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 0.3374527394771576, accuracy: 89.1 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 0.310866117477417, accuracy: 90.5 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 0.6124054789543152, accuracy: 80.7 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 0.3086823523044586, accuracy: 89.4 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 0.3168323040008545, accuracy: 89.4 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 0.314250111579895, accuracy: 89.2 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 0.3687, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 0.3478, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 0.5080, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 0.3762, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 0.5092, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 0.2578, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 0.3390, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 0.2237, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 0.2892, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 0.5517, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 0.3586498200893402, accuracy: 89.9 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 0.35770848393440247, accuracy: 89.6 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 0.3565504550933838, accuracy: 89.6 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 0.3565235733985901, accuracy: 89.6 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 0.849048376083374, accuracy: 75.2 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 0.34583738446235657, accuracy: 89.6 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 0.3539096415042877, accuracy: 89.3 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 0.3470141291618347, accuracy: 89.7 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 0.35775917768478394, accuracy: 90.2 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 0.34288063645362854, accuracy: 90.2 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 0.4371, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 0.5027, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 0.3470, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 0.5053, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 0.2753, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 0.3953, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 0.2363, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 0.3659, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 0.3635, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 0.4532, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 0.28766560554504395, accuracy: 91.4 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 20.379257202148438, accuracy: 14.9 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 0.36691394448280334, accuracy: 88.8 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 195.4999237060547, accuracy: 11.4 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 0.28225114941596985, accuracy: 91.8 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 0.2809905409812927, accuracy: 91.8 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 0.29191237688064575, accuracy: 91.3 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 0.31138354539871216, accuracy: 90.5 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 0.2750985622406006, accuracy: 91.6 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 0.2742835581302643, accuracy: 91.5 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 0.3102, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 0.3618, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 0.3813, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 0.3339, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 0.4242, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 0.3171, batch time: 0.09, accuracy:  91.41%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 0.3841, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 0.3556, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 0.3269, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 0.4062, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 0.44283899664878845, accuracy: 88.0 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 21.080354690551758, accuracy: 12.3 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 0.5723947286605835, accuracy: 82.6 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 0.4887984097003937, accuracy: 86.7 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 0.43052172660827637, accuracy: 87.9 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 0.4311702847480774, accuracy: 88.0 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 0.4396667778491974, accuracy: 87.0 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 0.5159092545509338, accuracy: 84.9 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 0.47995853424072266, accuracy: 84.4 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 0.43184325098991394, accuracy: 87.6 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 0.4896, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 0.3041, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 0.3070, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 0.3633, batch time: 0.07, accuracy:  90.62%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 0.3442, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 0.3621, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 0.2861, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 0.2086, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 0.3290, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 0.3155, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 0.27556461095809937, accuracy: 90.8 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 0.4811117351055145, accuracy: 84.7 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 0.2747774124145508, accuracy: 91.0 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 1.3880341053009033, accuracy: 70.3 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 0.31200990080833435, accuracy: 90.5 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 0.2825901508331299, accuracy: 91.4 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 0.26304325461387634, accuracy: 92.2 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 0.26490405201911926, accuracy: 92.2 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 0.27092450857162476, accuracy: 91.7 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 0.2636725604534149, accuracy: 92.2 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 0.3522, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 0.3391, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 0.3740, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 0.3025, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 0.3581, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 0.3450, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 0.4129, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 0.3942, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 0.3867, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 0.3935, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 0.4176841974258423, accuracy: 86.0 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 0.41672417521476746, accuracy: 85.9 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 0.36445146799087524, accuracy: 88.0 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 0.35749924182891846, accuracy: 88.0 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 1.0826166868209839, accuracy: 73.7 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 0.5623711347579956, accuracy: 81.3 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 1.1521347761154175, accuracy: 70.2 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 207.92262268066406, accuracy: 11.1 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 0.5328853130340576, accuracy: 81.7 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 1.356465220451355, accuracy: 63.6 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 0.4246, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 0.2857, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 0.4847, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 0.3862, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 0.3136, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 0.3461, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 0.3745, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 0.3288, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 0.3895, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 0.3118, batch time: 0.36, accuracy:  91.41%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 0.3563317060470581, accuracy: 88.6 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 226.7792205810547, accuracy: 10.8 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 0.3556210398674011, accuracy: 88.4 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 0.4027006924152374, accuracy: 87.6 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 0.3524134159088135, accuracy: 87.9 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 0.35051557421684265, accuracy: 88.5 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 0.34491467475891113, accuracy: 88.5 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 0.3498263657093048, accuracy: 88.4 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 0.3545890152454376, accuracy: 88.5 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 0.6498448848724365, accuracy: 79.5 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 0.2931, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 0.4046, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 0.2504, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 0.3141, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 0.2891, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 0.4906, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 0.3707, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 0.4626, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 0.3851, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 0.3520, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 0.382483571767807, accuracy: 87.0 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 585.0991821289062, accuracy: 8.5 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 0.47576403617858887, accuracy: 83.6 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 0.5991451740264893, accuracy: 80.8 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 12.06910514831543, accuracy: 23.6 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 0.35356634855270386, accuracy: 88.5 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 0.4213981330394745, accuracy: 87.2 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 0.361587792634964, accuracy: 88.7 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 0.35081031918525696, accuracy: 88.5 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 0.33843979239463806, accuracy: 89.2 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 0.2806, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 0.4285, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 0.2699, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 0.3951, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 0.2789, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 0.4625, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 0.4495, batch time: 0.09, accuracy:  85.94%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 0.3584, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 0.4267, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 0.3262, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 0.3687135577201843, accuracy: 89.6 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 0.3813868761062622, accuracy: 88.3 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 0.3661498427391052, accuracy: 89.5 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 0.3661498427391052, accuracy: 89.5 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 0.5679194331169128, accuracy: 81.0 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 0.365703284740448, accuracy: 89.2 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 9.051825523376465, accuracy: 25.0 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 0.3681938648223877, accuracy: 89.2 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 0.3571029305458069, accuracy: 89.8 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 0.35765960812568665, accuracy: 90.0 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 0.3915, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 0.4401, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 0.3991, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 0.4979, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 0.3702, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 0.4362, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 0.3886, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 0.4581, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 0.3745, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 0.2846, batch time: 0.06, accuracy:  89.06%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 0.38701730966567993, accuracy: 87.1 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 25.521732330322266, accuracy: 20.4 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 0.7133315205574036, accuracy: 76.7 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 0.37817880511283875, accuracy: 87.8 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 3.6323652267456055, accuracy: 34.6 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 26.562820434570312, accuracy: 12.8 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 0.38290783762931824, accuracy: 87.9 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 0.3554818332195282, accuracy: 88.5 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 0.3526251018047333, accuracy: 88.2 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 0.3430188298225403, accuracy: 89.0 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 0.4072, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 0.3737, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 0.3319, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 0.5481, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 0.2076, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 0.4076, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 0.5471, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 0.4634, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 0.2178, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 0.2673, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 0.3752152919769287, accuracy: 89.8 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 543.5955810546875, accuracy: 8.4 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 0.36977314949035645, accuracy: 90.3 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 0.3576657474040985, accuracy: 90.3 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 52.71377944946289, accuracy: 18.7 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 0.37188178300857544, accuracy: 88.8 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 0.33830660581588745, accuracy: 91.0 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 0.3333140015602112, accuracy: 90.9 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 0.3287053406238556, accuracy: 90.9 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 0.37670081853866577, accuracy: 89.2 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 0.5809, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 0.2800, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 0.3489, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 0.3590, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 0.4895, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 0.4048, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 0.2287, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 0.5475, batch time: 0.10, accuracy:  78.12%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 0.3192, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 0.3449, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 0.36502912640571594, accuracy: 89.5 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 38.76758575439453, accuracy: 20.1 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 0.3827010691165924, accuracy: 88.3 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 0.3470275104045868, accuracy: 89.5 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 0.35264697670936584, accuracy: 89.6 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 0.336844265460968, accuracy: 90.3 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 0.3370957374572754, accuracy: 89.8 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 0.3340814709663391, accuracy: 90.9 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 0.33326518535614014, accuracy: 90.6 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 0.33580338954925537, accuracy: 90.0 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 0.4199, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 0.3660, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 0.3386, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 0.3959, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 0.4130, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 0.3548, batch time: 0.06, accuracy:  88.28%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 0.5452, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 0.2692, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 0.3684, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 0.3321, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 0.37437236309051514, accuracy: 89.1 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 0.37637031078338623, accuracy: 88.6 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 0.5674259662628174, accuracy: 83.1 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 42.36379623413086, accuracy: 13.5 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 0.3579486012458801, accuracy: 90.3 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 0.354694128036499, accuracy: 90.7 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 0.3519408404827118, accuracy: 90.3 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 0.35080358386039734, accuracy: 90.2 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 0.3773536682128906, accuracy: 89.0 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 0.4100966453552246, accuracy: 88.2 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 0.3746, batch time: 0.07, accuracy:  88.28%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 0.3425, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 0.2314, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 0.3473, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 0.4145, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 0.3316, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 0.4624, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 0.4331, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 0.2948, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 0.2552, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 0.3489302694797516, accuracy: 88.5 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 4.350685119628906, accuracy: 39.8 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 0.5712788105010986, accuracy: 82.0 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 0.8242043852806091, accuracy: 73.9 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 0.33652910590171814, accuracy: 89.6 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 0.32778796553611755, accuracy: 89.9 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 2.291649580001831, accuracy: 50.4 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 0.35468584299087524, accuracy: 88.6 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 0.4022107422351837, accuracy: 86.8 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 0.3524833917617798, accuracy: 88.5 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 0.4663, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 0.3601, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 0.3166, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 0.3127, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 0.5056, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 0.3216, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 0.4399, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 0.2846, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 0.3032, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 0.4341, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 0.31046387553215027, accuracy: 91.0 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 22.188753128051758, accuracy: 15.5 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 0.4639764726161957, accuracy: 85.3 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 3.7798774242401123, accuracy: 41.9 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 0.30285391211509705, accuracy: 90.8 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 0.33408308029174805, accuracy: 90.3 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 0.3101976811885834, accuracy: 91.0 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 0.2983277142047882, accuracy: 90.7 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 0.2977025806903839, accuracy: 91.2 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 0.29683396220207214, accuracy: 90.6 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 0.3251, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 0.5556, batch time: 0.09, accuracy:  84.38%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 0.3292, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 0.3942, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 0.5083, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 0.3570, batch time: 0.06, accuracy:  90.62%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 0.3492, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 0.4605, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 0.4406, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 0.3213, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 0.35495224595069885, accuracy: 87.9 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 0.355006605386734, accuracy: 87.9 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 0.5269967317581177, accuracy: 81.8 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 201.08636474609375, accuracy: 7.7 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 0.4098767340183258, accuracy: 86.3 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 0.3420729637145996, accuracy: 88.3 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 3.7284719944000244, accuracy: 37.7 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 0.3649422228336334, accuracy: 88.3 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 0.33333414793014526, accuracy: 88.8 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 0.3365161418914795, accuracy: 88.4 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 0.3081, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 0.4557, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 0.4432, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 0.4262, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 0.3923, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 0.3516, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 0.2275, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 0.3208, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 0.3601, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 0.3995, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 0.3648207485675812, accuracy: 89.2 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 4.042182922363281, accuracy: 39.7 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 0.5258256793022156, accuracy: 83.3 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 0.6507619023323059, accuracy: 79.3 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 0.3492982089519501, accuracy: 89.0 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 0.3491353690624237, accuracy: 89.2 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 0.3560922145843506, accuracy: 88.5 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 0.34376364946365356, accuracy: 89.4 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 0.3866766691207886, accuracy: 87.9 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 6.5399346351623535, accuracy: 26.4 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 0.5106, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 0.3273, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 0.4031, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 0.2991, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 0.3370, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 0.4766, batch time: 0.08, accuracy:  83.59%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 0.3746, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 0.3323, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 0.4806, batch time: 0.07, accuracy:  89.06%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 0.2816, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 0.3235969543457031, accuracy: 89.5 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 4.400379180908203, accuracy: 39.3 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 0.644312858581543, accuracy: 78.7 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 0.6201326251029968, accuracy: 79.8 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 0.3204694986343384, accuracy: 89.6 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 0.29433003067970276, accuracy: 90.9 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 0.29613223671913147, accuracy: 90.2 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 0.40057581663131714, accuracy: 86.5 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 0.31211304664611816, accuracy: 89.7 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 0.29096290469169617, accuracy: 90.9 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 0.3381, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 0.3849, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 0.2882, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 0.4703, batch time: 0.04, accuracy:  82.81%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 0.4003, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 0.4180, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 0.4807, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 0.2060, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 0.3510, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 0.2775, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 0.36144524812698364, accuracy: 90.4 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 3.9721391201019287, accuracy: 39.8 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 0.4012267589569092, accuracy: 88.8 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 24.0323543548584, accuracy: 21.5 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 0.3318912088871002, accuracy: 90.0 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 0.3731272518634796, accuracy: 88.7 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 0.3278448283672333, accuracy: 90.3 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 0.32877445220947266, accuracy: 90.6 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 0.3375576436519623, accuracy: 89.7 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 0.3283080458641052, accuracy: 90.1 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 0.3311, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 0.4098, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 0.4225, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 0.3207, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 0.3651, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 0.4114, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 0.1883, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 0.3611, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 0.4093, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 0.3990, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 0.346763014793396, accuracy: 89.2 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 0.34570953249931335, accuracy: 90.3 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 0.44805392622947693, accuracy: 84.5 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 0.33145442605018616, accuracy: 90.7 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 0.3641173839569092, accuracy: 89.5 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 132.42520141601562, accuracy: 10.1 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 0.3262234032154083, accuracy: 90.5 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 0.330879807472229, accuracy: 90.5 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 0.3211580216884613, accuracy: 90.9 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 0.36809539794921875, accuracy: 89.4 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 0.1836, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 0.3272, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 0.2404, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 0.3637, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 0.4553, batch time: 0.07, accuracy:  84.38%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 0.4304, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 0.4299, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 0.3846, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 0.2885, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 0.3365, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 0.32558512687683105, accuracy: 89.5 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 0.326081782579422, accuracy: 89.5 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 0.5888228416442871, accuracy: 81.3 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 63.020259857177734, accuracy: 12.2 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 0.3211292028427124, accuracy: 90.1 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 0.5148265957832336, accuracy: 82.9 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 0.3190380036830902, accuracy: 90.4 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 0.363212525844574, accuracy: 88.1 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 0.3045172095298767, accuracy: 89.8 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 0.3252145051956177, accuracy: 89.1 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 0.3149, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 0.2961, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 0.3086, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 0.2811, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 0.3902, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 0.2534, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 0.4326, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 0.3284, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 0.4069, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 0.3162, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 0.3841733932495117, accuracy: 88.3 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 0.37990909814834595, accuracy: 88.4 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 0.371620237827301, accuracy: 88.4 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 0.35998135805130005, accuracy: 88.9 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 0.43685397505760193, accuracy: 86.9 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 23.633378982543945, accuracy: 16.7 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 0.3547743260860443, accuracy: 89.0 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 0.3376944363117218, accuracy: 90.3 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 0.33388081192970276, accuracy: 90.1 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 0.3329586088657379, accuracy: 90.3 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 0.2875, batch time: 0.07, accuracy:  91.41%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 0.4243, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 0.3691, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 0.3566, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 0.3685, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 0.4618, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 0.3784, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 0.3015, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 0.3165, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 0.3448, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 0.31487199664115906, accuracy: 89.6 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 0.38760867714881897, accuracy: 86.8 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 0.3072607219219208, accuracy: 90.7 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 1.0215468406677246, accuracy: 69.2 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 0.34061455726623535, accuracy: 88.7 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 0.2958696484565735, accuracy: 92.0 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 0.289999395608902, accuracy: 91.8 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 0.2990579307079315, accuracy: 90.8 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 0.2858564853668213, accuracy: 92.0 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 0.30175742506980896, accuracy: 91.1 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 0.3785, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 0.4127, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 0.3171, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 0.3875, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 0.4138, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 0.2402, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 0.3373, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 0.3079, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 0.5160, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 0.4397, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 0.3463572561740875, accuracy: 88.5 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 0.4187380373477936, accuracy: 86.8 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 0.9077681303024292, accuracy: 74.7 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 0.32207804918289185, accuracy: 89.4 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 0.4269132912158966, accuracy: 85.5 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 0.32346010208129883, accuracy: 89.2 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 0.33256930112838745, accuracy: 89.1 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 0.37896639108657837, accuracy: 89.5 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 0.31280115246772766, accuracy: 89.8 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 0.30946817994117737, accuracy: 89.6 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 0.2628, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 0.3089, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 0.3548, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 0.5114, batch time: 0.07, accuracy:  86.72%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 0.2508, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 0.3491, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 0.1924, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 0.2702, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 0.2959, batch time: 0.06, accuracy:  90.62%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 0.2817, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 0.27483806014060974, accuracy: 90.8 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 1276.3193359375, accuracy: 9.1 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 1.4897212982177734, accuracy: 64.9 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 19.166519165039062, accuracy: 11.1 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 0.32667505741119385, accuracy: 88.5 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 0.31309974193573, accuracy: 89.2 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 0.26992887258529663, accuracy: 91.8 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 0.26631471514701843, accuracy: 91.7 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 0.2736210227012634, accuracy: 91.3 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 0.3134019374847412, accuracy: 89.5 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 0.3946, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 0.2641, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 0.2106, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 0.4087, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 0.3139, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 0.4411, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 0.3648, batch time: 0.09, accuracy:  89.06%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 0.3641, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 0.3246, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 0.3306, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 0.31124722957611084, accuracy: 90.6 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 156.2073974609375, accuracy: 12.0 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 0.31869304180145264, accuracy: 91.2 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 0.43007218837738037, accuracy: 88.5 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 0.310320109128952, accuracy: 91.0 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 0.307045042514801, accuracy: 91.6 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 0.2999962270259857, accuracy: 91.1 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 0.30817678570747375, accuracy: 90.9 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 0.33232152462005615, accuracy: 91.3 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 0.3025105595588684, accuracy: 90.8 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 0.3021, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 0.3320, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 0.3471, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 0.4418, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 0.2295, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 0.2534, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 0.3178, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 0.3153, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 0.3881, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 0.2620, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 0.33160439133644104, accuracy: 90.4 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 0.6870889663696289, accuracy: 77.8 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 0.3300965130329132, accuracy: 90.4 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 0.32965806126594543, accuracy: 90.4 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 0.3301717936992645, accuracy: 90.1 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 0.3285060226917267, accuracy: 90.5 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 0.37663495540618896, accuracy: 88.0 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 0.3989037573337555, accuracy: 86.8 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 0.3231624662876129, accuracy: 90.3 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 0.3222936689853668, accuracy: 90.0 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 0.2643, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 0.4508, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 0.3749, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 0.3881, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 0.3484, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 0.2389, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 0.4197, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 0.3323, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 0.3562, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 0.2565, batch time: 0.08, accuracy:  94.53%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 0.32042089104652405, accuracy: 90.3 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 1295.3095703125, accuracy: 9.4 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 0.3225259482860565, accuracy: 90.1 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 137.70396423339844, accuracy: 9.7 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 0.3114275336265564, accuracy: 90.4 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 0.30944424867630005, accuracy: 90.5 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 0.349026083946228, accuracy: 88.7 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 0.30734890699386597, accuracy: 90.5 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 0.30633190274238586, accuracy: 90.9 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 0.3100071847438812, accuracy: 89.9 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 0.3784, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 0.3279, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 0.2840, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 0.4809, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 0.4643, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 0.3641, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 0.4243, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 0.2922, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 0.3255, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 0.4139, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 0.3383770287036896, accuracy: 89.0 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 1.2344448566436768, accuracy: 65.6 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 0.4535517394542694, accuracy: 84.7 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 0.33312875032424927, accuracy: 89.8 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 0.40758785605430603, accuracy: 86.4 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 0.31840819120407104, accuracy: 90.2 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 0.32186293601989746, accuracy: 89.3 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 0.3434600830078125, accuracy: 89.0 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 0.3545016646385193, accuracy: 88.5 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 1.6302608251571655, accuracy: 55.2 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 0.4012, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 0.5836, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 0.2453, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 0.3570, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 0.3306, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 0.2434, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 0.4010, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 0.4921, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 0.4272, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 0.2754, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 0.3136308193206787, accuracy: 90.5 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 3.2383344173431396, accuracy: 50.3 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 0.37067779898643494, accuracy: 89.1 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 1.2975329160690308, accuracy: 74.2 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 0.30749937891960144, accuracy: 90.6 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 0.3194386959075928, accuracy: 89.8 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 0.3048028349876404, accuracy: 90.0 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 0.32068485021591187, accuracy: 90.2 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 0.9113166928291321, accuracy: 72.6 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 0.30714693665504456, accuracy: 90.5 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 0.3238, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 0.4349, batch time: 0.11, accuracy:  81.25%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 0.3247, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 0.3208, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 0.3852, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 0.3170, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 0.4462, batch time: 0.11, accuracy:  82.81%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 0.2796, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 0.3484, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 0.3846, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 0.3063051402568817, accuracy: 90.3 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 92.4787368774414, accuracy: 9.8 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 0.30342400074005127, accuracy: 90.4 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 128.25807189941406, accuracy: 9.4 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 10.996500968933105, accuracy: 32.0 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 0.3200562298297882, accuracy: 89.2 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 0.3090428113937378, accuracy: 89.7 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 0.45357638597488403, accuracy: 84.8 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 0.2870916426181793, accuracy: 90.9 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 0.3416673243045807, accuracy: 89.9 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 0.2532, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 0.3685, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 0.3260, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 0.3060, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 0.2519, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 0.3048, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 0.2919, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 0.2965, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 0.2624, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 0.4530, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 0.30733761191368103, accuracy: 90.7 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 0.30961930751800537, accuracy: 90.8 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 0.30754008889198303, accuracy: 90.6 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 29.8190975189209, accuracy: 15.2 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 287.34759521484375, accuracy: 12.0 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 0.3070806860923767, accuracy: 91.1 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 0.30291280150413513, accuracy: 91.1 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 0.3071858584880829, accuracy: 90.3 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 0.2970217168331146, accuracy: 91.3 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 0.3022859990596771, accuracy: 91.5 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 0.5325, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 0.3590, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 0.3729, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 0.2904, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 0.4008, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 0.3636, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 0.4009, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 0.2477, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 0.4342, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 0.5431, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 0.3311357796192169, accuracy: 89.6 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 0.3309364914894104, accuracy: 89.6 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 0.3296678066253662, accuracy: 89.7 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 0.3296678066253662, accuracy: 89.7 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 0.37007081508636475, accuracy: 87.8 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 0.34222736954689026, accuracy: 89.7 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 0.3186507523059845, accuracy: 90.2 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 0.3086632788181305, accuracy: 90.8 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 0.3263365626335144, accuracy: 90.0 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 0.3780151307582855, accuracy: 88.4 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 0.2954, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 0.2223, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 0.3208, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 0.2745, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 0.3116, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 0.3093, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 0.3781, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 0.2375, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 0.3480, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 0.4319, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 0.3050994277000427, accuracy: 90.3 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 1202.177001953125, accuracy: 8.2 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 0.30502578616142273, accuracy: 90.4 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 2.909890651702881, accuracy: 45.1 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 0.2978924810886383, accuracy: 90.1 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 0.2991770803928375, accuracy: 90.4 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 0.2967907190322876, accuracy: 90.6 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 0.2967872619628906, accuracy: 90.4 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 0.2956133782863617, accuracy: 90.0 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 0.2935376763343811, accuracy: 90.2 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 0.4595, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 0.4096, batch time: 0.08, accuracy:  87.50%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 0.3290, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 0.4339, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 0.4502, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 0.2471, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 0.2318, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 0.4177, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 0.5049, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 0.2937, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 0.30748409032821655, accuracy: 90.0 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 1.3311734199523926, accuracy: 62.4 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 0.3598414659500122, accuracy: 87.8 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 0.3037298619747162, accuracy: 90.0 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 0.31629613041877747, accuracy: 90.0 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 0.2995903789997101, accuracy: 90.6 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 0.3010266125202179, accuracy: 91.1 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 0.3610862195491791, accuracy: 88.3 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 0.2952648103237152, accuracy: 90.9 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 0.29169797897338867, accuracy: 90.8 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 0.1759, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 0.3693, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 0.2507, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 0.2652, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 0.4701, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 0.2214, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 0.1738, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 0.4020, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 0.2036, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 0.2298, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 0.35130953788757324, accuracy: 88.1 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 1196.1781005859375, accuracy: 10.1 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 0.3422209918498993, accuracy: 88.2 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 0.3402635157108307, accuracy: 88.6 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 1.3400110006332397, accuracy: 68.1 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 0.4520418345928192, accuracy: 85.7 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 0.36328834295272827, accuracy: 88.9 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 0.431384801864624, accuracy: 86.2 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 0.3328617215156555, accuracy: 89.1 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 0.3560607135295868, accuracy: 88.4 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 0.4328, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 0.4005, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 0.2498, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 0.4597, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 0.4307, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 0.4238, batch time: 0.06, accuracy:  84.38%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 0.4245, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 0.3109, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 0.4097, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 0.4607, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 0.3137024939060211, accuracy: 90.7 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 8.261726379394531, accuracy: 34.0 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 0.3057546317577362, accuracy: 90.3 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 4.844537258148193, accuracy: 34.6 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 0.41974684596061707, accuracy: 87.3 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 0.44910138845443726, accuracy: 84.7 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 0.2971646785736084, accuracy: 90.5 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 0.2965899109840393, accuracy: 90.6 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 0.2961290776729584, accuracy: 90.6 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 0.30103185772895813, accuracy: 90.4 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 0.3167, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 0.3160, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 0.4075, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 0.4309, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 0.2774, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 0.2540, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 0.3148, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 0.3351, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 0.2638, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 0.4904, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 0.2980704605579376, accuracy: 90.2 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 1271.0833740234375, accuracy: 7.2 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 0.2979084849357605, accuracy: 90.2 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 0.8718615174293518, accuracy: 73.4 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 0.29341036081314087, accuracy: 90.7 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 0.29023098945617676, accuracy: 90.4 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 0.2889255881309509, accuracy: 90.8 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 0.2863646149635315, accuracy: 90.6 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 0.28495416045188904, accuracy: 90.5 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 0.2870849370956421, accuracy: 90.5 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 0.3581, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 0.3425, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 0.2986, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 0.3793, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 0.2387, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 0.3704, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 0.3334, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 0.2798, batch time: 0.40, accuracy:  89.06%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 0.1732, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 0.2264, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 0.3148767352104187, accuracy: 90.4 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 1381.1162109375, accuracy: 10.1 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 0.30475708842277527, accuracy: 91.0 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 0.30179035663604736, accuracy: 91.4 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 0.9182869791984558, accuracy: 69.8 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 0.29642462730407715, accuracy: 91.3 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 0.3075927793979645, accuracy: 90.1 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 0.29527729749679565, accuracy: 90.7 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 0.3377930521965027, accuracy: 88.7 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 0.30775582790374756, accuracy: 90.3 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 0.3380, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 0.4288, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 0.3212, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 0.2688, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 0.2963, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 0.4631, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 0.2949, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 0.4138, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 0.3762, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 0.2020, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 0.30418649315834045, accuracy: 90.4 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 1375.3074951171875, accuracy: 9.3 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 0.3002309501171112, accuracy: 91.0 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 0.2890782058238983, accuracy: 90.7 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 0.43709900975227356, accuracy: 85.0 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 0.36026665568351746, accuracy: 88.1 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 0.6434820294380188, accuracy: 81.3 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 0.2782764732837677, accuracy: 91.2 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 0.30900752544403076, accuracy: 89.6 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 0.2726461589336395, accuracy: 91.6 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 0.3062, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 0.5007, batch time: 0.30, accuracy:  81.25%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 0.5556, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 0.3555, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 0.3324, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 0.3633, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 0.3391, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 0.2603, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 0.3604, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 0.3002, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 0.3468340039253235, accuracy: 90.4 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 0.35953187942504883, accuracy: 89.8 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 0.5687468647956848, accuracy: 81.9 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 0.6818065047264099, accuracy: 78.8 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 1.2033021450042725, accuracy: 65.5 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 0.3581286072731018, accuracy: 90.4 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 0.3612077236175537, accuracy: 89.9 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 0.3419205844402313, accuracy: 90.6 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 0.33728840947151184, accuracy: 90.1 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 0.33131498098373413, accuracy: 90.7 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 0.3914, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 0.4920, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 0.3971, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 0.4599, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 0.2743, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 0.4080, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 0.1764, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 0.3758, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 0.3517, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 0.4497, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 0.3057076334953308, accuracy: 89.4 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 0.30670520663261414, accuracy: 89.5 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 0.6526564955711365, accuracy: 78.8 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 162.11280822753906, accuracy: 10.8 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 0.3207705318927765, accuracy: 89.4 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 0.2908591628074646, accuracy: 90.4 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 0.2902216911315918, accuracy: 90.8 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 0.28264978528022766, accuracy: 91.0 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 0.35397225618362427, accuracy: 87.6 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 0.2813122868537903, accuracy: 91.7 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 0.4508, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 0.3078, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 0.3016, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 0.3696, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 0.3387, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 0.3430, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 0.4115, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 0.3316, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 0.3211, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 0.2846, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 0.2817612588405609, accuracy: 92.1 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 0.28176459670066833, accuracy: 92.1 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 0.2793867290019989, accuracy: 92.2 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 0.278272420167923, accuracy: 92.1 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 0.27898499369621277, accuracy: 92.1 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 0.2790641188621521, accuracy: 91.9 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 0.2834007143974304, accuracy: 91.6 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 0.5121838450431824, accuracy: 83.2 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 0.27190759778022766, accuracy: 92.2 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 0.2707394063472748, accuracy: 92.1 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 0.3526, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 0.3120, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 0.3694, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 0.3217, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 0.3474, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 0.4106, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 0.3059, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 0.3058, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 0.3332, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 0.3656, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 0.280811607837677, accuracy: 91.6 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 0.2828925848007202, accuracy: 92.0 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 0.5636516213417053, accuracy: 82.1 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 12.5325345993042, accuracy: 21.1 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 0.28386735916137695, accuracy: 92.2 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 0.2732642590999603, accuracy: 92.4 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 0.2957640290260315, accuracy: 91.8 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 0.27362653613090515, accuracy: 91.8 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 0.2790897488594055, accuracy: 92.0 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 0.26730769872665405, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 0.2386, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 0.3568, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 0.3244, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 0.4208, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 0.2657, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 0.3527, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 0.2896, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 0.2595, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 0.2953, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 0.2729, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 0.31342121958732605, accuracy: 90.1 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 0.3187199831008911, accuracy: 89.5 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 0.33166852593421936, accuracy: 89.2 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 0.3066260516643524, accuracy: 90.4 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 0.31974440813064575, accuracy: 90.5 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 0.2948671877384186, accuracy: 90.8 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 0.3678636848926544, accuracy: 87.9 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 0.31162333488464355, accuracy: 90.2 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 0.3070909082889557, accuracy: 90.7 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 0.2867235243320465, accuracy: 91.1 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 0.2532, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 0.3643, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 0.3735, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 0.2923, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 0.2833, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 0.3144, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 0.3334, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 0.3051, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 0.3009, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 0.3666, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 0.34252581000328064, accuracy: 90.5 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 0.34230032563209534, accuracy: 90.3 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 0.444143682718277, accuracy: 86.1 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 0.5331060290336609, accuracy: 83.1 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 0.3467455208301544, accuracy: 89.8 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 0.33008211851119995, accuracy: 90.1 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 0.33812054991722107, accuracy: 89.5 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 0.32982686161994934, accuracy: 89.7 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 0.3262362778186798, accuracy: 90.5 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 0.3307000696659088, accuracy: 89.6 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 0.4195, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 0.3010, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 0.2681, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 0.1755, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 0.4253, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 0.2793, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 0.2867, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 0.3937, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 0.1797, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 0.2381, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 0.3337555527687073, accuracy: 88.7 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 4.391340732574463, accuracy: 42.3 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 0.5090107321739197, accuracy: 83.7 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 0.7853203415870667, accuracy: 76.9 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 0.3530443012714386, accuracy: 87.9 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 0.4351469874382019, accuracy: 85.2 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 0.3885364830493927, accuracy: 88.9 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 0.3599501848220825, accuracy: 88.4 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 0.31188875436782837, accuracy: 90.0 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 0.3138751685619354, accuracy: 89.7 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 0.3242, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 0.4855, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 0.2634, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 0.3647, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 0.2751, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 0.2268, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 0.3593, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 0.3470, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 0.3326, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 0.2648, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 0.3413803279399872, accuracy: 89.3 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 0.34269997477531433, accuracy: 89.6 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 0.3930557072162628, accuracy: 87.5 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 0.5119080543518066, accuracy: 84.6 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 0.33874428272247314, accuracy: 90.1 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 0.33287450671195984, accuracy: 90.2 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 0.332010954618454, accuracy: 89.7 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 0.329806923866272, accuracy: 90.1 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 0.3802354633808136, accuracy: 88.0 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 0.32629451155662537, accuracy: 90.4 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 0.3364, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 0.2726, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 0.3097, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 0.4337, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 0.3217, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 0.3599, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 0.3013, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 0.3156, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 0.2497, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 0.2290, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 0.2637036442756653, accuracy: 91.0 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 7.3383355140686035, accuracy: 28.4 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 0.2559552490711212, accuracy: 91.4 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 0.25557422637939453, accuracy: 91.2 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 0.5611963272094727, accuracy: 82.3 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 0.2624647617340088, accuracy: 91.8 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 0.25100645422935486, accuracy: 92.6 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 0.25315001606941223, accuracy: 91.4 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 0.2528800368309021, accuracy: 91.7 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 0.2417190819978714, accuracy: 92.7 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 0.3566, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 0.4019, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 0.6043, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 0.2656, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 0.4471, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 0.3437, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 0.2526, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 0.3130, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 0.4020, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 0.3609, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 0.3729158639907837, accuracy: 88.0 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 1039.63720703125, accuracy: 9.7 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 0.36579835414886475, accuracy: 88.1 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 0.35656052827835083, accuracy: 88.9 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 0.6612001657485962, accuracy: 79.2 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 0.34010541439056396, accuracy: 89.9 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 0.33364707231521606, accuracy: 89.8 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 0.34880220890045166, accuracy: 89.4 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 0.645521342754364, accuracy: 78.9 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 0.31902629137039185, accuracy: 90.5 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 0.3386, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 0.2309, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 0.2932, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 0.4207, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 0.2799, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 0.3966, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 0.3134, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 0.3892, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 0.4032, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 0.4009, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 0.2748631238937378, accuracy: 91.1 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 150.1580047607422, accuracy: 9.7 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 0.6204513907432556, accuracy: 80.4 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 1.0445756912231445, accuracy: 69.8 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 0.2637083828449249, accuracy: 91.9 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 0.25912371277809143, accuracy: 91.9 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 0.2610400319099426, accuracy: 92.3 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 0.25548285245895386, accuracy: 92.3 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 0.2572093605995178, accuracy: 92.1 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 0.2537795901298523, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 0.2200, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 0.3123, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 0.3073, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 0.1529, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 0.4103, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 0.4718, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 0.2687, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 0.2933, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 0.3360, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 0.2042, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 0.3055554926395416, accuracy: 91.0 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 0.4837443232536316, accuracy: 85.3 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 0.3958835005760193, accuracy: 87.3 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 0.31455764174461365, accuracy: 90.7 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 0.30591291189193726, accuracy: 90.8 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 0.2986176311969757, accuracy: 90.5 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 0.30556419491767883, accuracy: 90.2 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 0.3541046977043152, accuracy: 89.0 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 0.2949848473072052, accuracy: 90.2 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 0.2964623272418976, accuracy: 90.4 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 0.5389, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 0.3437, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 0.3719, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 0.4120, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 0.3369, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 0.3068, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 0.2611, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 0.2786, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 0.2301, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 0.3433, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 0.30935153365135193, accuracy: 91.0 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 0.3093825578689575, accuracy: 91.0 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 0.40597841143608093, accuracy: 87.7 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 27.124122619628906, accuracy: 19.7 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 0.33340945839881897, accuracy: 89.4 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 0.3135758340358734, accuracy: 90.4 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 0.3135215640068054, accuracy: 91.1 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 0.6009053587913513, accuracy: 80.5 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 0.2877081036567688, accuracy: 91.5 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 0.2869146764278412, accuracy: 91.4 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 0.3773, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 0.3967, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 0.4079, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 0.4607, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 0.2712, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 0.4166, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 0.2933, batch time: 0.32, accuracy:  90.62%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 0.4341, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 0.2700, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 0.3905, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 0.29019322991371155, accuracy: 90.0 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 3.3182034492492676, accuracy: 42.5 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 0.3552876114845276, accuracy: 87.8 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 0.2922143340110779, accuracy: 90.3 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 1.6198971271514893, accuracy: 64.1 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 0.26497378945350647, accuracy: 90.7 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 0.987837553024292, accuracy: 70.1 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 0.4740633964538574, accuracy: 84.6 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 0.26802486181259155, accuracy: 90.9 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 0.2612418830394745, accuracy: 91.3 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 0.1885, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 0.2722, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 0.2446, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 0.3797, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 0.2686, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 0.4055, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 0.4155, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 0.2576, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 0.3407, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 0.2236, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 0.3353954255580902, accuracy: 91.2 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 0.6800612807273865, accuracy: 77.8 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 0.36829861998558044, accuracy: 89.6 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 0.32350751757621765, accuracy: 91.1 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 0.7720370888710022, accuracy: 79.3 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 0.31643515825271606, accuracy: 91.0 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 0.3277168273925781, accuracy: 90.9 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 0.35909774899482727, accuracy: 90.1 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 0.3263747990131378, accuracy: 90.9 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 0.3332166373729706, accuracy: 90.8 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 0.2843, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 0.3854, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 0.3670, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 0.3396, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 0.2624, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 0.1739, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 0.4441, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 0.2311, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 0.3442, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 0.3601, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 0.2681221067905426, accuracy: 91.8 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 0.2863090932369232, accuracy: 91.7 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 0.7539485692977905, accuracy: 78.8 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 0.8192250728607178, accuracy: 76.4 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 0.2539828419685364, accuracy: 92.1 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 0.2523041367530823, accuracy: 92.4 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 0.27770426869392395, accuracy: 91.1 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 0.3099466860294342, accuracy: 90.4 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 0.35218867659568787, accuracy: 88.8 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 0.2578796446323395, accuracy: 92.1 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 0.3681, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 0.3287, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 0.2474, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 0.4091, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 0.1906, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 0.3029, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 0.2232, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 0.2990, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 0.2156, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 0.2721, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 0.29906851053237915, accuracy: 92.2 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 0.2990760803222656, accuracy: 92.2 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 0.5047588348388672, accuracy: 85.4 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 0.42947104573249817, accuracy: 87.0 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 0.2882043421268463, accuracy: 92.3 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 0.5314623117446899, accuracy: 84.5 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 0.3122599124908447, accuracy: 90.7 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 0.2805013954639435, accuracy: 93.1 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 0.2990722060203552, accuracy: 91.8 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 0.29220616817474365, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 0.4590, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 0.4487, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 0.4421, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 0.3012, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 0.4208, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 0.3628, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 0.3596, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 0.3804, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 0.2686, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 0.5263, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 0.28875064849853516, accuracy: 90.4 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 0.2884090542793274, accuracy: 90.6 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 0.27307891845703125, accuracy: 92.0 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 0.2655019462108612, accuracy: 92.6 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 82.06188201904297, accuracy: 9.7 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 0.25836610794067383, accuracy: 92.6 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 0.28908631205558777, accuracy: 91.4 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 0.27833476662635803, accuracy: 91.1 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 0.2649686634540558, accuracy: 92.0 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 0.30729222297668457, accuracy: 90.3 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 0.3326, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 0.4422, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 0.3031, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 0.3376, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 0.4955, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 0.4154, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 0.3369, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 0.4740, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 0.2628, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 0.2458, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 0.34522154927253723, accuracy: 89.3 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 0.35636386275291443, accuracy: 88.8 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 0.3430842459201813, accuracy: 88.9 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 0.33956223726272583, accuracy: 89.9 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 1.1949090957641602, accuracy: 69.8 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 0.3428914248943329, accuracy: 89.3 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 0.33869993686676025, accuracy: 89.7 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 0.33449405431747437, accuracy: 89.3 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 0.33374109864234924, accuracy: 89.3 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 0.3307431936264038, accuracy: 89.6 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 0.3630, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 0.1809, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 0.3555, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 0.2521, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 0.2672, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 0.2314, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 0.4402, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 0.3563, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 0.4914, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 0.1959, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 0.3529309034347534, accuracy: 89.6 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 35.65082550048828, accuracy: 12.8 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 0.3251756429672241, accuracy: 90.9 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 0.3003765940666199, accuracy: 91.0 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 0.7678671479225159, accuracy: 75.6 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 43.10177993774414, accuracy: 18.3 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 0.28720974922180176, accuracy: 91.0 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 0.28583917021751404, accuracy: 91.0 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 0.7555956244468689, accuracy: 76.7 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 0.29217252135276794, accuracy: 91.3 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 0.3890, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 0.3365, batch time: 0.09, accuracy:  89.84%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 0.3476, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 0.2910, batch time: 0.06, accuracy:  93.75%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 0.2418, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 0.4798, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 0.3956, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 0.4337, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 0.2239, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 0.2959, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 0.3253374695777893, accuracy: 91.1 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 727.7167358398438, accuracy: 8.8 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 0.3930664658546448, accuracy: 87.5 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 9.40990924835205, accuracy: 21.9 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 0.3222002685070038, accuracy: 90.3 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 0.3186814486980438, accuracy: 91.4 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 0.31510913372039795, accuracy: 90.4 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 0.35034969449043274, accuracy: 88.3 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 0.3152500092983246, accuracy: 90.3 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 0.3484591543674469, accuracy: 89.9 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 0.2980, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 0.4261, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 0.2940, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 0.2588, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 0.3104, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 0.3084, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 0.3770, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 0.3722, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 0.2713, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 0.3300, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 0.3105088472366333, accuracy: 91.4 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 38.723445892333984, accuracy: 13.6 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 0.30452707409858704, accuracy: 91.3 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 0.30264273285865784, accuracy: 91.1 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 0.620322585105896, accuracy: 81.3 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 0.29659098386764526, accuracy: 91.0 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 0.355336993932724, accuracy: 89.1 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 0.3056517243385315, accuracy: 91.2 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 0.3289320170879364, accuracy: 90.4 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 0.28969264030456543, accuracy: 91.1 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 0.2257, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 0.3168, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 0.3640, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 0.2650, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 0.1949, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 0.3762, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 0.3280, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 0.3166, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 0.4035, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 0.3680, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 0.32544171810150146, accuracy: 90.5 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 83.1458969116211, accuracy: 13.4 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 0.3253752589225769, accuracy: 90.5 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 0.3206807076931, accuracy: 91.0 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 1.1804583072662354, accuracy: 74.4 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 1.860998272895813, accuracy: 63.9 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 0.40887904167175293, accuracy: 86.5 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 0.3461432456970215, accuracy: 89.3 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 0.29867634177207947, accuracy: 91.0 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 0.3049768805503845, accuracy: 91.1 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 0.3162, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 0.3623, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 0.5582, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 0.3438, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 0.2924, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 0.4775, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 0.4034, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 0.3045, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 0.2650, batch time: 0.09, accuracy:  93.75%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 0.3862, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 0.2786683142185211, accuracy: 91.2 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 73.20771026611328, accuracy: 12.2 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 0.2741489112377167, accuracy: 91.5 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 0.274701327085495, accuracy: 91.4 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 12.453350067138672, accuracy: 15.9 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 0.36793965101242065, accuracy: 88.3 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 0.2739267349243164, accuracy: 91.5 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 0.2729600965976715, accuracy: 91.5 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 0.28504711389541626, accuracy: 90.9 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 0.2767432928085327, accuracy: 91.5 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 0.2960, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 0.4004, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 0.2732, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 0.4469, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 0.2606, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 0.3371, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 0.2335, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 0.2030, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 0.3884, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 0.2007, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 0.3872823417186737, accuracy: 87.9 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 20.770326614379883, accuracy: 10.8 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 0.5461750030517578, accuracy: 82.7 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 0.35444211959838867, accuracy: 88.2 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 0.5728803873062134, accuracy: 82.7 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 0.5129542350769043, accuracy: 85.0 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 0.3569442927837372, accuracy: 88.2 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 0.3518093526363373, accuracy: 89.0 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 0.3499264121055603, accuracy: 88.9 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 0.35138213634490967, accuracy: 88.9 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 0.1830, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 0.3533, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 0.3455, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 0.3423, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 0.3481, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 0.2734, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 0.3320, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 0.3010, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 0.5192, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 0.4852, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 0.33420267701148987, accuracy: 89.6 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 751.3175659179688, accuracy: 9.1 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 0.5150416493415833, accuracy: 82.5 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 0.3197212219238281, accuracy: 90.3 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 2.5141541957855225, accuracy: 46.5 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 0.3125464618206024, accuracy: 90.7 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 0.3106810748577118, accuracy: 90.9 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 0.3125620484352112, accuracy: 90.6 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 0.33781662583351135, accuracy: 89.5 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 0.3170550763607025, accuracy: 90.4 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 0.1996, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 0.2335, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 0.3934, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 0.4369, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 0.3842, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 0.2125, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 0.4729, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 0.4296, batch time: 0.44, accuracy:  87.50%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 0.3674, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 0.2972, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 0.3608853816986084, accuracy: 90.4 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 144.50152587890625, accuracy: 11.4 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 0.360134482383728, accuracy: 89.9 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 6.936914443969727, accuracy: 30.4 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 0.3559758961200714, accuracy: 90.3 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 0.3518840968608856, accuracy: 91.0 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 0.3465312421321869, accuracy: 90.9 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 0.37107133865356445, accuracy: 89.7 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 0.5372229218482971, accuracy: 84.3 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 0.36967891454696655, accuracy: 88.9 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 0.2438, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 0.2896, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 0.3663, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 0.2407, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 0.3339, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 0.4605, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 0.2786, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 0.3695, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 0.3942, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 0.3873, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 0.31666985154151917, accuracy: 90.1 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 703.0747680664062, accuracy: 9.9 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 0.31462982296943665, accuracy: 90.0 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 0.2974453270435333, accuracy: 90.9 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 0.798952043056488, accuracy: 76.0 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 0.29091677069664, accuracy: 91.2 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 0.29663383960723877, accuracy: 91.1 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 0.3018767237663269, accuracy: 90.8 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 0.3080657124519348, accuracy: 90.5 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 0.3490254282951355, accuracy: 89.5 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 0.3111, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 0.2371, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 0.4218, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 0.3179, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 0.3275, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 0.2442, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 0.2650, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 0.3496, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 0.1774, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 0.3140, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 0.30938854813575745, accuracy: 89.5 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 0.3119019567966461, accuracy: 89.6 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 0.4802720546722412, accuracy: 84.2 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 0.5112848281860352, accuracy: 81.1 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 0.3037915825843811, accuracy: 90.2 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 0.30213662981987, accuracy: 90.3 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 0.4843686819076538, accuracy: 84.6 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 0.3201140761375427, accuracy: 89.4 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 0.298933207988739, accuracy: 90.4 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 0.29518234729766846, accuracy: 90.7 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 0.2377, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 0.3088, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 0.2543, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 0.3221, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 0.3708, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 0.3001, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 0.2849, batch time: 0.06, accuracy:  90.62%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 0.3610, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 0.1987, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 0.2210, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 0.3176005780696869, accuracy: 90.4 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 707.9947509765625, accuracy: 9.7 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 0.3152027428150177, accuracy: 90.9 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 0.3676761984825134, accuracy: 89.0 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 0.30181777477264404, accuracy: 90.7 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 0.28782886266708374, accuracy: 91.3 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 0.28592774271965027, accuracy: 91.3 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 0.3269602060317993, accuracy: 90.1 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 0.318122535943985, accuracy: 90.2 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 0.36456939578056335, accuracy: 89.1 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 0.2375, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 0.1741, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 0.3905, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 0.3502, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 0.2833, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 0.2574, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 0.2698, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 0.3500, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 0.3998, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 0.4232, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 0.27307215332984924, accuracy: 91.2 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 0.5408516526222229, accuracy: 82.7 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 0.4635671079158783, accuracy: 84.2 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 0.844045877456665, accuracy: 75.3 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 0.28073588013648987, accuracy: 91.1 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 0.2666061520576477, accuracy: 91.5 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 0.2717914879322052, accuracy: 91.0 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 0.26393359899520874, accuracy: 91.4 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 0.26185160875320435, accuracy: 91.3 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 0.26376453042030334, accuracy: 91.8 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 0.5618, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 0.2519, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 0.2741, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 0.3012, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 0.3032, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 0.2831, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 0.3751, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 0.4276, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 0.2036, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 0.3344, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 0.34376272559165955, accuracy: 88.1 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 10.332351684570312, accuracy: 19.0 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 0.7068105936050415, accuracy: 76.4 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 0.29492875933647156, accuracy: 89.7 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 4.355459213256836, accuracy: 41.6 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 0.2833370864391327, accuracy: 90.3 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 0.2814013659954071, accuracy: 90.6 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 0.40260568261146545, accuracy: 84.4 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 0.288670152425766, accuracy: 89.5 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 0.30168312788009644, accuracy: 89.8 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 0.4254, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 0.3428, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 0.3569, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 0.1596, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 0.2976, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 0.3343, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 0.2966, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 0.2851, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 0.2436, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 0.1859, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 0.29465070366859436, accuracy: 91.6 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 627.2214965820312, accuracy: 9.0 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 0.29234305024147034, accuracy: 91.5 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 3.462667942047119, accuracy: 39.7 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 0.28295180201530457, accuracy: 91.5 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 0.281297892332077, accuracy: 91.5 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 0.2781369090080261, accuracy: 91.8 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 0.27930212020874023, accuracy: 92.1 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 0.27444586157798767, accuracy: 92.0 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 0.28341925144195557, accuracy: 91.6 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 0.3469, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 0.2525, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 0.3122, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 0.3784, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 0.4181, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 0.3072, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 0.5097, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 0.4897, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 0.2344, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 0.3594, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 0.3547161817550659, accuracy: 89.5 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 0.3915896713733673, accuracy: 88.4 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 0.5475097894668579, accuracy: 82.4 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 0.7723469138145447, accuracy: 76.7 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 0.33302634954452515, accuracy: 89.4 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 0.32498353719711304, accuracy: 89.9 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 0.3252510130405426, accuracy: 90.1 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 0.32272449135780334, accuracy: 89.9 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 0.3901633322238922, accuracy: 86.2 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 0.34543660283088684, accuracy: 89.2 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 0.2350, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 0.4171, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 0.5285, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 0.3858, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 0.3039, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 0.2728, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 0.2895, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 0.2583, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 0.3358, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 0.3079, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 0.3117491900920868, accuracy: 90.7 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 113.42633056640625, accuracy: 10.3 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 0.707121729850769, accuracy: 80.0 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 0.29962441325187683, accuracy: 91.0 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 0.31074273586273193, accuracy: 91.3 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 0.40700632333755493, accuracy: 86.5 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 0.3259638249874115, accuracy: 91.3 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 2.6930487155914307, accuracy: 59.5 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 1.3993781805038452, accuracy: 61.0 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 0.3018196225166321, accuracy: 90.9 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 0.3475, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 0.2997, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 0.2496, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 0.3710, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 0.3787, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 0.2772, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 0.4607, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 0.2630, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 0.2588, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 0.3005, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 0.314410001039505, accuracy: 89.8 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 0.3299891948699951, accuracy: 88.7 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 0.4835216701030731, accuracy: 84.4 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 1.3638414144515991, accuracy: 62.2 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 0.3334062099456787, accuracy: 88.9 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 0.2974352240562439, accuracy: 90.2 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 0.3197444677352905, accuracy: 89.6 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 0.28786107897758484, accuracy: 90.8 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 0.35060152411460876, accuracy: 89.9 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 0.29124128818511963, accuracy: 90.8 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 0.4190, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 0.2651, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 0.3990, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 0.2944, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 0.3564, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 0.4816, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 0.2224, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 0.4675, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 0.3501, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 0.3638, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 0.3110911250114441, accuracy: 89.9 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 0.30105990171432495, accuracy: 90.1 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 0.29730090498924255, accuracy: 90.2 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 0.28755319118499756, accuracy: 90.3 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 11.998217582702637, accuracy: 18.1 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 0.32141903042793274, accuracy: 90.0 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 0.26928970217704773, accuracy: 91.8 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 0.2611396610736847, accuracy: 92.3 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 0.2722455859184265, accuracy: 91.1 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 0.25683480501174927, accuracy: 91.9 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 0.2746, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 0.2777, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 0.4067, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 0.4341, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 0.3884, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 0.3339, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 0.2887, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 0.2324, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 0.3565, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 0.3804, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 0.36847564578056335, accuracy: 90.8 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 0.37369006872177124, accuracy: 90.7 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 0.3634549677371979, accuracy: 91.1 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 0.36283230781555176, accuracy: 91.1 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 0.3680577576160431, accuracy: 90.9 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 0.3741324543952942, accuracy: 90.8 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 0.36196982860565186, accuracy: 90.8 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 0.37383121252059937, accuracy: 90.3 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 0.3626224398612976, accuracy: 90.6 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 0.3565850257873535, accuracy: 90.3 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 0.3417, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 0.2390, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 0.4527, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 0.2514, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 0.2692, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 0.3605, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 0.2690, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 0.3320, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 0.2721, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 0.4082, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 0.33479300141334534, accuracy: 90.0 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 0.3297310173511505, accuracy: 90.9 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 0.32914337515830994, accuracy: 91.0 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 0.3288792669773102, accuracy: 90.9 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 64.7728271484375, accuracy: 15.4 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 0.32247230410575867, accuracy: 90.9 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 0.3193279504776001, accuracy: 91.7 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 0.3287105858325958, accuracy: 91.5 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 0.3387506604194641, accuracy: 90.3 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 0.5896755456924438, accuracy: 81.2 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 0.2062, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 0.3851, batch time: 0.09, accuracy:  89.06%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 0.3584, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 0.2906, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 0.3375, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 0.2038, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 0.3569, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 0.3118, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 0.2465, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 0.2732, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 0.31883224844932556, accuracy: 90.7 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 0.33119064569473267, accuracy: 89.9 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 1.9811859130859375, accuracy: 58.9 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 36.99341583251953, accuracy: 18.8 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 0.3000209629535675, accuracy: 91.4 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 0.2969258427619934, accuracy: 90.6 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 0.299349308013916, accuracy: 91.0 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 0.3030528724193573, accuracy: 90.6 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 0.29508092999458313, accuracy: 90.8 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 0.3033550977706909, accuracy: 91.4 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 0.3455, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 0.3293, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 0.3435, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 0.2292, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 0.2816, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 0.4156, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 0.2952, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 0.3717, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 0.6128, batch time: 0.41, accuracy:  82.03%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 0.2876, batch time: 0.08, accuracy:  87.50%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 0.3119499981403351, accuracy: 91.3 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 0.3117581307888031, accuracy: 91.1 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 0.3048844337463379, accuracy: 91.7 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 3.3620903491973877, accuracy: 50.0 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 0.3051217198371887, accuracy: 90.7 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 0.29451465606689453, accuracy: 91.4 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 0.410959929227829, accuracy: 87.4 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 0.31533583998680115, accuracy: 91.1 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 0.3331148624420166, accuracy: 90.2 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 0.2859842777252197, accuracy: 91.3 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 0.3220, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 0.2723, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 0.1941, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 0.3197, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 0.2656, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 0.4716, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 0.1824, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 0.3469, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 0.2844, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 0.3939, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 0.3582996129989624, accuracy: 89.0 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 20.278560638427734, accuracy: 22.7 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 0.3541691303253174, accuracy: 88.9 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 0.39547011256217957, accuracy: 87.9 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 0.4143737256526947, accuracy: 86.9 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 1.5002005100250244, accuracy: 59.7 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 0.32973334193229675, accuracy: 88.8 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 0.3288912773132324, accuracy: 89.0 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 0.3257388472557068, accuracy: 89.3 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 0.32543858885765076, accuracy: 89.5 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 0.4593, batch time: 0.09, accuracy:  84.38%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 0.3361, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 0.2728, batch time: 0.06, accuracy:  90.62%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 0.2960, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 0.3258, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 0.4983, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 0.2550, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 0.2939, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 0.3373, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 0.2140, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 0.299405574798584, accuracy: 91.6 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 24.22962760925293, accuracy: 24.5 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 0.2974933981895447, accuracy: 91.5 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 4.892048358917236, accuracy: 41.6 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 0.3049655556678772, accuracy: 90.5 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 0.2914251387119293, accuracy: 91.1 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 0.2983778417110443, accuracy: 90.9 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 0.29080966114997864, accuracy: 90.7 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 0.2853475511074066, accuracy: 91.0 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 0.3049076497554779, accuracy: 91.2 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 0.3067, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 0.3950, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 0.3780, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 0.3751, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 0.3042, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 0.3665, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 0.2689, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 0.3146, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 0.2923, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 0.2750, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 0.29503607749938965, accuracy: 91.0 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 0.2967258095741272, accuracy: 91.7 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 0.2945652902126312, accuracy: 90.9 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 0.29426172375679016, accuracy: 91.0 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 0.29429152607917786, accuracy: 90.9 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 0.28986218571662903, accuracy: 92.3 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 0.3335171341896057, accuracy: 90.6 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 0.29489046335220337, accuracy: 90.9 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 0.28672075271606445, accuracy: 92.0 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 0.2853626310825348, accuracy: 92.1 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 0.3294, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 0.2848, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 0.3702, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 0.2750, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 0.2417, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 0.4715, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 0.4435, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 0.3039, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 0.2601, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 0.2300, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 0.341426283121109, accuracy: 89.3 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 70.42263793945312, accuracy: 14.2 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 0.33497825264930725, accuracy: 89.6 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 6.704275131225586, accuracy: 37.0 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 0.32272207736968994, accuracy: 90.4 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 0.3033621311187744, accuracy: 90.7 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 0.30188557505607605, accuracy: 91.4 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 0.3027738034725189, accuracy: 91.2 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 0.32329651713371277, accuracy: 90.6 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 0.3786570131778717, accuracy: 89.0 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 0.3144, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 0.3622, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 0.2756, batch time: 0.06, accuracy:  92.19%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 0.2243, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 0.3361, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 0.2965, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 0.2698, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 0.3299, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 0.3678, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 0.4451, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 0.32191920280456543, accuracy: 90.6 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 34.63947677612305, accuracy: 12.4 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 0.5841108560562134, accuracy: 80.1 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 0.31678420305252075, accuracy: 90.6 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 0.44048023223876953, accuracy: 85.9 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 0.2954164147377014, accuracy: 91.1 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 0.31503531336784363, accuracy: 90.2 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 0.28923529386520386, accuracy: 91.9 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 0.3494992256164551, accuracy: 89.0 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 0.28839221596717834, accuracy: 91.2 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 0.3550, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 0.4838, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 0.2080, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 0.2508, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 0.4335, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 0.4957, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 0.3428, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 0.5154, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 0.2203, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 0.5218, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 0.3619292676448822, accuracy: 89.3 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 0.3574609160423279, accuracy: 89.7 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 0.3527325689792633, accuracy: 90.2 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 0.3413454592227936, accuracy: 90.3 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 0.34958505630493164, accuracy: 89.5 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 0.34416255354881287, accuracy: 89.5 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 0.3321884870529175, accuracy: 90.7 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 0.32560694217681885, accuracy: 91.1 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 0.35121482610702515, accuracy: 90.8 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 0.3588525056838989, accuracy: 90.6 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 0.4862, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 0.4522, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 0.2581, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 0.3811, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 0.4387, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 0.3836, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 0.3196, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 0.2299, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 0.2979, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 0.4650, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 0.35193586349487305, accuracy: 90.6 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 33.670467376708984, accuracy: 13.4 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 0.6933128833770752, accuracy: 79.8 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 0.3381509780883789, accuracy: 91.0 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 0.4826001524925232, accuracy: 87.0 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 0.7375495433807373, accuracy: 78.8 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 0.5119116902351379, accuracy: 84.9 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 2.4343013763427734, accuracy: 48.5 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 0.30078479647636414, accuracy: 91.1 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 0.29664766788482666, accuracy: 91.2 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 0.3133, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 0.3564, batch time: 0.06, accuracy:  89.06%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 0.3968, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 0.3179, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 0.3669, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 0.2555, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 0.2425, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 0.2312, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 0.3451, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 0.2971, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 0.31256523728370667, accuracy: 89.9 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 209.2439422607422, accuracy: 14.6 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 0.30461588501930237, accuracy: 90.6 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 0.29942646622657776, accuracy: 90.5 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 0.303611159324646, accuracy: 91.5 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 0.2986578047275543, accuracy: 91.0 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 0.28978273272514343, accuracy: 91.4 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 0.3250221014022827, accuracy: 89.5 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 0.283985435962677, accuracy: 91.7 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 0.28981566429138184, accuracy: 91.2 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 0.4501, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 0.2129, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 0.3829, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 0.4494, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 0.2657, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 0.2895, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 0.3939, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 0.2801, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 0.3965, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 0.3412, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 0.32816359400749207, accuracy: 88.9 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 50.42941665649414, accuracy: 10.8 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 0.35481321811676025, accuracy: 88.8 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 0.3163855969905853, accuracy: 89.6 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 27.185447692871094, accuracy: 14.9 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 0.3177989721298218, accuracy: 90.7 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 0.31310901045799255, accuracy: 89.5 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 0.31098663806915283, accuracy: 90.3 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 0.3057551980018616, accuracy: 90.3 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 0.30239927768707275, accuracy: 90.7 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 0.3229, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 0.3480, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 0.3138, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 0.2336, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 0.1638, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 0.2280, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 0.3341, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 0.4545, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 0.3327, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 0.4107, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 0.3907603323459625, accuracy: 89.5 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 0.3927422761917114, accuracy: 89.2 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 0.3827149569988251, accuracy: 89.2 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 0.3767266869544983, accuracy: 89.7 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 73.19223022460938, accuracy: 12.5 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 0.3609430193901062, accuracy: 89.8 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 0.36229822039604187, accuracy: 90.4 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 0.36188119649887085, accuracy: 89.8 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 0.36047860980033875, accuracy: 90.1 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 0.43516165018081665, accuracy: 87.1 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 0.3091, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 0.2673, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 0.4463, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 0.2909, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 0.4881, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 0.3329, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 0.2714, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 0.2380, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 0.3801, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 0.2768, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 0.3362880051136017, accuracy: 90.2 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 0.3405938744544983, accuracy: 90.2 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 0.5826166868209839, accuracy: 82.8 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 0.33463776111602783, accuracy: 91.3 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 0.32701337337493896, accuracy: 91.1 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 0.32248151302337646, accuracy: 91.1 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 0.31709524989128113, accuracy: 91.0 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 0.3152535557746887, accuracy: 91.7 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 0.3457874059677124, accuracy: 89.8 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 0.3100268840789795, accuracy: 91.5 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 0.2906, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 0.4802, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 0.2954, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 0.4477, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 0.2861, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 0.3681, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 0.3916, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 0.5260, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 0.2699, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 0.3476, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 0.29252684116363525, accuracy: 90.8 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 0.9433264136314392, accuracy: 72.2 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 0.5014388561248779, accuracy: 83.4 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 0.4054088890552521, accuracy: 87.6 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 0.30179592967033386, accuracy: 90.8 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 0.30084896087646484, accuracy: 90.8 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 0.2905731797218323, accuracy: 90.9 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 0.396790087223053, accuracy: 87.8 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 0.28548792004585266, accuracy: 90.9 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 0.3809400498867035, accuracy: 88.7 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 0.3003, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 0.3123, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 0.2233, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 0.2533, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 0.2863, batch time: 0.08, accuracy:  89.84%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 0.4804, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 0.3875, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 0.4321, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 0.4422, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 0.3613, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 0.2862433195114136, accuracy: 91.8 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 0.28281882405281067, accuracy: 91.7 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 0.2988787591457367, accuracy: 90.8 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 0.2737339437007904, accuracy: 92.3 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 0.2800998091697693, accuracy: 91.8 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 0.2721199691295624, accuracy: 92.2 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 0.29103606939315796, accuracy: 91.5 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 0.2759435474872589, accuracy: 92.7 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 0.2585735619068146, accuracy: 92.5 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 0.25542572140693665, accuracy: 93.0 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 0.3206, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 0.3127, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 0.3030, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 0.2174, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 0.1831, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 0.2542, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 0.3968, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 0.2705, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 0.1505, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 0.3390, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 0.29797297716140747, accuracy: 91.9 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 0.2977955639362335, accuracy: 91.6 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 0.29564809799194336, accuracy: 92.0 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 0.4298550486564636, accuracy: 85.9 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 0.3487650156021118, accuracy: 89.7 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 0.2879461646080017, accuracy: 92.3 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 0.30876418948173523, accuracy: 91.1 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 0.2871690094470978, accuracy: 92.2 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 0.32353055477142334, accuracy: 90.6 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 0.28163522481918335, accuracy: 92.2 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 0.4285, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 0.3111, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 0.1999, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 0.3798, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 0.3475, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 0.2499, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 0.2387, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 0.4403, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 0.2630, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 0.3502, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 0.3260732591152191, accuracy: 89.8 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 1.2842978239059448, accuracy: 66.6 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 0.9279841780662537, accuracy: 68.9 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 0.31527018547058105, accuracy: 90.4 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 0.8479090332984924, accuracy: 72.3 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 46.39946365356445, accuracy: 14.1 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 0.3181333839893341, accuracy: 90.3 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 0.30014434456825256, accuracy: 91.0 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 0.30255287885665894, accuracy: 90.7 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 0.2965059280395508, accuracy: 90.4 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 0.4502, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 0.3185, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 0.2864, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 0.3127, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 0.2926, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 0.2665, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 0.2864, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 0.4335, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 0.3360, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 0.4649, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 0.3287263810634613, accuracy: 89.9 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 197.2578582763672, accuracy: 14.8 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 0.3784380555152893, accuracy: 88.7 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 0.31736767292022705, accuracy: 91.2 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 0.32042399048805237, accuracy: 90.7 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 0.371771901845932, accuracy: 89.3 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 0.31094810366630554, accuracy: 91.8 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 0.42244648933410645, accuracy: 87.0 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 0.3091909885406494, accuracy: 91.4 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 0.3086412847042084, accuracy: 91.2 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 0.3232, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 0.3337, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 0.3839, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 0.3823, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 0.2506, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 0.3306, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 0.2091, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 0.2998, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 0.3529, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 0.7414, batch time: 0.06, accuracy:  82.03%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 0.31075915694236755, accuracy: 89.3 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 0.309120774269104, accuracy: 90.0 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 0.30903708934783936, accuracy: 90.0 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 0.3046215772628784, accuracy: 90.6 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 0.32075199484825134, accuracy: 89.5 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 0.2998690605163574, accuracy: 90.2 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 0.31175145506858826, accuracy: 89.9 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 0.357178270816803, accuracy: 88.2 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 0.3032883405685425, accuracy: 90.2 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 0.2996058166027069, accuracy: 91.1 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 0.3871, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 0.3866, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 0.1537, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 0.3518, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 0.2908, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 0.3273, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 0.3199, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 0.2288, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 0.2465, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 0.3142, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 0.3191344439983368, accuracy: 91.5 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 0.31915852427482605, accuracy: 91.8 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 0.6037241220474243, accuracy: 83.0 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 1.5815911293029785, accuracy: 65.3 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 0.3048425018787384, accuracy: 91.9 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 0.37081944942474365, accuracy: 91.1 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 0.32501885294914246, accuracy: 90.9 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 0.29720786213874817, accuracy: 92.0 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 0.2989113926887512, accuracy: 92.3 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 0.2964516580104828, accuracy: 92.2 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 0.3774, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 0.1999, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 0.3500, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 0.2541, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 0.4227, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 0.4140, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 0.1927, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 0.3440, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 0.2191, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 0.4017, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 0.3220534920692444, accuracy: 90.6 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 0.32232025265693665, accuracy: 90.5 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 0.3214186429977417, accuracy: 90.7 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 0.31951475143432617, accuracy: 90.9 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 0.32555487751960754, accuracy: 90.3 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 26.06374168395996, accuracy: 12.6 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 0.31793466210365295, accuracy: 90.5 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 0.30953890085220337, accuracy: 91.1 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 0.3102494776248932, accuracy: 91.0 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 0.3016638457775116, accuracy: 91.2 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 0.3696, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 0.3524, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 0.3727, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 0.3655, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 0.2379, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 0.2704, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 0.2986, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 0.3473, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 0.3902, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 0.2912, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 0.3262665569782257, accuracy: 90.5 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 1.2668240070343018, accuracy: 67.9 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 0.6540747880935669, accuracy: 79.3 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 0.30877426266670227, accuracy: 91.2 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 0.37660378217697144, accuracy: 88.8 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 0.2949560880661011, accuracy: 91.4 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 0.3138303756713867, accuracy: 90.6 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 0.3084966540336609, accuracy: 91.5 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 0.2806740403175354, accuracy: 92.7 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 0.28677138686180115, accuracy: 92.5 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 0.5661, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 0.2083, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 0.2431, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 0.4391, batch time: 0.09, accuracy:  85.94%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 0.3632, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 0.2951, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 0.3063, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 0.4809, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 0.3322, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 0.3328, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 0.36419495940208435, accuracy: 88.0 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 165.4898223876953, accuracy: 12.7 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 0.3606582283973694, accuracy: 87.7 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 0.6534318327903748, accuracy: 80.1 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 0.3686060309410095, accuracy: 87.9 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 0.3415934443473816, accuracy: 89.1 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 0.32788562774658203, accuracy: 89.1 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 0.33220502734184265, accuracy: 88.7 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 0.3616587817668915, accuracy: 87.9 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 0.3308475911617279, accuracy: 89.6 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 0.2748, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 0.2508, batch time: 0.08, accuracy:  92.19%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 0.3338, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 0.2171, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 0.3579, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 0.4454, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 0.3194, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 0.2908, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 0.2631, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 0.3151, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 0.33922818303108215, accuracy: 89.9 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 0.3388652205467224, accuracy: 89.9 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 0.33315789699554443, accuracy: 89.7 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 0.3273312747478485, accuracy: 90.5 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 0.585901141166687, accuracy: 81.9 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 0.32874637842178345, accuracy: 89.8 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 0.30859339237213135, accuracy: 91.1 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 0.31670790910720825, accuracy: 91.3 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 0.33851587772369385, accuracy: 90.8 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 0.3003513813018799, accuracy: 91.9 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 0.2785, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 0.2815, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 0.3425, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 0.4369, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 0.3720, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 0.4364, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 0.3001, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 0.5213, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 0.2606, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 0.3674, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 0.3207285702228546, accuracy: 89.2 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 0.32917821407318115, accuracy: 89.0 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 0.32169046998023987, accuracy: 89.1 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 0.7708181142807007, accuracy: 74.1 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 3.2350354194641113, accuracy: 35.8 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 0.30338940024375916, accuracy: 90.6 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 0.2965945899486542, accuracy: 90.9 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 0.29705679416656494, accuracy: 90.6 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 0.31035560369491577, accuracy: 90.1 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 0.29077115654945374, accuracy: 90.7 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 0.3851, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 0.4326, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 0.3572, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 0.2778, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 0.1532, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 0.2514, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 0.3228, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 0.3228, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 0.2810, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 0.3483, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 0.3178022801876068, accuracy: 90.3 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 0.31432056427001953, accuracy: 90.5 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 0.3141913414001465, accuracy: 90.4 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 0.30806729197502136, accuracy: 91.3 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 0.6316642165184021, accuracy: 80.5 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 77.90143585205078, accuracy: 8.5 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 0.3075770139694214, accuracy: 89.8 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 0.2929121255874634, accuracy: 91.4 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 0.2840498089790344, accuracy: 90.6 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 0.354742169380188, accuracy: 88.1 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 0.2915, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 0.4351, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 0.2726, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 0.2361, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 0.3238, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 0.3496, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 0.3840, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 0.2756, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 0.3523, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 0.3339, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 0.26786813139915466, accuracy: 92.0 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 0.2684122622013092, accuracy: 92.1 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 0.5622897744178772, accuracy: 80.7 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 0.34996697306632996, accuracy: 88.3 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 0.2659863829612732, accuracy: 92.8 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 0.26636865735054016, accuracy: 91.8 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 0.29164963960647583, accuracy: 91.9 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 0.27370887994766235, accuracy: 92.0 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 0.2535165250301361, accuracy: 92.5 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 0.2526119649410248, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 0.3806, batch time: 0.08, accuracy:  90.62%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 0.2728, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 0.3336, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 0.4666, batch time: 0.08, accuracy:  86.72%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 0.4463, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 0.3162, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 0.3381, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 0.3094, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 0.3545, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 0.3615, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 0.3387981653213501, accuracy: 90.6 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 47.7666015625, accuracy: 12.3 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 0.3241974115371704, accuracy: 90.8 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 0.3240695595741272, accuracy: 91.2 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 2.598480701446533, accuracy: 45.1 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 3.5783450603485107, accuracy: 41.9 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 0.3778095841407776, accuracy: 88.3 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 0.30354544520378113, accuracy: 91.5 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 0.3032052516937256, accuracy: 91.7 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 0.3522305488586426, accuracy: 90.3 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 0.3289, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 0.2741, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 0.3037, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 0.3993, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 0.2458, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 0.2910, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 0.3044, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 0.4565, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 0.3462, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 0.2683, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 0.2806973457336426, accuracy: 91.0 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 0.2862096130847931, accuracy: 91.3 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 0.2731115520000458, accuracy: 90.7 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 0.27048203349113464, accuracy: 91.2 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 1.5975351333618164, accuracy: 56.0 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 0.26632383465766907, accuracy: 91.4 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 0.26305341720581055, accuracy: 91.4 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 0.2580101191997528, accuracy: 92.1 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 0.2553907632827759, accuracy: 92.3 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 0.3545031249523163, accuracy: 89.2 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 0.3349, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 0.3294, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 0.4738, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 0.3497, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 0.3379, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 0.2296, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 0.3867, batch time: 0.11, accuracy:  84.38%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 0.3469, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 0.2650, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 0.2591, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 0.3181086480617523, accuracy: 91.8 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 0.3192739486694336, accuracy: 91.6 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 0.31371304392814636, accuracy: 91.9 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 0.43607744574546814, accuracy: 87.5 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 0.31202343106269836, accuracy: 91.3 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 0.2968258857727051, accuracy: 91.6 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 0.30604803562164307, accuracy: 91.0 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 0.37797752022743225, accuracy: 87.8 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 0.2935226261615753, accuracy: 92.0 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 0.2922700047492981, accuracy: 92.3 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 0.2655, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 0.3458, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 0.3169, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 0.2904, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 0.1973, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 0.2333, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 0.3505, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 0.2835, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 0.3685, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 0.3866, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 0.3392237424850464, accuracy: 89.8 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 0.3363753855228424, accuracy: 89.9 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 1.2017488479614258, accuracy: 68.0 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 0.32983633875846863, accuracy: 89.6 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 6.943272590637207, accuracy: 33.9 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 0.44225186109542847, accuracy: 86.9 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 0.3344268798828125, accuracy: 89.4 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 0.3105151057243347, accuracy: 90.4 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 0.3059055209159851, accuracy: 90.8 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 0.30920273065567017, accuracy: 91.1 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 0.2564, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 0.2434, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 0.4531, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 0.3768, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 0.2703, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 0.4113, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 0.3643, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 0.1941, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 0.2376, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 0.4407, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 0.3119799792766571, accuracy: 90.5 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 0.8454519510269165, accuracy: 76.6 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 0.30983519554138184, accuracy: 90.7 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 0.3060193657875061, accuracy: 90.9 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 1.3091188669204712, accuracy: 64.2 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 0.29607319831848145, accuracy: 90.8 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 0.297534704208374, accuracy: 91.3 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 0.2995378375053406, accuracy: 91.3 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 0.3226070702075958, accuracy: 90.6 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 0.30156421661376953, accuracy: 90.8 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 0.3339, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 0.2796, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 0.1820, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 0.2005, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 0.2016, batch time: 0.09, accuracy:  92.97%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 0.4571, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 0.2462, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 0.1789, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 0.3239, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 0.1905, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 0.3200768828392029, accuracy: 88.7 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 2.2231638431549072, accuracy: 51.0 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 0.575286328792572, accuracy: 82.6 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 48.09815979003906, accuracy: 9.3 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 0.2922250032424927, accuracy: 90.3 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 0.311477929353714, accuracy: 90.2 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 0.2910224199295044, accuracy: 90.0 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 0.29052096605300903, accuracy: 91.1 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 0.28615105152130127, accuracy: 90.8 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 0.29679688811302185, accuracy: 90.4 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 0.3299, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 0.3015, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 0.4436, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 0.4437, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 0.2652, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 0.2422, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 0.3352, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 0.5228, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 0.3407, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 0.3597, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 0.29220813512802124, accuracy: 91.0 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 0.29112979769706726, accuracy: 91.2 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 1.5781736373901367, accuracy: 61.0 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 0.2828901708126068, accuracy: 91.3 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 0.802903950214386, accuracy: 74.2 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 0.28224048018455505, accuracy: 91.7 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 0.28153330087661743, accuracy: 91.8 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 0.29065218567848206, accuracy: 91.7 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 0.2735404372215271, accuracy: 92.2 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 0.27192962169647217, accuracy: 92.5 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 0.1814, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 0.4044, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 0.3540, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 0.2740, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 0.2977, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 0.3746, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 0.2616, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 0.3484, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 0.3366, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 0.5298, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 0.2884160578250885, accuracy: 89.9 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 0.2830916941165924, accuracy: 90.0 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 0.27999308705329895, accuracy: 90.2 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 0.2796104848384857, accuracy: 90.5 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 2.4554946422576904, accuracy: 45.3 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 0.32195109128952026, accuracy: 89.4 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 0.28276878595352173, accuracy: 90.0 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 0.27170610427856445, accuracy: 92.0 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 0.27774375677108765, accuracy: 91.5 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 0.3131089508533478, accuracy: 90.3 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 0.2547, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 0.3488, batch time: 0.04, accuracy:  89.06%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 0.3778, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 0.2382, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 0.2188, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 0.3951, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 0.4397, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 0.1857, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 0.4186, batch time: 0.09, accuracy:  86.72%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 0.3512, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 0.2777882218360901, accuracy: 91.8 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 234.16268920898438, accuracy: 6.6 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 0.2680824398994446, accuracy: 92.1 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 0.2632251977920532, accuracy: 91.4 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 0.2587467133998871, accuracy: 92.1 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 0.5069301724433899, accuracy: 83.1 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 0.312478244304657, accuracy: 90.3 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 0.25639522075653076, accuracy: 92.5 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 0.2547193169593811, accuracy: 92.3 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 0.25577205419540405, accuracy: 92.2 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "loss_list_epoch = []\n",
    "acc_list_epoch = []\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0\n",
    "\n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter)\n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "\n",
    "            qnn_train_step += 1\n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\"\n",
    "                )\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA\n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(\n",
    "            qnn_minimize_loss,\n",
    "            init_param,\n",
    "            method=\"COBYLA\",\n",
    "            options={\"maxiter\": 1000, \"adaptive\": True},\n",
    "        )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3757351636886597, 0.8218008279800415, 0.96830815076828, 1.1447240114212036, 0.7509450316429138, 0.8643857836723328, 1.014678716659546, 0.47777390480041504, 0.6319013833999634, 0.7108213305473328, 0.592657744884491, 0.6564890742301941, 0.6291211247444153, 0.6582818627357483, 0.5362602472305298, 0.5351003408432007, 0.6283226013183594, 0.6367201805114746, 0.48551756143569946, 0.6989644765853882, 0.49899229407310486, 0.5451236963272095, 0.6208300590515137, 0.412431925535202, 0.41777753829956055, 0.49647435545921326, 0.7357740998268127, 0.5395223498344421, 0.2775757610797882, 0.4787340760231018, 0.5717739462852478, 0.4111577868461609, 0.527082622051239, 0.4590483605861664, 0.4349852502346039, 0.2685059607028961, 0.5299887657165527, 0.3113265037536621, 0.4737320840358734, 0.6251649260520935, 0.4721331000328064, 0.4560737907886505, 0.5566611289978027, 0.4190550148487091, 0.4938649535179138, 0.38275715708732605, 0.5618119835853577, 0.5071438550949097, 0.3933175206184387, 0.8582000136375427, 0.5365344882011414, 0.3265211284160614, 0.49995800852775574, 0.26972395181655884, 0.6712717413902283, 0.4175555109977722, 0.5967151522636414, 0.53566974401474, 0.3028879463672638, 0.32017824053764343, 0.3436308205127716, 0.37170881032943726, 0.3728133738040924, 0.5059276819229126, 0.5397340655326843, 0.5137009024620056, 0.40677544474601746, 0.2335740625858307, 0.5024585723876953, 0.39892056584358215, 0.4479982852935791, 0.4080207049846649, 0.4039449989795685, 0.4229017198085785, 0.4254590570926666, 0.41200730204582214, 0.2886587083339691, 0.3639640808105469, 0.3888586163520813, 0.4038752615451813, 0.3764328360557556, 0.44925838708877563, 0.31774720549583435, 0.4106016755104065, 0.29362550377845764, 0.4533405303955078, 0.2973351776599884, 0.4181906580924988, 0.3259337246417999, 0.28361645340919495, 0.4033912718296051, 0.3954926133155823, 0.39787527918815613, 0.21426577866077423, 0.4720265567302704, 0.3307725787162781, 0.17479301989078522, 0.46758797764778137, 0.177906796336174, 0.3478601276874542, 0.3612669110298157, 0.334657222032547, 0.3531111776828766, 0.48867931962013245, 0.31647494435310364, 0.27972611784935, 0.4645121395587921, 0.45047467947006226, 0.38849782943725586, 0.3830204904079437, 0.40352240204811096, 0.2887263298034668, 0.18343326449394226, 0.3484424948692322, 0.26451465487480164, 0.29756641387939453, 0.5017068982124329, 0.5154244303703308, 0.4212477505207062, 0.3495868146419525, 0.3282327353954315, 0.5142442584037781, 0.24938717484474182, 0.31047728657722473, 0.4303453266620636, 0.29799792170524597, 0.3013400733470917, 0.4288955628871918, 0.28607454895973206, 0.45505550503730774, 0.2613462507724762, 0.39356115460395813, 0.32908305525779724, 0.30812740325927734, 0.5924072265625, 0.4045230746269226, 0.3235114514827728, 0.34453073143959045, 0.30343887209892273, 0.3071446418762207, 0.42202112078666687, 0.3242444396018982, 0.2230321615934372, 0.272556871175766, 0.4073536694049835, 0.5774704217910767, 0.3156183362007141, 0.3602727949619293, 0.277992844581604, 0.4176483452320099, 0.29376497864723206, 0.20431244373321533, 0.24112002551555634, 0.42504873871803284, 0.4517810642719269, 0.18830111622810364, 0.4992930591106415, 0.21354687213897705, 0.4428255259990692, 0.4035013020038605, 0.2907755970954895, 0.36484041810035706, 0.2661612927913666, 0.3224569261074066, 0.24876011908054352, 0.2042054682970047, 0.30791494250297546, 0.4402293264865875, 0.33704859018325806, 0.2812013626098633, 0.28178104758262634, 0.30744102597236633, 0.5815460085868835, 0.41700416803359985, 0.3995397090911865, 0.3323385715484619, 0.21391423046588898, 0.39515990018844604, 0.4036598801612854, 0.20453329384326935, 0.32588961720466614, 0.20242249965667725, 0.3732073903083801, 0.39434269070625305, 0.1882021278142929, 0.360810786485672, 0.21150270104408264, 0.35550743341445923, 0.26008158922195435, 0.36239248514175415, 0.25569722056388855, 0.261184424161911, 0.3589418828487396, 0.3292432725429535, 0.33784857392311096, 0.4093613624572754, 0.3146112859249115, 0.27740609645843506, 0.22034740447998047, 0.27294090390205383]\n",
      "[52.67857142857143, 65.17857142857143, 70.53571428571429, 68.75, 73.21428571428571, 70.53571428571429, 69.64285714285714, 88.39285714285714, 79.46428571428571, 77.67857142857143, 80.35714285714286, 83.92857142857143, 85.71428571428571, 75.89285714285714, 83.03571428571429, 80.35714285714286, 81.25, 75.89285714285714, 88.39285714285714, 71.42857142857143, 83.03571428571429, 83.92857142857143, 82.14285714285714, 87.5, 87.5, 86.60714285714286, 79.46428571428571, 80.35714285714286, 90.17857142857143, 83.03571428571429, 80.35714285714286, 89.28571428571429, 86.60714285714286, 85.71428571428571, 88.39285714285714, 92.85714285714286, 80.35714285714286, 91.96428571428571, 84.82142857142857, 77.67857142857143, 81.25, 83.03571428571429, 85.71428571428571, 86.60714285714286, 86.60714285714286, 88.39285714285714, 81.25, 83.92857142857143, 87.5, 80.35714285714286, 84.82142857142857, 86.60714285714286, 83.92857142857143, 91.96428571428571, 84.82142857142857, 86.60714285714286, 79.46428571428571, 83.03571428571429, 91.07142857142857, 89.28571428571429, 91.96428571428571, 91.07142857142857, 91.07142857142857, 88.39285714285714, 84.82142857142857, 82.14285714285714, 86.60714285714286, 91.96428571428571, 85.71428571428571, 85.71428571428571, 83.92857142857143, 88.39285714285714, 87.5, 82.14285714285714, 85.71428571428571, 84.82142857142857, 91.96428571428571, 90.17857142857143, 88.39285714285714, 82.14285714285714, 84.82142857142857, 84.82142857142857, 90.17857142857143, 87.5, 88.39285714285714, 86.60714285714286, 90.17857142857143, 91.07142857142857, 91.96428571428571, 90.17857142857143, 87.5, 83.03571428571429, 90.17857142857143, 95.53571428571429, 83.92857142857143, 86.60714285714286, 94.64285714285714, 88.39285714285714, 93.75, 89.28571428571429, 86.60714285714286, 87.5, 88.39285714285714, 85.71428571428571, 90.17857142857143, 91.96428571428571, 90.17857142857143, 85.71428571428571, 88.39285714285714, 89.28571428571429, 88.39285714285714, 91.07142857142857, 94.64285714285714, 84.82142857142857, 88.39285714285714, 91.96428571428571, 83.92857142857143, 85.71428571428571, 91.96428571428571, 88.39285714285714, 91.07142857142857, 86.60714285714286, 91.96428571428571, 89.28571428571429, 88.39285714285714, 87.5, 89.28571428571429, 88.39285714285714, 89.28571428571429, 83.92857142857143, 91.07142857142857, 91.96428571428571, 89.28571428571429, 90.17857142857143, 86.60714285714286, 86.60714285714286, 89.28571428571429, 89.28571428571429, 90.17857142857143, 88.39285714285714, 89.28571428571429, 89.28571428571429, 94.64285714285714, 91.07142857142857, 89.28571428571429, 83.92857142857143, 91.07142857142857, 89.28571428571429, 90.17857142857143, 85.71428571428571, 90.17857142857143, 93.75, 92.85714285714286, 86.60714285714286, 86.60714285714286, 93.75, 85.71428571428571, 92.85714285714286, 85.71428571428571, 87.5, 90.17857142857143, 85.71428571428571, 91.07142857142857, 91.07142857142857, 91.07142857142857, 95.53571428571429, 91.07142857142857, 90.17857142857143, 91.07142857142857, 91.96428571428571, 92.85714285714286, 89.28571428571429, 80.35714285714286, 89.28571428571429, 91.07142857142857, 89.28571428571429, 92.85714285714286, 91.07142857142857, 90.17857142857143, 95.53571428571429, 93.75, 91.96428571428571, 89.28571428571429, 87.5, 96.42857142857143, 91.96428571428571, 94.64285714285714, 91.96428571428571, 91.07142857142857, 83.03571428571429, 89.28571428571429, 91.07142857142857, 85.71428571428571, 90.17857142857143, 90.17857142857143, 90.17857142857143, 88.39285714285714, 91.07142857142857, 94.64285714285714, 90.17857142857143]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [1.8659029006958008, 1.0114175081253052, 0.7894236445426941, 0.8472731709480286, 0.972960889339447, 0.6655892729759216, 0.8144146800041199, 0.6424515843391418, 0.9496526122093201, 0.9636737108230591, 0.8308879137039185, 0.7714968919754028, 0.6432841420173645, 0.5657731890678406, 0.6799550652503967, 0.7376074194908142, 0.4332921802997589, 0.601387619972229, 0.4874730110168457, 0.5530427098274231, 0.4708968997001648, 0.4042946696281433, 0.4766562283039093, 0.4874492585659027, 0.5408406257629395, 0.34133559465408325, 0.697836697101593, 0.5013027191162109, 0.4161888062953949, 0.45227962732315063, 0.49294358491897583, 0.5126746296882629, 0.5330145359039307, 0.4214167892932892, 0.3001425862312317, 0.40614503622055054, 0.5479076504707336, 0.4155104160308838, 0.4057805836200714, 0.3635489344596863, 0.4714345932006836, 0.6041955947875977, 0.48581835627555847, 0.32873669266700745, 0.4203832447528839, 0.4860703647136688, 0.3370680510997772, 0.5424385070800781, 0.48969411849975586, 0.3126077353954315, 0.5500335097312927, 0.5162601470947266, 0.3102653920650482, 0.5247257947921753, 0.3968731760978699, 0.4144159257411957, 0.4693611264228821, 0.5519578456878662, 0.2814164161682129, 0.4237074851989746, 0.5051514506340027, 0.36219099164009094, 0.2930101454257965, 0.39444980025291443, 0.4233984053134918, 0.3091633915901184, 0.4498511254787445, 0.49406102299690247, 0.29419398307800293, 0.6584022641181946, 0.49027344584465027, 0.38529977202415466, 0.35970744490623474, 0.4419007897377014, 0.39038974046707153, 0.4614807665348053, 0.3950057327747345, 0.4600768983364105, 0.42675596475601196, 0.5244494080543518, 0.2860519289970398, 0.3290395438671112, 0.3706439137458801, 0.4013698101043701, 0.3575269281864166, 0.46237653493881226, 0.41219744086265564, 0.3049541413784027, 0.3961615264415741, 0.6099297404289246, 0.4326234459877014, 0.4120914936065674, 0.3548559248447418, 0.5161176919937134, 0.43737348914146423, 0.5589717030525208, 0.43144017457962036, 0.2529344856739044, 0.3529343903064728, 0.4302687644958496, 0.47040364146232605, 0.2951113283634186, 0.4599674344062805, 0.4101117253303528, 0.4613316059112549, 0.3550489544868469, 0.46383705735206604, 0.32566356658935547, 0.34833186864852905, 0.5564172267913818, 0.5140848159790039, 0.3546297252178192, 0.5133334398269653, 0.24900688230991364, 0.648823618888855, 0.45948776602745056, 0.2651248574256897, 0.26247361302375793, 0.4038391709327698, 0.3530396819114685, 0.5127835273742676, 0.22933025658130646, 0.5402856469154358, 0.5111652612686157, 0.4472675919532776, 0.3747692108154297, 0.42233607172966003, 0.28661876916885376, 0.5031672716140747, 0.4256725013256073, 0.34286433458328247, 0.38685503602027893, 0.4258039891719818, 0.556299090385437, 0.35352227091789246, 0.3980681300163269, 0.32486796379089355, 0.29609185457229614, 0.5332227349281311, 0.43925541639328003, 0.5010014176368713, 0.5912306904792786, 0.40815871953964233, 0.36031100153923035, 0.39327874779701233, 0.37839630246162415, 0.36965662240982056, 0.46051639318466187, 0.4839703142642975, 0.384511262178421, 0.3403129577636719, 0.45515328645706177, 0.5565947890281677, 0.26640766859054565, 0.3089554011821747, 0.2560182213783264, 0.4501858353614807, 0.523838222026825, 0.27077192068099976, 0.43475836515426636, 0.43613409996032715, 0.45895761251449585, 0.40406590700149536, 0.2851075232028961, 0.28605151176452637, 0.45188549160957336, 0.3239971995353699, 0.34607192873954773, 0.6600301861763, 0.3324182629585266, 0.4418165683746338, 0.2774260640144348, 0.25871145725250244, 0.28420722484588623, 0.29635995626449585, 0.4265746474266052, 0.3605896830558777, 0.3856739401817322, 0.5902963876724243, 0.492372065782547, 0.48548683524131775, 0.43873950839042664, 0.4322543442249298, 0.3550132215023041, 0.5190008282661438, 0.3758506178855896, 0.3198237717151642, 0.5576151609420776, 0.31174159049987793, 0.45935872197151184, 0.35561174154281616, 0.3017100989818573, 0.3818623721599579, 0.38655051589012146, 0.40503570437431335, 0.25678497552871704, 0.3543322682380676, 0.2552958130836487, 0.49598604440689087, 0.2921765446662903]\n",
    "# acc_list_epoch_ = [41.07142857142857, 66.96428571428571, 70.53571428571429, 74.10714285714286, 66.96428571428571, 78.57142857142857, 73.21428571428571, 78.57142857142857, 72.32142857142857, 68.75, 78.57142857142857, 75.89285714285714, 80.35714285714286, 88.39285714285714, 79.46428571428571, 77.67857142857143, 85.71428571428571, 78.57142857142857, 83.92857142857143, 81.25, 88.39285714285714, 90.17857142857143, 90.17857142857143, 82.14285714285714, 84.82142857142857, 88.39285714285714, 78.57142857142857, 83.03571428571429, 85.71428571428571, 84.82142857142857, 82.14285714285714, 85.71428571428571, 87.5, 87.5, 91.07142857142857, 85.71428571428571, 83.03571428571429, 83.92857142857143, 87.5, 87.5, 82.14285714285714, 82.14285714285714, 84.82142857142857, 89.28571428571429, 88.39285714285714, 87.5, 90.17857142857143, 83.92857142857143, 82.14285714285714, 91.07142857142857, 80.35714285714286, 81.25, 90.17857142857143, 86.60714285714286, 84.82142857142857, 84.82142857142857, 84.82142857142857, 83.03571428571429, 91.07142857142857, 87.5, 84.82142857142857, 87.5, 91.07142857142857, 90.17857142857143, 86.60714285714286, 90.17857142857143, 83.03571428571429, 83.92857142857143, 91.96428571428571, 80.35714285714286, 84.82142857142857, 84.82142857142857, 85.71428571428571, 89.28571428571429, 89.28571428571429, 88.39285714285714, 87.5, 87.5, 86.60714285714286, 81.25, 91.96428571428571, 89.28571428571429, 86.60714285714286, 87.5, 90.17857142857143, 84.82142857142857, 86.60714285714286, 89.28571428571429, 86.60714285714286, 82.14285714285714, 85.71428571428571, 86.60714285714286, 90.17857142857143, 81.25, 85.71428571428571, 81.25, 85.71428571428571, 91.96428571428571, 89.28571428571429, 86.60714285714286, 83.03571428571429, 91.07142857142857, 87.5, 85.71428571428571, 88.39285714285714, 85.71428571428571, 87.5, 91.96428571428571, 90.17857142857143, 82.14285714285714, 81.25, 85.71428571428571, 85.71428571428571, 91.96428571428571, 79.46428571428571, 83.03571428571429, 91.07142857142857, 91.96428571428571, 88.39285714285714, 88.39285714285714, 85.71428571428571, 95.53571428571429, 86.60714285714286, 85.71428571428571, 83.03571428571429, 87.5, 85.71428571428571, 89.28571428571429, 83.92857142857143, 84.82142857142857, 90.17857142857143, 88.39285714285714, 85.71428571428571, 85.71428571428571, 90.17857142857143, 84.82142857142857, 90.17857142857143, 88.39285714285714, 83.03571428571429, 86.60714285714286, 88.39285714285714, 84.82142857142857, 83.03571428571429, 88.39285714285714, 88.39285714285714, 88.39285714285714, 88.39285714285714, 88.39285714285714, 88.39285714285714, 88.39285714285714, 91.07142857142857, 85.71428571428571, 83.92857142857143, 91.07142857142857, 91.07142857142857, 89.28571428571429, 87.5, 83.03571428571429, 90.17857142857143, 90.17857142857143, 84.82142857142857, 89.28571428571429, 87.5, 91.96428571428571, 89.28571428571429, 87.5, 90.17857142857143, 87.5, 81.25, 88.39285714285714, 85.71428571428571, 91.96428571428571, 95.53571428571429, 93.75, 91.96428571428571, 84.82142857142857, 88.39285714285714, 87.5, 81.25, 86.60714285714286, 88.39285714285714, 85.71428571428571, 85.71428571428571, 89.28571428571429, 84.82142857142857, 89.28571428571429, 91.96428571428571, 87.5, 91.96428571428571, 85.71428571428571, 87.5, 91.96428571428571, 88.39285714285714, 90.17857142857143, 90.17857142857143, 91.96428571428571, 88.39285714285714, 93.75, 88.39285714285714, 87.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 90.33%\n",
      "Loss on the train set: 0.31\n",
      "Accuracy on the test set: 91.00%\n",
      "Loss on the test set: 0.33\n",
      "Generalization error: 0.02170077\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
