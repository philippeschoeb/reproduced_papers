{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.252587</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.464607</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.911638</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.001959</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.810147</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.615082</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.771527</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.241991</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.880258</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.478797</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.675969</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.09896</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.703453</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.698257</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.544886</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.226452</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.946586</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.215088</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.307688</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.203607</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.500721</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.842887</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.066823</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.918338</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.628721</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.6105</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.324067</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.260515</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.082121</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.688233</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.747234</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.57585</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.696828</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.93765</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.991089</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.496165</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.652686</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.080026</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.800582</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.706598</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.460253</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.722008</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.908095</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.089203</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.72151</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.653475</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.328794</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.708542</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.00984</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.412571</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.549807</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.99841</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.050323</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.096373</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.715403</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.589222</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.402732</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.419345</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.569291</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.94644</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.567758</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.661519</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.155536</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.106593</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.207101</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.975476</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.517675</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.162464</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.585184</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.486708</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.67165</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.876734</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.835498</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.104284</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.734945</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7a0d5972a460>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m=8, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 63, and embedding size = 35\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1260.0\" height=\"468.75\" viewBox=\"-29.0 0 1008.0 375.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.40754</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.504534</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.819033</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.033518</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.549092</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.093654</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.699612</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.858877</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.861635</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.139878</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.089122</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.247547</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.882558</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.773225</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.436274</text>\n",
       "<path d=\"M25,325.0 L175,325.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.256729</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.180926</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.927486</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.049431</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.248923</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.974609</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.779928</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.449525</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.650454</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.200514</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.546625</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.700632</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.851187</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.622592</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.901764</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.025726</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.617106</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.058316</text>\n",
       "<path d=\"M325,325.0 L475,325.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.46782</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.40287</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.771506</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.34392</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.10265</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.023712</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.884342</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.937966</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.521238</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.95292</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.944475</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.061038</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.818257</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.955696</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.931532</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.031163</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.767417</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.828705</text>\n",
       "<path d=\"M625,325.0 L775,325.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.046913</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.210603</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.623277</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25.0 L940,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,75.0 L940,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,125.0 L940,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,175.0 L940,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,225.0 L940,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,275.0 L940,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,325.0 L940,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"950\" y=\"28.0\" font-size=\"8\" text-anchor=\"end\">0</text>\n",
       "<text x=\"950\" y=\"78.0\" font-size=\"8\" text-anchor=\"end\">1</text>\n",
       "<text x=\"950\" y=\"128.0\" font-size=\"8\" text-anchor=\"end\">2</text>\n",
       "<text x=\"950\" y=\"178.0\" font-size=\"8\" text-anchor=\"end\">3</text>\n",
       "<text x=\"950\" y=\"228.0\" font-size=\"8\" text-anchor=\"end\">4</text>\n",
       "<text x=\"950\" y=\"278.0\" font-size=\"8\" text-anchor=\"end\">5</text>\n",
       "<text x=\"950\" y=\"328.0\" font-size=\"8\" text-anchor=\"end\">6</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"8\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"8\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"8\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"8\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"8\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"8\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"8\" text-anchor=\"start\">6</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7a0d5969f2b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m=7, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2450"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "35 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(165)\n",
    "# res = bs.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        #     super(CNNModel, self).__init__()\n",
    "        #     self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #     self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        #     self.fc1 = nn.Linear(12*4*4, 20)\n",
    "        #     self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "        # def forward(self, x):\n",
    "        #     x = self.pool(self.conv1(x))\n",
    "        #     x = self.pool(self.conv2(x))\n",
    "        #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        #     x = self.fc1(x)\n",
    "        #     x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  1838\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 53.50%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  1838\n",
      "Required qubit number:  11\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    class MappingModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_sizes, output_size):\n",
    "            super().__init__()\n",
    "            # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "            self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "            self.hidden_layers = nn.ModuleList(\n",
    "                [\n",
    "                    nn.Linear(hidden_sizes[i], hidden_sizes[i + 1])\n",
    "                    for i in range(len(hidden_sizes) - 1)\n",
    "                ]\n",
    "            )\n",
    "            self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "        def forward(self, X):\n",
    "            # Ensure the input tensor is the same type as the weights\n",
    "            X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "            # Input layer with ReLU activation\n",
    "            X = self.input_layer(X)\n",
    "\n",
    "            # Hidden layers with ReLU activation\n",
    "            for hidden in self.hidden_layers:\n",
    "                X = hidden(X)\n",
    "\n",
    "            # Output layer with linear activation\n",
    "            output = self.output_layer(X)\n",
    "            # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "            return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "        self.MappingNetwork = self.MappingModel(n_qubit + 1, [8], 1).to(device)\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        # self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[\n",
    "            :84\n",
    "        ]  # nn.Parameter(q_delta * torch.randn(135)).to(device)\n",
    "        self.q_params_2 = qnn_parameters[84:]\n",
    "        device = x.device\n",
    "\n",
    "        res_1 = bs_1.run(parameters=self.q_params_1, samples=100000)\n",
    "        trans_res_1 = bs_1.translate_results(res=res_1)\n",
    "        trans_res_1 = trans_res_1 / torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)\n",
    "\n",
    "        res_2 = bs_2.run(parameters=self.q_params_2, samples=100000)\n",
    "        trans_res_2 = bs_2.translate_results(res=res_2)\n",
    "        trans_res_2 = trans_res_2 / torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)\n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(70 * 35, 1)\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[: len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), 1, n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  113\n",
      "# of trainable parameter in QNN model:  147\n",
      "# of trainable parameter in full model:  260\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(147)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\n",
    "    \"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters\n",
    ")\n",
    "print(\n",
    "    \"# of trainable parameter in full model: \",\n",
    "    num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 4.6909, batch time: 0.03, accuracy:  21.09%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.7423, batch time: 0.03, accuracy:  21.88%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.5275, batch time: 0.03, accuracy:  17.19%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.4302, batch time: 0.03, accuracy:  18.75%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 2.2619, batch time: 0.03, accuracy:  21.88%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 2.1164, batch time: 0.03, accuracy:  23.44%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 2.2258, batch time: 0.03, accuracy:  21.09%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 2.2251, batch time: 0.03, accuracy:  20.31%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 2.2338, batch time: 0.03, accuracy:  20.31%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 2.2333, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [1/200], qnn_train_step: [100/500], loss: 2.1509432792663574, accuracy: 20.7 %\n",
      "Training round [1/200], qnn_train_step: [200/500], loss: 2.145843982696533, accuracy: 21.6 %\n",
      "Training round [1/200], qnn_train_step: [300/500], loss: 2.1498987674713135, accuracy: 20.7 %\n",
      "Training round [1/200], qnn_train_step: [400/500], loss: 2.1489951610565186, accuracy: 22.2 %\n",
      "Training round [1/200], qnn_train_step: [500/500], loss: 2.1459290981292725, accuracy: 19.5 %\n",
      "Training round [1/200], qnn_train_step: [600/500], loss: 2.1498544216156006, accuracy: 23.0 %\n",
      "Training round [1/200], qnn_train_step: [700/500], loss: 2.148859977722168, accuracy: 22.3 %\n",
      "Training round [1/200], qnn_train_step: [800/500], loss: 2.1461758613586426, accuracy: 22.2 %\n",
      "Training round [1/200], qnn_train_step: [900/500], loss: 2.149768114089966, accuracy: 19.8 %\n",
      "Training round [1/200], qnn_train_step: [1000/500], loss: 2.1487374305725098, accuracy: 22.3 %\n",
      "Training round [1/200], qnn_train_step: [1100/500], loss: 2.146408796310425, accuracy: 22.9 %\n",
      "Training round [1/200], qnn_train_step: [1200/500], loss: 2.1499102115631104, accuracy: 20.2 %\n",
      "Training round [1/200], qnn_train_step: [1300/500], loss: 2.1486029624938965, accuracy: 22.4 %\n",
      "Training round [1/200], qnn_train_step: [1400/500], loss: 2.1467478275299072, accuracy: 21.4 %\n",
      "Training round [1/200], qnn_train_step: [1500/500], loss: 2.149840831756592, accuracy: 21.4 %\n",
      "Training round [1/200], qnn_train_step: [1600/500], loss: 2.1484689712524414, accuracy: 22.3 %\n",
      "Training round [1/200], qnn_train_step: [1700/500], loss: 2.1469886302948, accuracy: 22.0 %\n",
      "Training round [1/200], qnn_train_step: [1800/500], loss: 2.1497082710266113, accuracy: 19.6 %\n",
      "Training round [1/200], qnn_train_step: [1900/500], loss: 2.1483399868011475, accuracy: 22.2 %\n",
      "Training round [1/200], qnn_train_step: [2000/500], loss: 2.147073268890381, accuracy: 21.2 %\n",
      "Training round [1/200], qnn_train_step: [2100/500], loss: 2.149665355682373, accuracy: 22.3 %\n",
      "Training round [1/200], qnn_train_step: [2200/500], loss: 2.1482253074645996, accuracy: 22.2 %\n",
      "Training round [1/200], qnn_train_step: [2300/500], loss: 2.147029399871826, accuracy: 21.4 %\n",
      "Training round [1/200], qnn_train_step: [2400/500], loss: 2.1495630741119385, accuracy: 22.0 %\n",
      "Training round [1/200], qnn_train_step: [2500/500], loss: 2.148108959197998, accuracy: 22.2 %\n",
      "Training round [1/200], qnn_train_step: [2600/500], loss: 2.147019386291504, accuracy: 21.8 %\n",
      "Training round [1/200], qnn_train_step: [2700/500], loss: 2.1496047973632812, accuracy: 20.8 %\n",
      "Training round [1/200], qnn_train_step: [2800/500], loss: 2.14799165725708, accuracy: 22.2 %\n",
      "Training round [1/200], qnn_train_step: [2900/500], loss: 2.1470017433166504, accuracy: 19.3 %\n",
      "Training round [1/200], qnn_train_step: [3000/500], loss: 2.1495535373687744, accuracy: 20.8 %\n",
      "Training round [1/200], qnn_train_step: [3100/500], loss: 2.147871732711792, accuracy: 22.2 %\n",
      "Training round [1/200], qnn_train_step: [3200/500], loss: 2.1482577323913574, accuracy: 20.0 %\n",
      "Training round [1/200], qnn_train_step: [3300/500], loss: 2.1405746936798096, accuracy: 21.1 %\n",
      "Training round [1/200], qnn_train_step: [3400/500], loss: 2.140256881713867, accuracy: 22.9 %\n",
      "Training round [1/200], qnn_train_step: [3500/500], loss: 2.133589744567871, accuracy: 19.7 %\n",
      "Training round [1/200], qnn_train_step: [3600/500], loss: 2.13667631149292, accuracy: 18.7 %\n",
      "Training round [1/200], qnn_train_step: [3700/500], loss: 2.127683401107788, accuracy: 18.9 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 2.1692, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 2.1155, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 2.0963, batch time: 0.03, accuracy:  20.31%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 2.1082, batch time: 0.03, accuracy:  21.88%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 2.0897, batch time: 0.03, accuracy:  18.75%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 1.9966, batch time: 0.03, accuracy:  26.56%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 2.0620, batch time: 0.07, accuracy:  17.97%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 1.8786, batch time: 0.05, accuracy:  28.91%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 2.0647, batch time: 0.05, accuracy:  20.31%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 1.9105, batch time: 0.03, accuracy:  27.34%\n",
      "Training round [2/200], qnn_train_step: [100/500], loss: 1.9937995672225952, accuracy: 20.5 %\n",
      "Training round [2/200], qnn_train_step: [200/500], loss: 1.9769614934921265, accuracy: 21.0 %\n",
      "Training round [2/200], qnn_train_step: [300/500], loss: 1.9484423398971558, accuracy: 22.5 %\n",
      "Training round [2/200], qnn_train_step: [400/500], loss: 1.9445613622665405, accuracy: 21.7 %\n",
      "Training round [2/200], qnn_train_step: [500/500], loss: 1.9593585729599, accuracy: 21.3 %\n",
      "Training round [2/200], qnn_train_step: [600/500], loss: 1.956120252609253, accuracy: 21.6 %\n",
      "Training round [2/200], qnn_train_step: [700/500], loss: 1.9448988437652588, accuracy: 21.9 %\n",
      "Training round [2/200], qnn_train_step: [800/500], loss: 1.9591227769851685, accuracy: 21.9 %\n",
      "Training round [2/200], qnn_train_step: [900/500], loss: 1.9560550451278687, accuracy: 21.9 %\n",
      "Training round [2/200], qnn_train_step: [1000/500], loss: 1.9450751543045044, accuracy: 21.8 %\n",
      "Training round [2/200], qnn_train_step: [1100/500], loss: 1.9591374397277832, accuracy: 21.9 %\n",
      "Training round [2/200], qnn_train_step: [1200/500], loss: 1.9561975002288818, accuracy: 21.8 %\n",
      "Training round [2/200], qnn_train_step: [1300/500], loss: 1.95193612575531, accuracy: 21.9 %\n",
      "Training round [2/200], qnn_train_step: [1400/500], loss: 1.9396229982376099, accuracy: 22.3 %\n",
      "Training round [2/200], qnn_train_step: [1500/500], loss: 1.9336518049240112, accuracy: 22.5 %\n",
      "Training round [2/200], qnn_train_step: [1600/500], loss: 1.9335864782333374, accuracy: 22.2 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 1.9966, batch time: 0.03, accuracy:  21.88%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 1.9979, batch time: 0.03, accuracy:  19.53%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 1.9114, batch time: 0.03, accuracy:  27.34%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 2.0072, batch time: 0.03, accuracy:  18.75%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 1.8524, batch time: 0.03, accuracy:  28.12%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 1.9394, batch time: 0.03, accuracy:  21.88%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 1.8570, batch time: 0.03, accuracy:  19.53%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 1.8281, batch time: 0.03, accuracy:  28.12%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 2.1609, batch time: 0.03, accuracy:  17.19%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 1.9786, batch time: 0.03, accuracy:  22.66%\n",
      "Training round [3/200], qnn_train_step: [100/500], loss: 1.9154564142227173, accuracy: 23.4 %\n",
      "Training round [3/200], qnn_train_step: [200/500], loss: 1.9450527429580688, accuracy: 22.2 %\n",
      "Training round [3/200], qnn_train_step: [300/500], loss: 1.920749306678772, accuracy: 23.3 %\n",
      "Training round [3/200], qnn_train_step: [400/500], loss: 1.89584481716156, accuracy: 23.8 %\n",
      "Training round [3/200], qnn_train_step: [500/500], loss: 1.9025400876998901, accuracy: 22.8 %\n",
      "Training round [3/200], qnn_train_step: [600/500], loss: 1.8864446878433228, accuracy: 23.8 %\n",
      "Training round [3/200], qnn_train_step: [700/500], loss: 1.88253915309906, accuracy: 23.5 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 1.8864, batch time: 0.03, accuracy:  23.44%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 1.9314, batch time: 0.03, accuracy:  19.53%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 1.7761, batch time: 0.03, accuracy:  25.00%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 1.9840, batch time: 0.03, accuracy:  20.31%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 1.8244, batch time: 0.03, accuracy:  25.78%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 1.8482, batch time: 0.03, accuracy:  20.31%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 1.8743, batch time: 0.03, accuracy:  23.44%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 1.9018, batch time: 0.03, accuracy:  17.19%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 1.7467, batch time: 0.03, accuracy:  27.34%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 1.8171, batch time: 0.03, accuracy:  22.66%\n",
      "Training round [4/200], qnn_train_step: [100/500], loss: 1.847176432609558, accuracy: 26.7 %\n",
      "Training round [4/200], qnn_train_step: [200/500], loss: 1.8527891635894775, accuracy: 27.9 %\n",
      "Training round [4/200], qnn_train_step: [300/500], loss: 1.83441960811615, accuracy: 26.0 %\n",
      "Training round [4/200], qnn_train_step: [400/500], loss: 1.8248188495635986, accuracy: 25.9 %\n",
      "Training round [4/200], qnn_train_step: [500/500], loss: 1.8220292329788208, accuracy: 27.6 %\n",
      "Training round [4/200], qnn_train_step: [600/500], loss: 1.8235903978347778, accuracy: 25.4 %\n",
      "Training round [4/200], qnn_train_step: [700/500], loss: 1.8213279247283936, accuracy: 27.0 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 1.7109, batch time: 0.03, accuracy:  25.78%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 1.8346, batch time: 0.03, accuracy:  24.22%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 1.8825, batch time: 0.03, accuracy:  22.66%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 2.0062, batch time: 0.03, accuracy:  25.78%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 1.8189, batch time: 0.03, accuracy:  28.91%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 1.7809, batch time: 0.03, accuracy:  26.56%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 1.8310, batch time: 0.03, accuracy:  24.22%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 1.9779, batch time: 0.03, accuracy:  22.66%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 1.8791, batch time: 0.03, accuracy:  17.97%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 1.8692, batch time: 0.03, accuracy:  25.00%\n",
      "Training round [5/200], qnn_train_step: [100/500], loss: 1.8749463558197021, accuracy: 23.4 %\n",
      "Training round [5/200], qnn_train_step: [200/500], loss: 1.9067219495773315, accuracy: 23.8 %\n",
      "Training round [5/200], qnn_train_step: [300/500], loss: 1.8499056100845337, accuracy: 24.0 %\n",
      "Training round [5/200], qnn_train_step: [400/500], loss: 1.858816146850586, accuracy: 27.0 %\n",
      "Training round [5/200], qnn_train_step: [500/500], loss: 1.8484619855880737, accuracy: 25.5 %\n",
      "Training round [5/200], qnn_train_step: [600/500], loss: 1.8503731489181519, accuracy: 27.9 %\n",
      "Training round [5/200], qnn_train_step: [700/500], loss: 1.8400894403457642, accuracy: 28.1 %\n",
      "Training round [5/200], qnn_train_step: [800/500], loss: 1.837124228477478, accuracy: 27.7 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 1.8084, batch time: 0.03, accuracy:  29.69%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 1.8396, batch time: 0.03, accuracy:  28.91%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 1.8176, batch time: 0.03, accuracy:  29.69%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 1.7989, batch time: 0.03, accuracy:  29.69%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 1.8053, batch time: 0.03, accuracy:  27.34%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 1.8950, batch time: 0.03, accuracy:  27.34%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 1.8133, batch time: 0.03, accuracy:  32.03%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 1.8609, batch time: 0.03, accuracy:  28.91%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 1.8888, batch time: 0.03, accuracy:  19.53%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 1.7313, batch time: 0.03, accuracy:  30.47%\n",
      "Training round [6/200], qnn_train_step: [100/500], loss: 1.8128408193588257, accuracy: 28.6 %\n",
      "Training round [6/200], qnn_train_step: [200/500], loss: 1.843991994857788, accuracy: 29.9 %\n",
      "Training round [6/200], qnn_train_step: [300/500], loss: 1.820453405380249, accuracy: 29.1 %\n",
      "Training round [6/200], qnn_train_step: [400/500], loss: 1.8126654624938965, accuracy: 29.8 %\n",
      "Training round [6/200], qnn_train_step: [500/500], loss: 1.8103317022323608, accuracy: 31.5 %\n",
      "Training round [6/200], qnn_train_step: [600/500], loss: 1.8050531148910522, accuracy: 31.3 %\n",
      "Training round [6/200], qnn_train_step: [700/500], loss: 1.7937897443771362, accuracy: 31.9 %\n",
      "Training round [6/200], qnn_train_step: [800/500], loss: 1.8015995025634766, accuracy: 30.3 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 1.8299, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 1.9246, batch time: 0.03, accuracy:  27.34%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 1.6370, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 1.8019, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 1.9167, batch time: 0.03, accuracy:  28.91%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 1.8699, batch time: 0.03, accuracy:  30.47%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 1.6983, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 1.7363, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 1.9279, batch time: 0.03, accuracy:  29.69%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 1.7844, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [7/200], qnn_train_step: [100/500], loss: 1.8129642009735107, accuracy: 28.7 %\n",
      "Training round [7/200], qnn_train_step: [200/500], loss: 1.7889163494110107, accuracy: 34.2 %\n",
      "Training round [7/200], qnn_train_step: [300/500], loss: 1.7687530517578125, accuracy: 32.5 %\n",
      "Training round [7/200], qnn_train_step: [400/500], loss: 1.7684931755065918, accuracy: 32.9 %\n",
      "Training round [7/200], qnn_train_step: [500/500], loss: 1.7749053239822388, accuracy: 32.0 %\n",
      "Training round [7/200], qnn_train_step: [600/500], loss: 1.7695753574371338, accuracy: 33.3 %\n",
      "Training round [7/200], qnn_train_step: [700/500], loss: 1.767500877380371, accuracy: 33.0 %\n",
      "Training round [7/200], qnn_train_step: [800/500], loss: 1.768141508102417, accuracy: 32.3 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 1.7808, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 1.7783, batch time: 0.03, accuracy:  28.91%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 1.8181, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 1.7160, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 1.8155, batch time: 0.03, accuracy:  25.78%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 1.7085, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 1.7396, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 1.7437, batch time: 0.03, accuracy:  30.47%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 1.6735, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 1.8707, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [8/200], qnn_train_step: [100/500], loss: 1.7766358852386475, accuracy: 33.9 %\n",
      "Training round [8/200], qnn_train_step: [200/500], loss: 1.7818667888641357, accuracy: 31.2 %\n",
      "Training round [8/200], qnn_train_step: [300/500], loss: 1.7692936658859253, accuracy: 32.6 %\n",
      "Training round [8/200], qnn_train_step: [400/500], loss: 1.7682682275772095, accuracy: 33.6 %\n",
      "Training round [8/200], qnn_train_step: [500/500], loss: 1.763661503791809, accuracy: 33.0 %\n",
      "Training round [8/200], qnn_train_step: [600/500], loss: 1.7607612609863281, accuracy: 34.2 %\n",
      "Training round [8/200], qnn_train_step: [700/500], loss: 1.7589482069015503, accuracy: 33.2 %\n",
      "Training round [8/200], qnn_train_step: [800/500], loss: 1.757424235343933, accuracy: 34.3 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 1.8191, batch time: 0.03, accuracy:  32.03%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 1.6317, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 1.7105, batch time: 0.03, accuracy:  30.47%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 1.6560, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 1.8145, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 1.7100, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 1.7312, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 1.7203, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 1.7596, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 1.6775, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [9/200], qnn_train_step: [100/500], loss: 1.7517681121826172, accuracy: 36.3 %\n",
      "Training round [9/200], qnn_train_step: [200/500], loss: 1.7544043064117432, accuracy: 35.1 %\n",
      "Training round [9/200], qnn_train_step: [300/500], loss: 1.7420772314071655, accuracy: 34.1 %\n",
      "Training round [9/200], qnn_train_step: [400/500], loss: 1.7338722944259644, accuracy: 36.2 %\n",
      "Training round [9/200], qnn_train_step: [500/500], loss: 1.722259283065796, accuracy: 36.6 %\n",
      "Training round [9/200], qnn_train_step: [600/500], loss: 1.7228641510009766, accuracy: 36.8 %\n",
      "Training round [9/200], qnn_train_step: [700/500], loss: 1.72798490524292, accuracy: 35.2 %\n",
      "Training round [9/200], qnn_train_step: [800/500], loss: 1.7219719886779785, accuracy: 37.7 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 1.7981, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 1.7301, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 1.7308, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 1.7724, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 1.7034, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 1.7296, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 1.8799, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 1.6890, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 1.8929, batch time: 0.03, accuracy:  24.22%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 1.6984, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [10/200], qnn_train_step: [100/500], loss: 1.7468796968460083, accuracy: 34.2 %\n",
      "Training round [10/200], qnn_train_step: [200/500], loss: 1.7668718099594116, accuracy: 36.0 %\n",
      "Training round [10/200], qnn_train_step: [300/500], loss: 1.7104010581970215, accuracy: 36.0 %\n",
      "Training round [10/200], qnn_train_step: [400/500], loss: 1.6923315525054932, accuracy: 37.9 %\n",
      "Training round [10/200], qnn_train_step: [500/500], loss: 1.7027692794799805, accuracy: 36.5 %\n",
      "Training round [10/200], qnn_train_step: [600/500], loss: 1.6975398063659668, accuracy: 37.6 %\n",
      "Training round [10/200], qnn_train_step: [700/500], loss: 1.6916033029556274, accuracy: 38.1 %\n",
      "Training round [10/200], qnn_train_step: [800/500], loss: 1.6829557418823242, accuracy: 37.3 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 1.6983, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 1.6934, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 1.7892, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 1.7018, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 1.8500, batch time: 0.03, accuracy:  32.03%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 1.7772, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 1.7040, batch time: 0.03, accuracy:  30.47%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 1.7871, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 1.6626, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 1.7279, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [11/200], qnn_train_step: [100/500], loss: 1.7639250755310059, accuracy: 34.5 %\n",
      "Training round [11/200], qnn_train_step: [200/500], loss: 1.7176146507263184, accuracy: 36.7 %\n",
      "Training round [11/200], qnn_train_step: [300/500], loss: 1.7503834962844849, accuracy: 37.0 %\n",
      "Training round [11/200], qnn_train_step: [400/500], loss: 1.7134290933609009, accuracy: 38.8 %\n",
      "Training round [11/200], qnn_train_step: [500/500], loss: 1.7116379737854004, accuracy: 37.9 %\n",
      "Training round [11/200], qnn_train_step: [600/500], loss: 1.7110304832458496, accuracy: 37.2 %\n",
      "Training round [11/200], qnn_train_step: [700/500], loss: 1.7066255807876587, accuracy: 39.0 %\n",
      "Training round [11/200], qnn_train_step: [800/500], loss: 1.7075828313827515, accuracy: 39.1 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 1.7656, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 1.8153, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 1.5552, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 1.7024, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 1.7599, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 1.5279, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 1.8959, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 1.7268, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 1.8408, batch time: 0.03, accuracy:  28.91%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 1.5972, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [12/200], qnn_train_step: [100/500], loss: 1.6850709915161133, accuracy: 39.0 %\n",
      "Training round [12/200], qnn_train_step: [200/500], loss: 1.800177812576294, accuracy: 34.3 %\n",
      "Training round [12/200], qnn_train_step: [300/500], loss: 1.6860400438308716, accuracy: 39.2 %\n",
      "Training round [12/200], qnn_train_step: [400/500], loss: 1.6672112941741943, accuracy: 39.3 %\n",
      "Training round [12/200], qnn_train_step: [500/500], loss: 1.6639522314071655, accuracy: 41.0 %\n",
      "Training round [12/200], qnn_train_step: [600/500], loss: 1.660709261894226, accuracy: 41.3 %\n",
      "Training round [12/200], qnn_train_step: [700/500], loss: 1.6612038612365723, accuracy: 41.6 %\n",
      "Training round [12/200], qnn_train_step: [800/500], loss: 1.6623350381851196, accuracy: 41.7 %\n",
      "Training round [12/200], qnn_train_step: [900/500], loss: 1.6533994674682617, accuracy: 41.2 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 1.7243, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 1.7781, batch time: 0.06, accuracy:  36.72%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 1.6433, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 1.7447, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 1.6580, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 1.6141, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 1.7889, batch time: 0.03, accuracy:  30.47%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 1.7082, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 1.6885, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 1.8169, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [13/200], qnn_train_step: [100/500], loss: 1.6873185634613037, accuracy: 36.5 %\n",
      "Training round [13/200], qnn_train_step: [200/500], loss: 1.7037314176559448, accuracy: 37.5 %\n",
      "Training round [13/200], qnn_train_step: [300/500], loss: 1.6955989599227905, accuracy: 38.8 %\n",
      "Training round [13/200], qnn_train_step: [400/500], loss: 1.6700986623764038, accuracy: 38.1 %\n",
      "Training round [13/200], qnn_train_step: [500/500], loss: 1.6848467588424683, accuracy: 38.5 %\n",
      "Training round [13/200], qnn_train_step: [600/500], loss: 1.672265887260437, accuracy: 37.7 %\n",
      "Training round [13/200], qnn_train_step: [700/500], loss: 1.670621633529663, accuracy: 37.8 %\n",
      "Training round [13/200], qnn_train_step: [800/500], loss: 1.6708904504776, accuracy: 38.6 %\n",
      "Training round [13/200], qnn_train_step: [900/500], loss: 1.6693313121795654, accuracy: 39.1 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 1.7012, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 1.6918, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 1.7197, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 1.7353, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 1.7052, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 1.6752, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 1.7166, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 1.5477, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 1.8700, batch time: 0.06, accuracy:  34.38%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 1.8156, batch time: 0.03, accuracy:  32.03%\n",
      "Training round [14/200], qnn_train_step: [100/500], loss: 1.7225737571716309, accuracy: 36.3 %\n",
      "Training round [14/200], qnn_train_step: [200/500], loss: 1.729097604751587, accuracy: 32.9 %\n",
      "Training round [14/200], qnn_train_step: [300/500], loss: 1.7001827955245972, accuracy: 36.1 %\n",
      "Training round [14/200], qnn_train_step: [400/500], loss: 1.686832070350647, accuracy: 37.3 %\n",
      "Training round [14/200], qnn_train_step: [500/500], loss: 1.68776273727417, accuracy: 37.4 %\n",
      "Training round [14/200], qnn_train_step: [600/500], loss: 1.6811033487319946, accuracy: 37.5 %\n",
      "Training round [14/200], qnn_train_step: [700/500], loss: 1.6788997650146484, accuracy: 37.5 %\n",
      "Training round [14/200], qnn_train_step: [800/500], loss: 1.6769254207611084, accuracy: 37.7 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 1.6892, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 1.8155, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 1.7173, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 1.5386, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 1.7723, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 1.7644, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 1.7816, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 1.7827, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 1.7518, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 1.7376, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [15/200], qnn_train_step: [100/500], loss: 1.6820647716522217, accuracy: 39.0 %\n",
      "Training round [15/200], qnn_train_step: [200/500], loss: 1.7512511014938354, accuracy: 36.8 %\n",
      "Training round [15/200], qnn_train_step: [300/500], loss: 1.7044757604599, accuracy: 37.6 %\n",
      "Training round [15/200], qnn_train_step: [400/500], loss: 1.7003161907196045, accuracy: 37.2 %\n",
      "Training round [15/200], qnn_train_step: [500/500], loss: 1.6745002269744873, accuracy: 39.2 %\n",
      "Training round [15/200], qnn_train_step: [600/500], loss: 1.6722174882888794, accuracy: 39.2 %\n",
      "Training round [15/200], qnn_train_step: [700/500], loss: 1.6624064445495605, accuracy: 40.3 %\n",
      "Training round [15/200], qnn_train_step: [800/500], loss: 1.6669408082962036, accuracy: 39.6 %\n",
      "Training round [15/200], qnn_train_step: [900/500], loss: 1.6626403331756592, accuracy: 40.2 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 1.6091, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 1.5615, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 1.8356, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 1.6317, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 1.6749, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 1.7011, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 1.7698, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 1.6823, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 1.6366, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 1.6662, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [16/200], qnn_train_step: [100/500], loss: 1.7470167875289917, accuracy: 38.8 %\n",
      "Training round [16/200], qnn_train_step: [200/500], loss: 1.7763887643814087, accuracy: 38.0 %\n",
      "Training round [16/200], qnn_train_step: [300/500], loss: 1.7812150716781616, accuracy: 37.6 %\n",
      "Training round [16/200], qnn_train_step: [400/500], loss: 1.7653123140335083, accuracy: 39.4 %\n",
      "Training round [16/200], qnn_train_step: [500/500], loss: 1.7515851259231567, accuracy: 38.7 %\n",
      "Training round [16/200], qnn_train_step: [600/500], loss: 1.743720531463623, accuracy: 38.2 %\n",
      "Training round [16/200], qnn_train_step: [700/500], loss: 1.7481842041015625, accuracy: 39.4 %\n",
      "Training round [16/200], qnn_train_step: [800/500], loss: 1.7464889287948608, accuracy: 38.8 %\n",
      "Training round [16/200], qnn_train_step: [900/500], loss: 1.7282912731170654, accuracy: 39.7 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 1.8033, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 1.6159, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 1.7977, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 1.7391, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 1.5669, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 1.5764, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 1.7325, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 1.6931, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 1.7605, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 1.6543, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [17/200], qnn_train_step: [100/500], loss: 1.7010825872421265, accuracy: 39.7 %\n",
      "Training round [17/200], qnn_train_step: [200/500], loss: 1.7123159170150757, accuracy: 40.5 %\n",
      "Training round [17/200], qnn_train_step: [300/500], loss: 1.6759166717529297, accuracy: 40.0 %\n",
      "Training round [17/200], qnn_train_step: [400/500], loss: 1.6939775943756104, accuracy: 40.4 %\n",
      "Training round [17/200], qnn_train_step: [500/500], loss: 1.672978162765503, accuracy: 41.0 %\n",
      "Training round [17/200], qnn_train_step: [600/500], loss: 1.670553207397461, accuracy: 42.0 %\n",
      "Training round [17/200], qnn_train_step: [700/500], loss: 1.668319582939148, accuracy: 41.5 %\n",
      "Training round [17/200], qnn_train_step: [800/500], loss: 1.6678714752197266, accuracy: 40.6 %\n",
      "Training round [17/200], qnn_train_step: [900/500], loss: 1.6626362800598145, accuracy: 41.1 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 1.7028, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 1.6618, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 1.6885, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 1.6261, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 1.7215, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 1.7267, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 1.7299, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 1.6258, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 1.6612, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 1.5682, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [18/200], qnn_train_step: [100/500], loss: 1.7436896562576294, accuracy: 37.3 %\n",
      "Training round [18/200], qnn_train_step: [200/500], loss: 1.6982043981552124, accuracy: 39.8 %\n",
      "Training round [18/200], qnn_train_step: [300/500], loss: 1.7273614406585693, accuracy: 38.2 %\n",
      "Training round [18/200], qnn_train_step: [400/500], loss: 1.7338716983795166, accuracy: 38.0 %\n",
      "Training round [18/200], qnn_train_step: [500/500], loss: 1.69985032081604, accuracy: 39.7 %\n",
      "Training round [18/200], qnn_train_step: [600/500], loss: 1.7057932615280151, accuracy: 39.0 %\n",
      "Training round [18/200], qnn_train_step: [700/500], loss: 1.7029145956039429, accuracy: 40.2 %\n",
      "Training round [18/200], qnn_train_step: [800/500], loss: 1.69413161277771, accuracy: 41.1 %\n",
      "Training round [18/200], qnn_train_step: [900/500], loss: 1.692805528640747, accuracy: 39.0 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 1.6146, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 1.6796, batch time: 0.03, accuracy:  32.03%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 1.6697, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 1.6848, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 1.7997, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 1.7094, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 1.7611, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 1.8124, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 1.6442, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 1.6450, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [19/200], qnn_train_step: [100/500], loss: 1.7107634544372559, accuracy: 39.5 %\n",
      "Training round [19/200], qnn_train_step: [200/500], loss: 1.7420778274536133, accuracy: 37.4 %\n",
      "Training round [19/200], qnn_train_step: [300/500], loss: 1.7222282886505127, accuracy: 37.5 %\n",
      "Training round [19/200], qnn_train_step: [400/500], loss: 1.724112868309021, accuracy: 38.8 %\n",
      "Training round [19/200], qnn_train_step: [500/500], loss: 1.7168192863464355, accuracy: 38.3 %\n",
      "Training round [19/200], qnn_train_step: [600/500], loss: 1.7040189504623413, accuracy: 38.6 %\n",
      "Training round [19/200], qnn_train_step: [700/500], loss: 1.7069107294082642, accuracy: 38.8 %\n",
      "Training round [19/200], qnn_train_step: [800/500], loss: 1.7092140913009644, accuracy: 37.8 %\n",
      "Training round [19/200], qnn_train_step: [900/500], loss: 1.7010129690170288, accuracy: 38.3 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 1.6438, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 1.7521, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 1.6847, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 1.6772, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 1.6448, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 1.6188, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 1.5767, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 1.5797, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 1.6352, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 1.6280, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [20/200], qnn_train_step: [100/500], loss: 1.6667823791503906, accuracy: 39.2 %\n",
      "Training round [20/200], qnn_train_step: [200/500], loss: 1.7248669862747192, accuracy: 36.1 %\n",
      "Training round [20/200], qnn_train_step: [300/500], loss: 1.6855120658874512, accuracy: 38.3 %\n",
      "Training round [20/200], qnn_train_step: [400/500], loss: 1.6709210872650146, accuracy: 40.6 %\n",
      "Training round [20/200], qnn_train_step: [500/500], loss: 1.672804355621338, accuracy: 39.6 %\n",
      "Training round [20/200], qnn_train_step: [600/500], loss: 1.6669034957885742, accuracy: 39.6 %\n",
      "Training round [20/200], qnn_train_step: [700/500], loss: 1.6627871990203857, accuracy: 39.6 %\n",
      "Training round [20/200], qnn_train_step: [800/500], loss: 1.6626673936843872, accuracy: 38.6 %\n",
      "Training round [20/200], qnn_train_step: [900/500], loss: 1.6603662967681885, accuracy: 39.3 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 1.7916, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 1.5153, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 1.6486, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 1.6322, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 1.7519, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 1.7558, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 1.6580, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 1.7758, batch time: 0.03, accuracy:  32.03%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 1.5628, batch time: 0.06, accuracy:  42.19%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 1.5817, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [21/200], qnn_train_step: [100/500], loss: 1.6360623836517334, accuracy: 39.5 %\n",
      "Training round [21/200], qnn_train_step: [200/500], loss: 1.6887749433517456, accuracy: 36.9 %\n",
      "Training round [21/200], qnn_train_step: [300/500], loss: 1.6491215229034424, accuracy: 39.6 %\n",
      "Training round [21/200], qnn_train_step: [400/500], loss: 1.6388843059539795, accuracy: 39.4 %\n",
      "Training round [21/200], qnn_train_step: [500/500], loss: 1.6437246799468994, accuracy: 39.6 %\n",
      "Training round [21/200], qnn_train_step: [600/500], loss: 1.6308252811431885, accuracy: 40.8 %\n",
      "Training round [21/200], qnn_train_step: [700/500], loss: 1.6284621953964233, accuracy: 39.1 %\n",
      "Training round [21/200], qnn_train_step: [800/500], loss: 1.6272684335708618, accuracy: 39.3 %\n",
      "Training round [21/200], qnn_train_step: [900/500], loss: 1.628392219543457, accuracy: 39.3 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 1.6583, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 1.5992, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 1.6915, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 1.7426, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 1.6107, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 1.6528, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 1.6513, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 1.7218, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 1.6426, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 1.6380, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [22/200], qnn_train_step: [100/500], loss: 1.6985199451446533, accuracy: 36.7 %\n",
      "Training round [22/200], qnn_train_step: [200/500], loss: 1.7715785503387451, accuracy: 36.3 %\n",
      "Training round [22/200], qnn_train_step: [300/500], loss: 1.7237356901168823, accuracy: 37.4 %\n",
      "Training round [22/200], qnn_train_step: [400/500], loss: 1.7270761728286743, accuracy: 38.3 %\n",
      "Training round [22/200], qnn_train_step: [500/500], loss: 1.699506402015686, accuracy: 36.4 %\n",
      "Training round [22/200], qnn_train_step: [600/500], loss: 1.702805757522583, accuracy: 35.7 %\n",
      "Training round [22/200], qnn_train_step: [700/500], loss: 1.7003496885299683, accuracy: 37.5 %\n",
      "Training round [22/200], qnn_train_step: [800/500], loss: 1.6944689750671387, accuracy: 37.4 %\n",
      "Training round [22/200], qnn_train_step: [900/500], loss: 1.6952606439590454, accuracy: 35.7 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 1.5957, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 1.5525, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 1.5608, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 1.6935, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 1.6572, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 1.6512, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 1.5931, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 1.7472, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 1.6741, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 1.6484, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [23/200], qnn_train_step: [100/500], loss: 1.7089687585830688, accuracy: 37.7 %\n",
      "Training round [23/200], qnn_train_step: [200/500], loss: 2.0528528690338135, accuracy: 29.5 %\n",
      "Training round [23/200], qnn_train_step: [300/500], loss: 1.7263200283050537, accuracy: 36.4 %\n",
      "Training round [23/200], qnn_train_step: [400/500], loss: 1.731953740119934, accuracy: 36.4 %\n",
      "Training round [23/200], qnn_train_step: [500/500], loss: 1.696508765220642, accuracy: 37.9 %\n",
      "Training round [23/200], qnn_train_step: [600/500], loss: 1.6945130825042725, accuracy: 39.4 %\n",
      "Training round [23/200], qnn_train_step: [700/500], loss: 1.6871442794799805, accuracy: 40.0 %\n",
      "Training round [23/200], qnn_train_step: [800/500], loss: 1.686227798461914, accuracy: 39.6 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 1.7453, batch time: 0.03, accuracy:  29.69%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 1.6217, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 1.5699, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 1.6835, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 1.5883, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 1.6313, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 1.6616, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 1.8066, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 1.5849, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 1.5848, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [24/200], qnn_train_step: [100/500], loss: 1.7200504541397095, accuracy: 39.4 %\n",
      "Training round [24/200], qnn_train_step: [200/500], loss: 2.0616304874420166, accuracy: 32.4 %\n",
      "Training round [24/200], qnn_train_step: [300/500], loss: 1.756098747253418, accuracy: 37.1 %\n",
      "Training round [24/200], qnn_train_step: [400/500], loss: 1.7354263067245483, accuracy: 38.4 %\n",
      "Training round [24/200], qnn_train_step: [500/500], loss: 1.7266840934753418, accuracy: 40.5 %\n",
      "Training round [24/200], qnn_train_step: [600/500], loss: 1.7297358512878418, accuracy: 38.0 %\n",
      "Training round [24/200], qnn_train_step: [700/500], loss: 1.7203583717346191, accuracy: 40.5 %\n",
      "Training round [24/200], qnn_train_step: [800/500], loss: 1.7108790874481201, accuracy: 40.5 %\n",
      "Training round [24/200], qnn_train_step: [900/500], loss: 1.7099062204360962, accuracy: 38.8 %\n",
      "Training round [24/200], qnn_train_step: [1000/500], loss: 1.7046971321105957, accuracy: 40.2 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 1.7474, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 1.7769, batch time: 0.03, accuracy:  32.03%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 1.5259, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 1.6213, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 1.4902, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 1.7594, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 1.6042, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 1.7527, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 1.6374, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 1.7789, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [25/200], qnn_train_step: [100/500], loss: 1.6906992197036743, accuracy: 38.5 %\n",
      "Training round [25/200], qnn_train_step: [200/500], loss: 2.1495935916900635, accuracy: 32.1 %\n",
      "Training round [25/200], qnn_train_step: [300/500], loss: 1.8110108375549316, accuracy: 38.3 %\n",
      "Training round [25/200], qnn_train_step: [400/500], loss: 1.6973097324371338, accuracy: 39.7 %\n",
      "Training round [25/200], qnn_train_step: [500/500], loss: 1.6744554042816162, accuracy: 39.1 %\n",
      "Training round [25/200], qnn_train_step: [600/500], loss: 1.6533371210098267, accuracy: 39.5 %\n",
      "Training round [25/200], qnn_train_step: [700/500], loss: 1.6417540311813354, accuracy: 39.2 %\n",
      "Training round [25/200], qnn_train_step: [800/500], loss: 1.644946575164795, accuracy: 38.6 %\n",
      "Training round [25/200], qnn_train_step: [900/500], loss: 1.6387923955917358, accuracy: 39.2 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 1.6167, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 1.6283, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 1.5951, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 1.6858, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 1.6779, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 1.6235, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 1.6815, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 1.5891, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 1.6601, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 1.6506, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [26/200], qnn_train_step: [100/500], loss: 1.6384614706039429, accuracy: 40.8 %\n",
      "Training round [26/200], qnn_train_step: [200/500], loss: 1.7000349760055542, accuracy: 40.6 %\n",
      "Training round [26/200], qnn_train_step: [300/500], loss: 1.689032793045044, accuracy: 39.7 %\n",
      "Training round [26/200], qnn_train_step: [400/500], loss: 1.6466782093048096, accuracy: 41.6 %\n",
      "Training round [26/200], qnn_train_step: [500/500], loss: 1.637561559677124, accuracy: 41.2 %\n",
      "Training round [26/200], qnn_train_step: [600/500], loss: 1.6329920291900635, accuracy: 42.2 %\n",
      "Training round [26/200], qnn_train_step: [700/500], loss: 1.637070655822754, accuracy: 40.9 %\n",
      "Training round [26/200], qnn_train_step: [800/500], loss: 1.6327265501022339, accuracy: 42.3 %\n",
      "Training round [26/200], qnn_train_step: [900/500], loss: 1.6254668235778809, accuracy: 41.7 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 1.8689, batch time: 0.03, accuracy:  29.69%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 1.6189, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 1.6707, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 1.7006, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 1.7697, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 1.6605, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 1.7211, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 1.6799, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 1.6105, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 1.7789, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [27/200], qnn_train_step: [100/500], loss: 1.6729124784469604, accuracy: 38.9 %\n",
      "Training round [27/200], qnn_train_step: [200/500], loss: 1.7056936025619507, accuracy: 37.5 %\n",
      "Training round [27/200], qnn_train_step: [300/500], loss: 1.7127512693405151, accuracy: 37.3 %\n",
      "Training round [27/200], qnn_train_step: [400/500], loss: 1.7029422521591187, accuracy: 36.8 %\n",
      "Training round [27/200], qnn_train_step: [500/500], loss: 1.6866902112960815, accuracy: 37.7 %\n",
      "Training round [27/200], qnn_train_step: [600/500], loss: 1.706573486328125, accuracy: 38.2 %\n",
      "Training round [27/200], qnn_train_step: [700/500], loss: 1.6765474081039429, accuracy: 38.5 %\n",
      "Training round [27/200], qnn_train_step: [800/500], loss: 1.6690402030944824, accuracy: 39.0 %\n",
      "Training round [27/200], qnn_train_step: [900/500], loss: 1.6683512926101685, accuracy: 38.0 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 1.6101, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 1.6735, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 1.6171, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 1.6664, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 1.7463, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 1.6577, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 1.5782, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 1.5410, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 1.7403, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 1.8011, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [28/200], qnn_train_step: [100/500], loss: 1.6626505851745605, accuracy: 41.4 %\n",
      "Training round [28/200], qnn_train_step: [200/500], loss: 1.7128039598464966, accuracy: 39.1 %\n",
      "Training round [28/200], qnn_train_step: [300/500], loss: 1.67964506149292, accuracy: 41.0 %\n",
      "Training round [28/200], qnn_train_step: [400/500], loss: 1.6655396223068237, accuracy: 41.3 %\n",
      "Training round [28/200], qnn_train_step: [500/500], loss: 1.6822090148925781, accuracy: 40.6 %\n",
      "Training round [28/200], qnn_train_step: [600/500], loss: 1.6570945978164673, accuracy: 41.9 %\n",
      "Training round [28/200], qnn_train_step: [700/500], loss: 1.6536319255828857, accuracy: 41.4 %\n",
      "Training round [28/200], qnn_train_step: [800/500], loss: 1.6638123989105225, accuracy: 41.9 %\n",
      "Training round [28/200], qnn_train_step: [900/500], loss: 1.652087688446045, accuracy: 40.9 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 1.5909, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 1.6854, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 1.6355, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 1.4969, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 1.6550, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 1.8044, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 1.6707, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 1.4365, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 1.8325, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 1.6513, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [29/200], qnn_train_step: [100/500], loss: 1.6723490953445435, accuracy: 37.4 %\n",
      "Training round [29/200], qnn_train_step: [200/500], loss: 1.9220954179763794, accuracy: 33.7 %\n",
      "Training round [29/200], qnn_train_step: [300/500], loss: 1.752285122871399, accuracy: 34.8 %\n",
      "Training round [29/200], qnn_train_step: [400/500], loss: 1.7302342653274536, accuracy: 38.3 %\n",
      "Training round [29/200], qnn_train_step: [500/500], loss: 1.6780662536621094, accuracy: 38.8 %\n",
      "Training round [29/200], qnn_train_step: [600/500], loss: 1.663522720336914, accuracy: 38.2 %\n",
      "Training round [29/200], qnn_train_step: [700/500], loss: 1.6655622720718384, accuracy: 39.1 %\n",
      "Training round [29/200], qnn_train_step: [800/500], loss: 1.6636931896209717, accuracy: 38.7 %\n",
      "Training round [29/200], qnn_train_step: [900/500], loss: 1.6581059694290161, accuracy: 37.5 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 1.6595, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 1.5484, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 1.7177, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 1.6421, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 1.6470, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 1.6687, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 1.8340, batch time: 0.03, accuracy:  32.03%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 1.6013, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 1.5790, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 1.6252, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [30/200], qnn_train_step: [100/500], loss: 1.6437172889709473, accuracy: 40.7 %\n",
      "Training round [30/200], qnn_train_step: [200/500], loss: 1.7177700996398926, accuracy: 38.6 %\n",
      "Training round [30/200], qnn_train_step: [300/500], loss: 1.7021781206130981, accuracy: 39.5 %\n",
      "Training round [30/200], qnn_train_step: [400/500], loss: 1.6537301540374756, accuracy: 41.8 %\n",
      "Training round [30/200], qnn_train_step: [500/500], loss: 1.659486174583435, accuracy: 39.3 %\n",
      "Training round [30/200], qnn_train_step: [600/500], loss: 1.6422284841537476, accuracy: 40.7 %\n",
      "Training round [30/200], qnn_train_step: [700/500], loss: 1.6389857530593872, accuracy: 42.8 %\n",
      "Training round [30/200], qnn_train_step: [800/500], loss: 1.6433981657028198, accuracy: 41.4 %\n",
      "Training round [30/200], qnn_train_step: [900/500], loss: 1.6432976722717285, accuracy: 41.3 %\n",
      "Training round [30/200], qnn_train_step: [1000/500], loss: 1.638207197189331, accuracy: 41.7 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 1.4809, batch time: 0.16, accuracy:  44.53%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 1.6616, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 1.6553, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 1.6839, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 1.5624, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 1.5599, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 1.6478, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 1.5900, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 1.6429, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 1.7569, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [31/200], qnn_train_step: [100/500], loss: 1.7150993347167969, accuracy: 37.7 %\n",
      "Training round [31/200], qnn_train_step: [200/500], loss: 1.7795814275741577, accuracy: 35.1 %\n",
      "Training round [31/200], qnn_train_step: [300/500], loss: 1.749746561050415, accuracy: 39.0 %\n",
      "Training round [31/200], qnn_train_step: [400/500], loss: 1.7567356824874878, accuracy: 35.2 %\n",
      "Training round [31/200], qnn_train_step: [500/500], loss: 1.7808424234390259, accuracy: 35.6 %\n",
      "Training round [31/200], qnn_train_step: [600/500], loss: 1.741054654121399, accuracy: 36.2 %\n",
      "Training round [31/200], qnn_train_step: [700/500], loss: 1.7281663417816162, accuracy: 37.7 %\n",
      "Training round [31/200], qnn_train_step: [800/500], loss: 1.7216840982437134, accuracy: 37.5 %\n",
      "Training round [31/200], qnn_train_step: [900/500], loss: 1.7201793193817139, accuracy: 39.3 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 1.6371, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 1.5668, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 1.5918, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 1.9197, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 1.5748, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 1.6106, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 1.7531, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 1.6509, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 1.6008, batch time: 0.06, accuracy:  43.75%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 1.7506, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [32/200], qnn_train_step: [100/500], loss: 1.667754888534546, accuracy: 41.0 %\n",
      "Training round [32/200], qnn_train_step: [200/500], loss: 1.7138091325759888, accuracy: 40.2 %\n",
      "Training round [32/200], qnn_train_step: [300/500], loss: 1.6900371313095093, accuracy: 38.4 %\n",
      "Training round [32/200], qnn_train_step: [400/500], loss: 1.646390438079834, accuracy: 41.2 %\n",
      "Training round [32/200], qnn_train_step: [500/500], loss: 1.6398186683654785, accuracy: 42.0 %\n",
      "Training round [32/200], qnn_train_step: [600/500], loss: 1.6466706991195679, accuracy: 41.9 %\n",
      "Training round [32/200], qnn_train_step: [700/500], loss: 1.641875147819519, accuracy: 42.0 %\n",
      "Training round [32/200], qnn_train_step: [800/500], loss: 1.6333303451538086, accuracy: 42.0 %\n",
      "Training round [32/200], qnn_train_step: [900/500], loss: 1.631654977798462, accuracy: 42.6 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 1.6650, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 1.7134, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 1.6696, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 1.5597, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 1.5823, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 1.6528, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 1.6119, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 1.6456, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 1.6239, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 1.5633, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [33/200], qnn_train_step: [100/500], loss: 1.6469687223434448, accuracy: 40.0 %\n",
      "Training round [33/200], qnn_train_step: [200/500], loss: 1.6260275840759277, accuracy: 41.5 %\n",
      "Training round [33/200], qnn_train_step: [300/500], loss: 1.6025481224060059, accuracy: 42.5 %\n",
      "Training round [33/200], qnn_train_step: [400/500], loss: 1.6567093133926392, accuracy: 40.8 %\n",
      "Training round [33/200], qnn_train_step: [500/500], loss: 1.6215733289718628, accuracy: 40.9 %\n",
      "Training round [33/200], qnn_train_step: [600/500], loss: 1.6158124208450317, accuracy: 41.9 %\n",
      "Training round [33/200], qnn_train_step: [700/500], loss: 1.6233593225479126, accuracy: 40.8 %\n",
      "Training round [33/200], qnn_train_step: [800/500], loss: 1.6155009269714355, accuracy: 42.5 %\n",
      "Training round [33/200], qnn_train_step: [900/500], loss: 1.6049599647521973, accuracy: 42.0 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 1.5846, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 1.7247, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 1.7312, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 1.6294, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 1.6783, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 1.6095, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 1.6628, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 1.7942, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 1.6210, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 1.7000, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [34/200], qnn_train_step: [100/500], loss: 1.6048752069473267, accuracy: 43.2 %\n",
      "Training round [34/200], qnn_train_step: [200/500], loss: 1.8368085622787476, accuracy: 36.8 %\n",
      "Training round [34/200], qnn_train_step: [300/500], loss: 1.58930504322052, accuracy: 43.7 %\n",
      "Training round [34/200], qnn_train_step: [400/500], loss: 1.6050128936767578, accuracy: 41.9 %\n",
      "Training round [34/200], qnn_train_step: [500/500], loss: 1.6055865287780762, accuracy: 42.1 %\n",
      "Training round [34/200], qnn_train_step: [600/500], loss: 1.60476553440094, accuracy: 41.9 %\n",
      "Training round [34/200], qnn_train_step: [700/500], loss: 1.6013251543045044, accuracy: 43.7 %\n",
      "Training round [34/200], qnn_train_step: [800/500], loss: 1.5894558429718018, accuracy: 43.1 %\n",
      "Training round [34/200], qnn_train_step: [900/500], loss: 1.5860687494277954, accuracy: 43.1 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 1.7229, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 1.6595, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 1.6647, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 1.6635, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 1.7254, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 1.5326, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 1.5499, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 1.5684, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 1.7805, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 1.6556, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [35/200], qnn_train_step: [100/500], loss: 1.6652077436447144, accuracy: 40.9 %\n",
      "Training round [35/200], qnn_train_step: [200/500], loss: 1.7408891916275024, accuracy: 39.9 %\n",
      "Training round [35/200], qnn_train_step: [300/500], loss: 1.6787165403366089, accuracy: 42.1 %\n",
      "Training round [35/200], qnn_train_step: [400/500], loss: 1.7074474096298218, accuracy: 41.0 %\n",
      "Training round [35/200], qnn_train_step: [500/500], loss: 1.6566189527511597, accuracy: 41.9 %\n",
      "Training round [35/200], qnn_train_step: [600/500], loss: 1.6522998809814453, accuracy: 42.2 %\n",
      "Training round [35/200], qnn_train_step: [700/500], loss: 1.6555187702178955, accuracy: 43.6 %\n",
      "Training round [35/200], qnn_train_step: [800/500], loss: 1.6480774879455566, accuracy: 43.5 %\n",
      "Training round [35/200], qnn_train_step: [900/500], loss: 1.6455347537994385, accuracy: 44.4 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 1.6413, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 1.6765, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 1.5926, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 1.5884, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 1.7006, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 1.7056, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 1.6540, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 1.5502, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 1.7403, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 1.5146, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [36/200], qnn_train_step: [100/500], loss: 1.6962018013000488, accuracy: 41.2 %\n",
      "Training round [36/200], qnn_train_step: [200/500], loss: 1.779559850692749, accuracy: 38.1 %\n",
      "Training round [36/200], qnn_train_step: [300/500], loss: 1.7089167833328247, accuracy: 39.5 %\n",
      "Training round [36/200], qnn_train_step: [400/500], loss: 1.6969318389892578, accuracy: 40.5 %\n",
      "Training round [36/200], qnn_train_step: [500/500], loss: 1.6974941492080688, accuracy: 39.3 %\n",
      "Training round [36/200], qnn_train_step: [600/500], loss: 1.696439504623413, accuracy: 41.0 %\n",
      "Training round [36/200], qnn_train_step: [700/500], loss: 1.6777483224868774, accuracy: 41.5 %\n",
      "Training round [36/200], qnn_train_step: [800/500], loss: 1.6710615158081055, accuracy: 42.0 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 1.6596, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 1.6692, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 1.6857, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 1.6284, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 1.6857, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 1.5708, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 1.6156, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 1.6813, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 1.6143, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 1.7417, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [37/200], qnn_train_step: [100/500], loss: 1.6546870470046997, accuracy: 42.1 %\n",
      "Training round [37/200], qnn_train_step: [200/500], loss: 1.7230619192123413, accuracy: 40.9 %\n",
      "Training round [37/200], qnn_train_step: [300/500], loss: 1.6830099821090698, accuracy: 41.5 %\n",
      "Training round [37/200], qnn_train_step: [400/500], loss: 1.669315218925476, accuracy: 41.3 %\n",
      "Training round [37/200], qnn_train_step: [500/500], loss: 1.6570862531661987, accuracy: 41.9 %\n",
      "Training round [37/200], qnn_train_step: [600/500], loss: 1.657688021659851, accuracy: 40.7 %\n",
      "Training round [37/200], qnn_train_step: [700/500], loss: 1.648987054824829, accuracy: 41.1 %\n",
      "Training round [37/200], qnn_train_step: [800/500], loss: 1.6530965566635132, accuracy: 41.7 %\n",
      "Training round [37/200], qnn_train_step: [900/500], loss: 1.6397755146026611, accuracy: 42.3 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 1.6289, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 1.6172, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 1.6271, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 1.7241, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 1.7812, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 1.7363, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 1.8778, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 1.5049, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 1.6792, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 1.7386, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [38/200], qnn_train_step: [100/500], loss: 1.669516921043396, accuracy: 42.3 %\n",
      "Training round [38/200], qnn_train_step: [200/500], loss: 1.7641470432281494, accuracy: 38.5 %\n",
      "Training round [38/200], qnn_train_step: [300/500], loss: 1.7519984245300293, accuracy: 39.3 %\n",
      "Training round [38/200], qnn_train_step: [400/500], loss: 1.7029619216918945, accuracy: 41.7 %\n",
      "Training round [38/200], qnn_train_step: [500/500], loss: 1.668411374092102, accuracy: 41.5 %\n",
      "Training round [38/200], qnn_train_step: [600/500], loss: 1.6824312210083008, accuracy: 41.1 %\n",
      "Training round [38/200], qnn_train_step: [700/500], loss: 1.6653493642807007, accuracy: 42.2 %\n",
      "Training round [38/200], qnn_train_step: [800/500], loss: 1.6648499965667725, accuracy: 42.6 %\n",
      "Training round [38/200], qnn_train_step: [900/500], loss: 1.656753420829773, accuracy: 42.9 %\n",
      "Training round [38/200], qnn_train_step: [1000/500], loss: 1.6561555862426758, accuracy: 43.0 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 1.7527, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 1.7357, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 1.5385, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 1.5313, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 1.6254, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 1.5629, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 1.5994, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 1.6957, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 1.5488, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 1.7435, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [39/200], qnn_train_step: [100/500], loss: 1.5921725034713745, accuracy: 44.0 %\n",
      "Training round [39/200], qnn_train_step: [200/500], loss: 1.6227513551712036, accuracy: 43.8 %\n",
      "Training round [39/200], qnn_train_step: [300/500], loss: 1.6175543069839478, accuracy: 44.3 %\n",
      "Training round [39/200], qnn_train_step: [400/500], loss: 1.7054909467697144, accuracy: 35.6 %\n",
      "Training round [39/200], qnn_train_step: [500/500], loss: 1.59065580368042, accuracy: 45.6 %\n",
      "Training round [39/200], qnn_train_step: [600/500], loss: 1.5954372882843018, accuracy: 45.0 %\n",
      "Training round [39/200], qnn_train_step: [700/500], loss: 1.5811012983322144, accuracy: 45.9 %\n",
      "Training round [39/200], qnn_train_step: [800/500], loss: 1.5842519998550415, accuracy: 45.2 %\n",
      "Training round [39/200], qnn_train_step: [900/500], loss: 1.5769490003585815, accuracy: 46.3 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 1.8325, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 1.6361, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 1.7354, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 1.6319, batch time: 0.06, accuracy:  42.97%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 1.7484, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 1.5977, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 1.6577, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 1.5903, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 1.6981, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 1.6002, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [40/200], qnn_train_step: [100/500], loss: 1.625797152519226, accuracy: 44.9 %\n",
      "Training round [40/200], qnn_train_step: [200/500], loss: 1.6953954696655273, accuracy: 40.9 %\n",
      "Training round [40/200], qnn_train_step: [300/500], loss: 1.63699209690094, accuracy: 44.3 %\n",
      "Training round [40/200], qnn_train_step: [400/500], loss: 1.6339174509048462, accuracy: 45.7 %\n",
      "Training round [40/200], qnn_train_step: [500/500], loss: 1.6288161277770996, accuracy: 46.1 %\n",
      "Training round [40/200], qnn_train_step: [600/500], loss: 1.606071949005127, accuracy: 44.6 %\n",
      "Training round [40/200], qnn_train_step: [700/500], loss: 1.6097570657730103, accuracy: 43.6 %\n",
      "Training round [40/200], qnn_train_step: [800/500], loss: 1.6071299314498901, accuracy: 46.4 %\n",
      "Training round [40/200], qnn_train_step: [900/500], loss: 1.5990504026412964, accuracy: 46.2 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 1.5331, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 1.6066, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 1.5133, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 1.6641, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 1.4636, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 1.7952, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 1.5457, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 1.6890, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 1.5517, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 1.5503, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [41/200], qnn_train_step: [100/500], loss: 1.7352710962295532, accuracy: 41.7 %\n",
      "Training round [41/200], qnn_train_step: [200/500], loss: 1.9889204502105713, accuracy: 34.3 %\n",
      "Training round [41/200], qnn_train_step: [300/500], loss: 1.670746922492981, accuracy: 43.7 %\n",
      "Training round [41/200], qnn_train_step: [400/500], loss: 1.7055875062942505, accuracy: 42.6 %\n",
      "Training round [41/200], qnn_train_step: [500/500], loss: 1.7034608125686646, accuracy: 40.4 %\n",
      "Training round [41/200], qnn_train_step: [600/500], loss: 1.6852480173110962, accuracy: 43.0 %\n",
      "Training round [41/200], qnn_train_step: [700/500], loss: 1.692995548248291, accuracy: 39.8 %\n",
      "Training round [41/200], qnn_train_step: [800/500], loss: 1.6954960823059082, accuracy: 40.0 %\n",
      "Training round [41/200], qnn_train_step: [900/500], loss: 1.667928695678711, accuracy: 42.4 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 1.6701, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 1.6841, batch time: 0.06, accuracy:  40.62%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 1.6564, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 1.5783, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 1.7316, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 1.5821, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 1.7463, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 1.6909, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 1.6518, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 1.6366, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [42/200], qnn_train_step: [100/500], loss: 1.6243033409118652, accuracy: 45.2 %\n",
      "Training round [42/200], qnn_train_step: [200/500], loss: 1.7884780168533325, accuracy: 38.3 %\n",
      "Training round [42/200], qnn_train_step: [300/500], loss: 1.6870744228363037, accuracy: 41.6 %\n",
      "Training round [42/200], qnn_train_step: [400/500], loss: 1.6403393745422363, accuracy: 43.9 %\n",
      "Training round [42/200], qnn_train_step: [500/500], loss: 1.6161220073699951, accuracy: 44.7 %\n",
      "Training round [42/200], qnn_train_step: [600/500], loss: 1.6300921440124512, accuracy: 42.8 %\n",
      "Training round [42/200], qnn_train_step: [700/500], loss: 1.6172634363174438, accuracy: 44.9 %\n",
      "Training round [42/200], qnn_train_step: [800/500], loss: 1.610591173171997, accuracy: 44.8 %\n",
      "Training round [42/200], qnn_train_step: [900/500], loss: 1.6052582263946533, accuracy: 44.8 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 1.6063, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 1.6064, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 1.7584, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 1.6814, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 1.6667, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 1.4924, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 1.7888, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 1.4864, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 1.6626, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 1.6519, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [43/200], qnn_train_step: [100/500], loss: 1.621185064315796, accuracy: 43.1 %\n",
      "Training round [43/200], qnn_train_step: [200/500], loss: 4.1838178634643555, accuracy: 20.2 %\n",
      "Training round [43/200], qnn_train_step: [300/500], loss: 1.6988145112991333, accuracy: 41.3 %\n",
      "Training round [43/200], qnn_train_step: [400/500], loss: 1.648145318031311, accuracy: 41.3 %\n",
      "Training round [43/200], qnn_train_step: [500/500], loss: 1.6204354763031006, accuracy: 43.1 %\n",
      "Training round [43/200], qnn_train_step: [600/500], loss: 1.6159961223602295, accuracy: 44.0 %\n",
      "Training round [43/200], qnn_train_step: [700/500], loss: 1.6117390394210815, accuracy: 43.5 %\n",
      "Training round [43/200], qnn_train_step: [800/500], loss: 1.6073085069656372, accuracy: 43.4 %\n",
      "Training round [43/200], qnn_train_step: [900/500], loss: 1.6048413515090942, accuracy: 43.9 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 1.6652, batch time: 0.06, accuracy:  42.19%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 1.5287, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 1.5984, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 1.6330, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 1.6595, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 1.5263, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 1.4209, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 1.6269, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 1.5956, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 1.6568, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [44/200], qnn_train_step: [100/500], loss: 1.62106192111969, accuracy: 44.9 %\n",
      "Training round [44/200], qnn_train_step: [200/500], loss: 1.6927012205123901, accuracy: 41.4 %\n",
      "Training round [44/200], qnn_train_step: [300/500], loss: 1.6692612171173096, accuracy: 42.4 %\n",
      "Training round [44/200], qnn_train_step: [400/500], loss: 1.6287065744400024, accuracy: 45.5 %\n",
      "Training round [44/200], qnn_train_step: [500/500], loss: 1.6367921829223633, accuracy: 42.1 %\n",
      "Training round [44/200], qnn_train_step: [600/500], loss: 1.626193881034851, accuracy: 44.0 %\n",
      "Training round [44/200], qnn_train_step: [700/500], loss: 1.6256446838378906, accuracy: 43.9 %\n",
      "Training round [44/200], qnn_train_step: [800/500], loss: 1.6114095449447632, accuracy: 44.1 %\n",
      "Training round [44/200], qnn_train_step: [900/500], loss: 1.609179973602295, accuracy: 45.0 %\n",
      "Training round [44/200], qnn_train_step: [1000/500], loss: 1.6181782484054565, accuracy: 44.2 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 1.6311, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 1.7868, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 1.6314, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 1.5317, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 1.6287, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 1.7348, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 1.6118, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 1.6583, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 1.5624, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 1.6215, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [45/200], qnn_train_step: [100/500], loss: 1.7225252389907837, accuracy: 40.3 %\n",
      "Training round [45/200], qnn_train_step: [200/500], loss: 1.7604365348815918, accuracy: 40.0 %\n",
      "Training round [45/200], qnn_train_step: [300/500], loss: 1.6900614500045776, accuracy: 44.3 %\n",
      "Training round [45/200], qnn_train_step: [400/500], loss: 1.76893150806427, accuracy: 38.9 %\n",
      "Training round [45/200], qnn_train_step: [500/500], loss: 1.6672207117080688, accuracy: 43.5 %\n",
      "Training round [45/200], qnn_train_step: [600/500], loss: 1.6768598556518555, accuracy: 43.5 %\n",
      "Training round [45/200], qnn_train_step: [700/500], loss: 1.670771598815918, accuracy: 40.3 %\n",
      "Training round [45/200], qnn_train_step: [800/500], loss: 1.668144702911377, accuracy: 41.8 %\n",
      "Training round [45/200], qnn_train_step: [900/500], loss: 1.6593104600906372, accuracy: 42.5 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 1.6390, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 1.4274, batch time: 0.03, accuracy:  55.47%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 1.5609, batch time: 0.06, accuracy:  46.88%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 1.7010, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 1.6547, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 1.6793, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 1.5879, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 1.7498, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 1.6148, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 1.7920, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [46/200], qnn_train_step: [100/500], loss: 1.6044807434082031, accuracy: 44.6 %\n",
      "Training round [46/200], qnn_train_step: [200/500], loss: 1.670308232307434, accuracy: 43.0 %\n",
      "Training round [46/200], qnn_train_step: [300/500], loss: 1.6289242506027222, accuracy: 40.7 %\n",
      "Training round [46/200], qnn_train_step: [400/500], loss: 1.6034290790557861, accuracy: 45.0 %\n",
      "Training round [46/200], qnn_train_step: [500/500], loss: 1.5742974281311035, accuracy: 44.9 %\n",
      "Training round [46/200], qnn_train_step: [600/500], loss: 1.5845776796340942, accuracy: 45.7 %\n",
      "Training round [46/200], qnn_train_step: [700/500], loss: 1.580872654914856, accuracy: 43.6 %\n",
      "Training round [46/200], qnn_train_step: [800/500], loss: 1.5719692707061768, accuracy: 45.6 %\n",
      "Training round [46/200], qnn_train_step: [900/500], loss: 1.5675480365753174, accuracy: 44.4 %\n",
      "Training round [46/200], qnn_train_step: [1000/500], loss: 1.5651694536209106, accuracy: 45.5 %\n",
      "Training round [46/200], qnn_train_step: [1100/500], loss: 1.569618821144104, accuracy: 44.5 %\n",
      "Training round [46/200], qnn_train_step: [1200/500], loss: 1.5672338008880615, accuracy: 47.1 %\n",
      "Training round [46/200], qnn_train_step: [1300/500], loss: 1.5648465156555176, accuracy: 46.2 %\n",
      "Training round [46/200], qnn_train_step: [1400/500], loss: 1.5692857503890991, accuracy: 45.5 %\n",
      "Training round [46/200], qnn_train_step: [1500/500], loss: 1.5670369863510132, accuracy: 47.1 %\n",
      "Training round [46/200], qnn_train_step: [1600/500], loss: 1.5647671222686768, accuracy: 45.6 %\n",
      "Training round [46/200], qnn_train_step: [1700/500], loss: 1.5690957307815552, accuracy: 45.6 %\n",
      "Training round [46/200], qnn_train_step: [1800/500], loss: 1.5667754411697388, accuracy: 45.6 %\n",
      "Training round [46/200], qnn_train_step: [1900/500], loss: 1.5646063089370728, accuracy: 45.6 %\n",
      "Training round [46/200], qnn_train_step: [2000/500], loss: 1.5686980485916138, accuracy: 45.8 %\n",
      "Training round [46/200], qnn_train_step: [2100/500], loss: 1.566591739654541, accuracy: 44.4 %\n",
      "Training round [46/200], qnn_train_step: [2200/500], loss: 1.5643306970596313, accuracy: 45.5 %\n",
      "Training round [46/200], qnn_train_step: [2300/500], loss: 1.568559169769287, accuracy: 44.8 %\n",
      "Training round [46/200], qnn_train_step: [2400/500], loss: 1.5662791728973389, accuracy: 44.5 %\n",
      "Training round [46/200], qnn_train_step: [2500/500], loss: 1.564127802848816, accuracy: 45.5 %\n",
      "Training round [46/200], qnn_train_step: [2600/500], loss: 1.5681954622268677, accuracy: 44.9 %\n",
      "Training round [46/200], qnn_train_step: [2700/500], loss: 1.5661052465438843, accuracy: 44.5 %\n",
      "Training round [46/200], qnn_train_step: [2800/500], loss: 1.563978672027588, accuracy: 45.4 %\n",
      "Training round [46/200], qnn_train_step: [2900/500], loss: 1.5680088996887207, accuracy: 45.3 %\n",
      "Training round [46/200], qnn_train_step: [3000/500], loss: 1.5659422874450684, accuracy: 46.8 %\n",
      "Training round [46/200], qnn_train_step: [3100/500], loss: 1.5639195442199707, accuracy: 46.5 %\n",
      "Training round [46/200], qnn_train_step: [3200/500], loss: 1.567773461341858, accuracy: 44.7 %\n",
      "Training round [46/200], qnn_train_step: [3300/500], loss: 1.5658859014511108, accuracy: 45.6 %\n",
      "Training round [46/200], qnn_train_step: [3400/500], loss: 1.5637967586517334, accuracy: 46.2 %\n",
      "Training round [46/200], qnn_train_step: [3500/500], loss: 1.567533254623413, accuracy: 45.6 %\n",
      "Training round [46/200], qnn_train_step: [3600/500], loss: 1.5655438899993896, accuracy: 45.7 %\n",
      "Training round [46/200], qnn_train_step: [3700/500], loss: 1.563586950302124, accuracy: 46.1 %\n",
      "Training round [46/200], qnn_train_step: [3800/500], loss: 1.5675102472305298, accuracy: 45.3 %\n",
      "Training round [46/200], qnn_train_step: [3900/500], loss: 1.5653895139694214, accuracy: 46.1 %\n",
      "Training round [46/200], qnn_train_step: [4000/500], loss: 1.563430905342102, accuracy: 45.2 %\n",
      "Training round [46/200], qnn_train_step: [4100/500], loss: 1.5672780275344849, accuracy: 44.9 %\n",
      "Training round [46/200], qnn_train_step: [4200/500], loss: 1.5651743412017822, accuracy: 47.0 %\n",
      "Training round [46/200], qnn_train_step: [4300/500], loss: 1.5634210109710693, accuracy: 45.8 %\n",
      "Training round [46/200], qnn_train_step: [4400/500], loss: 1.5672285556793213, accuracy: 44.2 %\n",
      "Training round [46/200], qnn_train_step: [4500/500], loss: 1.5650622844696045, accuracy: 46.0 %\n",
      "Training round [46/200], qnn_train_step: [4600/500], loss: 1.5633231401443481, accuracy: 45.0 %\n",
      "Training round [46/200], qnn_train_step: [4700/500], loss: 1.5669901371002197, accuracy: 45.0 %\n",
      "Training round [46/200], qnn_train_step: [4800/500], loss: 1.5648565292358398, accuracy: 46.0 %\n",
      "Training round [46/200], qnn_train_step: [4900/500], loss: 1.5631028413772583, accuracy: 45.7 %\n",
      "Training round [46/200], qnn_train_step: [5000/500], loss: 1.5669949054718018, accuracy: 46.8 %\n",
      "Training round [46/200], qnn_train_step: [5100/500], loss: 1.5646281242370605, accuracy: 45.7 %\n",
      "Training round [46/200], qnn_train_step: [5200/500], loss: 1.5629920959472656, accuracy: 45.3 %\n",
      "Training round [46/200], qnn_train_step: [5300/500], loss: 1.5717867612838745, accuracy: 46.7 %\n",
      "Training round [46/200], qnn_train_step: [5400/500], loss: 1.564573049545288, accuracy: 46.1 %\n",
      "Training round [46/200], qnn_train_step: [5500/500], loss: 1.5628821849822998, accuracy: 45.1 %\n",
      "Training round [46/200], qnn_train_step: [5600/500], loss: 1.573486566543579, accuracy: 46.1 %\n",
      "Training round [46/200], qnn_train_step: [5700/500], loss: 1.5644326210021973, accuracy: 45.1 %\n",
      "Training round [46/200], qnn_train_step: [5800/500], loss: 1.562713861465454, accuracy: 45.1 %\n",
      "Training round [46/200], qnn_train_step: [5900/500], loss: 1.5598669052124023, accuracy: 46.2 %\n",
      "Training round [46/200], qnn_train_step: [6000/500], loss: 1.5643153190612793, accuracy: 45.3 %\n",
      "Training round [46/200], qnn_train_step: [6100/500], loss: 1.5625547170639038, accuracy: 45.8 %\n",
      "Training round [46/200], qnn_train_step: [6200/500], loss: 1.5605175495147705, accuracy: 44.9 %\n",
      "Training round [46/200], qnn_train_step: [6300/500], loss: 1.5641711950302124, accuracy: 45.8 %\n",
      "Training round [46/200], qnn_train_step: [6400/500], loss: 1.5623970031738281, accuracy: 45.8 %\n",
      "Training round [46/200], qnn_train_step: [6500/500], loss: 1.5606340169906616, accuracy: 45.3 %\n",
      "Training round [46/200], qnn_train_step: [6600/500], loss: 1.5640946626663208, accuracy: 45.8 %\n",
      "Training round [46/200], qnn_train_step: [6700/500], loss: 1.5623058080673218, accuracy: 45.5 %\n",
      "Training round [46/200], qnn_train_step: [6800/500], loss: 1.5608609914779663, accuracy: 45.6 %\n",
      "Training round [46/200], qnn_train_step: [6900/500], loss: 1.5638939142227173, accuracy: 45.9 %\n",
      "Training round [46/200], qnn_train_step: [7000/500], loss: 1.5623247623443604, accuracy: 45.5 %\n",
      "Training round [46/200], qnn_train_step: [7100/500], loss: 1.5606756210327148, accuracy: 45.6 %\n",
      "Training round [46/200], qnn_train_step: [7200/500], loss: 1.5637338161468506, accuracy: 45.5 %\n",
      "Training round [46/200], qnn_train_step: [7300/500], loss: 1.5621962547302246, accuracy: 45.5 %\n",
      "Training round [46/200], qnn_train_step: [7400/500], loss: 1.5607255697250366, accuracy: 46.6 %\n",
      "Training round [46/200], qnn_train_step: [7500/500], loss: 1.5635535717010498, accuracy: 45.5 %\n",
      "Training round [46/200], qnn_train_step: [7600/500], loss: 1.562073826789856, accuracy: 45.4 %\n",
      "Training round [46/200], qnn_train_step: [7700/500], loss: 1.5606062412261963, accuracy: 45.4 %\n",
      "Training round [46/200], qnn_train_step: [7800/500], loss: 1.5633505582809448, accuracy: 45.6 %\n",
      "Training round [46/200], qnn_train_step: [7900/500], loss: 1.5620695352554321, accuracy: 46.3 %\n",
      "Training round [46/200], qnn_train_step: [8000/500], loss: 1.5604822635650635, accuracy: 44.9 %\n",
      "Training round [46/200], qnn_train_step: [8100/500], loss: 1.5631816387176514, accuracy: 45.6 %\n",
      "Training round [46/200], qnn_train_step: [8200/500], loss: 1.5620253086090088, accuracy: 45.6 %\n",
      "Training round [46/200], qnn_train_step: [8300/500], loss: 1.5604784488677979, accuracy: 44.7 %\n",
      "Training round [46/200], qnn_train_step: [8400/500], loss: 1.5631481409072876, accuracy: 45.1 %\n",
      "Training round [46/200], qnn_train_step: [8500/500], loss: 1.5618085861206055, accuracy: 46.0 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 1.5855, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 1.6855, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 1.5324, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 1.7467, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 1.5353, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 1.7854, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 1.4516, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 1.5216, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 1.5270, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 1.4640, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [47/200], qnn_train_step: [100/500], loss: 1.6457319259643555, accuracy: 42.8 %\n",
      "Training round [47/200], qnn_train_step: [200/500], loss: 1.717793583869934, accuracy: 40.1 %\n",
      "Training round [47/200], qnn_train_step: [300/500], loss: 1.641251802444458, accuracy: 42.9 %\n",
      "Training round [47/200], qnn_train_step: [400/500], loss: 1.6364575624465942, accuracy: 42.9 %\n",
      "Training round [47/200], qnn_train_step: [500/500], loss: 1.6883641481399536, accuracy: 41.1 %\n",
      "Training round [47/200], qnn_train_step: [600/500], loss: 1.7272170782089233, accuracy: 41.4 %\n",
      "Training round [47/200], qnn_train_step: [700/500], loss: 1.6337764263153076, accuracy: 42.8 %\n",
      "Training round [47/200], qnn_train_step: [800/500], loss: 1.6317789554595947, accuracy: 43.8 %\n",
      "Training round [47/200], qnn_train_step: [900/500], loss: 1.633389949798584, accuracy: 43.9 %\n",
      "Training round [47/200], qnn_train_step: [1000/500], loss: 1.6340641975402832, accuracy: 42.8 %\n",
      "Training round [47/200], qnn_train_step: [1100/500], loss: 1.628224492073059, accuracy: 44.3 %\n",
      "Training round [47/200], qnn_train_step: [1200/500], loss: 1.6171139478683472, accuracy: 43.6 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 1.6920, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 1.5148, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 1.4279, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 1.6113, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 1.7263, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 1.5640, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 1.7735, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 1.4996, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 1.5465, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 1.6395, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [48/200], qnn_train_step: [100/500], loss: 1.706950068473816, accuracy: 41.8 %\n",
      "Training round [48/200], qnn_train_step: [200/500], loss: 2.108246088027954, accuracy: 31.5 %\n",
      "Training round [48/200], qnn_train_step: [300/500], loss: 1.779578685760498, accuracy: 40.0 %\n",
      "Training round [48/200], qnn_train_step: [400/500], loss: 1.6935532093048096, accuracy: 43.4 %\n",
      "Training round [48/200], qnn_train_step: [500/500], loss: 1.6840825080871582, accuracy: 43.8 %\n",
      "Training round [48/200], qnn_train_step: [600/500], loss: 1.6636686325073242, accuracy: 43.6 %\n",
      "Training round [48/200], qnn_train_step: [700/500], loss: 1.6806076765060425, accuracy: 44.2 %\n",
      "Training round [48/200], qnn_train_step: [800/500], loss: 1.6589592695236206, accuracy: 45.5 %\n",
      "Training round [48/200], qnn_train_step: [900/500], loss: 1.6600004434585571, accuracy: 44.3 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 1.5492, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 1.7590, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 1.5993, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 1.6395, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 1.5848, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 1.4702, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 1.5565, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 1.6943, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 1.6346, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 1.4953, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [49/200], qnn_train_step: [100/500], loss: 1.5578922033309937, accuracy: 47.7 %\n",
      "Training round [49/200], qnn_train_step: [200/500], loss: 1.6400628089904785, accuracy: 45.1 %\n",
      "Training round [49/200], qnn_train_step: [300/500], loss: 1.6324399709701538, accuracy: 44.9 %\n",
      "Training round [49/200], qnn_train_step: [400/500], loss: 1.5688679218292236, accuracy: 46.1 %\n",
      "Training round [49/200], qnn_train_step: [500/500], loss: 1.5751093626022339, accuracy: 46.3 %\n",
      "Training round [49/200], qnn_train_step: [600/500], loss: 1.5679235458374023, accuracy: 45.9 %\n",
      "Training round [49/200], qnn_train_step: [700/500], loss: 1.562139868736267, accuracy: 47.5 %\n",
      "Training round [49/200], qnn_train_step: [800/500], loss: 1.553349256515503, accuracy: 46.9 %\n",
      "Training round [49/200], qnn_train_step: [900/500], loss: 1.5542190074920654, accuracy: 47.2 %\n",
      "Training round [49/200], qnn_train_step: [1000/500], loss: 1.5458226203918457, accuracy: 48.1 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 1.6329, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 1.5656, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 1.6430, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 1.6084, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 1.6123, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 1.6803, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 1.7341, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 1.5377, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 1.5825, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 1.5196, batch time: 0.03, accuracy:  54.69%\n",
      "Training round [50/200], qnn_train_step: [100/500], loss: 1.6789608001708984, accuracy: 44.0 %\n",
      "Training round [50/200], qnn_train_step: [200/500], loss: 1.954198956489563, accuracy: 35.8 %\n",
      "Training round [50/200], qnn_train_step: [300/500], loss: 1.6452091932296753, accuracy: 42.3 %\n",
      "Training round [50/200], qnn_train_step: [400/500], loss: 1.6599940061569214, accuracy: 44.3 %\n",
      "Training round [50/200], qnn_train_step: [500/500], loss: 1.650325059890747, accuracy: 44.6 %\n",
      "Training round [50/200], qnn_train_step: [600/500], loss: 1.639451265335083, accuracy: 46.0 %\n",
      "Training round [50/200], qnn_train_step: [700/500], loss: 1.6398959159851074, accuracy: 45.5 %\n",
      "Training round [50/200], qnn_train_step: [800/500], loss: 1.6352726221084595, accuracy: 44.4 %\n",
      "Training round [50/200], qnn_train_step: [900/500], loss: 1.6334307193756104, accuracy: 44.8 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 1.4710, batch time: 0.19, accuracy:  49.22%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 1.6949, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 1.5819, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 1.6396, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 1.6891, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 1.5568, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 1.7749, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 1.5757, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 1.6226, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 1.4545, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [51/200], qnn_train_step: [100/500], loss: 1.5908039808273315, accuracy: 46.0 %\n",
      "Training round [51/200], qnn_train_step: [200/500], loss: 1.6798207759857178, accuracy: 44.2 %\n",
      "Training round [51/200], qnn_train_step: [300/500], loss: 1.595921516418457, accuracy: 46.6 %\n",
      "Training round [51/200], qnn_train_step: [400/500], loss: 1.5733259916305542, accuracy: 46.3 %\n",
      "Training round [51/200], qnn_train_step: [500/500], loss: 1.563796877861023, accuracy: 46.8 %\n",
      "Training round [51/200], qnn_train_step: [600/500], loss: 1.5702669620513916, accuracy: 45.4 %\n",
      "Training round [51/200], qnn_train_step: [700/500], loss: 1.5676404237747192, accuracy: 46.1 %\n",
      "Training round [51/200], qnn_train_step: [800/500], loss: 1.5629178285598755, accuracy: 44.6 %\n",
      "Training round [51/200], qnn_train_step: [900/500], loss: 1.5544347763061523, accuracy: 46.3 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 1.6763, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 1.8643, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 1.7450, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 1.6572, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 1.6118, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 1.7076, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 1.7057, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 1.5922, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 1.4550, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 1.5564, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [52/200], qnn_train_step: [100/500], loss: 1.5812550783157349, accuracy: 46.7 %\n",
      "Training round [52/200], qnn_train_step: [200/500], loss: 1.735492467880249, accuracy: 41.3 %\n",
      "Training round [52/200], qnn_train_step: [300/500], loss: 1.6663347482681274, accuracy: 42.6 %\n",
      "Training round [52/200], qnn_train_step: [400/500], loss: 1.6138333082199097, accuracy: 45.0 %\n",
      "Training round [52/200], qnn_train_step: [500/500], loss: 1.5812779664993286, accuracy: 45.7 %\n",
      "Training round [52/200], qnn_train_step: [600/500], loss: 1.5770864486694336, accuracy: 46.6 %\n",
      "Training round [52/200], qnn_train_step: [700/500], loss: 1.6191978454589844, accuracy: 44.8 %\n",
      "Training round [52/200], qnn_train_step: [800/500], loss: 1.5708285570144653, accuracy: 46.1 %\n",
      "Training round [52/200], qnn_train_step: [900/500], loss: 1.579506516456604, accuracy: 46.3 %\n",
      "Training round [52/200], qnn_train_step: [1000/500], loss: 1.5684823989868164, accuracy: 47.1 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 1.5870, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 1.5921, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 1.6246, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 1.6560, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 1.5077, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 1.6707, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 1.5184, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 1.5235, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 1.5188, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 1.4848, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [53/200], qnn_train_step: [100/500], loss: 1.631306529045105, accuracy: 45.6 %\n",
      "Training round [53/200], qnn_train_step: [200/500], loss: 1.685186505317688, accuracy: 41.5 %\n",
      "Training round [53/200], qnn_train_step: [300/500], loss: 1.6274433135986328, accuracy: 45.6 %\n",
      "Training round [53/200], qnn_train_step: [400/500], loss: 1.642120361328125, accuracy: 46.3 %\n",
      "Training round [53/200], qnn_train_step: [500/500], loss: 1.606569528579712, accuracy: 47.4 %\n",
      "Training round [53/200], qnn_train_step: [600/500], loss: 1.6042566299438477, accuracy: 47.1 %\n",
      "Training round [53/200], qnn_train_step: [700/500], loss: 1.5981343984603882, accuracy: 46.8 %\n",
      "Training round [53/200], qnn_train_step: [800/500], loss: 1.614753246307373, accuracy: 46.4 %\n",
      "Training round [53/200], qnn_train_step: [900/500], loss: 1.604812502861023, accuracy: 46.9 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 1.6033, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 1.5480, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 1.5791, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 1.4913, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 1.5409, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 1.4461, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 1.6991, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 1.4899, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 1.5393, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 1.5661, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [54/200], qnn_train_step: [100/500], loss: 1.6330814361572266, accuracy: 43.9 %\n",
      "Training round [54/200], qnn_train_step: [200/500], loss: 1.7469321489334106, accuracy: 41.0 %\n",
      "Training round [54/200], qnn_train_step: [300/500], loss: 1.6706608533859253, accuracy: 43.2 %\n",
      "Training round [54/200], qnn_train_step: [400/500], loss: 1.6505736112594604, accuracy: 44.6 %\n",
      "Training round [54/200], qnn_train_step: [500/500], loss: 1.6811654567718506, accuracy: 43.4 %\n",
      "Training round [54/200], qnn_train_step: [600/500], loss: 1.632619857788086, accuracy: 45.4 %\n",
      "Training round [54/200], qnn_train_step: [700/500], loss: 1.6376960277557373, accuracy: 44.5 %\n",
      "Training round [54/200], qnn_train_step: [800/500], loss: 1.6377801895141602, accuracy: 45.0 %\n",
      "Training round [54/200], qnn_train_step: [900/500], loss: 1.639165997505188, accuracy: 44.1 %\n",
      "Training round [54/200], qnn_train_step: [1000/500], loss: 1.6249207258224487, accuracy: 44.8 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 1.4766, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 1.4908, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 1.7489, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 1.7095, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 1.6267, batch time: 0.06, accuracy:  46.09%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 1.4415, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 1.8076, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 1.5861, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 1.7782, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 1.6395, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [55/200], qnn_train_step: [100/500], loss: 1.6142432689666748, accuracy: 46.0 %\n",
      "Training round [55/200], qnn_train_step: [200/500], loss: 1.670935869216919, accuracy: 45.0 %\n",
      "Training round [55/200], qnn_train_step: [300/500], loss: 1.6275492906570435, accuracy: 44.4 %\n",
      "Training round [55/200], qnn_train_step: [400/500], loss: 1.688989520072937, accuracy: 43.8 %\n",
      "Training round [55/200], qnn_train_step: [500/500], loss: 1.609714388847351, accuracy: 46.6 %\n",
      "Training round [55/200], qnn_train_step: [600/500], loss: 1.5956509113311768, accuracy: 46.9 %\n",
      "Training round [55/200], qnn_train_step: [700/500], loss: 1.5934978723526, accuracy: 46.7 %\n",
      "Training round [55/200], qnn_train_step: [800/500], loss: 1.6037342548370361, accuracy: 45.0 %\n",
      "Training round [55/200], qnn_train_step: [900/500], loss: 1.5907152891159058, accuracy: 46.2 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 1.6222, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 1.6725, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 1.5312, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 1.6491, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 1.6136, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 1.5876, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 1.4490, batch time: 0.03, accuracy:  55.47%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 1.5426, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 1.5748, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 1.5186, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [56/200], qnn_train_step: [100/500], loss: 1.5794055461883545, accuracy: 46.7 %\n",
      "Training round [56/200], qnn_train_step: [200/500], loss: 1.679111361503601, accuracy: 43.1 %\n",
      "Training round [56/200], qnn_train_step: [300/500], loss: 1.5934010744094849, accuracy: 42.4 %\n",
      "Training round [56/200], qnn_train_step: [400/500], loss: 1.557685375213623, accuracy: 46.0 %\n",
      "Training round [56/200], qnn_train_step: [500/500], loss: 1.5634902715682983, accuracy: 45.3 %\n",
      "Training round [56/200], qnn_train_step: [600/500], loss: 1.534708023071289, accuracy: 47.7 %\n",
      "Training round [56/200], qnn_train_step: [700/500], loss: 1.5397425889968872, accuracy: 47.1 %\n",
      "Training round [56/200], qnn_train_step: [800/500], loss: 1.5578058958053589, accuracy: 45.7 %\n",
      "Training round [56/200], qnn_train_step: [900/500], loss: 1.5298060178756714, accuracy: 45.6 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 1.5330, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 1.4849, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 1.4580, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 1.7072, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 1.6739, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 1.7268, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 1.7629, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 1.4620, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 1.6023, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 1.6663, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [57/200], qnn_train_step: [100/500], loss: 1.5697062015533447, accuracy: 47.1 %\n",
      "Training round [57/200], qnn_train_step: [200/500], loss: 1.6781989336013794, accuracy: 42.9 %\n",
      "Training round [57/200], qnn_train_step: [300/500], loss: 1.6851675510406494, accuracy: 38.7 %\n",
      "Training round [57/200], qnn_train_step: [400/500], loss: 1.5746501684188843, accuracy: 45.9 %\n",
      "Training round [57/200], qnn_train_step: [500/500], loss: 1.5703670978546143, accuracy: 47.4 %\n",
      "Training round [57/200], qnn_train_step: [600/500], loss: 1.5752530097961426, accuracy: 45.9 %\n",
      "Training round [57/200], qnn_train_step: [700/500], loss: 1.5855900049209595, accuracy: 46.3 %\n",
      "Training round [57/200], qnn_train_step: [800/500], loss: 1.5580974817276, accuracy: 46.7 %\n",
      "Training round [57/200], qnn_train_step: [900/500], loss: 1.5609948635101318, accuracy: 48.3 %\n",
      "Training round [57/200], qnn_train_step: [1000/500], loss: 1.559533953666687, accuracy: 48.4 %\n",
      "Training round [57/200], qnn_train_step: [1100/500], loss: 1.5579010248184204, accuracy: 48.6 %\n",
      "Training round [57/200], qnn_train_step: [1200/500], loss: 1.5506120920181274, accuracy: 48.2 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 1.4279, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 1.6355, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 1.5953, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 1.5535, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 1.6289, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 1.5437, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 1.3790, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 1.5017, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 1.4782, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 1.5847, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [58/200], qnn_train_step: [100/500], loss: 1.5579006671905518, accuracy: 46.4 %\n",
      "Training round [58/200], qnn_train_step: [200/500], loss: 1.6678663492202759, accuracy: 42.9 %\n",
      "Training round [58/200], qnn_train_step: [300/500], loss: 1.732795238494873, accuracy: 42.7 %\n",
      "Training round [58/200], qnn_train_step: [400/500], loss: 1.5580488443374634, accuracy: 45.6 %\n",
      "Training round [58/200], qnn_train_step: [500/500], loss: 1.5478163957595825, accuracy: 44.2 %\n",
      "Training round [58/200], qnn_train_step: [600/500], loss: 1.5576801300048828, accuracy: 46.3 %\n",
      "Training round [58/200], qnn_train_step: [700/500], loss: 1.5396599769592285, accuracy: 48.5 %\n",
      "Training round [58/200], qnn_train_step: [800/500], loss: 1.5452476739883423, accuracy: 46.6 %\n",
      "Training round [58/200], qnn_train_step: [900/500], loss: 1.5412933826446533, accuracy: 47.0 %\n",
      "Training round [58/200], qnn_train_step: [1000/500], loss: 1.5393544435501099, accuracy: 48.5 %\n",
      "Training round [58/200], qnn_train_step: [1100/500], loss: 1.5447876453399658, accuracy: 47.7 %\n",
      "Training round [58/200], qnn_train_step: [1200/500], loss: 1.5409005880355835, accuracy: 47.7 %\n",
      "Training round [58/200], qnn_train_step: [1300/500], loss: 1.539008378982544, accuracy: 48.5 %\n",
      "Training round [58/200], qnn_train_step: [1400/500], loss: 1.5446408987045288, accuracy: 46.6 %\n",
      "Training round [58/200], qnn_train_step: [1500/500], loss: 1.540980577468872, accuracy: 46.6 %\n",
      "Training round [58/200], qnn_train_step: [1600/500], loss: 1.5387282371520996, accuracy: 48.5 %\n",
      "Training round [58/200], qnn_train_step: [1700/500], loss: 1.5445359945297241, accuracy: 48.2 %\n",
      "Training round [58/200], qnn_train_step: [1800/500], loss: 1.5409051179885864, accuracy: 46.5 %\n",
      "Training round [58/200], qnn_train_step: [1900/500], loss: 1.538467288017273, accuracy: 48.5 %\n",
      "Training round [58/200], qnn_train_step: [2000/500], loss: 1.5444355010986328, accuracy: 47.9 %\n",
      "Training round [58/200], qnn_train_step: [2100/500], loss: 1.5407865047454834, accuracy: 48.1 %\n",
      "Training round [58/200], qnn_train_step: [2200/500], loss: 1.538169264793396, accuracy: 48.6 %\n",
      "Training round [58/200], qnn_train_step: [2300/500], loss: 1.544179916381836, accuracy: 47.0 %\n",
      "Training round [58/200], qnn_train_step: [2400/500], loss: 1.5405009984970093, accuracy: 46.9 %\n",
      "Training round [58/200], qnn_train_step: [2500/500], loss: 1.5378994941711426, accuracy: 48.6 %\n",
      "Training round [58/200], qnn_train_step: [2600/500], loss: 1.5440007448196411, accuracy: 46.6 %\n",
      "Training round [58/200], qnn_train_step: [2700/500], loss: 1.540407419204712, accuracy: 47.0 %\n",
      "Training round [58/200], qnn_train_step: [2800/500], loss: 1.5377260446548462, accuracy: 48.5 %\n",
      "Training round [58/200], qnn_train_step: [2900/500], loss: 1.543967843055725, accuracy: 46.7 %\n",
      "Training round [58/200], qnn_train_step: [3000/500], loss: 1.5402570962905884, accuracy: 48.5 %\n",
      "Training round [58/200], qnn_train_step: [3100/500], loss: 1.537468433380127, accuracy: 48.4 %\n",
      "Training round [58/200], qnn_train_step: [3200/500], loss: 1.5441304445266724, accuracy: 46.4 %\n",
      "Training round [58/200], qnn_train_step: [3300/500], loss: 1.5401779413223267, accuracy: 46.8 %\n",
      "Training round [58/200], qnn_train_step: [3400/500], loss: 1.5373098850250244, accuracy: 48.4 %\n",
      "Training round [58/200], qnn_train_step: [3500/500], loss: 1.5442941188812256, accuracy: 46.7 %\n",
      "Training round [58/200], qnn_train_step: [3600/500], loss: 1.5400879383087158, accuracy: 48.2 %\n",
      "Training round [58/200], qnn_train_step: [3700/500], loss: 1.5370346307754517, accuracy: 48.3 %\n",
      "Training round [58/200], qnn_train_step: [3800/500], loss: 1.5498757362365723, accuracy: 45.8 %\n",
      "Training round [58/200], qnn_train_step: [3900/500], loss: 1.5399110317230225, accuracy: 46.6 %\n",
      "Training round [58/200], qnn_train_step: [4000/500], loss: 1.5368237495422363, accuracy: 48.2 %\n",
      "Training round [58/200], qnn_train_step: [4100/500], loss: 1.556112289428711, accuracy: 45.9 %\n",
      "Training round [58/200], qnn_train_step: [4200/500], loss: 1.539530634880066, accuracy: 48.1 %\n",
      "Training round [58/200], qnn_train_step: [4300/500], loss: 1.536722183227539, accuracy: 48.2 %\n",
      "Training round [58/200], qnn_train_step: [4400/500], loss: 1.533936619758606, accuracy: 47.0 %\n",
      "Training round [58/200], qnn_train_step: [4500/500], loss: 1.5395135879516602, accuracy: 48.8 %\n",
      "Training round [58/200], qnn_train_step: [4600/500], loss: 1.5366029739379883, accuracy: 48.2 %\n",
      "Training round [58/200], qnn_train_step: [4700/500], loss: 1.534197211265564, accuracy: 47.5 %\n",
      "Training round [58/200], qnn_train_step: [4800/500], loss: 1.5392118692398071, accuracy: 46.7 %\n",
      "Training round [58/200], qnn_train_step: [4900/500], loss: 1.5364165306091309, accuracy: 48.2 %\n",
      "Training round [58/200], qnn_train_step: [5000/500], loss: 1.5345150232315063, accuracy: 48.1 %\n",
      "Training round [58/200], qnn_train_step: [5100/500], loss: 1.5390177965164185, accuracy: 47.3 %\n",
      "Training round [58/200], qnn_train_step: [5200/500], loss: 1.5363739728927612, accuracy: 48.2 %\n",
      "Training round [58/200], qnn_train_step: [5300/500], loss: 1.5346814393997192, accuracy: 47.9 %\n",
      "Training round [58/200], qnn_train_step: [5400/500], loss: 1.5388437509536743, accuracy: 47.0 %\n",
      "Training round [58/200], qnn_train_step: [5500/500], loss: 1.5361721515655518, accuracy: 48.3 %\n",
      "Training round [58/200], qnn_train_step: [5600/500], loss: 1.534714937210083, accuracy: 48.3 %\n",
      "Training round [58/200], qnn_train_step: [5700/500], loss: 1.5386571884155273, accuracy: 48.2 %\n",
      "Training round [58/200], qnn_train_step: [5800/500], loss: 1.5361120700836182, accuracy: 48.3 %\n",
      "Training round [58/200], qnn_train_step: [5900/500], loss: 1.5345712900161743, accuracy: 46.8 %\n",
      "Training round [58/200], qnn_train_step: [6000/500], loss: 1.5386326313018799, accuracy: 49.0 %\n",
      "Training round [58/200], qnn_train_step: [6100/500], loss: 1.5359853506088257, accuracy: 48.3 %\n",
      "Training round [58/200], qnn_train_step: [6200/500], loss: 1.5349061489105225, accuracy: 48.0 %\n",
      "Training round [58/200], qnn_train_step: [6300/500], loss: 1.5382364988327026, accuracy: 47.2 %\n",
      "Training round [58/200], qnn_train_step: [6400/500], loss: 1.5359119176864624, accuracy: 48.3 %\n",
      "Training round [58/200], qnn_train_step: [6500/500], loss: 1.534924030303955, accuracy: 48.5 %\n",
      "Training round [58/200], qnn_train_step: [6600/500], loss: 1.5381882190704346, accuracy: 46.9 %\n",
      "Training round [58/200], qnn_train_step: [6700/500], loss: 1.536064624786377, accuracy: 47.2 %\n",
      "Training round [58/200], qnn_train_step: [6800/500], loss: 1.534840703010559, accuracy: 46.7 %\n",
      "Training round [58/200], qnn_train_step: [6900/500], loss: 1.5382803678512573, accuracy: 48.4 %\n",
      "Training round [58/200], qnn_train_step: [7000/500], loss: 1.5358749628067017, accuracy: 48.1 %\n",
      "Training round [58/200], qnn_train_step: [7100/500], loss: 1.5348505973815918, accuracy: 47.1 %\n",
      "Training round [58/200], qnn_train_step: [7200/500], loss: 1.5380375385284424, accuracy: 47.2 %\n",
      "Training round [58/200], qnn_train_step: [7300/500], loss: 1.535791039466858, accuracy: 48.2 %\n",
      "Training round [58/200], qnn_train_step: [7400/500], loss: 1.5349187850952148, accuracy: 47.8 %\n",
      "Training round [58/200], qnn_train_step: [7500/500], loss: 1.5379557609558105, accuracy: 47.1 %\n",
      "Training round [58/200], qnn_train_step: [7600/500], loss: 1.5355740785598755, accuracy: 47.2 %\n",
      "Training round [58/200], qnn_train_step: [7700/500], loss: 1.5348966121673584, accuracy: 48.0 %\n",
      "Training round [58/200], qnn_train_step: [7800/500], loss: 1.537852168083191, accuracy: 48.0 %\n",
      "Training round [58/200], qnn_train_step: [7900/500], loss: 1.535385012626648, accuracy: 47.0 %\n",
      "Training round [58/200], qnn_train_step: [8000/500], loss: 1.534956693649292, accuracy: 46.9 %\n",
      "Training round [58/200], qnn_train_step: [8100/500], loss: 1.5377751588821411, accuracy: 47.4 %\n",
      "Training round [58/200], qnn_train_step: [8200/500], loss: 1.5353524684906006, accuracy: 48.4 %\n",
      "Training round [58/200], qnn_train_step: [8300/500], loss: 1.5348252058029175, accuracy: 48.0 %\n",
      "Training round [58/200], qnn_train_step: [8400/500], loss: 1.537492275238037, accuracy: 47.0 %\n",
      "Training round [58/200], qnn_train_step: [8500/500], loss: 1.5352449417114258, accuracy: 48.1 %\n",
      "Training round [58/200], qnn_train_step: [8600/500], loss: 1.5347461700439453, accuracy: 47.6 %\n",
      "Training round [58/200], qnn_train_step: [8700/500], loss: 1.5374648571014404, accuracy: 47.7 %\n",
      "Training round [58/200], qnn_train_step: [8800/500], loss: 1.5350141525268555, accuracy: 48.3 %\n",
      "Training round [58/200], qnn_train_step: [8900/500], loss: 1.5345309972763062, accuracy: 49.0 %\n",
      "Training round [58/200], qnn_train_step: [9000/500], loss: 1.5373026132583618, accuracy: 47.9 %\n",
      "Training round [58/200], qnn_train_step: [9100/500], loss: 1.5349866151809692, accuracy: 48.2 %\n",
      "Training round [58/200], qnn_train_step: [9200/500], loss: 1.5342118740081787, accuracy: 47.4 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 1.6327, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 1.6321, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 1.5188, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 1.5891, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 1.7081, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 1.5800, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 1.4341, batch time: 0.03, accuracy:  56.25%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 1.5411, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 1.5128, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 1.6159, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [59/200], qnn_train_step: [100/500], loss: 1.6098886728286743, accuracy: 47.1 %\n",
      "Training round [59/200], qnn_train_step: [200/500], loss: 1.7330251932144165, accuracy: 42.4 %\n",
      "Training round [59/200], qnn_train_step: [300/500], loss: 1.7122188806533813, accuracy: 43.3 %\n",
      "Training round [59/200], qnn_train_step: [400/500], loss: 1.6117830276489258, accuracy: 47.9 %\n",
      "Training round [59/200], qnn_train_step: [500/500], loss: 1.6187020540237427, accuracy: 43.8 %\n",
      "Training round [59/200], qnn_train_step: [600/500], loss: 1.6394727230072021, accuracy: 45.7 %\n",
      "Training round [59/200], qnn_train_step: [700/500], loss: 1.5997027158737183, accuracy: 47.4 %\n",
      "Training round [59/200], qnn_train_step: [800/500], loss: 1.596001148223877, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [900/500], loss: 1.6034148931503296, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [1000/500], loss: 1.5995428562164307, accuracy: 48.1 %\n",
      "Training round [59/200], qnn_train_step: [1100/500], loss: 1.5959962606430054, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [1200/500], loss: 1.603230595588684, accuracy: 46.5 %\n",
      "Training round [59/200], qnn_train_step: [1300/500], loss: 1.599455714225769, accuracy: 48.1 %\n",
      "Training round [59/200], qnn_train_step: [1400/500], loss: 1.5959635972976685, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [1500/500], loss: 1.6029261350631714, accuracy: 47.1 %\n",
      "Training round [59/200], qnn_train_step: [1600/500], loss: 1.5990991592407227, accuracy: 47.8 %\n",
      "Training round [59/200], qnn_train_step: [1700/500], loss: 1.595911979675293, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [1800/500], loss: 1.6027412414550781, accuracy: 47.3 %\n",
      "Training round [59/200], qnn_train_step: [1900/500], loss: 1.5992649793624878, accuracy: 48.1 %\n",
      "Training round [59/200], qnn_train_step: [2000/500], loss: 1.595871090888977, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [2100/500], loss: 1.6028934717178345, accuracy: 47.4 %\n",
      "Training round [59/200], qnn_train_step: [2200/500], loss: 1.599075198173523, accuracy: 46.3 %\n",
      "Training round [59/200], qnn_train_step: [2300/500], loss: 1.5958589315414429, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [2400/500], loss: 1.6027295589447021, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [2500/500], loss: 1.59891939163208, accuracy: 46.9 %\n",
      "Training round [59/200], qnn_train_step: [2600/500], loss: 1.5956982374191284, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [2700/500], loss: 1.6028001308441162, accuracy: 46.8 %\n",
      "Training round [59/200], qnn_train_step: [2800/500], loss: 1.598779559135437, accuracy: 48.0 %\n",
      "Training round [59/200], qnn_train_step: [2900/500], loss: 1.5955686569213867, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [3000/500], loss: 1.6024725437164307, accuracy: 46.8 %\n",
      "Training round [59/200], qnn_train_step: [3100/500], loss: 1.5986309051513672, accuracy: 47.7 %\n",
      "Training round [59/200], qnn_train_step: [3200/500], loss: 1.5954228639602661, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [3300/500], loss: 1.60216224193573, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [3400/500], loss: 1.5983432531356812, accuracy: 47.0 %\n",
      "Training round [59/200], qnn_train_step: [3500/500], loss: 1.59525728225708, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [3600/500], loss: 1.6019794940948486, accuracy: 47.4 %\n",
      "Training round [59/200], qnn_train_step: [3700/500], loss: 1.5982000827789307, accuracy: 47.7 %\n",
      "Training round [59/200], qnn_train_step: [3800/500], loss: 1.595089316368103, accuracy: 47.4 %\n",
      "Training round [59/200], qnn_train_step: [3900/500], loss: 1.6017491817474365, accuracy: 46.0 %\n",
      "Training round [59/200], qnn_train_step: [4000/500], loss: 1.598098635673523, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [4100/500], loss: 1.5949198007583618, accuracy: 47.4 %\n",
      "Training round [59/200], qnn_train_step: [4200/500], loss: 1.6015534400939941, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [4300/500], loss: 1.5979886054992676, accuracy: 46.3 %\n",
      "Training round [59/200], qnn_train_step: [4400/500], loss: 1.5947024822235107, accuracy: 47.4 %\n",
      "Training round [59/200], qnn_train_step: [4500/500], loss: 1.6012189388275146, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [4600/500], loss: 1.5978994369506836, accuracy: 47.2 %\n",
      "Training round [59/200], qnn_train_step: [4700/500], loss: 1.5945103168487549, accuracy: 47.4 %\n",
      "Training round [59/200], qnn_train_step: [4800/500], loss: 1.601401925086975, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [4900/500], loss: 1.5977389812469482, accuracy: 47.1 %\n",
      "Training round [59/200], qnn_train_step: [5000/500], loss: 1.5943806171417236, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [5100/500], loss: 1.601103663444519, accuracy: 46.9 %\n",
      "Training round [59/200], qnn_train_step: [5200/500], loss: 1.597556471824646, accuracy: 48.4 %\n",
      "Training round [59/200], qnn_train_step: [5300/500], loss: 1.5942771434783936, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [5400/500], loss: 1.6013333797454834, accuracy: 46.4 %\n",
      "Training round [59/200], qnn_train_step: [5500/500], loss: 1.5975651741027832, accuracy: 47.0 %\n",
      "Training round [59/200], qnn_train_step: [5600/500], loss: 1.5941444635391235, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [5700/500], loss: 1.601624846458435, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [5800/500], loss: 1.597401738166809, accuracy: 47.8 %\n",
      "Training round [59/200], qnn_train_step: [5900/500], loss: 1.5940181016921997, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [6000/500], loss: 1.6015878915786743, accuracy: 46.6 %\n",
      "Training round [59/200], qnn_train_step: [6100/500], loss: 1.5972687005996704, accuracy: 47.4 %\n",
      "Training round [59/200], qnn_train_step: [6200/500], loss: 1.5939109325408936, accuracy: 47.7 %\n",
      "Training round [59/200], qnn_train_step: [6300/500], loss: 1.601386547088623, accuracy: 48.0 %\n",
      "Training round [59/200], qnn_train_step: [6400/500], loss: 1.5970832109451294, accuracy: 48.1 %\n",
      "Training round [59/200], qnn_train_step: [6500/500], loss: 1.5940570831298828, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [6600/500], loss: 1.6122888326644897, accuracy: 46.3 %\n",
      "Training round [59/200], qnn_train_step: [6700/500], loss: 1.5969862937927246, accuracy: 47.7 %\n",
      "Training round [59/200], qnn_train_step: [6800/500], loss: 1.5940706729888916, accuracy: 47.4 %\n",
      "Training round [59/200], qnn_train_step: [6900/500], loss: 1.6158320903778076, accuracy: 45.6 %\n",
      "Training round [59/200], qnn_train_step: [7000/500], loss: 1.5968698263168335, accuracy: 48.1 %\n",
      "Training round [59/200], qnn_train_step: [7100/500], loss: 1.5938661098480225, accuracy: 48.7 %\n",
      "Training round [59/200], qnn_train_step: [7200/500], loss: 1.5919541120529175, accuracy: 48.4 %\n",
      "Training round [59/200], qnn_train_step: [7300/500], loss: 1.5966846942901611, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [7400/500], loss: 1.5940022468566895, accuracy: 48.5 %\n",
      "Training round [59/200], qnn_train_step: [7500/500], loss: 1.592827558517456, accuracy: 48.2 %\n",
      "Training round [59/200], qnn_train_step: [7600/500], loss: 1.5965214967727661, accuracy: 47.4 %\n",
      "Training round [59/200], qnn_train_step: [7700/500], loss: 1.59388267993927, accuracy: 47.7 %\n",
      "Training round [59/200], qnn_train_step: [7800/500], loss: 1.5930613279342651, accuracy: 47.1 %\n",
      "Training round [59/200], qnn_train_step: [7900/500], loss: 1.5964616537094116, accuracy: 47.8 %\n",
      "Training round [59/200], qnn_train_step: [8000/500], loss: 1.5938374996185303, accuracy: 47.8 %\n",
      "Training round [59/200], qnn_train_step: [8100/500], loss: 1.5930734872817993, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [8200/500], loss: 1.5963921546936035, accuracy: 47.4 %\n",
      "Training round [59/200], qnn_train_step: [8300/500], loss: 1.5937517881393433, accuracy: 47.2 %\n",
      "Training round [59/200], qnn_train_step: [8400/500], loss: 1.5929542779922485, accuracy: 47.7 %\n",
      "Training round [59/200], qnn_train_step: [8500/500], loss: 1.5962841510772705, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [8600/500], loss: 1.5938608646392822, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [8700/500], loss: 1.5928460359573364, accuracy: 47.7 %\n",
      "Training round [59/200], qnn_train_step: [8800/500], loss: 1.59611976146698, accuracy: 47.9 %\n",
      "Training round [59/200], qnn_train_step: [8900/500], loss: 1.593704104423523, accuracy: 47.0 %\n",
      "Training round [59/200], qnn_train_step: [9000/500], loss: 1.59275221824646, accuracy: 47.7 %\n",
      "Training round [59/200], qnn_train_step: [9100/500], loss: 1.5960785150527954, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [9200/500], loss: 1.5936156511306763, accuracy: 47.9 %\n",
      "Training round [59/200], qnn_train_step: [9300/500], loss: 1.5925986766815186, accuracy: 47.9 %\n",
      "Training round [59/200], qnn_train_step: [9400/500], loss: 1.596031665802002, accuracy: 47.3 %\n",
      "Training round [59/200], qnn_train_step: [9500/500], loss: 1.5936576128005981, accuracy: 47.5 %\n",
      "Training round [59/200], qnn_train_step: [9600/500], loss: 1.592490553855896, accuracy: 47.8 %\n",
      "Training round [59/200], qnn_train_step: [9700/500], loss: 1.5959199666976929, accuracy: 48.0 %\n",
      "Training round [59/200], qnn_train_step: [9800/500], loss: 1.5935697555541992, accuracy: 47.7 %\n",
      "Training round [59/200], qnn_train_step: [9900/500], loss: 1.5966157913208008, accuracy: 47.6 %\n",
      "Training round [59/200], qnn_train_step: [10000/500], loss: 1.591747522354126, accuracy: 48.2 %\n",
      "Training round [59/200], qnn_train_step: [10100/500], loss: 1.5951523780822754, accuracy: 47.9 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 1.8246, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 1.5584, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 1.4543, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 1.5717, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 1.7508, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 1.6005, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 1.4179, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 1.6585, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 1.3513, batch time: 0.03, accuracy:  57.03%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 1.5043, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [60/200], qnn_train_step: [100/500], loss: 1.5529849529266357, accuracy: 45.4 %\n",
      "Training round [60/200], qnn_train_step: [200/500], loss: 2.2083992958068848, accuracy: 36.2 %\n",
      "Training round [60/200], qnn_train_step: [300/500], loss: 1.7611287832260132, accuracy: 41.9 %\n",
      "Training round [60/200], qnn_train_step: [400/500], loss: 1.6095472574234009, accuracy: 43.9 %\n",
      "Training round [60/200], qnn_train_step: [500/500], loss: 1.5547441244125366, accuracy: 46.7 %\n",
      "Training round [60/200], qnn_train_step: [600/500], loss: 1.5623871088027954, accuracy: 45.2 %\n",
      "Training round [60/200], qnn_train_step: [700/500], loss: 1.5374995470046997, accuracy: 46.3 %\n",
      "Training round [60/200], qnn_train_step: [800/500], loss: 1.5472620725631714, accuracy: 47.0 %\n",
      "Training round [60/200], qnn_train_step: [900/500], loss: 1.5397193431854248, accuracy: 46.6 %\n",
      "Training round [60/200], qnn_train_step: [1000/500], loss: 1.5375813245773315, accuracy: 45.7 %\n",
      "Training round [60/200], qnn_train_step: [1100/500], loss: 1.546931266784668, accuracy: 47.0 %\n",
      "Training round [60/200], qnn_train_step: [1200/500], loss: 1.5413484573364258, accuracy: 46.9 %\n",
      "Training round [60/200], qnn_train_step: [1300/500], loss: 1.5375683307647705, accuracy: 46.1 %\n",
      "Training round [60/200], qnn_train_step: [1400/500], loss: 1.5468096733093262, accuracy: 47.0 %\n",
      "Training round [60/200], qnn_train_step: [1500/500], loss: 1.5415468215942383, accuracy: 46.0 %\n",
      "Training round [60/200], qnn_train_step: [1600/500], loss: 1.5375486612319946, accuracy: 46.1 %\n",
      "Training round [60/200], qnn_train_step: [1700/500], loss: 1.5467376708984375, accuracy: 47.8 %\n",
      "Training round [60/200], qnn_train_step: [1800/500], loss: 1.5420633554458618, accuracy: 47.2 %\n",
      "Training round [60/200], qnn_train_step: [1900/500], loss: 1.537467122077942, accuracy: 46.2 %\n",
      "Training round [60/200], qnn_train_step: [2000/500], loss: 1.546602487564087, accuracy: 47.0 %\n",
      "Training round [60/200], qnn_train_step: [2100/500], loss: 1.5419671535491943, accuracy: 48.2 %\n",
      "Training round [60/200], qnn_train_step: [2200/500], loss: 1.5374597311019897, accuracy: 46.2 %\n",
      "Training round [60/200], qnn_train_step: [2300/500], loss: 1.5464763641357422, accuracy: 46.5 %\n",
      "Training round [60/200], qnn_train_step: [2400/500], loss: 1.542094349861145, accuracy: 47.6 %\n",
      "Training round [60/200], qnn_train_step: [2500/500], loss: 1.5373871326446533, accuracy: 46.2 %\n",
      "Training round [60/200], qnn_train_step: [2600/500], loss: 1.5461961030960083, accuracy: 46.9 %\n",
      "Training round [60/200], qnn_train_step: [2700/500], loss: 1.5425903797149658, accuracy: 46.8 %\n",
      "Training round [60/200], qnn_train_step: [2800/500], loss: 1.537329077720642, accuracy: 46.3 %\n",
      "Training round [60/200], qnn_train_step: [2900/500], loss: 1.545958161354065, accuracy: 46.9 %\n",
      "Training round [60/200], qnn_train_step: [3000/500], loss: 1.5426173210144043, accuracy: 46.1 %\n",
      "Training round [60/200], qnn_train_step: [3100/500], loss: 1.537312626838684, accuracy: 46.3 %\n",
      "Training round [60/200], qnn_train_step: [3200/500], loss: 1.545897364616394, accuracy: 46.0 %\n",
      "Training round [60/200], qnn_train_step: [3300/500], loss: 1.5424689054489136, accuracy: 46.2 %\n",
      "Training round [60/200], qnn_train_step: [3400/500], loss: 1.5372533798217773, accuracy: 46.3 %\n",
      "Training round [60/200], qnn_train_step: [3500/500], loss: 1.54561448097229, accuracy: 46.8 %\n",
      "Training round [60/200], qnn_train_step: [3600/500], loss: 1.5422885417938232, accuracy: 46.6 %\n",
      "Training round [60/200], qnn_train_step: [3700/500], loss: 1.5371863842010498, accuracy: 46.3 %\n",
      "Training round [60/200], qnn_train_step: [3800/500], loss: 1.5454496145248413, accuracy: 47.1 %\n",
      "Training round [60/200], qnn_train_step: [3900/500], loss: 1.5421719551086426, accuracy: 46.6 %\n",
      "Training round [60/200], qnn_train_step: [4000/500], loss: 1.5371226072311401, accuracy: 46.3 %\n",
      "Training round [60/200], qnn_train_step: [4100/500], loss: 1.5451786518096924, accuracy: 47.1 %\n",
      "Training round [60/200], qnn_train_step: [4200/500], loss: 1.5420947074890137, accuracy: 46.3 %\n",
      "Training round [60/200], qnn_train_step: [4300/500], loss: 1.5453693866729736, accuracy: 46.8 %\n",
      "Training round [60/200], qnn_train_step: [4400/500], loss: 1.5392518043518066, accuracy: 46.9 %\n",
      "Training round [60/200], qnn_train_step: [4500/500], loss: 1.5405681133270264, accuracy: 46.8 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 1.5767, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 1.4753, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 1.7973, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 1.4972, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 1.6609, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 1.5905, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 1.5967, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 1.5583, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 1.6528, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 1.5270, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [61/200], qnn_train_step: [100/500], loss: 1.5758763551712036, accuracy: 46.6 %\n",
      "Training round [61/200], qnn_train_step: [200/500], loss: 1.5577914714813232, accuracy: 47.6 %\n",
      "Training round [61/200], qnn_train_step: [300/500], loss: 2.080446720123291, accuracy: 30.1 %\n",
      "Training round [61/200], qnn_train_step: [400/500], loss: 1.5948312282562256, accuracy: 45.8 %\n",
      "Training round [61/200], qnn_train_step: [500/500], loss: 1.7016938924789429, accuracy: 42.7 %\n",
      "Training round [61/200], qnn_train_step: [600/500], loss: 1.609634518623352, accuracy: 46.4 %\n",
      "Training round [61/200], qnn_train_step: [700/500], loss: 1.583691120147705, accuracy: 46.8 %\n",
      "Training round [61/200], qnn_train_step: [800/500], loss: 1.5731146335601807, accuracy: 47.0 %\n",
      "Training round [61/200], qnn_train_step: [900/500], loss: 1.5576938390731812, accuracy: 47.6 %\n",
      "Training round [61/200], qnn_train_step: [1000/500], loss: 1.5726714134216309, accuracy: 46.6 %\n",
      "Training round [61/200], qnn_train_step: [1100/500], loss: 1.5654717683792114, accuracy: 47.9 %\n",
      "Training round [61/200], qnn_train_step: [1200/500], loss: 1.5839654207229614, accuracy: 46.6 %\n",
      "Training round [61/200], qnn_train_step: [1300/500], loss: 1.5603166818618774, accuracy: 47.6 %\n",
      "Training round [61/200], qnn_train_step: [1400/500], loss: 1.5656737089157104, accuracy: 47.6 %\n",
      "Training round [61/200], qnn_train_step: [1500/500], loss: 1.5608792304992676, accuracy: 46.6 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 1.5371, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 1.4941, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 1.6984, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 1.6708, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 1.5370, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 1.4981, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 1.6767, batch time: 0.28, accuracy:  42.19%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 1.5691, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 1.5978, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 1.4861, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [62/200], qnn_train_step: [100/500], loss: 1.6632763147354126, accuracy: 42.6 %\n",
      "Training round [62/200], qnn_train_step: [200/500], loss: 1.6405941247940063, accuracy: 43.2 %\n",
      "Training round [62/200], qnn_train_step: [300/500], loss: 2.1535532474517822, accuracy: 29.3 %\n",
      "Training round [62/200], qnn_train_step: [400/500], loss: 1.6780636310577393, accuracy: 44.9 %\n",
      "Training round [62/200], qnn_train_step: [500/500], loss: 1.6404958963394165, accuracy: 43.2 %\n",
      "Training round [62/200], qnn_train_step: [600/500], loss: 2.364881992340088, accuracy: 23.2 %\n",
      "Training round [62/200], qnn_train_step: [700/500], loss: 1.847253680229187, accuracy: 40.0 %\n",
      "Training round [62/200], qnn_train_step: [800/500], loss: 1.7409522533416748, accuracy: 43.0 %\n",
      "Training round [62/200], qnn_train_step: [900/500], loss: 1.6556674242019653, accuracy: 44.6 %\n",
      "Training round [62/200], qnn_train_step: [1000/500], loss: 1.661792516708374, accuracy: 40.3 %\n",
      "Training round [62/200], qnn_train_step: [1100/500], loss: 1.6438547372817993, accuracy: 44.3 %\n",
      "Training round [62/200], qnn_train_step: [1200/500], loss: 1.642408847808838, accuracy: 42.6 %\n",
      "Training round [62/200], qnn_train_step: [1300/500], loss: 1.640210747718811, accuracy: 43.2 %\n",
      "Training round [62/200], qnn_train_step: [1400/500], loss: 1.646445393562317, accuracy: 43.2 %\n",
      "Training round [62/200], qnn_train_step: [1500/500], loss: 1.6424109935760498, accuracy: 44.3 %\n",
      "Training round [62/200], qnn_train_step: [1600/500], loss: 1.6399983167648315, accuracy: 43.1 %\n",
      "Training round [62/200], qnn_train_step: [1700/500], loss: 1.6459650993347168, accuracy: 44.4 %\n",
      "Training round [62/200], qnn_train_step: [1800/500], loss: 1.6421486139297485, accuracy: 42.8 %\n",
      "Training round [62/200], qnn_train_step: [1900/500], loss: 1.639827847480774, accuracy: 43.1 %\n",
      "Training round [62/200], qnn_train_step: [2000/500], loss: 1.6456574201583862, accuracy: 44.3 %\n",
      "Training round [62/200], qnn_train_step: [2100/500], loss: 1.6419364213943481, accuracy: 43.3 %\n",
      "Training round [62/200], qnn_train_step: [2200/500], loss: 1.6396105289459229, accuracy: 43.1 %\n",
      "Training round [62/200], qnn_train_step: [2300/500], loss: 1.6451570987701416, accuracy: 43.1 %\n",
      "Training round [62/200], qnn_train_step: [2400/500], loss: 1.641759991645813, accuracy: 43.9 %\n",
      "Training round [62/200], qnn_train_step: [2500/500], loss: 1.6393753290176392, accuracy: 43.1 %\n",
      "Training round [62/200], qnn_train_step: [2600/500], loss: 1.6451148986816406, accuracy: 43.0 %\n",
      "Training round [62/200], qnn_train_step: [2700/500], loss: 1.6414649486541748, accuracy: 44.1 %\n",
      "Training round [62/200], qnn_train_step: [2800/500], loss: 1.6400773525238037, accuracy: 43.5 %\n",
      "Training round [62/200], qnn_train_step: [2900/500], loss: 1.6381981372833252, accuracy: 43.3 %\n",
      "Training round [62/200], qnn_train_step: [3000/500], loss: 1.6404459476470947, accuracy: 42.6 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 1.5825, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 1.6426, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 1.5491, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 1.6590, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 1.6126, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 1.5055, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 1.5279, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 1.4379, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 1.5812, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 1.4043, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [63/200], qnn_train_step: [100/500], loss: 1.6085803508758545, accuracy: 44.6 %\n",
      "Training round [63/200], qnn_train_step: [200/500], loss: 1.593082070350647, accuracy: 46.0 %\n",
      "Training round [63/200], qnn_train_step: [300/500], loss: 2.018057107925415, accuracy: 35.6 %\n",
      "Training round [63/200], qnn_train_step: [400/500], loss: 1.6285030841827393, accuracy: 44.2 %\n",
      "Training round [63/200], qnn_train_step: [500/500], loss: 1.5928765535354614, accuracy: 46.0 %\n",
      "Training round [63/200], qnn_train_step: [600/500], loss: 2.0965898036956787, accuracy: 27.2 %\n",
      "Training round [63/200], qnn_train_step: [700/500], loss: 1.6289044618606567, accuracy: 44.6 %\n",
      "Training round [63/200], qnn_train_step: [800/500], loss: 1.5926152467727661, accuracy: 46.1 %\n",
      "Training round [63/200], qnn_train_step: [900/500], loss: 2.085336208343506, accuracy: 27.9 %\n",
      "Training round [63/200], qnn_train_step: [1000/500], loss: 1.7076833248138428, accuracy: 43.8 %\n",
      "Training round [63/200], qnn_train_step: [1100/500], loss: 1.6178371906280518, accuracy: 46.5 %\n",
      "Training round [63/200], qnn_train_step: [1200/500], loss: 1.6215972900390625, accuracy: 43.5 %\n",
      "Training round [63/200], qnn_train_step: [1300/500], loss: 1.5957536697387695, accuracy: 47.4 %\n",
      "Training round [63/200], qnn_train_step: [1400/500], loss: 1.6040174961090088, accuracy: 46.0 %\n",
      "Training round [63/200], qnn_train_step: [1500/500], loss: 1.5888352394104004, accuracy: 46.6 %\n",
      "Training round [63/200], qnn_train_step: [1600/500], loss: 1.5934481620788574, accuracy: 45.9 %\n",
      "Training round [63/200], qnn_train_step: [1700/500], loss: 1.5874677896499634, accuracy: 45.6 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 1.6552, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 1.6294, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 1.5621, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 1.7342, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 1.6474, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 1.4528, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 1.4645, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 1.5652, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 1.5058, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 1.5903, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [64/200], qnn_train_step: [100/500], loss: 1.5880414247512817, accuracy: 45.8 %\n",
      "Training round [64/200], qnn_train_step: [200/500], loss: 1.5570125579833984, accuracy: 47.6 %\n",
      "Training round [64/200], qnn_train_step: [300/500], loss: 2.101740837097168, accuracy: 35.7 %\n",
      "Training round [64/200], qnn_train_step: [400/500], loss: 1.5957168340682983, accuracy: 47.1 %\n",
      "Training round [64/200], qnn_train_step: [500/500], loss: 1.5568917989730835, accuracy: 47.6 %\n",
      "Training round [64/200], qnn_train_step: [600/500], loss: 2.297119379043579, accuracy: 24.0 %\n",
      "Training round [64/200], qnn_train_step: [700/500], loss: 1.6395777463912964, accuracy: 45.1 %\n",
      "Training round [64/200], qnn_train_step: [800/500], loss: 1.6201518774032593, accuracy: 45.6 %\n",
      "Training round [64/200], qnn_train_step: [900/500], loss: 1.573191523551941, accuracy: 46.8 %\n",
      "Training round [64/200], qnn_train_step: [1000/500], loss: 1.565095067024231, accuracy: 47.5 %\n",
      "Training round [64/200], qnn_train_step: [1100/500], loss: 1.5604854822158813, accuracy: 47.5 %\n",
      "Training round [64/200], qnn_train_step: [1200/500], loss: 1.5620495080947876, accuracy: 47.8 %\n",
      "Training round [64/200], qnn_train_step: [1300/500], loss: 1.5552737712860107, accuracy: 48.3 %\n",
      "Training round [64/200], qnn_train_step: [1400/500], loss: 1.5567505359649658, accuracy: 48.2 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 1.6847, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 1.5424, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 1.4774, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 1.5074, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 1.6220, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 1.5912, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 1.6046, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 1.3507, batch time: 0.03, accuracy:  57.03%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 1.6509, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 1.6768, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [65/200], qnn_train_step: [100/500], loss: 1.5535832643508911, accuracy: 46.9 %\n",
      "Training round [65/200], qnn_train_step: [200/500], loss: 1.5321930646896362, accuracy: 47.3 %\n",
      "Training round [65/200], qnn_train_step: [300/500], loss: 2.071237564086914, accuracy: 31.1 %\n",
      "Training round [65/200], qnn_train_step: [400/500], loss: 1.5826663970947266, accuracy: 45.1 %\n",
      "Training round [65/200], qnn_train_step: [500/500], loss: 1.532118558883667, accuracy: 46.9 %\n",
      "Training round [65/200], qnn_train_step: [600/500], loss: 2.4212889671325684, accuracy: 23.1 %\n",
      "Training round [65/200], qnn_train_step: [700/500], loss: 1.585877537727356, accuracy: 44.6 %\n",
      "Training round [65/200], qnn_train_step: [800/500], loss: 1.880923867225647, accuracy: 36.2 %\n",
      "Training round [65/200], qnn_train_step: [900/500], loss: 1.5809895992279053, accuracy: 45.1 %\n",
      "Training round [65/200], qnn_train_step: [1000/500], loss: 1.5836169719696045, accuracy: 45.2 %\n",
      "Training round [65/200], qnn_train_step: [1100/500], loss: 1.5598522424697876, accuracy: 46.8 %\n",
      "Training round [65/200], qnn_train_step: [1200/500], loss: 1.5515525341033936, accuracy: 45.9 %\n",
      "Training round [65/200], qnn_train_step: [1300/500], loss: 1.541873574256897, accuracy: 46.4 %\n",
      "Training round [65/200], qnn_train_step: [1400/500], loss: 1.5318422317504883, accuracy: 47.1 %\n",
      "Training round [65/200], qnn_train_step: [1500/500], loss: 1.5485334396362305, accuracy: 48.6 %\n",
      "Training round [65/200], qnn_train_step: [1600/500], loss: 1.5416603088378906, accuracy: 47.4 %\n",
      "Training round [65/200], qnn_train_step: [1700/500], loss: 1.5318143367767334, accuracy: 47.0 %\n",
      "Training round [65/200], qnn_train_step: [1800/500], loss: 1.5509718656539917, accuracy: 45.7 %\n",
      "Training round [65/200], qnn_train_step: [1900/500], loss: 1.5416181087493896, accuracy: 47.8 %\n",
      "Training round [65/200], qnn_train_step: [2000/500], loss: 1.532088279724121, accuracy: 47.2 %\n",
      "Training round [65/200], qnn_train_step: [2100/500], loss: 1.5527037382125854, accuracy: 45.7 %\n",
      "Training round [65/200], qnn_train_step: [2200/500], loss: 1.541286587715149, accuracy: 46.6 %\n",
      "Training round [65/200], qnn_train_step: [2300/500], loss: 1.532731533050537, accuracy: 47.3 %\n",
      "Training round [65/200], qnn_train_step: [2400/500], loss: 1.5301893949508667, accuracy: 47.6 %\n",
      "Training round [65/200], qnn_train_step: [2500/500], loss: 1.5410205125808716, accuracy: 46.7 %\n",
      "Training round [65/200], qnn_train_step: [2600/500], loss: 1.53367018699646, accuracy: 47.1 %\n",
      "Training round [65/200], qnn_train_step: [2700/500], loss: 1.5309209823608398, accuracy: 47.6 %\n",
      "Training round [65/200], qnn_train_step: [2800/500], loss: 1.540991187095642, accuracy: 47.6 %\n",
      "Training round [65/200], qnn_train_step: [2900/500], loss: 1.5585108995437622, accuracy: 45.6 %\n",
      "Training round [65/200], qnn_train_step: [3000/500], loss: 1.5329705476760864, accuracy: 47.6 %\n",
      "Training round [65/200], qnn_train_step: [3100/500], loss: 1.5415782928466797, accuracy: 46.4 %\n",
      "Training round [65/200], qnn_train_step: [3200/500], loss: 1.5245373249053955, accuracy: 48.1 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 1.5924, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 1.5041, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 1.5145, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 1.5861, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 1.7175, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 1.5508, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 1.6039, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 1.4555, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 1.5647, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 1.6420, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [66/200], qnn_train_step: [100/500], loss: 1.556441068649292, accuracy: 46.5 %\n",
      "Training round [66/200], qnn_train_step: [200/500], loss: 1.5364184379577637, accuracy: 48.5 %\n",
      "Training round [66/200], qnn_train_step: [300/500], loss: 2.206411600112915, accuracy: 28.0 %\n",
      "Training round [66/200], qnn_train_step: [400/500], loss: 1.5884910821914673, accuracy: 45.6 %\n",
      "Training round [66/200], qnn_train_step: [500/500], loss: 1.5362675189971924, accuracy: 48.5 %\n",
      "Training round [66/200], qnn_train_step: [600/500], loss: 2.4588582515716553, accuracy: 25.5 %\n",
      "Training round [66/200], qnn_train_step: [700/500], loss: 1.5884095430374146, accuracy: 45.9 %\n",
      "Training round [66/200], qnn_train_step: [800/500], loss: 1.7868212461471558, accuracy: 42.8 %\n",
      "Training round [66/200], qnn_train_step: [900/500], loss: 1.5885258913040161, accuracy: 44.7 %\n",
      "Training round [66/200], qnn_train_step: [1000/500], loss: 1.5899513959884644, accuracy: 45.1 %\n",
      "Training round [66/200], qnn_train_step: [1100/500], loss: 1.5592061281204224, accuracy: 46.5 %\n",
      "Training round [66/200], qnn_train_step: [1200/500], loss: 1.5441561937332153, accuracy: 47.6 %\n",
      "Training round [66/200], qnn_train_step: [1300/500], loss: 1.5360236167907715, accuracy: 48.6 %\n",
      "Training round [66/200], qnn_train_step: [1400/500], loss: 1.5519578456878662, accuracy: 48.6 %\n",
      "Training round [66/200], qnn_train_step: [1500/500], loss: 1.5438568592071533, accuracy: 47.6 %\n",
      "Training round [66/200], qnn_train_step: [1600/500], loss: 1.5358613729476929, accuracy: 48.6 %\n",
      "Training round [66/200], qnn_train_step: [1700/500], loss: 1.5523076057434082, accuracy: 47.8 %\n",
      "Training round [66/200], qnn_train_step: [1800/500], loss: 1.5442354679107666, accuracy: 47.4 %\n",
      "Training round [66/200], qnn_train_step: [1900/500], loss: 1.5357598066329956, accuracy: 48.6 %\n",
      "Training round [66/200], qnn_train_step: [2000/500], loss: 1.552320122718811, accuracy: 46.8 %\n",
      "Training round [66/200], qnn_train_step: [2100/500], loss: 1.5442293882369995, accuracy: 47.2 %\n",
      "Training round [66/200], qnn_train_step: [2200/500], loss: 1.5356717109680176, accuracy: 48.6 %\n",
      "Training round [66/200], qnn_train_step: [2300/500], loss: 1.5518524646759033, accuracy: 46.7 %\n",
      "Training round [66/200], qnn_train_step: [2400/500], loss: 1.5440089702606201, accuracy: 47.8 %\n",
      "Training round [66/200], qnn_train_step: [2500/500], loss: 1.535585880279541, accuracy: 48.6 %\n",
      "Training round [66/200], qnn_train_step: [2600/500], loss: 1.5516363382339478, accuracy: 47.3 %\n",
      "Training round [66/200], qnn_train_step: [2700/500], loss: 1.5437167882919312, accuracy: 47.3 %\n",
      "Training round [66/200], qnn_train_step: [2800/500], loss: 1.5355288982391357, accuracy: 48.5 %\n",
      "Training round [66/200], qnn_train_step: [2900/500], loss: 1.5513516664505005, accuracy: 47.0 %\n",
      "Training round [66/200], qnn_train_step: [3000/500], loss: 1.5436615943908691, accuracy: 47.4 %\n",
      "Training round [66/200], qnn_train_step: [3100/500], loss: 1.5354443788528442, accuracy: 48.5 %\n",
      "Training round [66/200], qnn_train_step: [3200/500], loss: 1.5510724782943726, accuracy: 48.2 %\n",
      "Training round [66/200], qnn_train_step: [3300/500], loss: 1.5435290336608887, accuracy: 47.8 %\n",
      "Training round [66/200], qnn_train_step: [3400/500], loss: 1.5353260040283203, accuracy: 48.5 %\n",
      "Training round [66/200], qnn_train_step: [3500/500], loss: 1.5506490468978882, accuracy: 48.2 %\n",
      "Training round [66/200], qnn_train_step: [3600/500], loss: 1.543205738067627, accuracy: 46.6 %\n",
      "Training round [66/200], qnn_train_step: [3700/500], loss: 1.5352567434310913, accuracy: 48.6 %\n",
      "Training round [66/200], qnn_train_step: [3800/500], loss: 1.5503313541412354, accuracy: 47.9 %\n",
      "Training round [66/200], qnn_train_step: [3900/500], loss: 1.5429346561431885, accuracy: 46.4 %\n",
      "Training round [66/200], qnn_train_step: [4000/500], loss: 1.5351898670196533, accuracy: 48.6 %\n",
      "Training round [66/200], qnn_train_step: [4100/500], loss: 1.550039529800415, accuracy: 46.3 %\n",
      "Training round [66/200], qnn_train_step: [4200/500], loss: 1.5427113771438599, accuracy: 46.8 %\n",
      "Training round [66/200], qnn_train_step: [4300/500], loss: 1.535098671913147, accuracy: 48.6 %\n",
      "Training round [66/200], qnn_train_step: [4400/500], loss: 1.549514889717102, accuracy: 46.3 %\n",
      "Training round [66/200], qnn_train_step: [4500/500], loss: 1.5428258180618286, accuracy: 47.8 %\n",
      "Training round [66/200], qnn_train_step: [4600/500], loss: 1.5350276231765747, accuracy: 48.6 %\n",
      "Training round [66/200], qnn_train_step: [4700/500], loss: 1.5491313934326172, accuracy: 48.4 %\n",
      "Training round [66/200], qnn_train_step: [4800/500], loss: 1.5425044298171997, accuracy: 47.8 %\n",
      "Training round [66/200], qnn_train_step: [4900/500], loss: 1.534977912902832, accuracy: 48.6 %\n",
      "Training round [66/200], qnn_train_step: [5000/500], loss: 1.5489566326141357, accuracy: 46.1 %\n",
      "Training round [66/200], qnn_train_step: [5100/500], loss: 1.542539358139038, accuracy: 47.7 %\n",
      "Training round [66/200], qnn_train_step: [5200/500], loss: 1.5350050926208496, accuracy: 48.7 %\n",
      "Training round [66/200], qnn_train_step: [5300/500], loss: 1.5676831007003784, accuracy: 46.2 %\n",
      "Training round [66/200], qnn_train_step: [5400/500], loss: 1.5424295663833618, accuracy: 47.3 %\n",
      "Training round [66/200], qnn_train_step: [5500/500], loss: 1.5352439880371094, accuracy: 48.7 %\n",
      "Training round [66/200], qnn_train_step: [5600/500], loss: 1.5727899074554443, accuracy: 45.9 %\n",
      "Training round [66/200], qnn_train_step: [5700/500], loss: 1.542201042175293, accuracy: 48.5 %\n",
      "Training round [66/200], qnn_train_step: [5800/500], loss: 1.5357164144515991, accuracy: 47.8 %\n",
      "Training round [66/200], qnn_train_step: [5900/500], loss: 1.5334076881408691, accuracy: 47.5 %\n",
      "Training round [66/200], qnn_train_step: [6000/500], loss: 1.5420948266983032, accuracy: 48.1 %\n",
      "Training round [66/200], qnn_train_step: [6100/500], loss: 1.5358401536941528, accuracy: 48.3 %\n",
      "Training round [66/200], qnn_train_step: [6200/500], loss: 1.5342179536819458, accuracy: 48.7 %\n",
      "Training round [66/200], qnn_train_step: [6300/500], loss: 1.5418322086334229, accuracy: 48.1 %\n",
      "Training round [66/200], qnn_train_step: [6400/500], loss: 1.536332607269287, accuracy: 48.5 %\n",
      "Training round [66/200], qnn_train_step: [6500/500], loss: 1.5342299938201904, accuracy: 48.5 %\n",
      "Training round [66/200], qnn_train_step: [6600/500], loss: 1.5417405366897583, accuracy: 47.9 %\n",
      "Training round [66/200], qnn_train_step: [6700/500], loss: 1.5363472700119019, accuracy: 46.7 %\n",
      "Training round [66/200], qnn_train_step: [6800/500], loss: 1.5343719720840454, accuracy: 48.8 %\n",
      "Training round [66/200], qnn_train_step: [6900/500], loss: 1.5415703058242798, accuracy: 47.6 %\n",
      "Training round [66/200], qnn_train_step: [7000/500], loss: 1.536499261856079, accuracy: 48.5 %\n",
      "Training round [66/200], qnn_train_step: [7100/500], loss: 1.5345340967178345, accuracy: 48.7 %\n",
      "Training round [66/200], qnn_train_step: [7200/500], loss: 1.5415418148040771, accuracy: 48.8 %\n",
      "Training round [66/200], qnn_train_step: [7300/500], loss: 1.5363123416900635, accuracy: 48.0 %\n",
      "Training round [66/200], qnn_train_step: [7400/500], loss: 1.5343153476715088, accuracy: 48.8 %\n",
      "Training round [66/200], qnn_train_step: [7500/500], loss: 1.5414921045303345, accuracy: 47.4 %\n",
      "Training round [66/200], qnn_train_step: [7600/500], loss: 1.5364385843276978, accuracy: 48.2 %\n",
      "Training round [66/200], qnn_train_step: [7700/500], loss: 1.539205551147461, accuracy: 47.9 %\n",
      "Training round [66/200], qnn_train_step: [7800/500], loss: 1.5304007530212402, accuracy: 49.3 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 1.4962, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 1.6079, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 1.6375, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 1.5601, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 1.6476, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 1.5107, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 1.4495, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 1.5011, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 1.5788, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 1.5649, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [67/200], qnn_train_step: [100/500], loss: 1.586029052734375, accuracy: 47.3 %\n",
      "Training round [67/200], qnn_train_step: [200/500], loss: 1.5487401485443115, accuracy: 49.2 %\n",
      "Training round [67/200], qnn_train_step: [300/500], loss: 1.8869022130966187, accuracy: 36.5 %\n",
      "Training round [67/200], qnn_train_step: [400/500], loss: 1.576270341873169, accuracy: 47.5 %\n",
      "Training round [67/200], qnn_train_step: [500/500], loss: 1.5481511354446411, accuracy: 49.3 %\n",
      "Training round [67/200], qnn_train_step: [600/500], loss: 1.9441828727722168, accuracy: 37.0 %\n",
      "Training round [67/200], qnn_train_step: [700/500], loss: 1.5805739164352417, accuracy: 48.8 %\n",
      "Training round [67/200], qnn_train_step: [800/500], loss: 1.547747015953064, accuracy: 49.3 %\n",
      "Training round [67/200], qnn_train_step: [900/500], loss: 1.9627224206924438, accuracy: 32.0 %\n",
      "Training round [67/200], qnn_train_step: [1000/500], loss: 1.5845069885253906, accuracy: 47.9 %\n",
      "Training round [67/200], qnn_train_step: [1100/500], loss: 1.5472133159637451, accuracy: 49.2 %\n",
      "Training round [67/200], qnn_train_step: [1200/500], loss: 2.062516450881958, accuracy: 32.0 %\n",
      "Training round [67/200], qnn_train_step: [1300/500], loss: 1.585481882095337, accuracy: 48.8 %\n",
      "Training round [67/200], qnn_train_step: [1400/500], loss: 1.5467064380645752, accuracy: 49.2 %\n",
      "Training round [67/200], qnn_train_step: [1500/500], loss: 2.235281229019165, accuracy: 37.2 %\n",
      "Training round [67/200], qnn_train_step: [1600/500], loss: 1.8487836122512817, accuracy: 39.7 %\n",
      "Training round [67/200], qnn_train_step: [1700/500], loss: 1.60391366481781, accuracy: 47.2 %\n",
      "Training round [67/200], qnn_train_step: [1800/500], loss: 1.5534625053405762, accuracy: 49.0 %\n",
      "Training round [67/200], qnn_train_step: [1900/500], loss: 1.5430712699890137, accuracy: 49.7 %\n",
      "Training round [67/200], qnn_train_step: [2000/500], loss: 1.5401439666748047, accuracy: 49.7 %\n",
      "Training round [67/200], qnn_train_step: [2100/500], loss: 1.551274299621582, accuracy: 49.2 %\n",
      "Training round [67/200], qnn_train_step: [2200/500], loss: 1.5371320247650146, accuracy: 49.4 %\n",
      "Training round [67/200], qnn_train_step: [2300/500], loss: 1.5373886823654175, accuracy: 49.2 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 1.5132, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 1.7057, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 1.5180, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 1.4942, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 1.4103, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 1.5603, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 1.7593, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 1.6898, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 1.5610, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 1.4680, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [68/200], qnn_train_step: [100/500], loss: 1.4952054023742676, accuracy: 49.1 %\n",
      "Training round [68/200], qnn_train_step: [200/500], loss: 1.4797905683517456, accuracy: 50.1 %\n",
      "Training round [68/200], qnn_train_step: [300/500], loss: 1.99057936668396, accuracy: 35.3 %\n",
      "Training round [68/200], qnn_train_step: [400/500], loss: 1.520922064781189, accuracy: 47.5 %\n",
      "Training round [68/200], qnn_train_step: [500/500], loss: 1.4798322916030884, accuracy: 50.4 %\n",
      "Training round [68/200], qnn_train_step: [600/500], loss: 1.9950826168060303, accuracy: 31.5 %\n",
      "Training round [68/200], qnn_train_step: [700/500], loss: 1.5229865312576294, accuracy: 48.5 %\n",
      "Training round [68/200], qnn_train_step: [800/500], loss: 1.4800480604171753, accuracy: 50.6 %\n",
      "Training round [68/200], qnn_train_step: [900/500], loss: 2.0875887870788574, accuracy: 30.7 %\n",
      "Training round [68/200], qnn_train_step: [1000/500], loss: 1.5239248275756836, accuracy: 47.5 %\n",
      "Training round [68/200], qnn_train_step: [1100/500], loss: 1.4808290004730225, accuracy: 50.3 %\n",
      "Training round [68/200], qnn_train_step: [1200/500], loss: 8.812307357788086, accuracy: 13.0 %\n",
      "Training round [68/200], qnn_train_step: [1300/500], loss: 1.5256986618041992, accuracy: 50.4 %\n",
      "Training round [68/200], qnn_train_step: [1400/500], loss: 1.480790138244629, accuracy: 50.2 %\n",
      "Training round [68/200], qnn_train_step: [1500/500], loss: 5.425441265106201, accuracy: 13.0 %\n",
      "Training round [68/200], qnn_train_step: [1600/500], loss: 1.7801011800765991, accuracy: 42.6 %\n",
      "Training round [68/200], qnn_train_step: [1700/500], loss: 1.6056348085403442, accuracy: 46.7 %\n",
      "Training round [68/200], qnn_train_step: [1800/500], loss: 1.5295631885528564, accuracy: 48.3 %\n",
      "Training round [68/200], qnn_train_step: [1900/500], loss: 1.4973549842834473, accuracy: 48.5 %\n",
      "Training round [68/200], qnn_train_step: [2000/500], loss: 1.487786054611206, accuracy: 50.2 %\n",
      "Training round [68/200], qnn_train_step: [2100/500], loss: 1.484474539756775, accuracy: 49.7 %\n",
      "Training round [68/200], qnn_train_step: [2200/500], loss: 1.482570767402649, accuracy: 50.3 %\n",
      "Training round [68/200], qnn_train_step: [2300/500], loss: 1.4808827638626099, accuracy: 50.1 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 1.5718, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 1.3545, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 1.4524, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 1.4341, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 1.6824, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 1.5513, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 1.4807, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 1.4456, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 1.4822, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 1.5655, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [69/200], qnn_train_step: [100/500], loss: 1.5813816785812378, accuracy: 46.0 %\n",
      "Training round [69/200], qnn_train_step: [200/500], loss: 1.5499656200408936, accuracy: 48.6 %\n",
      "Training round [69/200], qnn_train_step: [300/500], loss: 1.8263520002365112, accuracy: 39.3 %\n",
      "Training round [69/200], qnn_train_step: [400/500], loss: 1.5699832439422607, accuracy: 49.8 %\n",
      "Training round [69/200], qnn_train_step: [500/500], loss: 1.5494801998138428, accuracy: 48.6 %\n",
      "Training round [69/200], qnn_train_step: [600/500], loss: 1.8445717096328735, accuracy: 37.2 %\n",
      "Training round [69/200], qnn_train_step: [700/500], loss: 1.56825590133667, accuracy: 46.8 %\n",
      "Training round [69/200], qnn_train_step: [800/500], loss: 1.5490704774856567, accuracy: 48.6 %\n",
      "Training round [69/200], qnn_train_step: [900/500], loss: 1.8129734992980957, accuracy: 39.5 %\n",
      "Training round [69/200], qnn_train_step: [1000/500], loss: 1.5683130025863647, accuracy: 49.8 %\n",
      "Training round [69/200], qnn_train_step: [1100/500], loss: 1.548598051071167, accuracy: 48.6 %\n",
      "Training round [69/200], qnn_train_step: [1200/500], loss: 1.8278694152832031, accuracy: 37.6 %\n",
      "Training round [69/200], qnn_train_step: [1300/500], loss: 1.5729063749313354, accuracy: 47.8 %\n",
      "Training round [69/200], qnn_train_step: [1400/500], loss: 1.5482277870178223, accuracy: 48.6 %\n",
      "Training round [69/200], qnn_train_step: [1500/500], loss: 1.8378652334213257, accuracy: 37.5 %\n",
      "Training round [69/200], qnn_train_step: [1600/500], loss: 1.5721006393432617, accuracy: 47.4 %\n",
      "Training round [69/200], qnn_train_step: [1700/500], loss: 1.5477393865585327, accuracy: 48.6 %\n",
      "Training round [69/200], qnn_train_step: [1800/500], loss: 1.8401414155960083, accuracy: 39.0 %\n",
      "Training round [69/200], qnn_train_step: [1900/500], loss: 1.5741864442825317, accuracy: 48.8 %\n",
      "Training round [69/200], qnn_train_step: [2000/500], loss: 1.5473878383636475, accuracy: 48.6 %\n",
      "Training round [69/200], qnn_train_step: [2100/500], loss: 1.8829952478408813, accuracy: 33.5 %\n",
      "Training round [69/200], qnn_train_step: [2200/500], loss: 1.6007078886032104, accuracy: 46.5 %\n",
      "Training round [69/200], qnn_train_step: [2300/500], loss: 1.6195441484451294, accuracy: 44.7 %\n",
      "Training round [69/200], qnn_train_step: [2400/500], loss: 1.592256784439087, accuracy: 48.0 %\n",
      "Training round [69/200], qnn_train_step: [2500/500], loss: 1.5641329288482666, accuracy: 47.7 %\n",
      "Training round [69/200], qnn_train_step: [2600/500], loss: 1.5363167524337769, accuracy: 49.0 %\n",
      "Training round [69/200], qnn_train_step: [2700/500], loss: 1.535399317741394, accuracy: 49.0 %\n",
      "Training round [69/200], qnn_train_step: [2800/500], loss: 1.536234736442566, accuracy: 48.9 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 1.4765, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 1.5421, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 1.5849, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 1.5852, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 1.5159, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 1.5696, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 1.4914, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 1.5127, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 1.4352, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 1.6298, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [70/200], qnn_train_step: [100/500], loss: 1.6325711011886597, accuracy: 47.2 %\n",
      "Training round [70/200], qnn_train_step: [200/500], loss: 1.6036673784255981, accuracy: 48.6 %\n",
      "Training round [70/200], qnn_train_step: [300/500], loss: 2.2139298915863037, accuracy: 36.4 %\n",
      "Training round [70/200], qnn_train_step: [400/500], loss: 1.6511211395263672, accuracy: 46.8 %\n",
      "Training round [70/200], qnn_train_step: [500/500], loss: 1.603116512298584, accuracy: 48.6 %\n",
      "Training round [70/200], qnn_train_step: [600/500], loss: 2.3248209953308105, accuracy: 28.3 %\n",
      "Training round [70/200], qnn_train_step: [700/500], loss: 1.652543067932129, accuracy: 46.6 %\n",
      "Training round [70/200], qnn_train_step: [800/500], loss: 1.6026090383529663, accuracy: 48.4 %\n",
      "Training round [70/200], qnn_train_step: [900/500], loss: 8.485391616821289, accuracy: 12.5 %\n",
      "Training round [70/200], qnn_train_step: [1000/500], loss: 1.6559975147247314, accuracy: 44.1 %\n",
      "Training round [70/200], qnn_train_step: [1100/500], loss: 1.6020652055740356, accuracy: 48.6 %\n",
      "Training round [70/200], qnn_train_step: [1200/500], loss: 1.5909343957901, accuracy: 47.8 %\n",
      "Training round [70/200], qnn_train_step: [1300/500], loss: 1.6560419797897339, accuracy: 43.8 %\n",
      "Training round [70/200], qnn_train_step: [1400/500], loss: 1.6015859842300415, accuracy: 48.8 %\n",
      "Training round [70/200], qnn_train_step: [1500/500], loss: 1.5943247079849243, accuracy: 47.1 %\n",
      "Training round [70/200], qnn_train_step: [1600/500], loss: 1.6649171113967896, accuracy: 46.6 %\n",
      "Training round [70/200], qnn_train_step: [1700/500], loss: 1.6011420488357544, accuracy: 48.8 %\n",
      "Training round [70/200], qnn_train_step: [1800/500], loss: 1.5956482887268066, accuracy: 48.7 %\n",
      "Training round [70/200], qnn_train_step: [1900/500], loss: 1.6663920879364014, accuracy: 46.3 %\n",
      "Training round [70/200], qnn_train_step: [2000/500], loss: 1.6007875204086304, accuracy: 48.7 %\n",
      "Training round [70/200], qnn_train_step: [2100/500], loss: 6.576722621917725, accuracy: 18.7 %\n",
      "Training round [70/200], qnn_train_step: [2200/500], loss: 1.709761619567871, accuracy: 46.5 %\n",
      "Training round [70/200], qnn_train_step: [2300/500], loss: 1.6141384840011597, accuracy: 45.8 %\n",
      "Training round [70/200], qnn_train_step: [2400/500], loss: 1.62007737159729, accuracy: 47.8 %\n",
      "Training round [70/200], qnn_train_step: [2500/500], loss: 1.6167477369308472, accuracy: 47.2 %\n",
      "Training round [70/200], qnn_train_step: [2600/500], loss: 1.5904194116592407, accuracy: 47.5 %\n",
      "Training round [70/200], qnn_train_step: [2700/500], loss: 1.5975669622421265, accuracy: 48.2 %\n",
      "Training round [70/200], qnn_train_step: [2800/500], loss: 1.5945219993591309, accuracy: 47.0 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 1.6940, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 1.5769, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 1.7030, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 1.6085, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 1.6312, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 1.7215, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 1.8059, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 1.5780, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 1.5981, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 1.5104, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [71/200], qnn_train_step: [100/500], loss: 1.5852904319763184, accuracy: 45.5 %\n",
      "Training round [71/200], qnn_train_step: [200/500], loss: 1.5622427463531494, accuracy: 46.8 %\n",
      "Training round [71/200], qnn_train_step: [300/500], loss: 1.8988925218582153, accuracy: 38.7 %\n",
      "Training round [71/200], qnn_train_step: [400/500], loss: 1.589580774307251, accuracy: 46.6 %\n",
      "Training round [71/200], qnn_train_step: [500/500], loss: 1.5621296167373657, accuracy: 46.8 %\n",
      "Training round [71/200], qnn_train_step: [600/500], loss: 2.0291898250579834, accuracy: 35.4 %\n",
      "Training round [71/200], qnn_train_step: [700/500], loss: 1.5957471132278442, accuracy: 44.3 %\n",
      "Training round [71/200], qnn_train_step: [800/500], loss: 1.5620230436325073, accuracy: 46.9 %\n",
      "Training round [71/200], qnn_train_step: [900/500], loss: 2.0219504833221436, accuracy: 31.9 %\n",
      "Training round [71/200], qnn_train_step: [1000/500], loss: 1.5973989963531494, accuracy: 46.0 %\n",
      "Training round [71/200], qnn_train_step: [1100/500], loss: 1.5618966817855835, accuracy: 46.9 %\n",
      "Training round [71/200], qnn_train_step: [1200/500], loss: 2.0861499309539795, accuracy: 28.5 %\n",
      "Training round [71/200], qnn_train_step: [1300/500], loss: 1.5991748571395874, accuracy: 45.6 %\n",
      "Training round [71/200], qnn_train_step: [1400/500], loss: 1.5618141889572144, accuracy: 46.9 %\n",
      "Training round [71/200], qnn_train_step: [1500/500], loss: 2.1416993141174316, accuracy: 31.6 %\n",
      "Training round [71/200], qnn_train_step: [1600/500], loss: 1.6057864427566528, accuracy: 45.1 %\n",
      "Training round [71/200], qnn_train_step: [1700/500], loss: 1.5617784261703491, accuracy: 46.9 %\n",
      "Training round [71/200], qnn_train_step: [1800/500], loss: 8.306323051452637, accuracy: 10.8 %\n",
      "Training round [71/200], qnn_train_step: [1900/500], loss: 1.7405407428741455, accuracy: 43.4 %\n",
      "Training round [71/200], qnn_train_step: [2000/500], loss: 1.6391644477844238, accuracy: 43.6 %\n",
      "Training round [71/200], qnn_train_step: [2100/500], loss: 1.5816001892089844, accuracy: 44.7 %\n",
      "Training round [71/200], qnn_train_step: [2200/500], loss: 1.5920981168746948, accuracy: 45.0 %\n",
      "Training round [71/200], qnn_train_step: [2300/500], loss: 1.5762407779693604, accuracy: 46.5 %\n",
      "Training round [71/200], qnn_train_step: [2400/500], loss: 1.5738215446472168, accuracy: 47.1 %\n",
      "Training round [71/200], qnn_train_step: [2500/500], loss: 1.5684256553649902, accuracy: 46.4 %\n",
      "Training round [71/200], qnn_train_step: [2600/500], loss: 1.5671613216400146, accuracy: 46.2 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 1.5064, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 1.4837, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 1.5685, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 1.3499, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 1.5256, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 1.5106, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 1.7590, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 1.6445, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 1.4739, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 1.6463, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [72/200], qnn_train_step: [100/500], loss: 1.5784791707992554, accuracy: 47.3 %\n",
      "Training round [72/200], qnn_train_step: [200/500], loss: 1.5549404621124268, accuracy: 47.1 %\n",
      "Training round [72/200], qnn_train_step: [300/500], loss: 1.9797052145004272, accuracy: 33.5 %\n",
      "Training round [72/200], qnn_train_step: [400/500], loss: 1.5988701581954956, accuracy: 45.3 %\n",
      "Training round [72/200], qnn_train_step: [500/500], loss: 1.5539052486419678, accuracy: 47.0 %\n",
      "Training round [72/200], qnn_train_step: [600/500], loss: 1.9813734292984009, accuracy: 37.7 %\n",
      "Training round [72/200], qnn_train_step: [700/500], loss: 1.5980215072631836, accuracy: 45.7 %\n",
      "Training round [72/200], qnn_train_step: [800/500], loss: 1.5529887676239014, accuracy: 47.0 %\n",
      "Training round [72/200], qnn_train_step: [900/500], loss: 2.0542490482330322, accuracy: 29.5 %\n",
      "Training round [72/200], qnn_train_step: [1000/500], loss: 1.6014798879623413, accuracy: 46.3 %\n",
      "Training round [72/200], qnn_train_step: [1100/500], loss: 1.551987886428833, accuracy: 47.0 %\n",
      "Training round [72/200], qnn_train_step: [1200/500], loss: 2.252152919769287, accuracy: 28.3 %\n",
      "Training round [72/200], qnn_train_step: [1300/500], loss: 1.6025973558425903, accuracy: 45.2 %\n",
      "Training round [72/200], qnn_train_step: [1400/500], loss: 1.5510227680206299, accuracy: 46.9 %\n",
      "Training round [72/200], qnn_train_step: [1500/500], loss: 2.3721673488616943, accuracy: 27.4 %\n",
      "Training round [72/200], qnn_train_step: [1600/500], loss: 1.602225422859192, accuracy: 46.0 %\n",
      "Training round [72/200], qnn_train_step: [1700/500], loss: 1.5500571727752686, accuracy: 46.9 %\n",
      "Training round [72/200], qnn_train_step: [1800/500], loss: 8.031745910644531, accuracy: 11.6 %\n",
      "Training round [72/200], qnn_train_step: [1900/500], loss: 1.6041744947433472, accuracy: 44.5 %\n",
      "Training round [72/200], qnn_train_step: [2000/500], loss: 1.5491669178009033, accuracy: 47.0 %\n",
      "Training round [72/200], qnn_train_step: [2100/500], loss: 4.776562690734863, accuracy: 11.7 %\n",
      "Training round [72/200], qnn_train_step: [2200/500], loss: 1.58522629737854, accuracy: 46.1 %\n",
      "Training round [72/200], qnn_train_step: [2300/500], loss: 1.5535340309143066, accuracy: 49.5 %\n",
      "Training round [72/200], qnn_train_step: [2400/500], loss: 1.545052170753479, accuracy: 48.1 %\n",
      "Training round [72/200], qnn_train_step: [2500/500], loss: 1.5353189706802368, accuracy: 48.0 %\n",
      "Training round [72/200], qnn_train_step: [2600/500], loss: 1.5307557582855225, accuracy: 47.4 %\n",
      "Training round [72/200], qnn_train_step: [2700/500], loss: 1.536755084991455, accuracy: 48.7 %\n",
      "Training round [72/200], qnn_train_step: [2800/500], loss: 1.5245494842529297, accuracy: 47.0 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 1.5361, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 1.5385, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 1.4541, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 1.5865, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 1.5233, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 1.4344, batch time: 0.03, accuracy:  53.12%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 1.6680, batch time: 0.06, accuracy:  39.84%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 1.5375, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 1.5731, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 1.4289, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [73/200], qnn_train_step: [100/500], loss: 1.5704004764556885, accuracy: 45.0 %\n",
      "Training round [73/200], qnn_train_step: [200/500], loss: 1.5395420789718628, accuracy: 46.7 %\n",
      "Training round [73/200], qnn_train_step: [300/500], loss: 1.7611052989959717, accuracy: 42.8 %\n",
      "Training round [73/200], qnn_train_step: [400/500], loss: 1.5492353439331055, accuracy: 47.0 %\n",
      "Training round [73/200], qnn_train_step: [500/500], loss: 1.5390431880950928, accuracy: 46.7 %\n",
      "Training round [73/200], qnn_train_step: [600/500], loss: 1.7730145454406738, accuracy: 40.3 %\n",
      "Training round [73/200], qnn_train_step: [700/500], loss: 1.5539103746414185, accuracy: 47.3 %\n",
      "Training round [73/200], qnn_train_step: [800/500], loss: 1.5384328365325928, accuracy: 46.8 %\n",
      "Training round [73/200], qnn_train_step: [900/500], loss: 1.8065457344055176, accuracy: 39.6 %\n",
      "Training round [73/200], qnn_train_step: [1000/500], loss: 1.5537052154541016, accuracy: 46.1 %\n",
      "Training round [73/200], qnn_train_step: [1100/500], loss: 1.5379729270935059, accuracy: 46.8 %\n",
      "Training round [73/200], qnn_train_step: [1200/500], loss: 1.8317880630493164, accuracy: 37.6 %\n",
      "Training round [73/200], qnn_train_step: [1300/500], loss: 1.5560839176177979, accuracy: 46.4 %\n",
      "Training round [73/200], qnn_train_step: [1400/500], loss: 1.5374211072921753, accuracy: 46.7 %\n",
      "Training round [73/200], qnn_train_step: [1500/500], loss: 1.8490188121795654, accuracy: 41.6 %\n",
      "Training round [73/200], qnn_train_step: [1600/500], loss: 1.5583288669586182, accuracy: 46.2 %\n",
      "Training round [73/200], qnn_train_step: [1700/500], loss: 1.536960482597351, accuracy: 46.8 %\n",
      "Training round [73/200], qnn_train_step: [1800/500], loss: 1.847357988357544, accuracy: 39.5 %\n",
      "Training round [73/200], qnn_train_step: [1900/500], loss: 1.5590187311172485, accuracy: 46.3 %\n",
      "Training round [73/200], qnn_train_step: [2000/500], loss: 1.5365321636199951, accuracy: 46.9 %\n",
      "Training round [73/200], qnn_train_step: [2100/500], loss: 1.8590582609176636, accuracy: 38.6 %\n",
      "Training round [73/200], qnn_train_step: [2200/500], loss: 1.5606961250305176, accuracy: 48.8 %\n",
      "Training round [73/200], qnn_train_step: [2300/500], loss: 1.7400219440460205, accuracy: 43.7 %\n",
      "Training round [73/200], qnn_train_step: [2400/500], loss: 1.5578327178955078, accuracy: 47.7 %\n",
      "Training round [73/200], qnn_train_step: [2500/500], loss: 1.5476738214492798, accuracy: 47.7 %\n",
      "Training round [73/200], qnn_train_step: [2600/500], loss: 1.530497431755066, accuracy: 48.7 %\n",
      "Training round [73/200], qnn_train_step: [2700/500], loss: 1.5210607051849365, accuracy: 48.1 %\n",
      "Training round [73/200], qnn_train_step: [2800/500], loss: 1.5295987129211426, accuracy: 47.7 %\n",
      "Training round [73/200], qnn_train_step: [2900/500], loss: 1.5268768072128296, accuracy: 47.9 %\n",
      "Training round [73/200], qnn_train_step: [3000/500], loss: 1.5206204652786255, accuracy: 47.9 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 1.5627, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 1.3184, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 1.6264, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 1.5077, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 1.5450, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 1.4049, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 1.6424, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 1.4207, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 1.7068, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 1.5132, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [74/200], qnn_train_step: [100/500], loss: 1.581344723701477, accuracy: 45.4 %\n",
      "Training round [74/200], qnn_train_step: [200/500], loss: 1.5407938957214355, accuracy: 48.1 %\n",
      "Training round [74/200], qnn_train_step: [300/500], loss: 1.7963186502456665, accuracy: 39.9 %\n",
      "Training round [74/200], qnn_train_step: [400/500], loss: 1.560678243637085, accuracy: 49.6 %\n",
      "Training round [74/200], qnn_train_step: [500/500], loss: 1.5404822826385498, accuracy: 48.0 %\n",
      "Training round [74/200], qnn_train_step: [600/500], loss: 1.8108097314834595, accuracy: 39.0 %\n",
      "Training round [74/200], qnn_train_step: [700/500], loss: 1.5630757808685303, accuracy: 47.0 %\n",
      "Training round [74/200], qnn_train_step: [800/500], loss: 1.5401841402053833, accuracy: 48.0 %\n",
      "Training round [74/200], qnn_train_step: [900/500], loss: 1.827196478843689, accuracy: 40.0 %\n",
      "Training round [74/200], qnn_train_step: [1000/500], loss: 1.567154049873352, accuracy: 47.2 %\n",
      "Training round [74/200], qnn_train_step: [1100/500], loss: 1.5398908853530884, accuracy: 48.0 %\n",
      "Training round [74/200], qnn_train_step: [1200/500], loss: 1.8273932933807373, accuracy: 41.5 %\n",
      "Training round [74/200], qnn_train_step: [1300/500], loss: 1.5672893524169922, accuracy: 46.8 %\n",
      "Training round [74/200], qnn_train_step: [1400/500], loss: 1.539617896080017, accuracy: 48.0 %\n",
      "Training round [74/200], qnn_train_step: [1500/500], loss: 1.8356807231903076, accuracy: 40.6 %\n",
      "Training round [74/200], qnn_train_step: [1600/500], loss: 1.57167649269104, accuracy: 48.6 %\n",
      "Training round [74/200], qnn_train_step: [1700/500], loss: 1.5393428802490234, accuracy: 47.9 %\n",
      "Training round [74/200], qnn_train_step: [1800/500], loss: 1.8709700107574463, accuracy: 38.4 %\n",
      "Training round [74/200], qnn_train_step: [1900/500], loss: 1.5744225978851318, accuracy: 45.3 %\n",
      "Training round [74/200], qnn_train_step: [2000/500], loss: 1.539001703262329, accuracy: 48.0 %\n",
      "Training round [74/200], qnn_train_step: [2100/500], loss: 1.904295802116394, accuracy: 40.5 %\n",
      "Training round [74/200], qnn_train_step: [2200/500], loss: 1.5755175352096558, accuracy: 45.3 %\n",
      "Training round [74/200], qnn_train_step: [2300/500], loss: 1.5387612581253052, accuracy: 48.1 %\n",
      "Training round [74/200], qnn_train_step: [2400/500], loss: 1.9153215885162354, accuracy: 37.0 %\n",
      "Training round [74/200], qnn_train_step: [2500/500], loss: 1.5776287317276, accuracy: 49.7 %\n",
      "Training round [74/200], qnn_train_step: [2600/500], loss: 1.5384595394134521, accuracy: 48.3 %\n",
      "Training round [74/200], qnn_train_step: [2700/500], loss: 1.947657823562622, accuracy: 39.3 %\n",
      "Training round [74/200], qnn_train_step: [2800/500], loss: 1.579740047454834, accuracy: 45.7 %\n",
      "Training round [74/200], qnn_train_step: [2900/500], loss: 1.5382188558578491, accuracy: 48.4 %\n",
      "Training round [74/200], qnn_train_step: [3000/500], loss: 7.760064125061035, accuracy: 12.3 %\n",
      "Training round [74/200], qnn_train_step: [3100/500], loss: 1.736309289932251, accuracy: 42.4 %\n",
      "Training round [74/200], qnn_train_step: [3200/500], loss: 1.6010841131210327, accuracy: 49.0 %\n",
      "Training round [74/200], qnn_train_step: [3300/500], loss: 1.5524953603744507, accuracy: 47.9 %\n",
      "Training round [74/200], qnn_train_step: [3400/500], loss: 1.5523033142089844, accuracy: 49.2 %\n",
      "Training round [74/200], qnn_train_step: [3500/500], loss: 1.5383825302124023, accuracy: 47.8 %\n",
      "Training round [74/200], qnn_train_step: [3600/500], loss: 1.5412291288375854, accuracy: 48.1 %\n",
      "Training round [74/200], qnn_train_step: [3700/500], loss: 1.5286870002746582, accuracy: 49.8 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 1.4850, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 1.4882, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 1.5403, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 1.5573, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 1.3374, batch time: 0.03, accuracy:  55.47%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 1.2878, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 1.5541, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 1.6570, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 1.6309, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 1.4740, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [75/200], qnn_train_step: [100/500], loss: 1.5648305416107178, accuracy: 47.9 %\n",
      "Training round [75/200], qnn_train_step: [200/500], loss: 1.5391205549240112, accuracy: 50.0 %\n",
      "Training round [75/200], qnn_train_step: [300/500], loss: 1.7861167192459106, accuracy: 41.4 %\n",
      "Training round [75/200], qnn_train_step: [400/500], loss: 1.558197021484375, accuracy: 49.5 %\n",
      "Training round [75/200], qnn_train_step: [500/500], loss: 1.5390373468399048, accuracy: 50.0 %\n",
      "Training round [75/200], qnn_train_step: [600/500], loss: 1.7927641868591309, accuracy: 43.6 %\n",
      "Training round [75/200], qnn_train_step: [700/500], loss: 1.5638870000839233, accuracy: 49.4 %\n",
      "Training round [75/200], qnn_train_step: [800/500], loss: 1.5389783382415771, accuracy: 50.0 %\n",
      "Training round [75/200], qnn_train_step: [900/500], loss: 1.8081797361373901, accuracy: 38.1 %\n",
      "Training round [75/200], qnn_train_step: [1000/500], loss: 1.5664712190628052, accuracy: 49.6 %\n",
      "Training round [75/200], qnn_train_step: [1100/500], loss: 1.5388845205307007, accuracy: 50.2 %\n",
      "Training round [75/200], qnn_train_step: [1200/500], loss: 1.8249348402023315, accuracy: 42.8 %\n",
      "Training round [75/200], qnn_train_step: [1300/500], loss: 1.5675896406173706, accuracy: 50.3 %\n",
      "Training round [75/200], qnn_train_step: [1400/500], loss: 1.5388097763061523, accuracy: 50.2 %\n",
      "Training round [75/200], qnn_train_step: [1500/500], loss: 1.847996711730957, accuracy: 39.4 %\n",
      "Training round [75/200], qnn_train_step: [1600/500], loss: 1.5683057308197021, accuracy: 49.4 %\n",
      "Training round [75/200], qnn_train_step: [1700/500], loss: 1.5387251377105713, accuracy: 50.0 %\n",
      "Training round [75/200], qnn_train_step: [1800/500], loss: 1.8534553050994873, accuracy: 42.9 %\n",
      "Training round [75/200], qnn_train_step: [1900/500], loss: 1.570396065711975, accuracy: 48.8 %\n",
      "Training round [75/200], qnn_train_step: [2000/500], loss: 1.538710117340088, accuracy: 50.1 %\n",
      "Training round [75/200], qnn_train_step: [2100/500], loss: 1.8545410633087158, accuracy: 42.0 %\n",
      "Training round [75/200], qnn_train_step: [2200/500], loss: 1.620499610900879, accuracy: 47.2 %\n",
      "Training round [75/200], qnn_train_step: [2300/500], loss: 1.593979835510254, accuracy: 47.6 %\n",
      "Training round [75/200], qnn_train_step: [2400/500], loss: 1.5825883150100708, accuracy: 48.6 %\n",
      "Training round [75/200], qnn_train_step: [2500/500], loss: 1.55144464969635, accuracy: 48.9 %\n",
      "Training round [75/200], qnn_train_step: [2600/500], loss: 1.542935848236084, accuracy: 50.2 %\n",
      "Training round [75/200], qnn_train_step: [2700/500], loss: 1.5408656597137451, accuracy: 50.1 %\n",
      "Training round [75/200], qnn_train_step: [2800/500], loss: 1.5478800535202026, accuracy: 49.8 %\n",
      "Training round [75/200], qnn_train_step: [2900/500], loss: 1.536405324935913, accuracy: 50.4 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 1.6967, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 1.6157, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 1.3567, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 1.6562, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 1.5720, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 1.6748, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 1.4642, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 1.5373, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 1.5427, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 1.7917, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [76/200], qnn_train_step: [100/500], loss: 1.558364987373352, accuracy: 48.7 %\n",
      "Training round [76/200], qnn_train_step: [200/500], loss: 1.5311428308486938, accuracy: 49.6 %\n",
      "Training round [76/200], qnn_train_step: [300/500], loss: 1.8239046335220337, accuracy: 41.7 %\n",
      "Training round [76/200], qnn_train_step: [400/500], loss: 1.5331785678863525, accuracy: 49.4 %\n",
      "Training round [76/200], qnn_train_step: [500/500], loss: 1.5279598236083984, accuracy: 51.4 %\n",
      "Training round [76/200], qnn_train_step: [600/500], loss: 1.6580851078033447, accuracy: 45.7 %\n",
      "Training round [76/200], qnn_train_step: [700/500], loss: 1.5329325199127197, accuracy: 51.9 %\n",
      "Training round [76/200], qnn_train_step: [800/500], loss: 1.5283823013305664, accuracy: 50.0 %\n",
      "Training round [76/200], qnn_train_step: [900/500], loss: 1.6603399515151978, accuracy: 45.8 %\n",
      "Training round [76/200], qnn_train_step: [1000/500], loss: 1.5327033996582031, accuracy: 48.8 %\n",
      "Training round [76/200], qnn_train_step: [1100/500], loss: 1.5285797119140625, accuracy: 49.8 %\n",
      "Training round [76/200], qnn_train_step: [1200/500], loss: 1.6595661640167236, accuracy: 45.3 %\n",
      "Training round [76/200], qnn_train_step: [1300/500], loss: 1.5335427522659302, accuracy: 49.7 %\n",
      "Training round [76/200], qnn_train_step: [1400/500], loss: 1.5284689664840698, accuracy: 49.6 %\n",
      "Training round [76/200], qnn_train_step: [1500/500], loss: 1.668384075164795, accuracy: 40.9 %\n",
      "Training round [76/200], qnn_train_step: [1600/500], loss: 1.532935380935669, accuracy: 50.1 %\n",
      "Training round [76/200], qnn_train_step: [1700/500], loss: 1.5281572341918945, accuracy: 49.7 %\n",
      "Training round [76/200], qnn_train_step: [1800/500], loss: 1.6828548908233643, accuracy: 43.8 %\n",
      "Training round [76/200], qnn_train_step: [1900/500], loss: 1.5337687730789185, accuracy: 49.0 %\n",
      "Training round [76/200], qnn_train_step: [2000/500], loss: 1.5280439853668213, accuracy: 49.7 %\n",
      "Training round [76/200], qnn_train_step: [2100/500], loss: 1.706300973892212, accuracy: 43.0 %\n",
      "Training round [76/200], qnn_train_step: [2200/500], loss: 1.5352113246917725, accuracy: 48.3 %\n",
      "Training round [76/200], qnn_train_step: [2300/500], loss: 1.5275695323944092, accuracy: 49.8 %\n",
      "Training round [76/200], qnn_train_step: [2400/500], loss: 1.7119568586349487, accuracy: 42.0 %\n",
      "Training round [76/200], qnn_train_step: [2500/500], loss: 1.5364855527877808, accuracy: 47.7 %\n",
      "Training round [76/200], qnn_train_step: [2600/500], loss: 1.7225425243377686, accuracy: 43.0 %\n",
      "Training round [76/200], qnn_train_step: [2700/500], loss: 1.574388861656189, accuracy: 48.3 %\n",
      "Training round [76/200], qnn_train_step: [2800/500], loss: 1.5992223024368286, accuracy: 46.3 %\n",
      "Training round [76/200], qnn_train_step: [2900/500], loss: 1.5346980094909668, accuracy: 48.9 %\n",
      "Training round [76/200], qnn_train_step: [3000/500], loss: 1.5284528732299805, accuracy: 49.6 %\n",
      "Training round [76/200], qnn_train_step: [3100/500], loss: 1.521580696105957, accuracy: 50.5 %\n",
      "Training round [76/200], qnn_train_step: [3200/500], loss: 1.508925437927246, accuracy: 50.4 %\n",
      "Training round [76/200], qnn_train_step: [3300/500], loss: 1.5074974298477173, accuracy: 50.0 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 1.5631, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 1.4515, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 1.6131, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 1.6522, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 1.5335, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 1.5914, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 1.6263, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 1.3544, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 1.4690, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 1.4208, batch time: 0.07, accuracy:  57.81%\n",
      "Training round [77/200], qnn_train_step: [100/500], loss: 1.5581679344177246, accuracy: 46.0 %\n",
      "Training round [77/200], qnn_train_step: [200/500], loss: 1.531968593597412, accuracy: 47.0 %\n",
      "Training round [77/200], qnn_train_step: [300/500], loss: 1.907997965812683, accuracy: 40.6 %\n",
      "Training round [77/200], qnn_train_step: [400/500], loss: 1.5664373636245728, accuracy: 44.8 %\n",
      "Training round [77/200], qnn_train_step: [500/500], loss: 1.5319305658340454, accuracy: 47.0 %\n",
      "Training round [77/200], qnn_train_step: [600/500], loss: 1.9190142154693604, accuracy: 35.0 %\n",
      "Training round [77/200], qnn_train_step: [700/500], loss: 1.5679607391357422, accuracy: 48.2 %\n",
      "Training round [77/200], qnn_train_step: [800/500], loss: 1.5318868160247803, accuracy: 47.0 %\n",
      "Training round [77/200], qnn_train_step: [900/500], loss: 1.945955514907837, accuracy: 38.7 %\n",
      "Training round [77/200], qnn_train_step: [1000/500], loss: 1.5673620700836182, accuracy: 45.1 %\n",
      "Training round [77/200], qnn_train_step: [1100/500], loss: 1.5318361520767212, accuracy: 47.1 %\n",
      "Training round [77/200], qnn_train_step: [1200/500], loss: 1.989116907119751, accuracy: 32.2 %\n",
      "Training round [77/200], qnn_train_step: [1300/500], loss: 1.5745575428009033, accuracy: 46.8 %\n",
      "Training round [77/200], qnn_train_step: [1400/500], loss: 1.5318551063537598, accuracy: 47.1 %\n",
      "Training round [77/200], qnn_train_step: [1500/500], loss: 2.092726945877075, accuracy: 40.5 %\n",
      "Training round [77/200], qnn_train_step: [1600/500], loss: 1.5779889822006226, accuracy: 47.5 %\n",
      "Training round [77/200], qnn_train_step: [1700/500], loss: 1.531813621520996, accuracy: 47.1 %\n",
      "Training round [77/200], qnn_train_step: [1800/500], loss: 2.110447645187378, accuracy: 39.7 %\n",
      "Training round [77/200], qnn_train_step: [1900/500], loss: 1.5771961212158203, accuracy: 44.5 %\n",
      "Training round [77/200], qnn_train_step: [2000/500], loss: 1.5318554639816284, accuracy: 46.7 %\n",
      "Training round [77/200], qnn_train_step: [2100/500], loss: 1.9599230289459229, accuracy: 41.7 %\n",
      "Training round [77/200], qnn_train_step: [2200/500], loss: 1.598038673400879, accuracy: 44.2 %\n",
      "Training round [77/200], qnn_train_step: [2300/500], loss: 1.5706367492675781, accuracy: 44.2 %\n",
      "Training round [77/200], qnn_train_step: [2400/500], loss: 1.5478323698043823, accuracy: 47.5 %\n",
      "Training round [77/200], qnn_train_step: [2500/500], loss: 1.5418163537979126, accuracy: 46.0 %\n",
      "Training round [77/200], qnn_train_step: [2600/500], loss: 1.5439441204071045, accuracy: 47.8 %\n",
      "Training round [77/200], qnn_train_step: [2700/500], loss: 1.5529013872146606, accuracy: 47.4 %\n",
      "Training round [77/200], qnn_train_step: [2800/500], loss: 1.53982412815094, accuracy: 47.6 %\n",
      "Training round [77/200], qnn_train_step: [2900/500], loss: 1.531355619430542, accuracy: 47.8 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 1.5647, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 1.5206, batch time: 0.03, accuracy:  54.69%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 1.6817, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 1.5178, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 1.4937, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 1.4620, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 1.5580, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 1.6138, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 1.5826, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 1.6862, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [78/200], qnn_train_step: [100/500], loss: 1.5524364709854126, accuracy: 46.9 %\n",
      "Training round [78/200], qnn_train_step: [200/500], loss: 1.5553373098373413, accuracy: 48.9 %\n",
      "Training round [78/200], qnn_train_step: [300/500], loss: 1.8599272966384888, accuracy: 36.7 %\n",
      "Training round [78/200], qnn_train_step: [400/500], loss: 1.5881842374801636, accuracy: 47.3 %\n",
      "Training round [78/200], qnn_train_step: [500/500], loss: 1.5552666187286377, accuracy: 48.9 %\n",
      "Training round [78/200], qnn_train_step: [600/500], loss: 1.856885552406311, accuracy: 37.0 %\n",
      "Training round [78/200], qnn_train_step: [700/500], loss: 1.5901076793670654, accuracy: 47.6 %\n",
      "Training round [78/200], qnn_train_step: [800/500], loss: 1.5551786422729492, accuracy: 48.9 %\n",
      "Training round [78/200], qnn_train_step: [900/500], loss: 1.9197473526000977, accuracy: 37.3 %\n",
      "Training round [78/200], qnn_train_step: [1000/500], loss: 1.592926025390625, accuracy: 46.1 %\n",
      "Training round [78/200], qnn_train_step: [1100/500], loss: 1.5550297498703003, accuracy: 48.9 %\n",
      "Training round [78/200], qnn_train_step: [1200/500], loss: 1.9652318954467773, accuracy: 37.2 %\n",
      "Training round [78/200], qnn_train_step: [1300/500], loss: 1.5860530138015747, accuracy: 47.4 %\n",
      "Training round [78/200], qnn_train_step: [1400/500], loss: 1.5549756288528442, accuracy: 48.9 %\n",
      "Training round [78/200], qnn_train_step: [1500/500], loss: 1.8329447507858276, accuracy: 37.8 %\n",
      "Training round [78/200], qnn_train_step: [1600/500], loss: 1.587382197380066, accuracy: 47.6 %\n",
      "Training round [78/200], qnn_train_step: [1700/500], loss: 1.5549570322036743, accuracy: 48.9 %\n",
      "Training round [78/200], qnn_train_step: [1800/500], loss: 1.8694260120391846, accuracy: 39.3 %\n",
      "Training round [78/200], qnn_train_step: [1900/500], loss: 1.589643120765686, accuracy: 48.0 %\n",
      "Training round [78/200], qnn_train_step: [2000/500], loss: 1.5546386241912842, accuracy: 48.9 %\n",
      "Training round [78/200], qnn_train_step: [2100/500], loss: 1.9336073398590088, accuracy: 34.3 %\n",
      "Training round [78/200], qnn_train_step: [2200/500], loss: 1.728575587272644, accuracy: 42.0 %\n",
      "Training round [78/200], qnn_train_step: [2300/500], loss: 1.6419380903244019, accuracy: 48.3 %\n",
      "Training round [78/200], qnn_train_step: [2400/500], loss: 1.568697214126587, accuracy: 46.2 %\n",
      "Training round [78/200], qnn_train_step: [2500/500], loss: 1.555790662765503, accuracy: 47.2 %\n",
      "Training round [78/200], qnn_train_step: [2600/500], loss: 1.5625256299972534, accuracy: 47.7 %\n",
      "Training round [78/200], qnn_train_step: [2700/500], loss: 1.5502650737762451, accuracy: 49.5 %\n",
      "Training round [78/200], qnn_train_step: [2800/500], loss: 1.552626371383667, accuracy: 48.3 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 1.4437, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 1.6736, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 1.6506, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 1.4925, batch time: 0.03, accuracy:  54.69%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 1.5259, batch time: 0.03, accuracy:  54.69%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 1.7164, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 1.7210, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 1.6119, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 1.6044, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 1.7250, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [79/200], qnn_train_step: [100/500], loss: 1.561956763267517, accuracy: 46.2 %\n",
      "Training round [79/200], qnn_train_step: [200/500], loss: 1.5430419445037842, accuracy: 47.9 %\n",
      "Training round [79/200], qnn_train_step: [300/500], loss: 1.8788554668426514, accuracy: 40.7 %\n",
      "Training round [79/200], qnn_train_step: [400/500], loss: 1.57489013671875, accuracy: 49.6 %\n",
      "Training round [79/200], qnn_train_step: [500/500], loss: 1.5424952507019043, accuracy: 47.7 %\n",
      "Training round [79/200], qnn_train_step: [600/500], loss: 1.6490185260772705, accuracy: 44.7 %\n",
      "Training round [79/200], qnn_train_step: [700/500], loss: 1.54496169090271, accuracy: 47.9 %\n",
      "Training round [79/200], qnn_train_step: [800/500], loss: 1.542377233505249, accuracy: 48.0 %\n",
      "Training round [79/200], qnn_train_step: [900/500], loss: 1.6544619798660278, accuracy: 43.8 %\n",
      "Training round [79/200], qnn_train_step: [1000/500], loss: 1.5452195405960083, accuracy: 47.9 %\n",
      "Training round [79/200], qnn_train_step: [1100/500], loss: 1.5422282218933105, accuracy: 47.9 %\n",
      "Training round [79/200], qnn_train_step: [1200/500], loss: 1.673765778541565, accuracy: 42.5 %\n",
      "Training round [79/200], qnn_train_step: [1300/500], loss: 1.5486096143722534, accuracy: 47.3 %\n",
      "Training round [79/200], qnn_train_step: [1400/500], loss: 1.5419838428497314, accuracy: 47.9 %\n",
      "Training round [79/200], qnn_train_step: [1500/500], loss: 1.6840088367462158, accuracy: 41.6 %\n",
      "Training round [79/200], qnn_train_step: [1600/500], loss: 1.5490342378616333, accuracy: 47.1 %\n",
      "Training round [79/200], qnn_train_step: [1700/500], loss: 1.5417612791061401, accuracy: 47.8 %\n",
      "Training round [79/200], qnn_train_step: [1800/500], loss: 1.6907026767730713, accuracy: 45.1 %\n",
      "Training round [79/200], qnn_train_step: [1900/500], loss: 1.549026370048523, accuracy: 47.6 %\n",
      "Training round [79/200], qnn_train_step: [2000/500], loss: 1.5415542125701904, accuracy: 47.8 %\n",
      "Training round [79/200], qnn_train_step: [2100/500], loss: 1.6904170513153076, accuracy: 45.8 %\n",
      "Training round [79/200], qnn_train_step: [2200/500], loss: 1.5492353439331055, accuracy: 47.3 %\n",
      "Training round [79/200], qnn_train_step: [2300/500], loss: 1.6308866739273071, accuracy: 46.4 %\n",
      "Training round [79/200], qnn_train_step: [2400/500], loss: 1.6366921663284302, accuracy: 45.4 %\n",
      "Training round [79/200], qnn_train_step: [2500/500], loss: 1.5495909452438354, accuracy: 47.5 %\n",
      "Training round [79/200], qnn_train_step: [2600/500], loss: 1.5855270624160767, accuracy: 45.9 %\n",
      "Training round [79/200], qnn_train_step: [2700/500], loss: 1.5399105548858643, accuracy: 47.3 %\n",
      "Training round [79/200], qnn_train_step: [2800/500], loss: 1.533480167388916, accuracy: 48.3 %\n",
      "Training round [79/200], qnn_train_step: [2900/500], loss: 1.535583257675171, accuracy: 47.6 %\n",
      "Training round [79/200], qnn_train_step: [3000/500], loss: 1.5424453020095825, accuracy: 47.3 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 1.5931, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 1.4383, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 1.6212, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 1.5558, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 1.6078, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 1.6807, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 1.5221, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 1.5933, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 1.5687, batch time: 0.08, accuracy:  47.66%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 1.5310, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [80/200], qnn_train_step: [100/500], loss: 1.5670427083969116, accuracy: 46.8 %\n",
      "Training round [80/200], qnn_train_step: [200/500], loss: 1.5390446186065674, accuracy: 48.5 %\n",
      "Training round [80/200], qnn_train_step: [300/500], loss: 1.8985109329223633, accuracy: 37.1 %\n",
      "Training round [80/200], qnn_train_step: [400/500], loss: 1.578253149986267, accuracy: 45.9 %\n",
      "Training round [80/200], qnn_train_step: [500/500], loss: 1.5389660596847534, accuracy: 48.5 %\n",
      "Training round [80/200], qnn_train_step: [600/500], loss: 1.943216323852539, accuracy: 37.3 %\n",
      "Training round [80/200], qnn_train_step: [700/500], loss: 1.5802589654922485, accuracy: 47.7 %\n",
      "Training round [80/200], qnn_train_step: [800/500], loss: 1.5388871431350708, accuracy: 48.5 %\n",
      "Training round [80/200], qnn_train_step: [900/500], loss: 1.969762921333313, accuracy: 35.5 %\n",
      "Training round [80/200], qnn_train_step: [1000/500], loss: 1.5856356620788574, accuracy: 43.3 %\n",
      "Training round [80/200], qnn_train_step: [1100/500], loss: 1.5387992858886719, accuracy: 48.6 %\n",
      "Training round [80/200], qnn_train_step: [1200/500], loss: 1.7005985975265503, accuracy: 41.3 %\n",
      "Training round [80/200], qnn_train_step: [1300/500], loss: 1.5542086362838745, accuracy: 45.4 %\n",
      "Training round [80/200], qnn_train_step: [1400/500], loss: 1.5387438535690308, accuracy: 48.6 %\n",
      "Training round [80/200], qnn_train_step: [1500/500], loss: 1.7029811143875122, accuracy: 44.1 %\n",
      "Training round [80/200], qnn_train_step: [1600/500], loss: 1.5560468435287476, accuracy: 48.1 %\n",
      "Training round [80/200], qnn_train_step: [1700/500], loss: 1.5386847257614136, accuracy: 48.7 %\n",
      "Training round [80/200], qnn_train_step: [1800/500], loss: 1.703987717628479, accuracy: 45.9 %\n",
      "Training round [80/200], qnn_train_step: [1900/500], loss: 1.5598666667938232, accuracy: 46.2 %\n",
      "Training round [80/200], qnn_train_step: [2000/500], loss: 1.538626790046692, accuracy: 48.7 %\n",
      "Training round [80/200], qnn_train_step: [2100/500], loss: 1.7486004829406738, accuracy: 42.3 %\n",
      "Training round [80/200], qnn_train_step: [2200/500], loss: 1.5622087717056274, accuracy: 47.1 %\n",
      "Training round [80/200], qnn_train_step: [2300/500], loss: 1.5385549068450928, accuracy: 48.7 %\n",
      "Training round [80/200], qnn_train_step: [2400/500], loss: 1.7491523027420044, accuracy: 40.7 %\n",
      "Training round [80/200], qnn_train_step: [2500/500], loss: 1.5624858140945435, accuracy: 46.1 %\n",
      "Training round [80/200], qnn_train_step: [2600/500], loss: 1.5384948253631592, accuracy: 48.6 %\n",
      "Training round [80/200], qnn_train_step: [2700/500], loss: 1.7593837976455688, accuracy: 41.3 %\n",
      "Training round [80/200], qnn_train_step: [2800/500], loss: 1.5620743036270142, accuracy: 44.2 %\n",
      "Training round [80/200], qnn_train_step: [2900/500], loss: 1.5384368896484375, accuracy: 48.6 %\n",
      "Training round [80/200], qnn_train_step: [3000/500], loss: 1.7659111022949219, accuracy: 38.8 %\n",
      "Training round [80/200], qnn_train_step: [3100/500], loss: 1.562670111656189, accuracy: 47.7 %\n",
      "Training round [80/200], qnn_train_step: [3200/500], loss: 1.5384103059768677, accuracy: 48.6 %\n",
      "Training round [80/200], qnn_train_step: [3300/500], loss: 1.7679964303970337, accuracy: 42.1 %\n",
      "Training round [80/200], qnn_train_step: [3400/500], loss: 1.5684843063354492, accuracy: 48.1 %\n",
      "Training round [80/200], qnn_train_step: [3500/500], loss: 1.5383516550064087, accuracy: 48.6 %\n",
      "Training round [80/200], qnn_train_step: [3600/500], loss: 1.7758623361587524, accuracy: 42.6 %\n",
      "Training round [80/200], qnn_train_step: [3700/500], loss: 1.5692729949951172, accuracy: 46.2 %\n",
      "Training round [80/200], qnn_train_step: [3800/500], loss: 1.538292407989502, accuracy: 48.5 %\n",
      "Training round [80/200], qnn_train_step: [3900/500], loss: 1.7878035306930542, accuracy: 42.9 %\n",
      "Training round [80/200], qnn_train_step: [4000/500], loss: 1.5737464427947998, accuracy: 47.2 %\n",
      "Training round [80/200], qnn_train_step: [4100/500], loss: 1.5382660627365112, accuracy: 48.5 %\n",
      "Training round [80/200], qnn_train_step: [4200/500], loss: 1.788543701171875, accuracy: 39.7 %\n",
      "Training round [80/200], qnn_train_step: [4300/500], loss: 1.5745443105697632, accuracy: 43.7 %\n",
      "Training round [80/200], qnn_train_step: [4400/500], loss: 1.612578272819519, accuracy: 46.2 %\n",
      "Training round [80/200], qnn_train_step: [4500/500], loss: 1.5808873176574707, accuracy: 46.1 %\n",
      "Training round [80/200], qnn_train_step: [4600/500], loss: 1.5588195323944092, accuracy: 45.9 %\n",
      "Training round [80/200], qnn_train_step: [4700/500], loss: 1.5596706867218018, accuracy: 47.6 %\n",
      "Training round [80/200], qnn_train_step: [4800/500], loss: 1.5605212450027466, accuracy: 48.5 %\n",
      "Training round [80/200], qnn_train_step: [4900/500], loss: 1.554150104522705, accuracy: 47.0 %\n",
      "Training round [80/200], qnn_train_step: [5000/500], loss: 1.5404484272003174, accuracy: 47.8 %\n",
      "Training round [80/200], qnn_train_step: [5100/500], loss: 1.5384881496429443, accuracy: 47.6 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 1.6875, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 1.7009, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 1.7595, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 1.3955, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 1.5037, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 1.7309, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 1.6671, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 1.4931, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 1.5659, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 1.7287, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [81/200], qnn_train_step: [100/500], loss: 1.5189833641052246, accuracy: 47.9 %\n",
      "Training round [81/200], qnn_train_step: [200/500], loss: 1.4989310503005981, accuracy: 49.4 %\n",
      "Training round [81/200], qnn_train_step: [300/500], loss: 1.789787769317627, accuracy: 40.0 %\n",
      "Training round [81/200], qnn_train_step: [400/500], loss: 1.529583215713501, accuracy: 46.2 %\n",
      "Training round [81/200], qnn_train_step: [500/500], loss: 1.4988709688186646, accuracy: 49.4 %\n",
      "Training round [81/200], qnn_train_step: [600/500], loss: 1.8163849115371704, accuracy: 41.7 %\n",
      "Training round [81/200], qnn_train_step: [700/500], loss: 1.5304750204086304, accuracy: 47.7 %\n",
      "Training round [81/200], qnn_train_step: [800/500], loss: 1.4988261461257935, accuracy: 49.4 %\n",
      "Training round [81/200], qnn_train_step: [900/500], loss: 1.829827070236206, accuracy: 38.8 %\n",
      "Training round [81/200], qnn_train_step: [1000/500], loss: 1.532247543334961, accuracy: 46.9 %\n",
      "Training round [81/200], qnn_train_step: [1100/500], loss: 1.4987621307373047, accuracy: 49.4 %\n",
      "Training round [81/200], qnn_train_step: [1200/500], loss: 1.8579901456832886, accuracy: 41.8 %\n",
      "Training round [81/200], qnn_train_step: [1300/500], loss: 1.5404212474822998, accuracy: 45.8 %\n",
      "Training round [81/200], qnn_train_step: [1400/500], loss: 1.4987328052520752, accuracy: 49.4 %\n",
      "Training round [81/200], qnn_train_step: [1500/500], loss: 1.8113582134246826, accuracy: 39.1 %\n",
      "Training round [81/200], qnn_train_step: [1600/500], loss: 1.5304502248764038, accuracy: 47.0 %\n",
      "Training round [81/200], qnn_train_step: [1700/500], loss: 1.498650312423706, accuracy: 49.4 %\n",
      "Training round [81/200], qnn_train_step: [1800/500], loss: 1.8409124612808228, accuracy: 42.6 %\n",
      "Training round [81/200], qnn_train_step: [1900/500], loss: 1.5376240015029907, accuracy: 46.4 %\n",
      "Training round [81/200], qnn_train_step: [2000/500], loss: 1.4986164569854736, accuracy: 49.4 %\n",
      "Training round [81/200], qnn_train_step: [2100/500], loss: 1.8398703336715698, accuracy: 37.6 %\n",
      "Training round [81/200], qnn_train_step: [2200/500], loss: 1.538238286972046, accuracy: 49.3 %\n",
      "Training round [81/200], qnn_train_step: [2300/500], loss: 1.4985969066619873, accuracy: 49.4 %\n",
      "Training round [81/200], qnn_train_step: [2400/500], loss: 1.9010084867477417, accuracy: 34.9 %\n",
      "Training round [81/200], qnn_train_step: [2500/500], loss: 1.5394049882888794, accuracy: 47.3 %\n",
      "Training round [81/200], qnn_train_step: [2600/500], loss: 1.4985382556915283, accuracy: 49.4 %\n",
      "Training round [81/200], qnn_train_step: [2700/500], loss: 1.902109146118164, accuracy: 33.0 %\n",
      "Training round [81/200], qnn_train_step: [2800/500], loss: 1.5408400297164917, accuracy: 47.1 %\n",
      "Training round [81/200], qnn_train_step: [2900/500], loss: 1.4985015392303467, accuracy: 49.4 %\n",
      "Training round [81/200], qnn_train_step: [3000/500], loss: 6.770267009735107, accuracy: 13.0 %\n",
      "Training round [81/200], qnn_train_step: [3100/500], loss: 1.542684555053711, accuracy: 47.6 %\n",
      "Training round [81/200], qnn_train_step: [3200/500], loss: 1.4984828233718872, accuracy: 49.5 %\n",
      "Training round [81/200], qnn_train_step: [3300/500], loss: 1.4961262941360474, accuracy: 48.7 %\n",
      "Training round [81/200], qnn_train_step: [3400/500], loss: 1.551541805267334, accuracy: 48.8 %\n",
      "Training round [81/200], qnn_train_step: [3500/500], loss: 1.4984153509140015, accuracy: 48.0 %\n",
      "Training round [81/200], qnn_train_step: [3600/500], loss: 1.4968528747558594, accuracy: 49.8 %\n",
      "Training round [81/200], qnn_train_step: [3700/500], loss: 1.5566831827163696, accuracy: 47.9 %\n",
      "Training round [81/200], qnn_train_step: [3800/500], loss: 1.4990975856781006, accuracy: 49.5 %\n",
      "Training round [81/200], qnn_train_step: [3900/500], loss: 1.497009038925171, accuracy: 49.7 %\n",
      "Training round [81/200], qnn_train_step: [4000/500], loss: 1.5640161037445068, accuracy: 45.7 %\n",
      "Training round [81/200], qnn_train_step: [4100/500], loss: 1.499172329902649, accuracy: 49.4 %\n",
      "Training round [81/200], qnn_train_step: [4200/500], loss: 1.902657389640808, accuracy: 41.5 %\n",
      "Training round [81/200], qnn_train_step: [4300/500], loss: 1.5877116918563843, accuracy: 41.9 %\n",
      "Training round [81/200], qnn_train_step: [4400/500], loss: 1.5202107429504395, accuracy: 46.7 %\n",
      "Training round [81/200], qnn_train_step: [4500/500], loss: 1.5378206968307495, accuracy: 46.9 %\n",
      "Training round [81/200], qnn_train_step: [4600/500], loss: 1.50212562084198, accuracy: 48.2 %\n",
      "Training round [81/200], qnn_train_step: [4700/500], loss: 1.513800024986267, accuracy: 47.3 %\n",
      "Training round [81/200], qnn_train_step: [4800/500], loss: 1.5090258121490479, accuracy: 48.5 %\n",
      "Training round [81/200], qnn_train_step: [4900/500], loss: 1.4983652830123901, accuracy: 46.8 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 1.5632, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 1.5591, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 1.5559, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 1.5406, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 1.6018, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 1.4779, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 1.5035, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 1.4790, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 1.5196, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 1.4810, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [82/200], qnn_train_step: [100/500], loss: 1.5979872941970825, accuracy: 43.6 %\n",
      "Training round [82/200], qnn_train_step: [200/500], loss: 1.5744632482528687, accuracy: 46.7 %\n",
      "Training round [82/200], qnn_train_step: [300/500], loss: 1.9746242761611938, accuracy: 39.6 %\n",
      "Training round [82/200], qnn_train_step: [400/500], loss: 1.6114243268966675, accuracy: 45.3 %\n",
      "Training round [82/200], qnn_train_step: [500/500], loss: 1.5743849277496338, accuracy: 46.7 %\n",
      "Training round [82/200], qnn_train_step: [600/500], loss: 1.9863884449005127, accuracy: 36.1 %\n",
      "Training round [82/200], qnn_train_step: [700/500], loss: 1.6129392385482788, accuracy: 42.8 %\n",
      "Training round [82/200], qnn_train_step: [800/500], loss: 1.5743622779846191, accuracy: 46.7 %\n",
      "Training round [82/200], qnn_train_step: [900/500], loss: 2.0231924057006836, accuracy: 30.8 %\n",
      "Training round [82/200], qnn_train_step: [1000/500], loss: 1.594698190689087, accuracy: 45.1 %\n",
      "Training round [82/200], qnn_train_step: [1100/500], loss: 1.5743275880813599, accuracy: 46.7 %\n",
      "Training round [82/200], qnn_train_step: [1200/500], loss: 1.7414592504501343, accuracy: 41.7 %\n",
      "Training round [82/200], qnn_train_step: [1300/500], loss: 1.5951216220855713, accuracy: 43.5 %\n",
      "Training round [82/200], qnn_train_step: [1400/500], loss: 1.5742502212524414, accuracy: 46.7 %\n",
      "Training round [82/200], qnn_train_step: [1500/500], loss: 1.7859630584716797, accuracy: 39.0 %\n",
      "Training round [82/200], qnn_train_step: [1600/500], loss: 1.595232367515564, accuracy: 45.2 %\n",
      "Training round [82/200], qnn_train_step: [1700/500], loss: 1.5742285251617432, accuracy: 46.7 %\n",
      "Training round [82/200], qnn_train_step: [1800/500], loss: 1.7914297580718994, accuracy: 39.8 %\n",
      "Training round [82/200], qnn_train_step: [1900/500], loss: 1.5954604148864746, accuracy: 43.4 %\n",
      "Training round [82/200], qnn_train_step: [2000/500], loss: 1.574198603630066, accuracy: 46.8 %\n",
      "Training round [82/200], qnn_train_step: [2100/500], loss: 1.822709560394287, accuracy: 33.5 %\n",
      "Training round [82/200], qnn_train_step: [2200/500], loss: 1.5976519584655762, accuracy: 44.1 %\n",
      "Training round [82/200], qnn_train_step: [2300/500], loss: 1.5741572380065918, accuracy: 46.8 %\n",
      "Training round [82/200], qnn_train_step: [2400/500], loss: 1.8357021808624268, accuracy: 39.8 %\n",
      "Training round [82/200], qnn_train_step: [2500/500], loss: 1.6025925874710083, accuracy: 44.4 %\n",
      "Training round [82/200], qnn_train_step: [2600/500], loss: 1.5741130113601685, accuracy: 46.8 %\n",
      "Training round [82/200], qnn_train_step: [2700/500], loss: 1.8320271968841553, accuracy: 40.2 %\n",
      "Training round [82/200], qnn_train_step: [2800/500], loss: 1.6034387350082397, accuracy: 45.7 %\n",
      "Training round [82/200], qnn_train_step: [2900/500], loss: 1.5740751028060913, accuracy: 46.9 %\n",
      "Training round [82/200], qnn_train_step: [3000/500], loss: 1.849827766418457, accuracy: 36.3 %\n",
      "Training round [82/200], qnn_train_step: [3100/500], loss: 1.6040544509887695, accuracy: 45.5 %\n",
      "Training round [82/200], qnn_train_step: [3200/500], loss: 1.5740578174591064, accuracy: 46.7 %\n",
      "Training round [82/200], qnn_train_step: [3300/500], loss: 1.8643708229064941, accuracy: 38.0 %\n",
      "Training round [82/200], qnn_train_step: [3400/500], loss: 1.6096889972686768, accuracy: 42.2 %\n",
      "Training round [82/200], qnn_train_step: [3500/500], loss: 1.5740901231765747, accuracy: 47.0 %\n",
      "Training round [82/200], qnn_train_step: [3600/500], loss: 1.8762896060943604, accuracy: 35.1 %\n",
      "Training round [82/200], qnn_train_step: [3700/500], loss: 1.6118764877319336, accuracy: 45.9 %\n",
      "Training round [82/200], qnn_train_step: [3800/500], loss: 1.5741233825683594, accuracy: 46.6 %\n",
      "Training round [82/200], qnn_train_step: [3900/500], loss: 2.065622329711914, accuracy: 38.9 %\n",
      "Training round [82/200], qnn_train_step: [4000/500], loss: 1.7005727291107178, accuracy: 41.5 %\n",
      "Training round [82/200], qnn_train_step: [4100/500], loss: 1.6002246141433716, accuracy: 45.4 %\n",
      "Training round [82/200], qnn_train_step: [4200/500], loss: 1.6052263975143433, accuracy: 45.2 %\n",
      "Training round [82/200], qnn_train_step: [4300/500], loss: 1.5662959814071655, accuracy: 47.2 %\n",
      "Training round [82/200], qnn_train_step: [4400/500], loss: 1.5847342014312744, accuracy: 46.4 %\n",
      "Training round [82/200], qnn_train_step: [4500/500], loss: 1.5738720893859863, accuracy: 46.4 %\n",
      "Training round [82/200], qnn_train_step: [4600/500], loss: 1.5752742290496826, accuracy: 47.0 %\n",
      "Training round [82/200], qnn_train_step: [4700/500], loss: 1.5634809732437134, accuracy: 47.3 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 1.4702, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 1.5918, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 1.6401, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 1.5645, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 1.5999, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 1.2948, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 1.5701, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 1.4173, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 1.4042, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 1.6410, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [83/200], qnn_train_step: [100/500], loss: 1.549187183380127, accuracy: 45.6 %\n",
      "Training round [83/200], qnn_train_step: [200/500], loss: 1.516025424003601, accuracy: 47.5 %\n",
      "Training round [83/200], qnn_train_step: [300/500], loss: 1.772013783454895, accuracy: 38.1 %\n",
      "Training round [83/200], qnn_train_step: [400/500], loss: 1.5265483856201172, accuracy: 47.3 %\n",
      "Training round [83/200], qnn_train_step: [500/500], loss: 1.5145713090896606, accuracy: 47.6 %\n",
      "Training round [83/200], qnn_train_step: [600/500], loss: 1.7867531776428223, accuracy: 41.8 %\n",
      "Training round [83/200], qnn_train_step: [700/500], loss: 1.5255581140518188, accuracy: 48.1 %\n",
      "Training round [83/200], qnn_train_step: [800/500], loss: 1.6131322383880615, accuracy: 44.8 %\n",
      "Training round [83/200], qnn_train_step: [900/500], loss: 1.5311286449432373, accuracy: 47.5 %\n",
      "Training round [83/200], qnn_train_step: [1000/500], loss: 1.512665867805481, accuracy: 47.8 %\n",
      "Training round [83/200], qnn_train_step: [1100/500], loss: 1.666616678237915, accuracy: 42.8 %\n",
      "Training round [83/200], qnn_train_step: [1200/500], loss: 1.5340759754180908, accuracy: 47.0 %\n",
      "Training round [83/200], qnn_train_step: [1300/500], loss: 1.5113749504089355, accuracy: 47.7 %\n",
      "Training round [83/200], qnn_train_step: [1400/500], loss: 1.671290397644043, accuracy: 42.2 %\n",
      "Training round [83/200], qnn_train_step: [1500/500], loss: 1.5346815586090088, accuracy: 48.8 %\n",
      "Training round [83/200], qnn_train_step: [1600/500], loss: 1.5101813077926636, accuracy: 47.6 %\n",
      "Training round [83/200], qnn_train_step: [1700/500], loss: 6.934546947479248, accuracy: 12.3 %\n",
      "Training round [83/200], qnn_train_step: [1800/500], loss: 1.5341476202011108, accuracy: 48.9 %\n",
      "Training round [83/200], qnn_train_step: [1900/500], loss: 1.5091021060943604, accuracy: 47.6 %\n",
      "Training round [83/200], qnn_train_step: [2000/500], loss: 1.4849425554275513, accuracy: 49.1 %\n",
      "Training round [83/200], qnn_train_step: [2100/500], loss: 1.5384771823883057, accuracy: 45.0 %\n",
      "Training round [83/200], qnn_train_step: [2200/500], loss: 1.5078446865081787, accuracy: 47.6 %\n",
      "Training round [83/200], qnn_train_step: [2300/500], loss: 1.4913034439086914, accuracy: 50.4 %\n",
      "Training round [83/200], qnn_train_step: [2400/500], loss: 1.5414022207260132, accuracy: 47.4 %\n",
      "Training round [83/200], qnn_train_step: [2500/500], loss: 1.5066851377487183, accuracy: 47.6 %\n",
      "Training round [83/200], qnn_train_step: [2600/500], loss: 1.4925264120101929, accuracy: 49.0 %\n",
      "Training round [83/200], qnn_train_step: [2700/500], loss: 1.547797679901123, accuracy: 45.0 %\n",
      "Training round [83/200], qnn_train_step: [2800/500], loss: 1.5057278871536255, accuracy: 47.9 %\n",
      "Training round [83/200], qnn_train_step: [2900/500], loss: 1.493571162223816, accuracy: 48.3 %\n",
      "Training round [83/200], qnn_train_step: [3000/500], loss: 1.550565481185913, accuracy: 48.1 %\n",
      "Training round [83/200], qnn_train_step: [3100/500], loss: 1.504626750946045, accuracy: 47.9 %\n",
      "Training round [83/200], qnn_train_step: [3200/500], loss: 1.4944571256637573, accuracy: 48.6 %\n",
      "Training round [83/200], qnn_train_step: [3300/500], loss: 1.5497162342071533, accuracy: 48.9 %\n",
      "Training round [83/200], qnn_train_step: [3400/500], loss: 1.503736138343811, accuracy: 48.0 %\n",
      "Training round [83/200], qnn_train_step: [3500/500], loss: 1.4959803819656372, accuracy: 48.6 %\n",
      "Training round [83/200], qnn_train_step: [3600/500], loss: 1.5572758913040161, accuracy: 44.5 %\n",
      "Training round [83/200], qnn_train_step: [3700/500], loss: 1.5026718378067017, accuracy: 48.0 %\n",
      "Training round [83/200], qnn_train_step: [3800/500], loss: 1.719278335571289, accuracy: 41.1 %\n",
      "Training round [83/200], qnn_train_step: [3900/500], loss: 1.5854767560958862, accuracy: 44.9 %\n",
      "Training round [83/200], qnn_train_step: [4000/500], loss: 1.50901460647583, accuracy: 49.1 %\n",
      "Training round [83/200], qnn_train_step: [4100/500], loss: 1.4972585439682007, accuracy: 49.9 %\n",
      "Training round [83/200], qnn_train_step: [4200/500], loss: 1.5064629316329956, accuracy: 47.9 %\n",
      "Training round [83/200], qnn_train_step: [4300/500], loss: 1.4924092292785645, accuracy: 48.7 %\n",
      "Training round [83/200], qnn_train_step: [4400/500], loss: 1.4929449558258057, accuracy: 48.9 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 1.6898, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 1.5184, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 1.6969, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 1.4566, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 1.6974, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 1.5414, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 1.6097, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 1.7217, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 1.4973, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 1.5141, batch time: 0.08, accuracy:  50.00%\n",
      "Training round [84/200], qnn_train_step: [100/500], loss: 1.530827283859253, accuracy: 47.7 %\n",
      "Training round [84/200], qnn_train_step: [200/500], loss: 1.5090787410736084, accuracy: 48.5 %\n",
      "Training round [84/200], qnn_train_step: [300/500], loss: 1.8632593154907227, accuracy: 39.0 %\n",
      "Training round [84/200], qnn_train_step: [400/500], loss: 1.5426642894744873, accuracy: 48.5 %\n",
      "Training round [84/200], qnn_train_step: [500/500], loss: 1.5089558362960815, accuracy: 48.5 %\n",
      "Training round [84/200], qnn_train_step: [600/500], loss: 1.8980107307434082, accuracy: 37.7 %\n",
      "Training round [84/200], qnn_train_step: [700/500], loss: 1.546633243560791, accuracy: 47.8 %\n",
      "Training round [84/200], qnn_train_step: [800/500], loss: 1.5087809562683105, accuracy: 48.6 %\n",
      "Training round [84/200], qnn_train_step: [900/500], loss: 1.9196466207504272, accuracy: 37.2 %\n",
      "Training round [84/200], qnn_train_step: [1000/500], loss: 1.5520364046096802, accuracy: 47.0 %\n",
      "Training round [84/200], qnn_train_step: [1100/500], loss: 1.508623480796814, accuracy: 48.6 %\n",
      "Training round [84/200], qnn_train_step: [1200/500], loss: 1.9213181734085083, accuracy: 34.5 %\n",
      "Training round [84/200], qnn_train_step: [1300/500], loss: 1.553276777267456, accuracy: 47.8 %\n",
      "Training round [84/200], qnn_train_step: [1400/500], loss: 1.508463740348816, accuracy: 48.6 %\n",
      "Training round [84/200], qnn_train_step: [1500/500], loss: 1.9350714683532715, accuracy: 36.1 %\n",
      "Training round [84/200], qnn_train_step: [1600/500], loss: 1.5585647821426392, accuracy: 46.8 %\n",
      "Training round [84/200], qnn_train_step: [1700/500], loss: 1.508306622505188, accuracy: 48.6 %\n",
      "Training round [84/200], qnn_train_step: [1800/500], loss: 1.715274691581726, accuracy: 43.4 %\n",
      "Training round [84/200], qnn_train_step: [1900/500], loss: 1.532069206237793, accuracy: 48.8 %\n",
      "Training round [84/200], qnn_train_step: [2000/500], loss: 1.508158564567566, accuracy: 48.7 %\n",
      "Training round [84/200], qnn_train_step: [2100/500], loss: 1.7412470579147339, accuracy: 42.1 %\n",
      "Training round [84/200], qnn_train_step: [2200/500], loss: 1.5364693403244019, accuracy: 48.3 %\n",
      "Training round [84/200], qnn_train_step: [2300/500], loss: 1.5080031156539917, accuracy: 48.7 %\n",
      "Training round [84/200], qnn_train_step: [2400/500], loss: 1.7617894411087036, accuracy: 41.0 %\n",
      "Training round [84/200], qnn_train_step: [2500/500], loss: 1.536040186882019, accuracy: 48.0 %\n",
      "Training round [84/200], qnn_train_step: [2600/500], loss: 1.507665753364563, accuracy: 48.8 %\n",
      "Training round [84/200], qnn_train_step: [2700/500], loss: 1.7694671154022217, accuracy: 42.0 %\n",
      "Training round [84/200], qnn_train_step: [2800/500], loss: 1.5392454862594604, accuracy: 48.1 %\n",
      "Training round [84/200], qnn_train_step: [2900/500], loss: 1.5073726177215576, accuracy: 48.9 %\n",
      "Training round [84/200], qnn_train_step: [3000/500], loss: 1.7925914525985718, accuracy: 39.3 %\n",
      "Training round [84/200], qnn_train_step: [3100/500], loss: 1.5428546667099, accuracy: 47.4 %\n",
      "Training round [84/200], qnn_train_step: [3200/500], loss: 1.507190465927124, accuracy: 48.9 %\n",
      "Training round [84/200], qnn_train_step: [3300/500], loss: 1.7990487813949585, accuracy: 39.6 %\n",
      "Training round [84/200], qnn_train_step: [3400/500], loss: 1.5434309244155884, accuracy: 48.1 %\n",
      "Training round [84/200], qnn_train_step: [3500/500], loss: 1.5068881511688232, accuracy: 48.9 %\n",
      "Training round [84/200], qnn_train_step: [3600/500], loss: 1.823585867881775, accuracy: 39.6 %\n",
      "Training round [84/200], qnn_train_step: [3700/500], loss: 1.5490469932556152, accuracy: 46.3 %\n",
      "Training round [84/200], qnn_train_step: [3800/500], loss: 1.5066739320755005, accuracy: 48.9 %\n",
      "Training round [84/200], qnn_train_step: [3900/500], loss: 1.8432878255844116, accuracy: 37.8 %\n",
      "Training round [84/200], qnn_train_step: [4000/500], loss: 1.5560237169265747, accuracy: 47.1 %\n",
      "Training round [84/200], qnn_train_step: [4100/500], loss: 1.506546974182129, accuracy: 48.9 %\n",
      "Training round [84/200], qnn_train_step: [4200/500], loss: 5.936538219451904, accuracy: 12.0 %\n",
      "Training round [84/200], qnn_train_step: [4300/500], loss: 1.5475006103515625, accuracy: 45.8 %\n",
      "Training round [84/200], qnn_train_step: [4400/500], loss: 1.5301263332366943, accuracy: 45.9 %\n",
      "Training round [84/200], qnn_train_step: [4500/500], loss: 1.5135014057159424, accuracy: 48.5 %\n",
      "Training round [84/200], qnn_train_step: [4600/500], loss: 1.5075725317001343, accuracy: 48.0 %\n",
      "Training round [84/200], qnn_train_step: [4700/500], loss: 1.5032302141189575, accuracy: 49.1 %\n",
      "Training round [84/200], qnn_train_step: [4800/500], loss: 1.5015524625778198, accuracy: 47.9 %\n",
      "Training round [84/200], qnn_train_step: [4900/500], loss: 1.506311058998108, accuracy: 48.8 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 1.3803, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 1.5679, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 1.5082, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 1.4396, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 1.5871, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 1.3910, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 1.5746, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 1.5380, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 1.5394, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 1.4164, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [85/200], qnn_train_step: [100/500], loss: 1.561954140663147, accuracy: 46.1 %\n",
      "Training round [85/200], qnn_train_step: [200/500], loss: 1.5367683172225952, accuracy: 48.3 %\n",
      "Training round [85/200], qnn_train_step: [300/500], loss: 1.8576470613479614, accuracy: 38.2 %\n",
      "Training round [85/200], qnn_train_step: [400/500], loss: 1.5682885646820068, accuracy: 47.0 %\n",
      "Training round [85/200], qnn_train_step: [500/500], loss: 1.5367482900619507, accuracy: 48.2 %\n",
      "Training round [85/200], qnn_train_step: [600/500], loss: 1.8636358976364136, accuracy: 38.7 %\n",
      "Training round [85/200], qnn_train_step: [700/500], loss: 1.5714324712753296, accuracy: 46.0 %\n",
      "Training round [85/200], qnn_train_step: [800/500], loss: 1.5366836786270142, accuracy: 48.2 %\n",
      "Training round [85/200], qnn_train_step: [900/500], loss: 1.891064167022705, accuracy: 40.9 %\n",
      "Training round [85/200], qnn_train_step: [1000/500], loss: 1.5734775066375732, accuracy: 47.1 %\n",
      "Training round [85/200], qnn_train_step: [1100/500], loss: 1.5366464853286743, accuracy: 48.2 %\n",
      "Training round [85/200], qnn_train_step: [1200/500], loss: 1.9347922801971436, accuracy: 33.3 %\n",
      "Training round [85/200], qnn_train_step: [1300/500], loss: 1.5385034084320068, accuracy: 49.2 %\n",
      "Training round [85/200], qnn_train_step: [1400/500], loss: 1.5363824367523193, accuracy: 48.2 %\n",
      "Training round [85/200], qnn_train_step: [1500/500], loss: 1.6168779134750366, accuracy: 47.2 %\n",
      "Training round [85/200], qnn_train_step: [1600/500], loss: 1.5384020805358887, accuracy: 49.4 %\n",
      "Training round [85/200], qnn_train_step: [1700/500], loss: 1.5364904403686523, accuracy: 48.4 %\n",
      "Training round [85/200], qnn_train_step: [1800/500], loss: 1.6249363422393799, accuracy: 45.9 %\n",
      "Training round [85/200], qnn_train_step: [1900/500], loss: 1.5389721393585205, accuracy: 49.0 %\n",
      "Training round [85/200], qnn_train_step: [2000/500], loss: 1.5364711284637451, accuracy: 48.2 %\n",
      "Training round [85/200], qnn_train_step: [2100/500], loss: 1.6309962272644043, accuracy: 46.2 %\n",
      "Training round [85/200], qnn_train_step: [2200/500], loss: 1.5394171476364136, accuracy: 48.1 %\n",
      "Training round [85/200], qnn_train_step: [2300/500], loss: 1.5364298820495605, accuracy: 48.2 %\n",
      "Training round [85/200], qnn_train_step: [2400/500], loss: 1.6362450122833252, accuracy: 47.9 %\n",
      "Training round [85/200], qnn_train_step: [2500/500], loss: 1.5404977798461914, accuracy: 48.7 %\n",
      "Training round [85/200], qnn_train_step: [2600/500], loss: 1.5364010334014893, accuracy: 48.2 %\n",
      "Training round [85/200], qnn_train_step: [2700/500], loss: 1.6375445127487183, accuracy: 41.6 %\n",
      "Training round [85/200], qnn_train_step: [2800/500], loss: 1.5412042140960693, accuracy: 48.9 %\n",
      "Training round [85/200], qnn_train_step: [2900/500], loss: 1.5363929271697998, accuracy: 48.2 %\n",
      "Training round [85/200], qnn_train_step: [3000/500], loss: 1.6581377983093262, accuracy: 44.5 %\n",
      "Training round [85/200], qnn_train_step: [3100/500], loss: 1.5434097051620483, accuracy: 47.4 %\n",
      "Training round [85/200], qnn_train_step: [3200/500], loss: 1.5363227128982544, accuracy: 48.4 %\n",
      "Training round [85/200], qnn_train_step: [3300/500], loss: 1.6693511009216309, accuracy: 45.7 %\n",
      "Training round [85/200], qnn_train_step: [3400/500], loss: 1.543703556060791, accuracy: 47.6 %\n",
      "Training round [85/200], qnn_train_step: [3500/500], loss: 1.5362498760223389, accuracy: 48.4 %\n",
      "Training round [85/200], qnn_train_step: [3600/500], loss: 1.6763087511062622, accuracy: 38.9 %\n",
      "Training round [85/200], qnn_train_step: [3700/500], loss: 1.7073297500610352, accuracy: 44.9 %\n",
      "Training round [85/200], qnn_train_step: [3800/500], loss: 1.5661945343017578, accuracy: 47.2 %\n",
      "Training round [85/200], qnn_train_step: [3900/500], loss: 1.585078239440918, accuracy: 46.2 %\n",
      "Training round [85/200], qnn_train_step: [4000/500], loss: 1.544270396232605, accuracy: 49.0 %\n",
      "Training round [85/200], qnn_train_step: [4100/500], loss: 1.6127427816390991, accuracy: 44.5 %\n",
      "Training round [85/200], qnn_train_step: [4200/500], loss: 1.5376118421554565, accuracy: 49.2 %\n",
      "Training round [85/200], qnn_train_step: [4300/500], loss: 1.5351461172103882, accuracy: 48.7 %\n",
      "Training round [85/200], qnn_train_step: [4400/500], loss: 1.5305366516113281, accuracy: 49.1 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 1.5671, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 1.5195, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 1.5102, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 1.5111, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 1.5727, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 1.3873, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 1.6997, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 1.4058, batch time: 0.03, accuracy:  57.81%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 1.4681, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 1.4153, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [86/200], qnn_train_step: [100/500], loss: 1.5525414943695068, accuracy: 45.3 %\n",
      "Training round [86/200], qnn_train_step: [200/500], loss: 1.5242574214935303, accuracy: 47.9 %\n",
      "Training round [86/200], qnn_train_step: [300/500], loss: 1.8154555559158325, accuracy: 36.9 %\n",
      "Training round [86/200], qnn_train_step: [400/500], loss: 1.5521584749221802, accuracy: 47.7 %\n",
      "Training round [86/200], qnn_train_step: [500/500], loss: 1.5241117477416992, accuracy: 47.9 %\n",
      "Training round [86/200], qnn_train_step: [600/500], loss: 1.8337291479110718, accuracy: 42.2 %\n",
      "Training round [86/200], qnn_train_step: [700/500], loss: 1.5563181638717651, accuracy: 46.7 %\n",
      "Training round [86/200], qnn_train_step: [800/500], loss: 1.5239830017089844, accuracy: 47.9 %\n",
      "Training round [86/200], qnn_train_step: [900/500], loss: 1.8560453653335571, accuracy: 40.2 %\n",
      "Training round [86/200], qnn_train_step: [1000/500], loss: 1.5576379299163818, accuracy: 47.4 %\n",
      "Training round [86/200], qnn_train_step: [1100/500], loss: 1.766986608505249, accuracy: 43.9 %\n",
      "Training round [86/200], qnn_train_step: [1200/500], loss: 1.575505018234253, accuracy: 43.7 %\n",
      "Training round [86/200], qnn_train_step: [1300/500], loss: 1.524216651916504, accuracy: 47.9 %\n",
      "Training round [86/200], qnn_train_step: [1400/500], loss: 1.520058512687683, accuracy: 47.9 %\n",
      "Training round [86/200], qnn_train_step: [1500/500], loss: 1.5794997215270996, accuracy: 47.4 %\n",
      "Training round [86/200], qnn_train_step: [1600/500], loss: 1.524255394935608, accuracy: 47.9 %\n",
      "Training round [86/200], qnn_train_step: [1700/500], loss: 1.5202759504318237, accuracy: 48.0 %\n",
      "Training round [86/200], qnn_train_step: [1800/500], loss: 1.5801507234573364, accuracy: 45.0 %\n",
      "Training round [86/200], qnn_train_step: [1900/500], loss: 1.5242283344268799, accuracy: 48.2 %\n",
      "Training round [86/200], qnn_train_step: [2000/500], loss: 1.5222169160842896, accuracy: 48.7 %\n",
      "Training round [86/200], qnn_train_step: [2100/500], loss: 1.5876682996749878, accuracy: 46.9 %\n",
      "Training round [86/200], qnn_train_step: [2200/500], loss: 1.5258843898773193, accuracy: 48.1 %\n",
      "Training round [86/200], qnn_train_step: [2300/500], loss: 1.5222668647766113, accuracy: 48.3 %\n",
      "Training round [86/200], qnn_train_step: [2400/500], loss: 1.5929220914840698, accuracy: 45.6 %\n",
      "Training round [86/200], qnn_train_step: [2500/500], loss: 1.52646005153656, accuracy: 47.7 %\n",
      "Training round [86/200], qnn_train_step: [2600/500], loss: 1.5223610401153564, accuracy: 48.2 %\n",
      "Training round [86/200], qnn_train_step: [2700/500], loss: 1.5936235189437866, accuracy: 44.5 %\n",
      "Training round [86/200], qnn_train_step: [2800/500], loss: 1.5265228748321533, accuracy: 47.9 %\n",
      "Training round [86/200], qnn_train_step: [2900/500], loss: 1.522783637046814, accuracy: 48.2 %\n",
      "Training round [86/200], qnn_train_step: [3000/500], loss: 1.5999938249588013, accuracy: 44.2 %\n",
      "Training round [86/200], qnn_train_step: [3100/500], loss: 1.526395320892334, accuracy: 48.8 %\n",
      "Training round [86/200], qnn_train_step: [3200/500], loss: 1.5228021144866943, accuracy: 48.2 %\n",
      "Training round [86/200], qnn_train_step: [3300/500], loss: 1.6029084920883179, accuracy: 46.2 %\n",
      "Training round [86/200], qnn_train_step: [3400/500], loss: 1.6365622282028198, accuracy: 43.1 %\n",
      "Training round [86/200], qnn_train_step: [3500/500], loss: 1.5883746147155762, accuracy: 45.1 %\n",
      "Training round [86/200], qnn_train_step: [3600/500], loss: 1.5661346912384033, accuracy: 45.9 %\n",
      "Training round [86/200], qnn_train_step: [3700/500], loss: 1.518082857131958, accuracy: 48.0 %\n",
      "Training round [86/200], qnn_train_step: [3800/500], loss: 1.5693211555480957, accuracy: 44.7 %\n",
      "Training round [86/200], qnn_train_step: [3900/500], loss: 1.5333960056304932, accuracy: 48.6 %\n",
      "Training round [86/200], qnn_train_step: [4000/500], loss: 1.5186293125152588, accuracy: 49.3 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 1.5232, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 1.5696, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 1.3356, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 1.7139, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 1.5928, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 1.5598, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 1.4294, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 1.6063, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 1.5716, batch time: 0.08, accuracy:  46.88%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 1.4899, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [87/200], qnn_train_step: [100/500], loss: 1.5797693729400635, accuracy: 49.9 %\n",
      "Training round [87/200], qnn_train_step: [200/500], loss: 1.55967116355896, accuracy: 52.3 %\n",
      "Training round [87/200], qnn_train_step: [300/500], loss: 1.9914292097091675, accuracy: 36.4 %\n",
      "Training round [87/200], qnn_train_step: [400/500], loss: 1.5994027853012085, accuracy: 48.7 %\n",
      "Training round [87/200], qnn_train_step: [500/500], loss: 1.5591033697128296, accuracy: 52.4 %\n",
      "Training round [87/200], qnn_train_step: [600/500], loss: 2.0394809246063232, accuracy: 37.4 %\n",
      "Training round [87/200], qnn_train_step: [700/500], loss: 1.6028491258621216, accuracy: 47.9 %\n",
      "Training round [87/200], qnn_train_step: [800/500], loss: 1.5585335493087769, accuracy: 52.3 %\n",
      "Training round [87/200], qnn_train_step: [900/500], loss: 2.179018974304199, accuracy: 32.3 %\n",
      "Training round [87/200], qnn_train_step: [1000/500], loss: 1.5686570405960083, accuracy: 51.6 %\n",
      "Training round [87/200], qnn_train_step: [1100/500], loss: 1.5581213235855103, accuracy: 52.3 %\n",
      "Training round [87/200], qnn_train_step: [1200/500], loss: 1.6764510869979858, accuracy: 45.4 %\n",
      "Training round [87/200], qnn_train_step: [1300/500], loss: 1.5695425271987915, accuracy: 51.4 %\n",
      "Training round [87/200], qnn_train_step: [1400/500], loss: 1.5576237440109253, accuracy: 52.2 %\n",
      "Training round [87/200], qnn_train_step: [1500/500], loss: 1.6853595972061157, accuracy: 47.4 %\n",
      "Training round [87/200], qnn_train_step: [1600/500], loss: 1.5712298154830933, accuracy: 52.0 %\n",
      "Training round [87/200], qnn_train_step: [1700/500], loss: 1.5570595264434814, accuracy: 52.2 %\n",
      "Training round [87/200], qnn_train_step: [1800/500], loss: 1.686528205871582, accuracy: 43.2 %\n",
      "Training round [87/200], qnn_train_step: [1900/500], loss: 1.5719293355941772, accuracy: 51.2 %\n",
      "Training round [87/200], qnn_train_step: [2000/500], loss: 1.5567063093185425, accuracy: 52.2 %\n",
      "Training round [87/200], qnn_train_step: [2100/500], loss: 1.6896727085113525, accuracy: 46.4 %\n",
      "Training round [87/200], qnn_train_step: [2200/500], loss: 1.5723562240600586, accuracy: 49.8 %\n",
      "Training round [87/200], qnn_train_step: [2300/500], loss: 1.5562156438827515, accuracy: 52.1 %\n",
      "Training round [87/200], qnn_train_step: [2400/500], loss: 1.7080073356628418, accuracy: 43.1 %\n",
      "Training round [87/200], qnn_train_step: [2500/500], loss: 1.5735691785812378, accuracy: 50.4 %\n",
      "Training round [87/200], qnn_train_step: [2600/500], loss: 1.5557550191879272, accuracy: 52.1 %\n",
      "Training round [87/200], qnn_train_step: [2700/500], loss: 1.7114466428756714, accuracy: 44.2 %\n",
      "Training round [87/200], qnn_train_step: [2800/500], loss: 1.5752145051956177, accuracy: 50.1 %\n",
      "Training round [87/200], qnn_train_step: [2900/500], loss: 1.555367112159729, accuracy: 52.1 %\n",
      "Training round [87/200], qnn_train_step: [3000/500], loss: 1.7117915153503418, accuracy: 43.9 %\n",
      "Training round [87/200], qnn_train_step: [3100/500], loss: 1.5766209363937378, accuracy: 50.1 %\n",
      "Training round [87/200], qnn_train_step: [3200/500], loss: 1.554990530014038, accuracy: 52.0 %\n",
      "Training round [87/200], qnn_train_step: [3300/500], loss: 1.7184557914733887, accuracy: 41.8 %\n",
      "Training round [87/200], qnn_train_step: [3400/500], loss: 1.576836109161377, accuracy: 47.6 %\n",
      "Training round [87/200], qnn_train_step: [3500/500], loss: 1.5545393228530884, accuracy: 52.1 %\n",
      "Training round [87/200], qnn_train_step: [3600/500], loss: 1.7192171812057495, accuracy: 45.4 %\n",
      "Training round [87/200], qnn_train_step: [3700/500], loss: 1.5779531002044678, accuracy: 50.6 %\n",
      "Training round [87/200], qnn_train_step: [3800/500], loss: 1.5541150569915771, accuracy: 52.1 %\n",
      "Training round [87/200], qnn_train_step: [3900/500], loss: 1.7249408960342407, accuracy: 46.8 %\n",
      "Training round [87/200], qnn_train_step: [4000/500], loss: 1.5785588026046753, accuracy: 51.2 %\n",
      "Training round [87/200], qnn_train_step: [4100/500], loss: 1.5537720918655396, accuracy: 52.3 %\n",
      "Training round [87/200], qnn_train_step: [4200/500], loss: 1.7329769134521484, accuracy: 42.7 %\n",
      "Training round [87/200], qnn_train_step: [4300/500], loss: 1.5802812576293945, accuracy: 48.9 %\n",
      "Training round [87/200], qnn_train_step: [4400/500], loss: 1.5533223152160645, accuracy: 52.2 %\n",
      "Training round [87/200], qnn_train_step: [4500/500], loss: 1.75149667263031, accuracy: 43.9 %\n",
      "Training round [87/200], qnn_train_step: [4600/500], loss: 1.58677339553833, accuracy: 47.8 %\n",
      "Training round [87/200], qnn_train_step: [4700/500], loss: 1.569527268409729, accuracy: 49.5 %\n",
      "Training round [87/200], qnn_train_step: [4800/500], loss: 1.5575162172317505, accuracy: 49.4 %\n",
      "Training round [87/200], qnn_train_step: [4900/500], loss: 1.5517427921295166, accuracy: 49.9 %\n",
      "Training round [87/200], qnn_train_step: [5000/500], loss: 1.5477553606033325, accuracy: 51.0 %\n",
      "Training round [87/200], qnn_train_step: [5100/500], loss: 1.5557926893234253, accuracy: 51.2 %\n",
      "Training round [87/200], qnn_train_step: [5200/500], loss: 1.5451688766479492, accuracy: 50.1 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 1.4544, batch time: 0.03, accuracy:  53.12%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 1.3788, batch time: 0.03, accuracy:  57.81%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 1.4859, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 1.4885, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 1.6540, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 1.6144, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 1.5243, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 1.5175, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 1.5412, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 1.6089, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [88/200], qnn_train_step: [100/500], loss: 1.5453578233718872, accuracy: 47.8 %\n",
      "Training round [88/200], qnn_train_step: [200/500], loss: 1.5210777521133423, accuracy: 49.5 %\n",
      "Training round [88/200], qnn_train_step: [300/500], loss: 1.8420323133468628, accuracy: 38.4 %\n",
      "Training round [88/200], qnn_train_step: [400/500], loss: 1.5501724481582642, accuracy: 49.1 %\n",
      "Training round [88/200], qnn_train_step: [500/500], loss: 1.5209834575653076, accuracy: 49.5 %\n",
      "Training round [88/200], qnn_train_step: [600/500], loss: 1.8606340885162354, accuracy: 37.7 %\n",
      "Training round [88/200], qnn_train_step: [700/500], loss: 1.553506851196289, accuracy: 47.5 %\n",
      "Training round [88/200], qnn_train_step: [800/500], loss: 1.5208981037139893, accuracy: 49.5 %\n",
      "Training round [88/200], qnn_train_step: [900/500], loss: 1.9002071619033813, accuracy: 38.5 %\n",
      "Training round [88/200], qnn_train_step: [1000/500], loss: 1.556105375289917, accuracy: 46.1 %\n",
      "Training round [88/200], qnn_train_step: [1100/500], loss: 1.5208442211151123, accuracy: 49.5 %\n",
      "Training round [88/200], qnn_train_step: [1200/500], loss: 1.9275755882263184, accuracy: 34.5 %\n",
      "Training round [88/200], qnn_train_step: [1300/500], loss: 1.5578895807266235, accuracy: 48.1 %\n",
      "Training round [88/200], qnn_train_step: [1400/500], loss: 1.520782470703125, accuracy: 49.5 %\n",
      "Training round [88/200], qnn_train_step: [1500/500], loss: 1.9582414627075195, accuracy: 33.1 %\n",
      "Training round [88/200], qnn_train_step: [1600/500], loss: 1.748784065246582, accuracy: 42.3 %\n",
      "Training round [88/200], qnn_train_step: [1700/500], loss: 1.5999983549118042, accuracy: 45.6 %\n",
      "Training round [88/200], qnn_train_step: [1800/500], loss: 1.550153374671936, accuracy: 49.0 %\n",
      "Training round [88/200], qnn_train_step: [1900/500], loss: 1.5443761348724365, accuracy: 47.1 %\n",
      "Training round [88/200], qnn_train_step: [2000/500], loss: 1.5255534648895264, accuracy: 49.1 %\n",
      "Training round [88/200], qnn_train_step: [2100/500], loss: 1.5419666767120361, accuracy: 48.4 %\n",
      "Training round [88/200], qnn_train_step: [2200/500], loss: 1.5200016498565674, accuracy: 48.5 %\n",
      "Training round [88/200], qnn_train_step: [2300/500], loss: 1.5178509950637817, accuracy: 48.4 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 1.7448, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 1.5872, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 1.5581, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 1.5326, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 1.5095, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 1.5894, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 1.5137, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 1.5804, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 1.5784, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 1.6640, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [89/200], qnn_train_step: [100/500], loss: 1.5358150005340576, accuracy: 49.4 %\n",
      "Training round [89/200], qnn_train_step: [200/500], loss: 1.5254650115966797, accuracy: 49.8 %\n",
      "Training round [89/200], qnn_train_step: [300/500], loss: 1.9731336832046509, accuracy: 39.5 %\n",
      "Training round [89/200], qnn_train_step: [400/500], loss: 1.5642979145050049, accuracy: 48.6 %\n",
      "Training round [89/200], qnn_train_step: [500/500], loss: 1.524868130683899, accuracy: 49.7 %\n",
      "Training round [89/200], qnn_train_step: [600/500], loss: 1.9894359111785889, accuracy: 35.0 %\n",
      "Training round [89/200], qnn_train_step: [700/500], loss: 1.5663533210754395, accuracy: 48.1 %\n",
      "Training round [89/200], qnn_train_step: [800/500], loss: 1.524189829826355, accuracy: 49.7 %\n",
      "Training round [89/200], qnn_train_step: [900/500], loss: 2.1596429347991943, accuracy: 29.2 %\n",
      "Training round [89/200], qnn_train_step: [1000/500], loss: 1.5663565397262573, accuracy: 50.1 %\n",
      "Training round [89/200], qnn_train_step: [1100/500], loss: 1.5236101150512695, accuracy: 49.8 %\n",
      "Training round [89/200], qnn_train_step: [1200/500], loss: 2.268662214279175, accuracy: 30.4 %\n",
      "Training round [89/200], qnn_train_step: [1300/500], loss: 1.571312427520752, accuracy: 48.5 %\n",
      "Training round [89/200], qnn_train_step: [1400/500], loss: 1.5169692039489746, accuracy: 48.1 %\n",
      "Training round [89/200], qnn_train_step: [1500/500], loss: 1.5784602165222168, accuracy: 48.4 %\n",
      "Training round [89/200], qnn_train_step: [1600/500], loss: 1.5234109163284302, accuracy: 49.8 %\n",
      "Training round [89/200], qnn_train_step: [1700/500], loss: 1.5182446241378784, accuracy: 49.4 %\n",
      "Training round [89/200], qnn_train_step: [1800/500], loss: 1.5832993984222412, accuracy: 49.1 %\n",
      "Training round [89/200], qnn_train_step: [1900/500], loss: 1.5236812829971313, accuracy: 49.8 %\n",
      "Training round [89/200], qnn_train_step: [2000/500], loss: 1.5204932689666748, accuracy: 50.1 %\n",
      "Training round [89/200], qnn_train_step: [2100/500], loss: 1.5836830139160156, accuracy: 48.1 %\n",
      "Training round [89/200], qnn_train_step: [2200/500], loss: 1.5237094163894653, accuracy: 49.6 %\n",
      "Training round [89/200], qnn_train_step: [2300/500], loss: 1.5200639963150024, accuracy: 49.8 %\n",
      "Training round [89/200], qnn_train_step: [2400/500], loss: 1.5845545530319214, accuracy: 46.1 %\n",
      "Training round [89/200], qnn_train_step: [2500/500], loss: 1.5238991975784302, accuracy: 49.8 %\n",
      "Training round [89/200], qnn_train_step: [2600/500], loss: 1.520725131034851, accuracy: 49.6 %\n",
      "Training round [89/200], qnn_train_step: [2700/500], loss: 1.5926240682601929, accuracy: 48.5 %\n",
      "Training round [89/200], qnn_train_step: [2800/500], loss: 1.5258735418319702, accuracy: 49.1 %\n",
      "Training round [89/200], qnn_train_step: [2900/500], loss: 1.5203702449798584, accuracy: 49.8 %\n",
      "Training round [89/200], qnn_train_step: [3000/500], loss: 1.5984750986099243, accuracy: 46.8 %\n",
      "Training round [89/200], qnn_train_step: [3100/500], loss: 1.5274112224578857, accuracy: 48.8 %\n",
      "Training round [89/200], qnn_train_step: [3200/500], loss: 1.51985764503479, accuracy: 50.0 %\n",
      "Training round [89/200], qnn_train_step: [3300/500], loss: 1.6000666618347168, accuracy: 47.3 %\n",
      "Training round [89/200], qnn_train_step: [3400/500], loss: 1.5271937847137451, accuracy: 49.2 %\n",
      "Training round [89/200], qnn_train_step: [3500/500], loss: 1.519404649734497, accuracy: 50.0 %\n",
      "Training round [89/200], qnn_train_step: [3600/500], loss: 1.6051267385482788, accuracy: 47.5 %\n",
      "Training round [89/200], qnn_train_step: [3700/500], loss: 1.5266460180282593, accuracy: 50.0 %\n",
      "Training round [89/200], qnn_train_step: [3800/500], loss: 1.518947720527649, accuracy: 50.1 %\n",
      "Training round [89/200], qnn_train_step: [3900/500], loss: 1.6062008142471313, accuracy: 47.4 %\n",
      "Training round [89/200], qnn_train_step: [4000/500], loss: 1.5279737710952759, accuracy: 49.8 %\n",
      "Training round [89/200], qnn_train_step: [4100/500], loss: 1.518470048904419, accuracy: 50.0 %\n",
      "Training round [89/200], qnn_train_step: [4200/500], loss: 1.6113464832305908, accuracy: 44.5 %\n",
      "Training round [89/200], qnn_train_step: [4300/500], loss: 1.5283557176589966, accuracy: 49.2 %\n",
      "Training round [89/200], qnn_train_step: [4400/500], loss: 1.5180654525756836, accuracy: 50.1 %\n",
      "Training round [89/200], qnn_train_step: [4500/500], loss: 1.6086723804473877, accuracy: 47.2 %\n",
      "Training round [89/200], qnn_train_step: [4600/500], loss: 1.5276614427566528, accuracy: 49.2 %\n",
      "Training round [89/200], qnn_train_step: [4700/500], loss: 1.517577052116394, accuracy: 50.0 %\n",
      "Training round [89/200], qnn_train_step: [4800/500], loss: 1.6109669208526611, accuracy: 46.4 %\n",
      "Training round [89/200], qnn_train_step: [4900/500], loss: 1.5275778770446777, accuracy: 49.2 %\n",
      "Training round [89/200], qnn_train_step: [5000/500], loss: 1.51715886592865, accuracy: 50.0 %\n",
      "Training round [89/200], qnn_train_step: [5100/500], loss: 1.6135352849960327, accuracy: 47.5 %\n",
      "Training round [89/200], qnn_train_step: [5200/500], loss: 1.6638387441635132, accuracy: 44.5 %\n",
      "Training round [89/200], qnn_train_step: [5300/500], loss: 1.523188591003418, accuracy: 50.1 %\n",
      "Training round [89/200], qnn_train_step: [5400/500], loss: 1.5650663375854492, accuracy: 49.0 %\n",
      "Training round [89/200], qnn_train_step: [5500/500], loss: 1.5293269157409668, accuracy: 49.6 %\n",
      "Training round [89/200], qnn_train_step: [5600/500], loss: 1.5137232542037964, accuracy: 50.2 %\n",
      "Training round [89/200], qnn_train_step: [5700/500], loss: 1.5044081211090088, accuracy: 51.1 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 1.6994, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 1.3855, batch time: 0.03, accuracy:  54.69%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 1.6258, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 1.4552, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 1.7379, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 1.4080, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 1.3388, batch time: 0.03, accuracy:  56.25%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 1.3750, batch time: 0.03, accuracy:  55.47%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 1.5448, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 1.4825, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [90/200], qnn_train_step: [100/500], loss: 1.5691848993301392, accuracy: 44.2 %\n",
      "Training round [90/200], qnn_train_step: [200/500], loss: 1.6934614181518555, accuracy: 41.4 %\n",
      "Training round [90/200], qnn_train_step: [300/500], loss: 1.5618033409118652, accuracy: 46.7 %\n",
      "Training round [90/200], qnn_train_step: [400/500], loss: 1.5307700634002686, accuracy: 48.4 %\n",
      "Training round [90/200], qnn_train_step: [500/500], loss: 1.7297202348709106, accuracy: 41.5 %\n",
      "Training round [90/200], qnn_train_step: [600/500], loss: 1.5636883974075317, accuracy: 46.0 %\n",
      "Training round [90/200], qnn_train_step: [700/500], loss: 1.5306352376937866, accuracy: 48.4 %\n",
      "Training round [90/200], qnn_train_step: [800/500], loss: 1.7396209239959717, accuracy: 46.2 %\n",
      "Training round [90/200], qnn_train_step: [900/500], loss: 1.5666589736938477, accuracy: 44.5 %\n",
      "Training round [90/200], qnn_train_step: [1000/500], loss: 1.5304865837097168, accuracy: 48.3 %\n",
      "Training round [90/200], qnn_train_step: [1100/500], loss: 1.741973638534546, accuracy: 42.6 %\n",
      "Training round [90/200], qnn_train_step: [1200/500], loss: 1.5718079805374146, accuracy: 48.2 %\n",
      "Training round [90/200], qnn_train_step: [1300/500], loss: 1.5303902626037598, accuracy: 48.3 %\n",
      "Training round [90/200], qnn_train_step: [1400/500], loss: 1.7450460195541382, accuracy: 37.6 %\n",
      "Training round [90/200], qnn_train_step: [1500/500], loss: 1.5745904445648193, accuracy: 46.6 %\n",
      "Training round [90/200], qnn_train_step: [1600/500], loss: 1.530269980430603, accuracy: 48.3 %\n",
      "Training round [90/200], qnn_train_step: [1700/500], loss: 1.7456587553024292, accuracy: 40.9 %\n",
      "Training round [90/200], qnn_train_step: [1800/500], loss: 1.5753902196884155, accuracy: 48.2 %\n",
      "Training round [90/200], qnn_train_step: [1900/500], loss: 1.5301644802093506, accuracy: 48.2 %\n",
      "Training round [90/200], qnn_train_step: [2000/500], loss: 1.82465660572052, accuracy: 44.4 %\n",
      "Training round [90/200], qnn_train_step: [2100/500], loss: 1.5777459144592285, accuracy: 44.9 %\n",
      "Training round [90/200], qnn_train_step: [2200/500], loss: 1.5304330587387085, accuracy: 48.3 %\n",
      "Training round [90/200], qnn_train_step: [2300/500], loss: 1.9040627479553223, accuracy: 41.7 %\n",
      "Training round [90/200], qnn_train_step: [2400/500], loss: 1.5871819257736206, accuracy: 45.0 %\n",
      "Training round [90/200], qnn_train_step: [2500/500], loss: 1.530395269393921, accuracy: 48.4 %\n",
      "Training round [90/200], qnn_train_step: [2600/500], loss: 1.5276352167129517, accuracy: 48.5 %\n",
      "Training round [90/200], qnn_train_step: [2700/500], loss: 1.5927410125732422, accuracy: 47.6 %\n",
      "Training round [90/200], qnn_train_step: [2800/500], loss: 1.5307466983795166, accuracy: 48.5 %\n",
      "Training round [90/200], qnn_train_step: [2900/500], loss: 1.5279005765914917, accuracy: 48.4 %\n",
      "Training round [90/200], qnn_train_step: [3000/500], loss: 1.5926103591918945, accuracy: 47.3 %\n",
      "Training round [90/200], qnn_train_step: [3100/500], loss: 1.530737042427063, accuracy: 46.9 %\n",
      "Training round [90/200], qnn_train_step: [3200/500], loss: 1.529046654701233, accuracy: 48.0 %\n",
      "Training round [90/200], qnn_train_step: [3300/500], loss: 1.6007685661315918, accuracy: 46.4 %\n",
      "Training round [90/200], qnn_train_step: [3400/500], loss: 1.5315003395080566, accuracy: 48.0 %\n",
      "Training round [90/200], qnn_train_step: [3500/500], loss: 1.529115080833435, accuracy: 48.3 %\n",
      "Training round [90/200], qnn_train_step: [3600/500], loss: 1.5993094444274902, accuracy: 44.4 %\n",
      "Training round [90/200], qnn_train_step: [3700/500], loss: 1.5317970514297485, accuracy: 48.0 %\n",
      "Training round [90/200], qnn_train_step: [3800/500], loss: 1.5292367935180664, accuracy: 48.3 %\n",
      "Training round [90/200], qnn_train_step: [3900/500], loss: 1.6034053564071655, accuracy: 46.7 %\n",
      "Training round [90/200], qnn_train_step: [4000/500], loss: 1.5321377515792847, accuracy: 50.0 %\n",
      "Training round [90/200], qnn_train_step: [4100/500], loss: 1.5293660163879395, accuracy: 48.2 %\n",
      "Training round [90/200], qnn_train_step: [4200/500], loss: 1.6127688884735107, accuracy: 46.7 %\n",
      "Training round [90/200], qnn_train_step: [4300/500], loss: 1.5333852767944336, accuracy: 47.0 %\n",
      "Training round [90/200], qnn_train_step: [4400/500], loss: 1.5292766094207764, accuracy: 48.3 %\n",
      "Training round [90/200], qnn_train_step: [4500/500], loss: 1.6119704246520996, accuracy: 46.3 %\n",
      "Training round [90/200], qnn_train_step: [4600/500], loss: 1.5337955951690674, accuracy: 48.4 %\n",
      "Training round [90/200], qnn_train_step: [4700/500], loss: 1.5291861295700073, accuracy: 48.3 %\n",
      "Training round [90/200], qnn_train_step: [4800/500], loss: 1.613309383392334, accuracy: 43.6 %\n",
      "Training round [90/200], qnn_train_step: [4900/500], loss: 1.5354573726654053, accuracy: 47.2 %\n",
      "Training round [90/200], qnn_train_step: [5000/500], loss: 1.5290888547897339, accuracy: 48.3 %\n",
      "Training round [90/200], qnn_train_step: [5100/500], loss: 1.6143945455551147, accuracy: 43.5 %\n",
      "Training round [90/200], qnn_train_step: [5200/500], loss: 1.5360368490219116, accuracy: 48.3 %\n",
      "Training round [90/200], qnn_train_step: [5300/500], loss: 1.5289884805679321, accuracy: 48.3 %\n",
      "Training round [90/200], qnn_train_step: [5400/500], loss: 1.6131136417388916, accuracy: 45.9 %\n",
      "Training round [90/200], qnn_train_step: [5500/500], loss: 1.5708317756652832, accuracy: 46.1 %\n",
      "Training round [90/200], qnn_train_step: [5600/500], loss: 1.5483320951461792, accuracy: 46.2 %\n",
      "Training round [90/200], qnn_train_step: [5700/500], loss: 1.5355961322784424, accuracy: 46.3 %\n",
      "Training round [90/200], qnn_train_step: [5800/500], loss: 1.5308455228805542, accuracy: 46.0 %\n",
      "Training round [90/200], qnn_train_step: [5900/500], loss: 1.5273561477661133, accuracy: 46.8 %\n",
      "Training round [90/200], qnn_train_step: [6000/500], loss: 1.5324023962020874, accuracy: 47.9 %\n",
      "Training round [90/200], qnn_train_step: [6100/500], loss: 1.5287656784057617, accuracy: 46.6 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 1.7153, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 1.4574, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 1.5865, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 1.5457, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 1.5148, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 1.4128, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 1.6322, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 1.5411, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 1.6115, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 1.4346, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [91/200], qnn_train_step: [100/500], loss: 1.5650920867919922, accuracy: 45.1 %\n",
      "Training round [91/200], qnn_train_step: [200/500], loss: 1.8599785566329956, accuracy: 38.4 %\n",
      "Training round [91/200], qnn_train_step: [300/500], loss: 1.6305205821990967, accuracy: 42.5 %\n",
      "Training round [91/200], qnn_train_step: [400/500], loss: 1.6728483438491821, accuracy: 41.1 %\n",
      "Training round [91/200], qnn_train_step: [500/500], loss: 1.6125822067260742, accuracy: 42.9 %\n",
      "Training round [91/200], qnn_train_step: [600/500], loss: 1.5725014209747314, accuracy: 43.7 %\n",
      "Training round [91/200], qnn_train_step: [700/500], loss: 1.566516399383545, accuracy: 44.2 %\n",
      "Training round [91/200], qnn_train_step: [800/500], loss: 1.5554308891296387, accuracy: 44.9 %\n",
      "Training round [91/200], qnn_train_step: [900/500], loss: 1.5650548934936523, accuracy: 45.2 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 1.4802, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 1.5154, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 1.5486, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 1.3342, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 1.6638, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 1.4766, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 1.8422, batch time: 0.08, accuracy:  42.19%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 1.4834, batch time: 0.08, accuracy:  52.34%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 1.4775, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 1.4702, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [92/200], qnn_train_step: [100/500], loss: 1.5668123960494995, accuracy: 45.8 %\n",
      "Training round [92/200], qnn_train_step: [200/500], loss: 1.8116657733917236, accuracy: 39.9 %\n",
      "Training round [92/200], qnn_train_step: [300/500], loss: 1.5508484840393066, accuracy: 46.9 %\n",
      "Training round [92/200], qnn_train_step: [400/500], loss: 1.5351122617721558, accuracy: 47.4 %\n",
      "Training round [92/200], qnn_train_step: [500/500], loss: 1.7017079591751099, accuracy: 45.9 %\n",
      "Training round [92/200], qnn_train_step: [600/500], loss: 1.5536339282989502, accuracy: 47.0 %\n",
      "Training round [92/200], qnn_train_step: [700/500], loss: 1.5350921154022217, accuracy: 47.4 %\n",
      "Training round [92/200], qnn_train_step: [800/500], loss: 1.6983394622802734, accuracy: 42.6 %\n",
      "Training round [92/200], qnn_train_step: [900/500], loss: 1.554610013961792, accuracy: 47.3 %\n",
      "Training round [92/200], qnn_train_step: [1000/500], loss: 1.5350767374038696, accuracy: 47.5 %\n",
      "Training round [92/200], qnn_train_step: [1100/500], loss: 1.69707190990448, accuracy: 43.1 %\n",
      "Training round [92/200], qnn_train_step: [1200/500], loss: 1.5558819770812988, accuracy: 47.7 %\n",
      "Training round [92/200], qnn_train_step: [1300/500], loss: 1.5350887775421143, accuracy: 47.5 %\n",
      "Training round [92/200], qnn_train_step: [1400/500], loss: 1.6968847513198853, accuracy: 42.2 %\n",
      "Training round [92/200], qnn_train_step: [1500/500], loss: 1.5586484670639038, accuracy: 48.1 %\n",
      "Training round [92/200], qnn_train_step: [1600/500], loss: 1.535070776939392, accuracy: 47.5 %\n",
      "Training round [92/200], qnn_train_step: [1700/500], loss: 1.6948720216751099, accuracy: 42.9 %\n",
      "Training round [92/200], qnn_train_step: [1800/500], loss: 1.5587525367736816, accuracy: 48.5 %\n",
      "Training round [92/200], qnn_train_step: [1900/500], loss: 1.5350534915924072, accuracy: 47.5 %\n",
      "Training round [92/200], qnn_train_step: [2000/500], loss: 1.6940202713012695, accuracy: 45.0 %\n",
      "Training round [92/200], qnn_train_step: [2100/500], loss: 1.5588290691375732, accuracy: 46.9 %\n",
      "Training round [92/200], qnn_train_step: [2200/500], loss: 1.535053014755249, accuracy: 47.5 %\n",
      "Training round [92/200], qnn_train_step: [2300/500], loss: 1.6990009546279907, accuracy: 41.7 %\n",
      "Training round [92/200], qnn_train_step: [2400/500], loss: 1.563398838043213, accuracy: 44.3 %\n",
      "Training round [92/200], qnn_train_step: [2500/500], loss: 1.5350342988967896, accuracy: 47.5 %\n",
      "Training round [92/200], qnn_train_step: [2600/500], loss: 1.6974996328353882, accuracy: 41.9 %\n",
      "Training round [92/200], qnn_train_step: [2700/500], loss: 1.5667240619659424, accuracy: 47.6 %\n",
      "Training round [92/200], qnn_train_step: [2800/500], loss: 1.535037636756897, accuracy: 47.6 %\n",
      "Training round [92/200], qnn_train_step: [2900/500], loss: 1.6974376440048218, accuracy: 44.9 %\n",
      "Training round [92/200], qnn_train_step: [3000/500], loss: 1.5747764110565186, accuracy: 46.7 %\n",
      "Training round [92/200], qnn_train_step: [3100/500], loss: 1.5350866317749023, accuracy: 47.4 %\n",
      "Training round [92/200], qnn_train_step: [3200/500], loss: 1.6967264413833618, accuracy: 42.8 %\n",
      "Training round [92/200], qnn_train_step: [3300/500], loss: 1.5806066989898682, accuracy: 48.2 %\n",
      "Training round [92/200], qnn_train_step: [3400/500], loss: 1.535176396369934, accuracy: 47.7 %\n",
      "Training round [92/200], qnn_train_step: [3500/500], loss: 1.7016212940216064, accuracy: 42.5 %\n",
      "Training round [92/200], qnn_train_step: [3600/500], loss: 1.5846556425094604, accuracy: 46.6 %\n",
      "Training round [92/200], qnn_train_step: [3700/500], loss: 1.5352829694747925, accuracy: 47.5 %\n",
      "Training round [92/200], qnn_train_step: [3800/500], loss: 5.847332954406738, accuracy: 13.5 %\n",
      "Training round [92/200], qnn_train_step: [3900/500], loss: 1.5849645137786865, accuracy: 47.4 %\n",
      "Training round [92/200], qnn_train_step: [4000/500], loss: 1.5355771780014038, accuracy: 47.8 %\n",
      "Training round [92/200], qnn_train_step: [4100/500], loss: 1.5344440937042236, accuracy: 47.6 %\n",
      "Training round [92/200], qnn_train_step: [4200/500], loss: 1.5930298566818237, accuracy: 48.0 %\n",
      "Training round [92/200], qnn_train_step: [4300/500], loss: 1.5356411933898926, accuracy: 47.8 %\n",
      "Training round [92/200], qnn_train_step: [4400/500], loss: 1.534565806388855, accuracy: 47.5 %\n",
      "Training round [92/200], qnn_train_step: [4500/500], loss: 1.595590353012085, accuracy: 47.7 %\n",
      "Training round [92/200], qnn_train_step: [4600/500], loss: 1.5361857414245605, accuracy: 47.4 %\n",
      "Training round [92/200], qnn_train_step: [4700/500], loss: 1.534808874130249, accuracy: 47.4 %\n",
      "Training round [92/200], qnn_train_step: [4800/500], loss: 1.597398281097412, accuracy: 46.4 %\n",
      "Training round [92/200], qnn_train_step: [4900/500], loss: 1.5372141599655151, accuracy: 47.8 %\n",
      "Training round [92/200], qnn_train_step: [5000/500], loss: 1.5348756313323975, accuracy: 47.6 %\n",
      "Training round [92/200], qnn_train_step: [5100/500], loss: 1.6025593280792236, accuracy: 45.1 %\n",
      "Training round [92/200], qnn_train_step: [5200/500], loss: 1.537373661994934, accuracy: 48.0 %\n",
      "Training round [92/200], qnn_train_step: [5300/500], loss: 1.5349061489105225, accuracy: 47.6 %\n",
      "Training round [92/200], qnn_train_step: [5400/500], loss: 1.6085182428359985, accuracy: 45.4 %\n",
      "Training round [92/200], qnn_train_step: [5500/500], loss: 1.5377212762832642, accuracy: 47.7 %\n",
      "Training round [92/200], qnn_train_step: [5600/500], loss: 1.5348737239837646, accuracy: 47.6 %\n",
      "Training round [92/200], qnn_train_step: [5700/500], loss: 1.6112728118896484, accuracy: 44.0 %\n",
      "Training round [92/200], qnn_train_step: [5800/500], loss: 1.5378212928771973, accuracy: 47.9 %\n",
      "Training round [92/200], qnn_train_step: [5900/500], loss: 1.5348695516586304, accuracy: 47.6 %\n",
      "Training round [92/200], qnn_train_step: [6000/500], loss: 1.6110713481903076, accuracy: 45.0 %\n",
      "Training round [92/200], qnn_train_step: [6100/500], loss: 1.5383048057556152, accuracy: 47.9 %\n",
      "Training round [92/200], qnn_train_step: [6200/500], loss: 1.6965972185134888, accuracy: 44.3 %\n",
      "Training round [92/200], qnn_train_step: [6300/500], loss: 1.5682990550994873, accuracy: 47.1 %\n",
      "Training round [92/200], qnn_train_step: [6400/500], loss: 1.5713841915130615, accuracy: 45.7 %\n",
      "Training round [92/200], qnn_train_step: [6500/500], loss: 1.5447241067886353, accuracy: 47.6 %\n",
      "Training round [92/200], qnn_train_step: [6600/500], loss: 1.5485482215881348, accuracy: 48.0 %\n",
      "Training round [92/200], qnn_train_step: [6700/500], loss: 1.537725567817688, accuracy: 48.2 %\n",
      "Training round [92/200], qnn_train_step: [6800/500], loss: 1.5322575569152832, accuracy: 48.3 %\n",
      "Training round [92/200], qnn_train_step: [6900/500], loss: 1.5348879098892212, accuracy: 48.4 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 1.3931, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 1.4075, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 1.5691, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 1.5478, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 1.6211, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 1.4679, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 1.4049, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 1.5136, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 1.5779, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 1.4222, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [93/200], qnn_train_step: [100/500], loss: 1.5321255922317505, accuracy: 47.5 %\n",
      "Training round [93/200], qnn_train_step: [200/500], loss: 2.0659782886505127, accuracy: 34.5 %\n",
      "Training round [93/200], qnn_train_step: [300/500], loss: 1.5170774459838867, accuracy: 49.3 %\n",
      "Training round [93/200], qnn_train_step: [400/500], loss: 1.488350510597229, accuracy: 49.4 %\n",
      "Training round [93/200], qnn_train_step: [500/500], loss: 1.690433144569397, accuracy: 39.9 %\n",
      "Training round [93/200], qnn_train_step: [600/500], loss: 1.5254100561141968, accuracy: 46.5 %\n",
      "Training round [93/200], qnn_train_step: [700/500], loss: 1.488302230834961, accuracy: 49.4 %\n",
      "Training round [93/200], qnn_train_step: [800/500], loss: 1.6867419481277466, accuracy: 45.3 %\n",
      "Training round [93/200], qnn_train_step: [900/500], loss: 1.5262000560760498, accuracy: 46.2 %\n",
      "Training round [93/200], qnn_train_step: [1000/500], loss: 1.4882712364196777, accuracy: 49.4 %\n",
      "Training round [93/200], qnn_train_step: [1100/500], loss: 1.6921509504318237, accuracy: 46.1 %\n",
      "Training round [93/200], qnn_train_step: [1200/500], loss: 1.5287182331085205, accuracy: 47.7 %\n",
      "Training round [93/200], qnn_train_step: [1300/500], loss: 1.4882428646087646, accuracy: 49.4 %\n",
      "Training round [93/200], qnn_train_step: [1400/500], loss: 1.7056151628494263, accuracy: 44.0 %\n",
      "Training round [93/200], qnn_train_step: [1500/500], loss: 1.534096360206604, accuracy: 47.5 %\n",
      "Training round [93/200], qnn_train_step: [1600/500], loss: 1.4882779121398926, accuracy: 49.6 %\n",
      "Training round [93/200], qnn_train_step: [1700/500], loss: 1.7098685503005981, accuracy: 42.3 %\n",
      "Training round [93/200], qnn_train_step: [1800/500], loss: 1.539117455482483, accuracy: 45.8 %\n",
      "Training round [93/200], qnn_train_step: [1900/500], loss: 1.4882975816726685, accuracy: 49.4 %\n",
      "Training round [93/200], qnn_train_step: [2000/500], loss: 1.7130980491638184, accuracy: 39.3 %\n",
      "Training round [93/200], qnn_train_step: [2100/500], loss: 1.547304630279541, accuracy: 48.5 %\n",
      "Training round [93/200], qnn_train_step: [2200/500], loss: 1.488570213317871, accuracy: 49.6 %\n",
      "Training round [93/200], qnn_train_step: [2300/500], loss: 6.680587291717529, accuracy: 11.9 %\n",
      "Training round [93/200], qnn_train_step: [2400/500], loss: 1.5494072437286377, accuracy: 44.2 %\n",
      "Training round [93/200], qnn_train_step: [2500/500], loss: 1.4885762929916382, accuracy: 49.2 %\n",
      "Training round [93/200], qnn_train_step: [2600/500], loss: 1.486586332321167, accuracy: 49.3 %\n",
      "Training round [93/200], qnn_train_step: [2700/500], loss: 1.5496689081192017, accuracy: 46.9 %\n",
      "Training round [93/200], qnn_train_step: [2800/500], loss: 1.4887932538986206, accuracy: 49.4 %\n",
      "Training round [93/200], qnn_train_step: [2900/500], loss: 1.4877206087112427, accuracy: 49.3 %\n",
      "Training round [93/200], qnn_train_step: [3000/500], loss: 1.5591703653335571, accuracy: 49.2 %\n",
      "Training round [93/200], qnn_train_step: [3100/500], loss: 1.489039659500122, accuracy: 50.0 %\n",
      "Training round [93/200], qnn_train_step: [3200/500], loss: 1.4878220558166504, accuracy: 49.5 %\n",
      "Training round [93/200], qnn_train_step: [3300/500], loss: 1.5661554336547852, accuracy: 48.4 %\n",
      "Training round [93/200], qnn_train_step: [3400/500], loss: 1.4895390272140503, accuracy: 50.0 %\n",
      "Training round [93/200], qnn_train_step: [3500/500], loss: 1.4879242181777954, accuracy: 49.2 %\n",
      "Training round [93/200], qnn_train_step: [3600/500], loss: 1.5666937828063965, accuracy: 49.9 %\n",
      "Training round [93/200], qnn_train_step: [3700/500], loss: 1.490054965019226, accuracy: 50.0 %\n",
      "Training round [93/200], qnn_train_step: [3800/500], loss: 1.4879844188690186, accuracy: 49.4 %\n",
      "Training round [93/200], qnn_train_step: [3900/500], loss: 1.5691046714782715, accuracy: 47.0 %\n",
      "Training round [93/200], qnn_train_step: [4000/500], loss: 1.490757703781128, accuracy: 49.8 %\n",
      "Training round [93/200], qnn_train_step: [4100/500], loss: 1.4879567623138428, accuracy: 49.4 %\n",
      "Training round [93/200], qnn_train_step: [4200/500], loss: 1.5703625679016113, accuracy: 46.2 %\n",
      "Training round [93/200], qnn_train_step: [4300/500], loss: 1.490836262702942, accuracy: 49.7 %\n",
      "Training round [93/200], qnn_train_step: [4400/500], loss: 1.4879252910614014, accuracy: 49.4 %\n",
      "Training round [93/200], qnn_train_step: [4500/500], loss: 1.571048617362976, accuracy: 48.1 %\n",
      "Training round [93/200], qnn_train_step: [4600/500], loss: 1.4916119575500488, accuracy: 49.8 %\n",
      "Training round [93/200], qnn_train_step: [4700/500], loss: 1.4878902435302734, accuracy: 49.4 %\n",
      "Training round [93/200], qnn_train_step: [4800/500], loss: 1.5726194381713867, accuracy: 45.5 %\n",
      "Training round [93/200], qnn_train_step: [4900/500], loss: 1.4931690692901611, accuracy: 50.4 %\n",
      "Training round [93/200], qnn_train_step: [5000/500], loss: 1.4878787994384766, accuracy: 49.4 %\n",
      "Training round [93/200], qnn_train_step: [5100/500], loss: 1.5763753652572632, accuracy: 44.4 %\n",
      "Training round [93/200], qnn_train_step: [5200/500], loss: 1.5317295789718628, accuracy: 48.3 %\n",
      "Training round [93/200], qnn_train_step: [5300/500], loss: 1.5149537324905396, accuracy: 50.3 %\n",
      "Training round [93/200], qnn_train_step: [5400/500], loss: 1.502143383026123, accuracy: 48.0 %\n",
      "Training round [93/200], qnn_train_step: [5500/500], loss: 1.507086992263794, accuracy: 48.1 %\n",
      "Training round [93/200], qnn_train_step: [5600/500], loss: 1.503980278968811, accuracy: 47.9 %\n",
      "Training round [93/200], qnn_train_step: [5700/500], loss: 1.497774362564087, accuracy: 48.0 %\n",
      "Training round [93/200], qnn_train_step: [5800/500], loss: 1.487454891204834, accuracy: 50.5 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 1.4754, batch time: 0.08, accuracy:  48.44%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 1.5287, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 1.6133, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 1.4732, batch time: 0.03, accuracy:  53.12%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 1.5644, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 1.6732, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 1.6226, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 1.7295, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 1.5836, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 1.5052, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [94/200], qnn_train_step: [100/500], loss: 1.5619086027145386, accuracy: 45.7 %\n",
      "Training round [94/200], qnn_train_step: [200/500], loss: 1.7316372394561768, accuracy: 40.0 %\n",
      "Training round [94/200], qnn_train_step: [300/500], loss: 1.5482218265533447, accuracy: 47.5 %\n",
      "Training round [94/200], qnn_train_step: [400/500], loss: 1.5248219966888428, accuracy: 48.7 %\n",
      "Training round [94/200], qnn_train_step: [500/500], loss: 1.69384765625, accuracy: 44.4 %\n",
      "Training round [94/200], qnn_train_step: [600/500], loss: 1.5491628646850586, accuracy: 48.8 %\n",
      "Training round [94/200], qnn_train_step: [700/500], loss: 1.5247249603271484, accuracy: 48.8 %\n",
      "Training round [94/200], qnn_train_step: [800/500], loss: 1.6904480457305908, accuracy: 43.5 %\n",
      "Training round [94/200], qnn_train_step: [900/500], loss: 1.5498385429382324, accuracy: 48.3 %\n",
      "Training round [94/200], qnn_train_step: [1000/500], loss: 1.5247151851654053, accuracy: 48.7 %\n",
      "Training round [94/200], qnn_train_step: [1100/500], loss: 1.6926296949386597, accuracy: 45.4 %\n",
      "Training round [94/200], qnn_train_step: [1200/500], loss: 1.5537663698196411, accuracy: 46.9 %\n",
      "Training round [94/200], qnn_train_step: [1300/500], loss: 1.5246429443359375, accuracy: 48.6 %\n",
      "Training round [94/200], qnn_train_step: [1400/500], loss: 1.691707968711853, accuracy: 42.1 %\n",
      "Training round [94/200], qnn_train_step: [1500/500], loss: 1.5573949813842773, accuracy: 46.4 %\n",
      "Training round [94/200], qnn_train_step: [1600/500], loss: 1.5246026515960693, accuracy: 48.6 %\n",
      "Training round [94/200], qnn_train_step: [1700/500], loss: 1.7043486833572388, accuracy: 43.5 %\n",
      "Training round [94/200], qnn_train_step: [1800/500], loss: 1.5609275102615356, accuracy: 47.7 %\n",
      "Training round [94/200], qnn_train_step: [1900/500], loss: 1.524524211883545, accuracy: 48.6 %\n",
      "Training round [94/200], qnn_train_step: [2000/500], loss: 1.7026838064193726, accuracy: 41.5 %\n",
      "Training round [94/200], qnn_train_step: [2100/500], loss: 1.5623191595077515, accuracy: 47.0 %\n",
      "Training round [94/200], qnn_train_step: [2200/500], loss: 1.524427890777588, accuracy: 48.6 %\n",
      "Training round [94/200], qnn_train_step: [2300/500], loss: 1.703645944595337, accuracy: 44.6 %\n",
      "Training round [94/200], qnn_train_step: [2400/500], loss: 1.5645557641983032, accuracy: 47.9 %\n",
      "Training round [94/200], qnn_train_step: [2500/500], loss: 1.5243637561798096, accuracy: 48.6 %\n",
      "Training round [94/200], qnn_train_step: [2600/500], loss: 1.7186716794967651, accuracy: 42.4 %\n",
      "Training round [94/200], qnn_train_step: [2700/500], loss: 1.568532109260559, accuracy: 44.7 %\n",
      "Training round [94/200], qnn_train_step: [2800/500], loss: 1.5243232250213623, accuracy: 48.8 %\n",
      "Training round [94/200], qnn_train_step: [2900/500], loss: 1.7239731550216675, accuracy: 45.6 %\n",
      "Training round [94/200], qnn_train_step: [3000/500], loss: 1.570098876953125, accuracy: 47.4 %\n",
      "Training round [94/200], qnn_train_step: [3100/500], loss: 1.5245020389556885, accuracy: 48.8 %\n",
      "Training round [94/200], qnn_train_step: [3200/500], loss: 1.7277058362960815, accuracy: 45.4 %\n",
      "Training round [94/200], qnn_train_step: [3300/500], loss: 1.576180100440979, accuracy: 46.9 %\n",
      "Training round [94/200], qnn_train_step: [3400/500], loss: 1.5246572494506836, accuracy: 48.6 %\n",
      "Training round [94/200], qnn_train_step: [3500/500], loss: 5.879654884338379, accuracy: 10.8 %\n",
      "Training round [94/200], qnn_train_step: [3600/500], loss: 1.581526756286621, accuracy: 45.6 %\n",
      "Training round [94/200], qnn_train_step: [3700/500], loss: 1.5247740745544434, accuracy: 48.6 %\n",
      "Training round [94/200], qnn_train_step: [3800/500], loss: 1.5218091011047363, accuracy: 48.3 %\n",
      "Training round [94/200], qnn_train_step: [3900/500], loss: 1.5809690952301025, accuracy: 48.2 %\n",
      "Training round [94/200], qnn_train_step: [4000/500], loss: 1.52481210231781, accuracy: 48.6 %\n",
      "Training round [94/200], qnn_train_step: [4100/500], loss: 1.522470235824585, accuracy: 49.2 %\n",
      "Training round [94/200], qnn_train_step: [4200/500], loss: 1.5915287733078003, accuracy: 46.0 %\n",
      "Training round [94/200], qnn_train_step: [4300/500], loss: 1.5254895687103271, accuracy: 48.3 %\n",
      "Training round [94/200], qnn_train_step: [4400/500], loss: 1.5232360363006592, accuracy: 49.2 %\n",
      "Training round [94/200], qnn_train_step: [4500/500], loss: 1.600045084953308, accuracy: 47.8 %\n",
      "Training round [94/200], qnn_train_step: [4600/500], loss: 1.5265777111053467, accuracy: 49.0 %\n",
      "Training round [94/200], qnn_train_step: [4700/500], loss: 1.5236246585845947, accuracy: 48.3 %\n",
      "Training round [94/200], qnn_train_step: [4800/500], loss: 1.6021547317504883, accuracy: 46.6 %\n",
      "Training round [94/200], qnn_train_step: [4900/500], loss: 1.5272001028060913, accuracy: 49.8 %\n",
      "Training round [94/200], qnn_train_step: [5000/500], loss: 1.5238701105117798, accuracy: 48.5 %\n",
      "Training round [94/200], qnn_train_step: [5100/500], loss: 1.602239966392517, accuracy: 44.3 %\n",
      "Training round [94/200], qnn_train_step: [5200/500], loss: 1.5281904935836792, accuracy: 48.6 %\n",
      "Training round [94/200], qnn_train_step: [5300/500], loss: 1.5238170623779297, accuracy: 48.5 %\n",
      "Training round [94/200], qnn_train_step: [5400/500], loss: 1.6010584831237793, accuracy: 44.5 %\n",
      "Training round [94/200], qnn_train_step: [5500/500], loss: 1.5285505056381226, accuracy: 48.5 %\n",
      "Training round [94/200], qnn_train_step: [5600/500], loss: 1.5237880945205688, accuracy: 48.5 %\n",
      "Training round [94/200], qnn_train_step: [5700/500], loss: 1.5992751121520996, accuracy: 45.2 %\n",
      "Training round [94/200], qnn_train_step: [5800/500], loss: 1.5286259651184082, accuracy: 49.4 %\n",
      "Training round [94/200], qnn_train_step: [5900/500], loss: 1.5237483978271484, accuracy: 48.5 %\n",
      "Training round [94/200], qnn_train_step: [6000/500], loss: 1.6045818328857422, accuracy: 44.7 %\n",
      "Training round [94/200], qnn_train_step: [6100/500], loss: 1.5300730466842651, accuracy: 48.3 %\n",
      "Training round [94/200], qnn_train_step: [6200/500], loss: 1.5237246751785278, accuracy: 48.5 %\n",
      "Training round [94/200], qnn_train_step: [6300/500], loss: 1.6061574220657349, accuracy: 48.1 %\n",
      "Training round [94/200], qnn_train_step: [6400/500], loss: 1.5305300951004028, accuracy: 49.1 %\n",
      "Training round [94/200], qnn_train_step: [6500/500], loss: 1.5236480236053467, accuracy: 48.5 %\n",
      "Training round [94/200], qnn_train_step: [6600/500], loss: 1.6077840328216553, accuracy: 46.3 %\n",
      "Training round [94/200], qnn_train_step: [6700/500], loss: 1.5685750246047974, accuracy: 45.7 %\n",
      "Training round [94/200], qnn_train_step: [6800/500], loss: 1.54396653175354, accuracy: 47.3 %\n",
      "Training round [94/200], qnn_train_step: [6900/500], loss: 1.5343793630599976, accuracy: 46.3 %\n",
      "Training round [94/200], qnn_train_step: [7000/500], loss: 1.5264467000961304, accuracy: 48.2 %\n",
      "Training round [94/200], qnn_train_step: [7100/500], loss: 1.5309338569641113, accuracy: 48.4 %\n",
      "Training round [94/200], qnn_train_step: [7200/500], loss: 1.5272985696792603, accuracy: 48.1 %\n",
      "Training round [94/200], qnn_train_step: [7300/500], loss: 1.5188173055648804, accuracy: 49.0 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 1.4886, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 1.5141, batch time: 0.08, accuracy:  50.00%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 1.5309, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 1.2992, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 1.4832, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 1.5883, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 1.4227, batch time: 0.08, accuracy:  48.44%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 1.5740, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 1.4989, batch time: 0.08, accuracy:  47.66%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 1.5603, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [95/200], qnn_train_step: [100/500], loss: 1.5404417514801025, accuracy: 46.2 %\n",
      "Training round [95/200], qnn_train_step: [200/500], loss: 1.7209415435791016, accuracy: 41.5 %\n",
      "Training round [95/200], qnn_train_step: [300/500], loss: 1.6850210428237915, accuracy: 46.2 %\n",
      "Training round [95/200], qnn_train_step: [400/500], loss: 1.5448994636535645, accuracy: 45.3 %\n",
      "Training round [95/200], qnn_train_step: [500/500], loss: 1.5750483274459839, accuracy: 45.8 %\n",
      "Training round [95/200], qnn_train_step: [600/500], loss: 1.5453827381134033, accuracy: 46.0 %\n",
      "Training round [95/200], qnn_train_step: [700/500], loss: 1.5271613597869873, accuracy: 47.0 %\n",
      "Training round [95/200], qnn_train_step: [800/500], loss: 1.5110636949539185, accuracy: 47.1 %\n",
      "Training round [95/200], qnn_train_step: [900/500], loss: 1.5092835426330566, accuracy: 47.4 %\n",
      "Training round [95/200], qnn_train_step: [1000/500], loss: 1.5062196254730225, accuracy: 48.5 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 1.4432, batch time: 0.03, accuracy:  57.81%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 1.5796, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 1.5155, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 1.6694, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 1.5492, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 1.4656, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 1.6646, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 1.3968, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 1.4427, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 1.4011, batch time: 0.03, accuracy:  56.25%\n",
      "Training round [96/200], qnn_train_step: [100/500], loss: 1.5141946077346802, accuracy: 47.6 %\n",
      "Training round [96/200], qnn_train_step: [200/500], loss: 2.2330551147460938, accuracy: 35.1 %\n",
      "Training round [96/200], qnn_train_step: [300/500], loss: 1.5464228391647339, accuracy: 47.5 %\n",
      "Training round [96/200], qnn_train_step: [400/500], loss: 1.4985674619674683, accuracy: 48.0 %\n",
      "Training round [96/200], qnn_train_step: [500/500], loss: 1.487084150314331, accuracy: 48.7 %\n",
      "Training round [96/200], qnn_train_step: [600/500], loss: 1.4971110820770264, accuracy: 48.6 %\n",
      "Training round [96/200], qnn_train_step: [700/500], loss: 1.5151175260543823, accuracy: 47.6 %\n",
      "Training round [96/200], qnn_train_step: [800/500], loss: 1.491981029510498, accuracy: 48.8 %\n",
      "Training round [96/200], qnn_train_step: [900/500], loss: 1.4623281955718994, accuracy: 50.3 %\n",
      "Training round [96/200], qnn_train_step: [1000/500], loss: 1.4677906036376953, accuracy: 49.4 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 1.5099, batch time: 0.03, accuracy:  53.12%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 1.5591, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 1.5912, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 1.6067, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 1.5200, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 1.4323, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 1.5238, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 1.5504, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 1.3270, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 1.5174, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [97/200], qnn_train_step: [100/500], loss: 1.5421768426895142, accuracy: 46.1 %\n",
      "Training round [97/200], qnn_train_step: [200/500], loss: 1.7204420566558838, accuracy: 43.8 %\n",
      "Training round [97/200], qnn_train_step: [300/500], loss: 1.5408477783203125, accuracy: 47.4 %\n",
      "Training round [97/200], qnn_train_step: [400/500], loss: 1.5088412761688232, accuracy: 49.3 %\n",
      "Training round [97/200], qnn_train_step: [500/500], loss: 1.6940085887908936, accuracy: 42.0 %\n",
      "Training round [97/200], qnn_train_step: [600/500], loss: 1.5404812097549438, accuracy: 49.4 %\n",
      "Training round [97/200], qnn_train_step: [700/500], loss: 1.5086750984191895, accuracy: 49.3 %\n",
      "Training round [97/200], qnn_train_step: [800/500], loss: 1.7018699645996094, accuracy: 42.7 %\n",
      "Training round [97/200], qnn_train_step: [900/500], loss: 1.5408507585525513, accuracy: 46.6 %\n",
      "Training round [97/200], qnn_train_step: [1000/500], loss: 1.5085365772247314, accuracy: 49.3 %\n",
      "Training round [97/200], qnn_train_step: [1100/500], loss: 1.7070871591567993, accuracy: 42.4 %\n",
      "Training round [97/200], qnn_train_step: [1200/500], loss: 1.5422461032867432, accuracy: 48.0 %\n",
      "Training round [97/200], qnn_train_step: [1300/500], loss: 1.5083731412887573, accuracy: 49.3 %\n",
      "Training round [97/200], qnn_train_step: [1400/500], loss: 1.706302523612976, accuracy: 43.6 %\n",
      "Training round [97/200], qnn_train_step: [1500/500], loss: 1.5499744415283203, accuracy: 49.3 %\n",
      "Training round [97/200], qnn_train_step: [1600/500], loss: 1.5082149505615234, accuracy: 49.3 %\n",
      "Training round [97/200], qnn_train_step: [1700/500], loss: 1.7131596803665161, accuracy: 44.1 %\n",
      "Training round [97/200], qnn_train_step: [1800/500], loss: 1.551789402961731, accuracy: 47.1 %\n",
      "Training round [97/200], qnn_train_step: [1900/500], loss: 1.5080549716949463, accuracy: 49.3 %\n",
      "Training round [97/200], qnn_train_step: [2000/500], loss: 1.7202152013778687, accuracy: 43.8 %\n",
      "Training round [97/200], qnn_train_step: [2100/500], loss: 1.5530892610549927, accuracy: 47.8 %\n",
      "Training round [97/200], qnn_train_step: [2200/500], loss: 1.5079282522201538, accuracy: 49.3 %\n",
      "Training round [97/200], qnn_train_step: [2300/500], loss: 1.7203819751739502, accuracy: 42.6 %\n",
      "Training round [97/200], qnn_train_step: [2400/500], loss: 1.5545035600662231, accuracy: 48.1 %\n",
      "Training round [97/200], qnn_train_step: [2500/500], loss: 1.50780189037323, accuracy: 49.2 %\n",
      "Training round [97/200], qnn_train_step: [2600/500], loss: 1.7198522090911865, accuracy: 39.6 %\n",
      "Training round [97/200], qnn_train_step: [2700/500], loss: 1.5566346645355225, accuracy: 46.3 %\n",
      "Training round [97/200], qnn_train_step: [2800/500], loss: 1.5077741146087646, accuracy: 49.3 %\n",
      "Training round [97/200], qnn_train_step: [2900/500], loss: 6.221653461456299, accuracy: 10.7 %\n",
      "Training round [97/200], qnn_train_step: [3000/500], loss: 1.5596897602081299, accuracy: 44.1 %\n",
      "Training round [97/200], qnn_train_step: [3100/500], loss: 1.5078176259994507, accuracy: 49.4 %\n",
      "Training round [97/200], qnn_train_step: [3200/500], loss: 1.5012770891189575, accuracy: 48.4 %\n",
      "Training round [97/200], qnn_train_step: [3300/500], loss: 1.569345474243164, accuracy: 46.5 %\n",
      "Training round [97/200], qnn_train_step: [3400/500], loss: 1.508195161819458, accuracy: 49.2 %\n",
      "Training round [97/200], qnn_train_step: [3500/500], loss: 1.5033071041107178, accuracy: 48.6 %\n",
      "Training round [97/200], qnn_train_step: [3600/500], loss: 1.569711685180664, accuracy: 46.2 %\n",
      "Training round [97/200], qnn_train_step: [3700/500], loss: 1.5087696313858032, accuracy: 49.5 %\n",
      "Training round [97/200], qnn_train_step: [3800/500], loss: 1.5057315826416016, accuracy: 49.3 %\n",
      "Training round [97/200], qnn_train_step: [3900/500], loss: 1.5837419033050537, accuracy: 47.3 %\n",
      "Training round [97/200], qnn_train_step: [4000/500], loss: 1.5090959072113037, accuracy: 49.4 %\n",
      "Training round [97/200], qnn_train_step: [4100/500], loss: 1.5063403844833374, accuracy: 49.2 %\n",
      "Training round [97/200], qnn_train_step: [4200/500], loss: 1.584545373916626, accuracy: 47.5 %\n",
      "Training round [97/200], qnn_train_step: [4300/500], loss: 1.5105626583099365, accuracy: 49.7 %\n",
      "Training round [97/200], qnn_train_step: [4400/500], loss: 1.506561517715454, accuracy: 49.2 %\n",
      "Training round [97/200], qnn_train_step: [4500/500], loss: 1.5839632749557495, accuracy: 43.3 %\n",
      "Training round [97/200], qnn_train_step: [4600/500], loss: 1.5120676755905151, accuracy: 48.5 %\n",
      "Training round [97/200], qnn_train_step: [4700/500], loss: 1.5067058801651, accuracy: 49.3 %\n",
      "Training round [97/200], qnn_train_step: [4800/500], loss: 1.5899800062179565, accuracy: 44.6 %\n",
      "Training round [97/200], qnn_train_step: [4900/500], loss: 1.5132288932800293, accuracy: 48.9 %\n",
      "Training round [97/200], qnn_train_step: [5000/500], loss: 1.5066484212875366, accuracy: 49.5 %\n",
      "Training round [97/200], qnn_train_step: [5100/500], loss: 1.5895854234695435, accuracy: 45.7 %\n",
      "Training round [97/200], qnn_train_step: [5200/500], loss: 1.5135854482650757, accuracy: 49.4 %\n",
      "Training round [97/200], qnn_train_step: [5300/500], loss: 1.5063481330871582, accuracy: 49.6 %\n",
      "Training round [97/200], qnn_train_step: [5400/500], loss: 1.5901529788970947, accuracy: 46.6 %\n",
      "Training round [97/200], qnn_train_step: [5500/500], loss: 1.514561653137207, accuracy: 49.5 %\n",
      "Training round [97/200], qnn_train_step: [5600/500], loss: 1.5062017440795898, accuracy: 49.5 %\n",
      "Training round [97/200], qnn_train_step: [5700/500], loss: 1.5894381999969482, accuracy: 43.6 %\n",
      "Training round [97/200], qnn_train_step: [5800/500], loss: 1.6009951829910278, accuracy: 45.9 %\n",
      "Training round [97/200], qnn_train_step: [5900/500], loss: 1.5606374740600586, accuracy: 48.8 %\n",
      "Training round [97/200], qnn_train_step: [6000/500], loss: 1.5090636014938354, accuracy: 47.2 %\n",
      "Training round [97/200], qnn_train_step: [6100/500], loss: 1.5078538656234741, accuracy: 47.8 %\n",
      "Training round [97/200], qnn_train_step: [6200/500], loss: 1.5142195224761963, accuracy: 49.5 %\n",
      "Training round [97/200], qnn_train_step: [6300/500], loss: 1.5094540119171143, accuracy: 47.2 %\n",
      "Training round [97/200], qnn_train_step: [6400/500], loss: 1.5168014764785767, accuracy: 47.0 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 1.6341, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 1.5926, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 1.4311, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 1.6856, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 1.3765, batch time: 0.03, accuracy:  57.03%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 1.5479, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 1.4427, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 1.5244, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 1.5371, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 1.3597, batch time: 0.03, accuracy:  55.47%\n",
      "Training round [98/200], qnn_train_step: [100/500], loss: 1.5796043872833252, accuracy: 44.7 %\n",
      "Training round [98/200], qnn_train_step: [200/500], loss: 1.744337558746338, accuracy: 41.1 %\n",
      "Training round [98/200], qnn_train_step: [300/500], loss: 1.5509233474731445, accuracy: 46.7 %\n",
      "Training round [98/200], qnn_train_step: [400/500], loss: 1.5341318845748901, accuracy: 48.3 %\n",
      "Training round [98/200], qnn_train_step: [500/500], loss: 1.6626830101013184, accuracy: 42.6 %\n",
      "Training round [98/200], qnn_train_step: [600/500], loss: 1.55502188205719, accuracy: 45.0 %\n",
      "Training round [98/200], qnn_train_step: [700/500], loss: 1.5335296392440796, accuracy: 48.2 %\n",
      "Training round [98/200], qnn_train_step: [800/500], loss: 1.6636523008346558, accuracy: 44.6 %\n",
      "Training round [98/200], qnn_train_step: [900/500], loss: 1.5570036172866821, accuracy: 47.7 %\n",
      "Training round [98/200], qnn_train_step: [1000/500], loss: 1.532927393913269, accuracy: 48.2 %\n",
      "Training round [98/200], qnn_train_step: [1100/500], loss: 1.6661971807479858, accuracy: 43.0 %\n",
      "Training round [98/200], qnn_train_step: [1200/500], loss: 1.557694435119629, accuracy: 47.4 %\n",
      "Training round [98/200], qnn_train_step: [1300/500], loss: 1.5325355529785156, accuracy: 48.2 %\n",
      "Training round [98/200], qnn_train_step: [1400/500], loss: 1.665440320968628, accuracy: 46.0 %\n",
      "Training round [98/200], qnn_train_step: [1500/500], loss: 1.5597219467163086, accuracy: 46.0 %\n",
      "Training round [98/200], qnn_train_step: [1600/500], loss: 1.5319136381149292, accuracy: 48.1 %\n",
      "Training round [98/200], qnn_train_step: [1700/500], loss: 1.6654783487319946, accuracy: 45.4 %\n",
      "Training round [98/200], qnn_train_step: [1800/500], loss: 1.562200903892517, accuracy: 46.9 %\n",
      "Training round [98/200], qnn_train_step: [1900/500], loss: 1.531566858291626, accuracy: 48.0 %\n",
      "Training round [98/200], qnn_train_step: [2000/500], loss: 1.6709704399108887, accuracy: 44.3 %\n",
      "Training round [98/200], qnn_train_step: [2100/500], loss: 1.5640652179718018, accuracy: 47.9 %\n",
      "Training round [98/200], qnn_train_step: [2200/500], loss: 1.5311380624771118, accuracy: 47.9 %\n",
      "Training round [98/200], qnn_train_step: [2300/500], loss: 1.6867660284042358, accuracy: 45.9 %\n",
      "Training round [98/200], qnn_train_step: [2400/500], loss: 1.5649107694625854, accuracy: 47.8 %\n",
      "Training round [98/200], qnn_train_step: [2500/500], loss: 1.5306912660598755, accuracy: 48.0 %\n",
      "Training round [98/200], qnn_train_step: [2600/500], loss: 1.6885838508605957, accuracy: 44.0 %\n",
      "Training round [98/200], qnn_train_step: [2700/500], loss: 1.5650750398635864, accuracy: 47.7 %\n",
      "Training round [98/200], qnn_train_step: [2800/500], loss: 1.5303831100463867, accuracy: 48.0 %\n",
      "Training round [98/200], qnn_train_step: [2900/500], loss: 1.6855500936508179, accuracy: 43.4 %\n",
      "Training round [98/200], qnn_train_step: [3000/500], loss: 1.564620852470398, accuracy: 48.3 %\n",
      "Training round [98/200], qnn_train_step: [3100/500], loss: 1.5298858880996704, accuracy: 48.2 %\n",
      "Training round [98/200], qnn_train_step: [3200/500], loss: 1.689154863357544, accuracy: 43.6 %\n",
      "Training round [98/200], qnn_train_step: [3300/500], loss: 1.5660487413406372, accuracy: 47.5 %\n",
      "Training round [98/200], qnn_train_step: [3400/500], loss: 1.5296645164489746, accuracy: 48.1 %\n",
      "Training round [98/200], qnn_train_step: [3500/500], loss: 1.6923327445983887, accuracy: 42.4 %\n",
      "Training round [98/200], qnn_train_step: [3600/500], loss: 1.5653687715530396, accuracy: 46.0 %\n",
      "Training round [98/200], qnn_train_step: [3700/500], loss: 1.5291837453842163, accuracy: 48.1 %\n",
      "Training round [98/200], qnn_train_step: [3800/500], loss: 1.6897900104522705, accuracy: 44.9 %\n",
      "Training round [98/200], qnn_train_step: [3900/500], loss: 1.5669701099395752, accuracy: 46.5 %\n",
      "Training round [98/200], qnn_train_step: [4000/500], loss: 1.5288658142089844, accuracy: 48.1 %\n",
      "Training round [98/200], qnn_train_step: [4100/500], loss: 1.6875298023223877, accuracy: 42.6 %\n",
      "Training round [98/200], qnn_train_step: [4200/500], loss: 1.5679152011871338, accuracy: 46.9 %\n",
      "Training round [98/200], qnn_train_step: [4300/500], loss: 1.5285708904266357, accuracy: 48.2 %\n",
      "Training round [98/200], qnn_train_step: [4400/500], loss: 1.8036035299301147, accuracy: 44.2 %\n",
      "Training round [98/200], qnn_train_step: [4500/500], loss: 1.5681995153427124, accuracy: 46.1 %\n",
      "Training round [98/200], qnn_train_step: [4600/500], loss: 1.5283275842666626, accuracy: 48.2 %\n",
      "Training round [98/200], qnn_train_step: [4700/500], loss: 1.843345284461975, accuracy: 41.7 %\n",
      "Training round [98/200], qnn_train_step: [4800/500], loss: 1.5704306364059448, accuracy: 45.6 %\n",
      "Training round [98/200], qnn_train_step: [4900/500], loss: 1.5282225608825684, accuracy: 48.2 %\n",
      "Training round [98/200], qnn_train_step: [5000/500], loss: 1.522662878036499, accuracy: 47.9 %\n",
      "Training round [98/200], qnn_train_step: [5100/500], loss: 1.5736067295074463, accuracy: 48.3 %\n",
      "Training round [98/200], qnn_train_step: [5200/500], loss: 1.528398036956787, accuracy: 48.2 %\n",
      "Training round [98/200], qnn_train_step: [5300/500], loss: 1.5245240926742554, accuracy: 47.7 %\n",
      "Training round [98/200], qnn_train_step: [5400/500], loss: 1.5794757604599, accuracy: 47.0 %\n",
      "Training round [98/200], qnn_train_step: [5500/500], loss: 1.5282468795776367, accuracy: 47.9 %\n",
      "Training round [98/200], qnn_train_step: [5600/500], loss: 1.5247465372085571, accuracy: 47.6 %\n",
      "Training round [98/200], qnn_train_step: [5700/500], loss: 1.5861146450042725, accuracy: 45.0 %\n",
      "Training round [98/200], qnn_train_step: [5800/500], loss: 1.528282880783081, accuracy: 47.8 %\n",
      "Training round [98/200], qnn_train_step: [5900/500], loss: 1.525238037109375, accuracy: 47.8 %\n",
      "Training round [98/200], qnn_train_step: [6000/500], loss: 1.5881625413894653, accuracy: 45.2 %\n",
      "Training round [98/200], qnn_train_step: [6100/500], loss: 1.5285261869430542, accuracy: 48.1 %\n",
      "Training round [98/200], qnn_train_step: [6200/500], loss: 1.5261489152908325, accuracy: 48.0 %\n",
      "Training round [98/200], qnn_train_step: [6300/500], loss: 1.5878188610076904, accuracy: 46.4 %\n",
      "Training round [98/200], qnn_train_step: [6400/500], loss: 1.529471516609192, accuracy: 48.2 %\n",
      "Training round [98/200], qnn_train_step: [6500/500], loss: 1.526314616203308, accuracy: 48.0 %\n",
      "Training round [98/200], qnn_train_step: [6600/500], loss: 1.5872302055358887, accuracy: 47.0 %\n",
      "Training round [98/200], qnn_train_step: [6700/500], loss: 1.5307024717330933, accuracy: 47.0 %\n",
      "Training round [98/200], qnn_train_step: [6800/500], loss: 1.5261056423187256, accuracy: 47.9 %\n",
      "Training round [98/200], qnn_train_step: [6900/500], loss: 1.5880305767059326, accuracy: 44.9 %\n",
      "Training round [98/200], qnn_train_step: [7000/500], loss: 1.6241897344589233, accuracy: 46.8 %\n",
      "Training round [98/200], qnn_train_step: [7100/500], loss: 1.6337504386901855, accuracy: 46.2 %\n",
      "Training round [98/200], qnn_train_step: [7200/500], loss: 1.5482975244522095, accuracy: 47.6 %\n",
      "Training round [98/200], qnn_train_step: [7300/500], loss: 1.537774920463562, accuracy: 47.8 %\n",
      "Training round [98/200], qnn_train_step: [7400/500], loss: 1.5290883779525757, accuracy: 47.1 %\n",
      "Training round [98/200], qnn_train_step: [7500/500], loss: 1.5283448696136475, accuracy: 47.5 %\n",
      "Training round [98/200], qnn_train_step: [7600/500], loss: 1.518379807472229, accuracy: 48.1 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 1.5932, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 1.4875, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 1.5963, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 1.4851, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 1.4674, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 1.4246, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 1.6266, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 1.5107, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 1.5933, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 1.4535, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [99/200], qnn_train_step: [100/500], loss: 1.543389916419983, accuracy: 47.4 %\n",
      "Training round [99/200], qnn_train_step: [200/500], loss: 2.1529178619384766, accuracy: 37.8 %\n",
      "Training round [99/200], qnn_train_step: [300/500], loss: 1.586319088935852, accuracy: 45.6 %\n",
      "Training round [99/200], qnn_train_step: [400/500], loss: 1.5911203622817993, accuracy: 48.6 %\n",
      "Training round [99/200], qnn_train_step: [500/500], loss: 1.595687747001648, accuracy: 45.7 %\n",
      "Training round [99/200], qnn_train_step: [600/500], loss: 1.5496504306793213, accuracy: 47.8 %\n",
      "Training round [99/200], qnn_train_step: [700/500], loss: 1.5204262733459473, accuracy: 48.5 %\n",
      "Training round [99/200], qnn_train_step: [800/500], loss: 1.5372035503387451, accuracy: 49.0 %\n",
      "Training round [99/200], qnn_train_step: [900/500], loss: 1.520982027053833, accuracy: 48.5 %\n",
      "Training round [99/200], qnn_train_step: [1000/500], loss: 1.522185206413269, accuracy: 48.7 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 1.4336, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 1.5402, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 1.3598, batch time: 0.07, accuracy:  57.81%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 1.5842, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 1.4990, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 1.5501, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 1.4197, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 1.4934, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 1.3354, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 1.4902, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [100/200], qnn_train_step: [100/500], loss: 1.504568099975586, accuracy: 47.1 %\n",
      "Training round [100/200], qnn_train_step: [200/500], loss: 1.694338083267212, accuracy: 45.0 %\n",
      "Training round [100/200], qnn_train_step: [300/500], loss: 1.5736687183380127, accuracy: 43.2 %\n",
      "Training round [100/200], qnn_train_step: [400/500], loss: 1.5381319522857666, accuracy: 45.9 %\n",
      "Training round [100/200], qnn_train_step: [500/500], loss: 1.4883291721343994, accuracy: 47.1 %\n",
      "Training round [100/200], qnn_train_step: [600/500], loss: 1.5000348091125488, accuracy: 48.9 %\n",
      "Training round [100/200], qnn_train_step: [700/500], loss: 1.4731745719909668, accuracy: 50.3 %\n",
      "Training round [100/200], qnn_train_step: [800/500], loss: 1.4749101400375366, accuracy: 50.2 %\n",
      "Training round [100/200], qnn_train_step: [900/500], loss: 1.4729021787643433, accuracy: 49.0 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 1.4973, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 1.6226, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 1.5552, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 1.4866, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 1.6030, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 1.5790, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 1.6315, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 1.4319, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 1.5255, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 1.5398, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [101/200], qnn_train_step: [100/500], loss: 1.5732641220092773, accuracy: 47.4 %\n",
      "Training round [101/200], qnn_train_step: [200/500], loss: 2.3565211296081543, accuracy: 29.4 %\n",
      "Training round [101/200], qnn_train_step: [300/500], loss: 1.5556143522262573, accuracy: 49.0 %\n",
      "Training round [101/200], qnn_train_step: [400/500], loss: 1.521605134010315, accuracy: 49.7 %\n",
      "Training round [101/200], qnn_train_step: [500/500], loss: 1.696174144744873, accuracy: 46.1 %\n",
      "Training round [101/200], qnn_train_step: [600/500], loss: 1.555548906326294, accuracy: 50.2 %\n",
      "Training round [101/200], qnn_train_step: [700/500], loss: 1.521250605583191, accuracy: 49.6 %\n",
      "Training round [101/200], qnn_train_step: [800/500], loss: 1.700275182723999, accuracy: 43.2 %\n",
      "Training round [101/200], qnn_train_step: [900/500], loss: 1.5561530590057373, accuracy: 49.3 %\n",
      "Training round [101/200], qnn_train_step: [1000/500], loss: 1.5209429264068604, accuracy: 49.5 %\n",
      "Training round [101/200], qnn_train_step: [1100/500], loss: 1.7063060998916626, accuracy: 44.9 %\n",
      "Training round [101/200], qnn_train_step: [1200/500], loss: 1.5549365282058716, accuracy: 47.5 %\n",
      "Training round [101/200], qnn_train_step: [1300/500], loss: 1.5206775665283203, accuracy: 49.5 %\n",
      "Training round [101/200], qnn_train_step: [1400/500], loss: 1.7124004364013672, accuracy: 43.4 %\n",
      "Training round [101/200], qnn_train_step: [1500/500], loss: 1.5578864812850952, accuracy: 49.4 %\n",
      "Training round [101/200], qnn_train_step: [1600/500], loss: 1.5203068256378174, accuracy: 49.5 %\n",
      "Training round [101/200], qnn_train_step: [1700/500], loss: 1.7188957929611206, accuracy: 42.6 %\n",
      "Training round [101/200], qnn_train_step: [1800/500], loss: 1.5609307289123535, accuracy: 48.4 %\n",
      "Training round [101/200], qnn_train_step: [1900/500], loss: 1.5199811458587646, accuracy: 49.6 %\n",
      "Training round [101/200], qnn_train_step: [2000/500], loss: 1.7177979946136475, accuracy: 44.0 %\n",
      "Training round [101/200], qnn_train_step: [2100/500], loss: 1.562643051147461, accuracy: 48.7 %\n",
      "Training round [101/200], qnn_train_step: [2200/500], loss: 1.5197737216949463, accuracy: 49.7 %\n",
      "Training round [101/200], qnn_train_step: [2300/500], loss: 1.7156692743301392, accuracy: 43.5 %\n",
      "Training round [101/200], qnn_train_step: [2400/500], loss: 1.5621587038040161, accuracy: 49.9 %\n",
      "Training round [101/200], qnn_train_step: [2500/500], loss: 1.519500494003296, accuracy: 49.7 %\n",
      "Training round [101/200], qnn_train_step: [2600/500], loss: 1.714047908782959, accuracy: 43.7 %\n",
      "Training round [101/200], qnn_train_step: [2700/500], loss: 1.5621272325515747, accuracy: 49.3 %\n",
      "Training round [101/200], qnn_train_step: [2800/500], loss: 1.5191881656646729, accuracy: 49.6 %\n",
      "Training round [101/200], qnn_train_step: [2900/500], loss: 1.7838596105575562, accuracy: 46.5 %\n",
      "Training round [101/200], qnn_train_step: [3000/500], loss: 1.5789037942886353, accuracy: 48.4 %\n",
      "Training round [101/200], qnn_train_step: [3100/500], loss: 1.5189430713653564, accuracy: 49.7 %\n",
      "Training round [101/200], qnn_train_step: [3200/500], loss: 1.8265608549118042, accuracy: 44.0 %\n",
      "Training round [101/200], qnn_train_step: [3300/500], loss: 1.5774129629135132, accuracy: 46.9 %\n",
      "Training round [101/200], qnn_train_step: [3400/500], loss: 1.5190885066986084, accuracy: 48.9 %\n",
      "Training round [101/200], qnn_train_step: [3500/500], loss: 1.5145264863967896, accuracy: 49.2 %\n",
      "Training round [101/200], qnn_train_step: [3600/500], loss: 1.5786049365997314, accuracy: 47.3 %\n",
      "Training round [101/200], qnn_train_step: [3700/500], loss: 1.519012689590454, accuracy: 49.2 %\n",
      "Training round [101/200], qnn_train_step: [3800/500], loss: 1.5153647661209106, accuracy: 49.7 %\n",
      "Training round [101/200], qnn_train_step: [3900/500], loss: 1.5881842374801636, accuracy: 47.0 %\n",
      "Training round [101/200], qnn_train_step: [4000/500], loss: 1.5195097923278809, accuracy: 49.8 %\n",
      "Training round [101/200], qnn_train_step: [4100/500], loss: 1.516053557395935, accuracy: 49.1 %\n",
      "Training round [101/200], qnn_train_step: [4200/500], loss: 1.586134433746338, accuracy: 46.9 %\n",
      "Training round [101/200], qnn_train_step: [4300/500], loss: 1.519468069076538, accuracy: 49.8 %\n",
      "Training round [101/200], qnn_train_step: [4400/500], loss: 1.5166029930114746, accuracy: 50.0 %\n",
      "Training round [101/200], qnn_train_step: [4500/500], loss: 1.5905113220214844, accuracy: 48.3 %\n",
      "Training round [101/200], qnn_train_step: [4600/500], loss: 1.520151138305664, accuracy: 49.8 %\n",
      "Training round [101/200], qnn_train_step: [4700/500], loss: 1.5171246528625488, accuracy: 49.5 %\n",
      "Training round [101/200], qnn_train_step: [4800/500], loss: 1.5925352573394775, accuracy: 49.0 %\n",
      "Training round [101/200], qnn_train_step: [4900/500], loss: 1.520264983177185, accuracy: 49.4 %\n",
      "Training round [101/200], qnn_train_step: [5000/500], loss: 1.5173271894454956, accuracy: 49.8 %\n",
      "Training round [101/200], qnn_train_step: [5100/500], loss: 1.59126615524292, accuracy: 46.4 %\n",
      "Training round [101/200], qnn_train_step: [5200/500], loss: 1.5215903520584106, accuracy: 49.6 %\n",
      "Training round [101/200], qnn_train_step: [5300/500], loss: 1.5171676874160767, accuracy: 49.8 %\n",
      "Training round [101/200], qnn_train_step: [5400/500], loss: 1.5923572778701782, accuracy: 46.6 %\n",
      "Training round [101/200], qnn_train_step: [5500/500], loss: 1.5250946283340454, accuracy: 49.4 %\n",
      "Training round [101/200], qnn_train_step: [5600/500], loss: 1.5169583559036255, accuracy: 49.8 %\n",
      "Training round [101/200], qnn_train_step: [5700/500], loss: 1.5962547063827515, accuracy: 45.6 %\n",
      "Training round [101/200], qnn_train_step: [5800/500], loss: 1.5250977277755737, accuracy: 49.8 %\n",
      "Training round [101/200], qnn_train_step: [5900/500], loss: 1.5168180465698242, accuracy: 49.7 %\n",
      "Training round [101/200], qnn_train_step: [6000/500], loss: 1.595376968383789, accuracy: 47.6 %\n",
      "Training round [101/200], qnn_train_step: [6100/500], loss: 1.5251706838607788, accuracy: 49.3 %\n",
      "Training round [101/200], qnn_train_step: [6200/500], loss: 1.569202184677124, accuracy: 46.3 %\n",
      "Training round [101/200], qnn_train_step: [6300/500], loss: 1.542906403541565, accuracy: 47.4 %\n",
      "Training round [101/200], qnn_train_step: [6400/500], loss: 1.5445181131362915, accuracy: 47.7 %\n",
      "Training round [101/200], qnn_train_step: [6500/500], loss: 1.5199042558670044, accuracy: 47.9 %\n",
      "Training round [101/200], qnn_train_step: [6600/500], loss: 1.5290601253509521, accuracy: 50.0 %\n",
      "Training round [101/200], qnn_train_step: [6700/500], loss: 1.5131878852844238, accuracy: 48.0 %\n",
      "Training round [101/200], qnn_train_step: [6800/500], loss: 1.5181564092636108, accuracy: 48.7 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 1.3430, batch time: 0.07, accuracy:  57.81%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 1.4642, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 1.4639, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 1.3373, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 1.5090, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 1.4097, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 1.4467, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 1.5428, batch time: 0.03, accuracy:  57.03%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 1.5401, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 1.5795, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [102/200], qnn_train_step: [100/500], loss: 1.5720431804656982, accuracy: 46.0 %\n",
      "Training round [102/200], qnn_train_step: [200/500], loss: 2.0678281784057617, accuracy: 33.5 %\n",
      "Training round [102/200], qnn_train_step: [300/500], loss: 1.5942106246948242, accuracy: 45.4 %\n",
      "Training round [102/200], qnn_train_step: [400/500], loss: 1.564389705657959, accuracy: 47.4 %\n",
      "Training round [102/200], qnn_train_step: [500/500], loss: 1.570322036743164, accuracy: 47.8 %\n",
      "Training round [102/200], qnn_train_step: [600/500], loss: 1.5575484037399292, accuracy: 46.0 %\n",
      "Training round [102/200], qnn_train_step: [700/500], loss: 1.5634962320327759, accuracy: 48.1 %\n",
      "Training round [102/200], qnn_train_step: [800/500], loss: 1.5233428478240967, accuracy: 48.6 %\n",
      "Training round [102/200], qnn_train_step: [900/500], loss: 1.5257642269134521, accuracy: 48.2 %\n",
      "Training round [102/200], qnn_train_step: [1000/500], loss: 1.5271092653274536, accuracy: 47.0 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 1.6786, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 1.5646, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 1.4819, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 1.5522, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 1.3694, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 1.5622, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 1.3501, batch time: 0.03, accuracy:  58.59%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 1.4345, batch time: 0.03, accuracy:  56.25%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 1.4454, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 1.6212, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [103/200], qnn_train_step: [100/500], loss: 1.5557985305786133, accuracy: 44.8 %\n",
      "Training round [103/200], qnn_train_step: [200/500], loss: 7.488653659820557, accuracy: 13.4 %\n",
      "Training round [103/200], qnn_train_step: [300/500], loss: 1.7694870233535767, accuracy: 40.4 %\n",
      "Training round [103/200], qnn_train_step: [400/500], loss: 1.6727877855300903, accuracy: 44.6 %\n",
      "Training round [103/200], qnn_train_step: [500/500], loss: 1.592104434967041, accuracy: 44.5 %\n",
      "Training round [103/200], qnn_train_step: [600/500], loss: 1.5555938482284546, accuracy: 47.3 %\n",
      "Training round [103/200], qnn_train_step: [700/500], loss: 1.5540621280670166, accuracy: 49.3 %\n",
      "Training round [103/200], qnn_train_step: [800/500], loss: 1.5412321090698242, accuracy: 46.0 %\n",
      "Training round [103/200], qnn_train_step: [900/500], loss: 1.5483226776123047, accuracy: 48.5 %\n",
      "Training round [103/200], qnn_train_step: [1000/500], loss: 1.5390634536743164, accuracy: 45.1 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 1.4878, batch time: 0.09, accuracy:  50.00%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 1.5838, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 1.4653, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 1.4344, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 1.5809, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 1.4570, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 1.4787, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 1.6219, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 1.5718, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 1.6510, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [104/200], qnn_train_step: [100/500], loss: 1.56019926071167, accuracy: 43.6 %\n",
      "Training round [104/200], qnn_train_step: [200/500], loss: 1.6649497747421265, accuracy: 45.6 %\n",
      "Training round [104/200], qnn_train_step: [300/500], loss: 1.7128510475158691, accuracy: 45.4 %\n",
      "Training round [104/200], qnn_train_step: [400/500], loss: 1.5368913412094116, accuracy: 46.8 %\n",
      "Training round [104/200], qnn_train_step: [500/500], loss: 1.5166832208633423, accuracy: 46.9 %\n",
      "Training round [104/200], qnn_train_step: [600/500], loss: 1.5241833925247192, accuracy: 47.8 %\n",
      "Training round [104/200], qnn_train_step: [700/500], loss: 1.5046021938323975, accuracy: 49.3 %\n",
      "Training round [104/200], qnn_train_step: [800/500], loss: 1.5132943391799927, accuracy: 47.4 %\n",
      "Training round [104/200], qnn_train_step: [900/500], loss: 1.501896619796753, accuracy: 48.0 %\n",
      "Training round [104/200], qnn_train_step: [1000/500], loss: 1.493829369544983, accuracy: 49.0 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 1.4638, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 1.5633, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 1.5205, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 1.4836, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 1.5028, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 1.5324, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 1.5900, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 1.4130, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 1.4226, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 1.5547, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [105/200], qnn_train_step: [100/500], loss: 1.5582952499389648, accuracy: 46.0 %\n",
      "Training round [105/200], qnn_train_step: [200/500], loss: 1.7982367277145386, accuracy: 40.4 %\n",
      "Training round [105/200], qnn_train_step: [300/500], loss: 1.6100670099258423, accuracy: 46.4 %\n",
      "Training round [105/200], qnn_train_step: [400/500], loss: 1.5709335803985596, accuracy: 49.0 %\n",
      "Training round [105/200], qnn_train_step: [500/500], loss: 1.5743229389190674, accuracy: 44.8 %\n",
      "Training round [105/200], qnn_train_step: [600/500], loss: 1.544245958328247, accuracy: 46.7 %\n",
      "Training round [105/200], qnn_train_step: [700/500], loss: 1.5775905847549438, accuracy: 48.5 %\n",
      "Training round [105/200], qnn_train_step: [800/500], loss: 1.5406705141067505, accuracy: 48.4 %\n",
      "Training round [105/200], qnn_train_step: [900/500], loss: 1.5369919538497925, accuracy: 48.8 %\n",
      "Training round [105/200], qnn_train_step: [1000/500], loss: 1.5295658111572266, accuracy: 47.5 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 1.3559, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 1.4968, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 1.7719, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 1.5970, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 1.5112, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 1.4484, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 1.6461, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 1.4972, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 1.5476, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 1.4178, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [106/200], qnn_train_step: [100/500], loss: 1.607426643371582, accuracy: 46.3 %\n",
      "Training round [106/200], qnn_train_step: [200/500], loss: 1.7248661518096924, accuracy: 43.8 %\n",
      "Training round [106/200], qnn_train_step: [300/500], loss: 1.574976921081543, accuracy: 47.6 %\n",
      "Training round [106/200], qnn_train_step: [400/500], loss: 1.5531642436981201, accuracy: 49.0 %\n",
      "Training round [106/200], qnn_train_step: [500/500], loss: 1.674728274345398, accuracy: 44.6 %\n",
      "Training round [106/200], qnn_train_step: [600/500], loss: 1.5742007493972778, accuracy: 47.9 %\n",
      "Training round [106/200], qnn_train_step: [700/500], loss: 1.5516685247421265, accuracy: 49.2 %\n",
      "Training round [106/200], qnn_train_step: [800/500], loss: 1.672675371170044, accuracy: 44.6 %\n",
      "Training round [106/200], qnn_train_step: [900/500], loss: 1.5728768110275269, accuracy: 46.9 %\n",
      "Training round [106/200], qnn_train_step: [1000/500], loss: 1.5505106449127197, accuracy: 49.2 %\n",
      "Training round [106/200], qnn_train_step: [1100/500], loss: 1.6718430519104004, accuracy: 46.1 %\n",
      "Training round [106/200], qnn_train_step: [1200/500], loss: 1.574093222618103, accuracy: 48.8 %\n",
      "Training round [106/200], qnn_train_step: [1300/500], loss: 1.5492862462997437, accuracy: 49.4 %\n",
      "Training round [106/200], qnn_train_step: [1400/500], loss: 1.6696521043777466, accuracy: 44.7 %\n",
      "Training round [106/200], qnn_train_step: [1500/500], loss: 1.5739855766296387, accuracy: 48.3 %\n",
      "Training round [106/200], qnn_train_step: [1600/500], loss: 1.5481982231140137, accuracy: 49.4 %\n",
      "Training round [106/200], qnn_train_step: [1700/500], loss: 1.6858044862747192, accuracy: 43.6 %\n",
      "Training round [106/200], qnn_train_step: [1800/500], loss: 1.5747054815292358, accuracy: 48.6 %\n",
      "Training round [106/200], qnn_train_step: [1900/500], loss: 1.5468263626098633, accuracy: 49.5 %\n",
      "Training round [106/200], qnn_train_step: [2000/500], loss: 1.6888693571090698, accuracy: 45.2 %\n",
      "Training round [106/200], qnn_train_step: [2100/500], loss: 1.5748275518417358, accuracy: 45.6 %\n",
      "Training round [106/200], qnn_train_step: [2200/500], loss: 1.5456963777542114, accuracy: 49.5 %\n",
      "Training round [106/200], qnn_train_step: [2300/500], loss: 1.7033874988555908, accuracy: 41.4 %\n",
      "Training round [106/200], qnn_train_step: [2400/500], loss: 1.5755274295806885, accuracy: 47.7 %\n",
      "Training round [106/200], qnn_train_step: [2500/500], loss: 1.5446593761444092, accuracy: 49.6 %\n",
      "Training round [106/200], qnn_train_step: [2600/500], loss: 1.7082338333129883, accuracy: 44.8 %\n",
      "Training round [106/200], qnn_train_step: [2700/500], loss: 1.575362205505371, accuracy: 47.1 %\n",
      "Training round [106/200], qnn_train_step: [2800/500], loss: 1.542768955230713, accuracy: 49.6 %\n",
      "Training round [106/200], qnn_train_step: [2900/500], loss: 5.828547954559326, accuracy: 12.2 %\n",
      "Training round [106/200], qnn_train_step: [3000/500], loss: 1.5784590244293213, accuracy: 45.3 %\n",
      "Training round [106/200], qnn_train_step: [3100/500], loss: 1.541333794593811, accuracy: 49.5 %\n",
      "Training round [106/200], qnn_train_step: [3200/500], loss: 1.4882229566574097, accuracy: 51.2 %\n",
      "Training round [106/200], qnn_train_step: [3300/500], loss: 1.5786291360855103, accuracy: 45.8 %\n",
      "Training round [106/200], qnn_train_step: [3400/500], loss: 1.539916753768921, accuracy: 49.4 %\n",
      "Training round [106/200], qnn_train_step: [3500/500], loss: 1.4963065385818481, accuracy: 48.9 %\n",
      "Training round [106/200], qnn_train_step: [3600/500], loss: 1.5798834562301636, accuracy: 47.0 %\n",
      "Training round [106/200], qnn_train_step: [3700/500], loss: 1.5385526418685913, accuracy: 49.5 %\n",
      "Training round [106/200], qnn_train_step: [3800/500], loss: 1.5026941299438477, accuracy: 50.1 %\n",
      "Training round [106/200], qnn_train_step: [3900/500], loss: 1.580176830291748, accuracy: 48.2 %\n",
      "Training round [106/200], qnn_train_step: [4000/500], loss: 1.537203311920166, accuracy: 49.7 %\n",
      "Training round [106/200], qnn_train_step: [4100/500], loss: 1.5250113010406494, accuracy: 50.2 %\n",
      "Training round [106/200], qnn_train_step: [4200/500], loss: 1.5793148279190063, accuracy: 48.7 %\n",
      "Training round [106/200], qnn_train_step: [4300/500], loss: 1.5359221696853638, accuracy: 49.8 %\n",
      "Training round [106/200], qnn_train_step: [4400/500], loss: 1.5240141153335571, accuracy: 46.6 %\n",
      "Training round [106/200], qnn_train_step: [4500/500], loss: 1.5777322053909302, accuracy: 45.0 %\n",
      "Training round [106/200], qnn_train_step: [4600/500], loss: 1.5345802307128906, accuracy: 49.8 %\n",
      "Training round [106/200], qnn_train_step: [4700/500], loss: 1.526677131652832, accuracy: 49.4 %\n",
      "Training round [106/200], qnn_train_step: [4800/500], loss: 1.5803980827331543, accuracy: 47.8 %\n",
      "Training round [106/200], qnn_train_step: [4900/500], loss: 1.533145546913147, accuracy: 50.1 %\n",
      "Training round [106/200], qnn_train_step: [5000/500], loss: 1.5263429880142212, accuracy: 50.3 %\n",
      "Training round [106/200], qnn_train_step: [5100/500], loss: 1.5788931846618652, accuracy: 46.6 %\n",
      "Training round [106/200], qnn_train_step: [5200/500], loss: 1.532291054725647, accuracy: 50.0 %\n",
      "Training round [106/200], qnn_train_step: [5300/500], loss: 1.525815486907959, accuracy: 49.2 %\n",
      "Training round [106/200], qnn_train_step: [5400/500], loss: 1.580651879310608, accuracy: 48.9 %\n",
      "Training round [106/200], qnn_train_step: [5500/500], loss: 1.5313831567764282, accuracy: 48.0 %\n",
      "Training round [106/200], qnn_train_step: [5600/500], loss: 1.5260562896728516, accuracy: 50.1 %\n",
      "Training round [106/200], qnn_train_step: [5700/500], loss: 1.579689621925354, accuracy: 48.6 %\n",
      "Training round [106/200], qnn_train_step: [5800/500], loss: 1.531089425086975, accuracy: 48.5 %\n",
      "Training round [106/200], qnn_train_step: [5900/500], loss: 1.5256855487823486, accuracy: 50.1 %\n",
      "Training round [106/200], qnn_train_step: [6000/500], loss: 1.5775409936904907, accuracy: 48.5 %\n",
      "Training round [106/200], qnn_train_step: [6100/500], loss: 1.5300073623657227, accuracy: 50.1 %\n",
      "Training round [106/200], qnn_train_step: [6200/500], loss: 1.5163798332214355, accuracy: 50.2 %\n",
      "Training round [106/200], qnn_train_step: [6300/500], loss: 1.490479588508606, accuracy: 49.7 %\n",
      "Training round [106/200], qnn_train_step: [6400/500], loss: 1.5388587713241577, accuracy: 46.9 %\n",
      "Training round [106/200], qnn_train_step: [6500/500], loss: 1.518402338027954, accuracy: 47.8 %\n",
      "Training round [106/200], qnn_train_step: [6600/500], loss: 1.4945697784423828, accuracy: 50.6 %\n",
      "Training round [106/200], qnn_train_step: [6700/500], loss: 1.5020735263824463, accuracy: 49.1 %\n",
      "Training round [106/200], qnn_train_step: [6800/500], loss: 1.4908925294876099, accuracy: 50.8 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 1.4481, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 1.4948, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 1.5124, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 1.6267, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 1.6389, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 1.5388, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 1.5976, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 1.5790, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 1.5485, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 1.5724, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [107/200], qnn_train_step: [100/500], loss: 1.5168333053588867, accuracy: 48.1 %\n",
      "Training round [107/200], qnn_train_step: [200/500], loss: 1.922092080116272, accuracy: 38.9 %\n",
      "Training round [107/200], qnn_train_step: [300/500], loss: 1.79205322265625, accuracy: 42.2 %\n",
      "Training round [107/200], qnn_train_step: [400/500], loss: 1.562408447265625, accuracy: 45.6 %\n",
      "Training round [107/200], qnn_train_step: [500/500], loss: 1.517927885055542, accuracy: 48.8 %\n",
      "Training round [107/200], qnn_train_step: [600/500], loss: 1.5021899938583374, accuracy: 50.0 %\n",
      "Training round [107/200], qnn_train_step: [700/500], loss: 1.5105996131896973, accuracy: 47.9 %\n",
      "Training round [107/200], qnn_train_step: [800/500], loss: 1.539955735206604, accuracy: 48.2 %\n",
      "Training round [107/200], qnn_train_step: [900/500], loss: 1.4947198629379272, accuracy: 50.7 %\n",
      "Training round [107/200], qnn_train_step: [1000/500], loss: 1.4953913688659668, accuracy: 50.4 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 1.4189, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 1.4983, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 1.5391, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 1.4798, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 1.4894, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 1.6005, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 1.4815, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 1.4096, batch time: 0.03, accuracy:  55.47%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 1.6093, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 1.4680, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [108/200], qnn_train_step: [100/500], loss: 1.5403424501419067, accuracy: 49.2 %\n",
      "Training round [108/200], qnn_train_step: [200/500], loss: 1.6866536140441895, accuracy: 44.5 %\n",
      "Training round [108/200], qnn_train_step: [300/500], loss: 1.5769661664962769, accuracy: 48.0 %\n",
      "Training round [108/200], qnn_train_step: [400/500], loss: 1.5356005430221558, accuracy: 48.2 %\n",
      "Training round [108/200], qnn_train_step: [500/500], loss: 1.515745997428894, accuracy: 48.3 %\n",
      "Training round [108/200], qnn_train_step: [600/500], loss: 1.5386712551116943, accuracy: 47.9 %\n",
      "Training round [108/200], qnn_train_step: [700/500], loss: 1.5024179220199585, accuracy: 48.5 %\n",
      "Training round [108/200], qnn_train_step: [800/500], loss: 1.4956432580947876, accuracy: 48.4 %\n",
      "Training round [108/200], qnn_train_step: [900/500], loss: 1.501869797706604, accuracy: 47.9 %\n",
      "Training round [108/200], qnn_train_step: [1000/500], loss: 1.4923713207244873, accuracy: 48.2 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 1.4994, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 1.4234, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 1.6251, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 1.4433, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 1.7675, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 1.3929, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 1.3577, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 1.4276, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 1.5686, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 1.4340, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [109/200], qnn_train_step: [100/500], loss: 1.5624232292175293, accuracy: 46.4 %\n",
      "Training round [109/200], qnn_train_step: [200/500], loss: 1.7675864696502686, accuracy: 39.2 %\n",
      "Training round [109/200], qnn_train_step: [300/500], loss: 1.6081238985061646, accuracy: 45.3 %\n",
      "Training round [109/200], qnn_train_step: [400/500], loss: 1.5625299215316772, accuracy: 47.4 %\n",
      "Training round [109/200], qnn_train_step: [500/500], loss: 1.5770753622055054, accuracy: 44.2 %\n",
      "Training round [109/200], qnn_train_step: [600/500], loss: 1.5343823432922363, accuracy: 47.2 %\n",
      "Training round [109/200], qnn_train_step: [700/500], loss: 1.527409315109253, accuracy: 48.5 %\n",
      "Training round [109/200], qnn_train_step: [800/500], loss: 1.534827470779419, accuracy: 48.1 %\n",
      "Training round [109/200], qnn_train_step: [900/500], loss: 1.52146315574646, accuracy: 48.4 %\n",
      "Training round [109/200], qnn_train_step: [1000/500], loss: 1.5295330286026, accuracy: 48.4 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 1.5609, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 1.3901, batch time: 0.07, accuracy:  60.16%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 1.5102, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 1.4496, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 1.2949, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 1.3529, batch time: 0.07, accuracy:  60.94%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 1.4741, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 1.4967, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 1.5218, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 1.3542, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [110/200], qnn_train_step: [100/500], loss: 1.583011507987976, accuracy: 45.4 %\n",
      "Training round [110/200], qnn_train_step: [200/500], loss: 2.0521790981292725, accuracy: 31.3 %\n",
      "Training round [110/200], qnn_train_step: [300/500], loss: 1.5872594118118286, accuracy: 46.8 %\n",
      "Training round [110/200], qnn_train_step: [400/500], loss: 1.5684330463409424, accuracy: 47.0 %\n",
      "Training round [110/200], qnn_train_step: [500/500], loss: 1.521748661994934, accuracy: 48.1 %\n",
      "Training round [110/200], qnn_train_step: [600/500], loss: 1.5670585632324219, accuracy: 46.0 %\n",
      "Training round [110/200], qnn_train_step: [700/500], loss: 1.5317364931106567, accuracy: 48.2 %\n",
      "Training round [110/200], qnn_train_step: [800/500], loss: 1.5202630758285522, accuracy: 47.3 %\n",
      "Training round [110/200], qnn_train_step: [900/500], loss: 1.5079518556594849, accuracy: 49.6 %\n",
      "Training round [110/200], qnn_train_step: [1000/500], loss: 1.5154228210449219, accuracy: 48.2 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 1.4220, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 1.7265, batch time: 0.08, accuracy:  45.31%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 1.6617, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 1.3850, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 1.3905, batch time: 0.03, accuracy:  53.12%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 1.5556, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 1.4961, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 1.5545, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 1.5346, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 1.4480, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [111/200], qnn_train_step: [100/500], loss: 1.5599099397659302, accuracy: 46.8 %\n",
      "Training round [111/200], qnn_train_step: [200/500], loss: 2.1315929889678955, accuracy: 34.0 %\n",
      "Training round [111/200], qnn_train_step: [300/500], loss: 1.6072720289230347, accuracy: 47.3 %\n",
      "Training round [111/200], qnn_train_step: [400/500], loss: 1.6321721076965332, accuracy: 42.2 %\n",
      "Training round [111/200], qnn_train_step: [500/500], loss: 1.5582915544509888, accuracy: 47.7 %\n",
      "Training round [111/200], qnn_train_step: [600/500], loss: 1.5494698286056519, accuracy: 46.6 %\n",
      "Training round [111/200], qnn_train_step: [700/500], loss: 1.5328611135482788, accuracy: 49.1 %\n",
      "Training round [111/200], qnn_train_step: [800/500], loss: 1.5104655027389526, accuracy: 48.3 %\n",
      "Training round [111/200], qnn_train_step: [900/500], loss: 1.5203911066055298, accuracy: 48.7 %\n",
      "Training round [111/200], qnn_train_step: [1000/500], loss: 1.5148465633392334, accuracy: 48.9 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 1.3440, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 1.3560, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 1.5774, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 1.5303, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 1.3839, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 1.5022, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 1.5107, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 1.5419, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 1.5283, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 1.4732, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [112/200], qnn_train_step: [100/500], loss: 1.5381784439086914, accuracy: 46.5 %\n",
      "Training round [112/200], qnn_train_step: [200/500], loss: 1.8820512294769287, accuracy: 40.1 %\n",
      "Training round [112/200], qnn_train_step: [300/500], loss: 1.7247916460037231, accuracy: 42.0 %\n",
      "Training round [112/200], qnn_train_step: [400/500], loss: 1.5488544702529907, accuracy: 49.6 %\n",
      "Training round [112/200], qnn_train_step: [500/500], loss: 1.5234012603759766, accuracy: 48.4 %\n",
      "Training round [112/200], qnn_train_step: [600/500], loss: 1.5175366401672363, accuracy: 49.4 %\n",
      "Training round [112/200], qnn_train_step: [700/500], loss: 1.5201730728149414, accuracy: 49.9 %\n",
      "Training round [112/200], qnn_train_step: [800/500], loss: 1.5124908685684204, accuracy: 47.8 %\n",
      "Training round [112/200], qnn_train_step: [900/500], loss: 1.500938892364502, accuracy: 50.2 %\n",
      "Training round [112/200], qnn_train_step: [1000/500], loss: 1.4984182119369507, accuracy: 50.2 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 1.5041, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 1.5604, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 1.5038, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 1.3695, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 1.5762, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 1.6157, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 1.5243, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 1.4827, batch time: 0.03, accuracy:  55.47%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 1.3820, batch time: 0.03, accuracy:  54.69%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 1.5016, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [113/200], qnn_train_step: [100/500], loss: 1.536236047744751, accuracy: 46.2 %\n",
      "Training round [113/200], qnn_train_step: [200/500], loss: 1.761124849319458, accuracy: 40.4 %\n",
      "Training round [113/200], qnn_train_step: [300/500], loss: 1.673592448234558, accuracy: 45.7 %\n",
      "Training round [113/200], qnn_train_step: [400/500], loss: 1.5978039503097534, accuracy: 44.4 %\n",
      "Training round [113/200], qnn_train_step: [500/500], loss: 1.4910770654678345, accuracy: 49.5 %\n",
      "Training round [113/200], qnn_train_step: [600/500], loss: 1.5131731033325195, accuracy: 47.7 %\n",
      "Training round [113/200], qnn_train_step: [700/500], loss: 1.5104588270187378, accuracy: 47.4 %\n",
      "Training round [113/200], qnn_train_step: [800/500], loss: 1.4869587421417236, accuracy: 50.1 %\n",
      "Training round [113/200], qnn_train_step: [900/500], loss: 1.4820374250411987, accuracy: 48.3 %\n",
      "Training round [113/200], qnn_train_step: [1000/500], loss: 1.4587980508804321, accuracy: 49.2 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 1.3955, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 1.4262, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 1.5524, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 1.3447, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 1.4146, batch time: 0.12, accuracy:  50.78%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 1.6251, batch time: 0.08, accuracy:  49.22%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 1.5086, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 1.4804, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 1.5928, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 1.3433, batch time: 0.08, accuracy:  51.56%\n",
      "Training round [114/200], qnn_train_step: [100/500], loss: 1.58470618724823, accuracy: 45.7 %\n",
      "Training round [114/200], qnn_train_step: [200/500], loss: 1.6972922086715698, accuracy: 42.1 %\n",
      "Training round [114/200], qnn_train_step: [300/500], loss: 1.5256357192993164, accuracy: 48.9 %\n",
      "Training round [114/200], qnn_train_step: [400/500], loss: 1.5124192237854004, accuracy: 51.1 %\n",
      "Training round [114/200], qnn_train_step: [500/500], loss: 1.6262075901031494, accuracy: 44.3 %\n",
      "Training round [114/200], qnn_train_step: [600/500], loss: 1.5963367223739624, accuracy: 43.5 %\n",
      "Training round [114/200], qnn_train_step: [700/500], loss: 1.5751820802688599, accuracy: 49.0 %\n",
      "Training round [114/200], qnn_train_step: [800/500], loss: 1.4941710233688354, accuracy: 47.7 %\n",
      "Training round [114/200], qnn_train_step: [900/500], loss: 1.4933363199234009, accuracy: 50.5 %\n",
      "Training round [114/200], qnn_train_step: [1000/500], loss: 1.4885344505310059, accuracy: 47.7 %\n",
      "Training round [114/200], qnn_train_step: [1100/500], loss: 1.4988210201263428, accuracy: 50.1 %\n",
      "Training round [114/200], qnn_train_step: [1200/500], loss: 1.4967190027236938, accuracy: 46.8 %\n",
      "Training round [114/200], qnn_train_step: [1300/500], loss: 1.4793320894241333, accuracy: 48.2 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 1.4792, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 1.6300, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 1.5529, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 1.5794, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 1.3730, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 1.6418, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 1.5587, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 1.6425, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 1.3472, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 1.5653, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [115/200], qnn_train_step: [100/500], loss: 1.5314651727676392, accuracy: 47.0 %\n",
      "Training round [115/200], qnn_train_step: [200/500], loss: 1.5338332653045654, accuracy: 48.0 %\n",
      "Training round [115/200], qnn_train_step: [300/500], loss: 1.5618836879730225, accuracy: 46.5 %\n",
      "Training round [115/200], qnn_train_step: [400/500], loss: 1.758744478225708, accuracy: 38.6 %\n",
      "Training round [115/200], qnn_train_step: [500/500], loss: 1.5336105823516846, accuracy: 48.7 %\n",
      "Training round [115/200], qnn_train_step: [600/500], loss: 1.544437289237976, accuracy: 48.3 %\n",
      "Training round [115/200], qnn_train_step: [700/500], loss: 1.5048614740371704, accuracy: 47.9 %\n",
      "Training round [115/200], qnn_train_step: [800/500], loss: 1.486575961112976, accuracy: 50.4 %\n",
      "Training round [115/200], qnn_train_step: [900/500], loss: 1.4741795063018799, accuracy: 50.9 %\n",
      "Training round [115/200], qnn_train_step: [1000/500], loss: 1.4782869815826416, accuracy: 50.8 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 1.4933, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 1.4054, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 1.5007, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 1.5736, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 1.5840, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 1.4103, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 1.5082, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 1.4942, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 1.5736, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 1.3843, batch time: 0.07, accuracy:  58.59%\n",
      "Training round [116/200], qnn_train_step: [100/500], loss: 1.5085235834121704, accuracy: 46.1 %\n",
      "Training round [116/200], qnn_train_step: [200/500], loss: 2.423863410949707, accuracy: 32.5 %\n",
      "Training round [116/200], qnn_train_step: [300/500], loss: 3.043184280395508, accuracy: 17.1 %\n",
      "Training round [116/200], qnn_train_step: [400/500], loss: 1.5712721347808838, accuracy: 47.6 %\n",
      "Training round [116/200], qnn_train_step: [500/500], loss: 1.5285731554031372, accuracy: 46.8 %\n",
      "Training round [116/200], qnn_train_step: [600/500], loss: 1.4873261451721191, accuracy: 49.7 %\n",
      "Training round [116/200], qnn_train_step: [700/500], loss: 1.4789791107177734, accuracy: 48.6 %\n",
      "Training round [116/200], qnn_train_step: [800/500], loss: 1.4775114059448242, accuracy: 49.2 %\n",
      "Training round [116/200], qnn_train_step: [900/500], loss: 1.4706275463104248, accuracy: 48.5 %\n",
      "Training round [116/200], qnn_train_step: [1000/500], loss: 1.4744622707366943, accuracy: 47.6 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 1.6489, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 1.5995, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 1.7030, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 1.7118, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 1.4595, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 1.5373, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 1.5046, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 1.4420, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 1.4584, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 1.4574, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [117/200], qnn_train_step: [100/500], loss: 1.5399580001831055, accuracy: 47.0 %\n",
      "Training round [117/200], qnn_train_step: [200/500], loss: 1.6955540180206299, accuracy: 42.0 %\n",
      "Training round [117/200], qnn_train_step: [300/500], loss: 1.63119637966156, accuracy: 43.8 %\n",
      "Training round [117/200], qnn_train_step: [400/500], loss: 1.5239506959915161, accuracy: 47.6 %\n",
      "Training round [117/200], qnn_train_step: [500/500], loss: 1.6881849765777588, accuracy: 41.4 %\n",
      "Training round [117/200], qnn_train_step: [600/500], loss: 1.507138967514038, accuracy: 46.6 %\n",
      "Training round [117/200], qnn_train_step: [700/500], loss: 1.490241527557373, accuracy: 49.1 %\n",
      "Training round [117/200], qnn_train_step: [800/500], loss: 1.5042606592178345, accuracy: 48.4 %\n",
      "Training round [117/200], qnn_train_step: [900/500], loss: 1.4853856563568115, accuracy: 49.2 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 1.5149, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 1.4970, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 1.4300, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 1.7098, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 1.5056, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 1.7324, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 1.3623, batch time: 0.03, accuracy:  54.69%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mqt_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqnn_parameters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqnn_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# print(\"output: \", outputs)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m labels_one_hot \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(labels, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/envs/quandela/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quandela/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 68\u001b[0m, in \u001b[0;36mPhotonicQuantumTrain.forward\u001b[0;34m(self, x, qnn_parameters)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_params_2 \u001b[38;5;241m=\u001b[39m qnn_parameters[\u001b[38;5;241m84\u001b[39m:]\n\u001b[1;32m     66\u001b[0m device \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 68\u001b[0m res_1 \u001b[38;5;241m=\u001b[39m \u001b[43mbs_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_params_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\n\u001b[1;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m trans_res_1 \u001b[38;5;241m=\u001b[39m bs_1\u001b[38;5;241m.\u001b[39mtranslate_results(res \u001b[38;5;241m=\u001b[39m res_1)\n\u001b[1;32m     73\u001b[0m trans_res_1 \u001b[38;5;241m=\u001b[39m trans_res_1\u001b[38;5;241m/\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmean(trans_res_1)\n",
      "File \u001b[0;32m~/Quandela_Quantum_Challenge/boson_sampler.py:181\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(self, parameters, samples)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_state_list_k\u001b[39m(\u001b[38;5;28mself\u001b[39m, k) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    180\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generates all binary states of size self.m with exactly k ones.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m     res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m indices \u001b[38;5;129;01min\u001b[39;00m combinations(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm), k):\n\u001b[1;32m    183\u001b[0m         state \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\n",
      "File \u001b[0;32m~/Quandela_Quantum_Challenge/boson_sampler.py:159\u001b[0m, in \u001b[0;36mprepare_processor\u001b[0;34m(self, processor, parameters)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostselect, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    158\u001b[0m     s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m comb(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm, k)\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "File \u001b[0;32m~/Quandela_Quantum_Challenge/boson_sampler.py:77\u001b[0m, in \u001b[0;36mBosonSampler.create_circuit\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m     75\u001b[0m bs_theta \u001b[38;5;241m=\u001b[39m parameters[param_idx]\n\u001b[1;32m     76\u001b[0m param_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 77\u001b[0m bs \u001b[38;5;241m=\u001b[39m pcvl\u001b[38;5;241m.\u001b[39mBS(theta\u001b[38;5;241m=\u001b[39mbs_theta)\n\u001b[1;32m     78\u001b[0m circuit\u001b[38;5;241m.\u001b[39madd((i, j), bs)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Add Phase Shifters to modes i and j\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quandela/lib/python3.9/site-packages/perceval/components/unitary_components.py:56\u001b[0m, in \u001b[0;36mBS.__init__\u001b[0;34m(self, theta, phi_tl, phi_bl, phi_tr, phi_br, convention)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convention \u001b[38;5;241m=\u001b[39m convention\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m\"\u001b[39m, theta, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39msp\u001b[38;5;241m.\u001b[39mpi)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_phi_tl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_parameter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphi_tl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_tl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_phi_bl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi_bl\u001b[39m\u001b[38;5;124m\"\u001b[39m, phi_bl, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39msp\u001b[38;5;241m.\u001b[39mpi)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_phi_tr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi_tr\u001b[39m\u001b[38;5;124m\"\u001b[39m, phi_tr, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39msp\u001b[38;5;241m.\u001b[39mpi)\n",
      "File \u001b[0;32m~/anaconda3/envs/quandela/lib/python3.9/site-packages/perceval/components/abstract_component.py:150\u001b[0m, in \u001b[0;36mAParametrizedComponent._set_parameter\u001b[0;34m(self, name, p, min_v, max_v, periodic)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vars[p\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_v\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_v\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiodic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperiodic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params[name] \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/anaconda3/envs/quandela/lib/python3.9/site-packages/perceval/utils/parameter.py:56\u001b[0m, in \u001b[0;36mParameter.__init__\u001b[0;34m(self, name, value, min_v, max_v, periodic, is_expression)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_v\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quandela/lib/python3.9/site-packages/sympy/core/expr.py:346\u001b[0m, in \u001b[0;36mExpr.__float__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__float__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;66;03m# Don't bother testing if it's a number; if it's not this is going\u001b[39;00m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;66;03m# to fail, and if it is we still need to check that it evalf'ed to\u001b[39;00m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;66;03m# a number.\u001b[39;00m\n\u001b[0;32m--> 346\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevalf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mis_Number:\n\u001b[1;32m    348\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/quandela/lib/python3.9/site-packages/sympy/core/evalf.py:1647\u001b[0m, in \u001b[0;36mEvalfMixin.evalf\u001b[0;34m(self, n, subs, maxn, chop, strict, quad, verbose)\u001b[0m\n\u001b[1;32m   1645\u001b[0m     options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquad\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m quad\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1647\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mevalf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;66;03m# Fall back to the ordinary evalf\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubs\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m subs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# issue 20291\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quandela/lib/python3.9/site-packages/sympy/core/evalf.py:1482\u001b[0m, in \u001b[0;36mevalf\u001b[0;34m(x, prec, options)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1481\u001b[0m     rf \u001b[38;5;241m=\u001b[39m evalf_table[\u001b[38;5;28mtype\u001b[39m(x)]\n\u001b[0;32m-> 1482\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mrf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   1484\u001b[0m     \u001b[38;5;66;03m# Fall back to ordinary evalf if possible\u001b[39;00m\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubs\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m options:\n",
      "File \u001b[0;32m~/anaconda3/envs/quandela/lib/python3.9/site-packages/sympy/core/evalf.py:648\u001b[0m, in \u001b[0;36mevalf_mul\u001b[0;34m(v, prec, options)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Float\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[0;32m--> 648\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mevalf\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m S\u001b[38;5;241m.\u001b[39mComplexInfinity:\n\u001b[1;32m    650\u001b[0m         special\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/quandela/lib/python3.9/site-packages/sympy/core/evalf.py:1514\u001b[0m, in \u001b[0;36mevalf\u001b[0;34m(x, prec, options)\u001b[0m\n\u001b[1;32m   1511\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m   1512\u001b[0m     r \u001b[38;5;241m=\u001b[39m re, im, reprec, imprec\n\u001b[0;32m-> 1514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1515\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### input\u001b[39m\u001b[38;5;124m\"\u001b[39m, x)\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### output\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_str(r[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m fzero, \u001b[38;5;241m50\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(r, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m r)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0\n",
    "\n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter)\n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "\n",
    "            qnn_train_step += 1\n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{500}], loss: {loss}, accuracy: {acc} %\"\n",
    "                )\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA\n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(\n",
    "            qnn_minimize_loss,\n",
    "            init_param,\n",
    "            method=\"Nelder-Mead\",\n",
    "            options={\"maxiter\": 500, \"adaptive\": True},\n",
    "        )\n",
    "\n",
    "        qnn_parameters = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.ylim(0.5, 2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
