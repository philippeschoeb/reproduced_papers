{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 216, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"3200.0\" height=\"593.75\" viewBox=\"-30.0 0 2560.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.01681</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.294466</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.781915</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.418166</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.055246</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.845198</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.794894</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.598337</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.657806</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.60833</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.272109</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.483624</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.881912</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.624746</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.580025</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.67226</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.297532</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.635301</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.533233</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.44091</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.858009</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.090023</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.540216</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.741486</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.91527</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.248801</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.90114</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.637561</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.952139</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.374628</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.083213</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.135774</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.676058</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.194015</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.521349</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.114197</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.309525</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.771404</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.926015</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.29153</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.372964</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.134823</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.826377</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.398762</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.733753</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.710723</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.260571</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.164895</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.689371</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.151657</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.707312</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.08877</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.014097</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.977183</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.761834</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.410219</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.493733</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.052326</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.285546</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.285289</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.948752</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.387442</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.713639</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.004218</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.92998</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.779285</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.477019</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.155895</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.734487</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.287098</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.977896</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.505663</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.485342</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.597587</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.440408</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.338144</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.24951</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.189167</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.080871</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.616743</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.112814</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.229316</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.702833</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.340242</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.970962</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.336552</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.863034</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.589999</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.492394</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.585766</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.505078</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.307889</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.497289</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.707421</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.413405</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.273428</text>\n",
       "<path d=\"M1075,25 L1125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1080,40 L1089,40 L1103,10 L1094,10 L1080,40 L1089,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1097\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1225,75 L1275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,90 L1239,90 L1253,60 L1244,60 L1230,90 L1239,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1225,125 L1275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,140 L1239,140 L1253,110 L1244,110 L1230,140 L1239,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1225,175 L1275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,190 L1239,190 L1253,160 L1244,160 L1230,190 L1239,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1225,225 L1275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,240 L1239,240 L1253,210 L1244,210 L1230,240 L1239,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1225,275 L1275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,290 L1239,290 L1253,260 L1244,260 L1230,290 L1239,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1225,325 L1275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,340 L1239,340 L1253,310 L1244,310 L1230,340 L1239,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1225,375 L1275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,390 L1239,390 L1253,360 L1244,360 L1230,390 L1239,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1225,425 L1275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,440 L1239,440 L1253,410 L1244,410 L1230,440 L1239,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1125,25.0 L1275,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,25 L1303,25 L1322,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,44 L1347,25 L1375,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,75 L1303,75 L1322,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,56 L1347,75 L1375,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1300,43 L1350,43 L1350,57 L1300,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1325\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1325\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.597645</text>\n",
       "<path d=\"M1300,43 L1350,43 L1350,47 L1300,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1343,50 L1353,50 L1353,60 L1343,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1348\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1375,25 L1425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,40 L1389,40 L1403,10 L1394,10 L1380,40 L1389,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.24342</text>\n",
       "<path d=\"M1375,75 L1425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,90 L1389,90 L1403,60 L1394,60 L1380,90 L1389,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.432935</text>\n",
       "<path d=\"M1275,125 L1303,125 L1322,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,144 L1347,125 L1375,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,175 L1303,175 L1322,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,156 L1347,175 L1375,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1300,143 L1350,143 L1350,157 L1300,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1325\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1325\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.675939</text>\n",
       "<path d=\"M1300,143 L1350,143 L1350,147 L1300,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1343,150 L1353,150 L1353,160 L1343,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1348\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1375,125 L1425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,140 L1389,140 L1403,110 L1394,110 L1380,140 L1389,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.850591</text>\n",
       "<path d=\"M1375,175 L1425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,190 L1389,190 L1403,160 L1394,160 L1380,190 L1389,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.310991</text>\n",
       "<path d=\"M1275,225 L1303,225 L1322,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,244 L1347,225 L1375,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,275 L1303,275 L1322,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,256 L1347,275 L1375,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1300,243 L1350,243 L1350,257 L1300,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1325\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1325\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.090436</text>\n",
       "<path d=\"M1300,243 L1350,243 L1350,247 L1300,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1343,250 L1353,250 L1353,260 L1343,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1348\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1375,225 L1425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,240 L1389,240 L1403,210 L1394,210 L1380,240 L1389,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.421619</text>\n",
       "<path d=\"M1375,275 L1425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,290 L1389,290 L1403,260 L1394,260 L1380,290 L1389,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.519618</text>\n",
       "<path d=\"M1275,325 L1303,325 L1322,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,344 L1347,325 L1375,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,375 L1303,375 L1322,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,356 L1347,375 L1375,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1300,343 L1350,343 L1350,357 L1300,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1325\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1325\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.493192</text>\n",
       "<path d=\"M1300,343 L1350,343 L1350,347 L1300,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1343,350 L1353,350 L1353,360 L1343,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1348\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1375,325 L1425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,340 L1389,340 L1403,310 L1394,310 L1380,340 L1389,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.94308</text>\n",
       "<path d=\"M1375,375 L1425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,390 L1389,390 L1403,360 L1394,360 L1380,390 L1389,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.681745</text>\n",
       "<path d=\"M1425,75 L1453,75 L1472,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,94 L1497,75 L1525,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,125 L1453,125 L1472,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,106 L1497,125 L1525,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1450,93 L1500,93 L1500,107 L1450,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1475\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1475\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.962872</text>\n",
       "<path d=\"M1450,93 L1500,93 L1500,97 L1450,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1493,100 L1503,100 L1503,110 L1493,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1498\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1525,75 L1575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,90 L1539,90 L1553,60 L1544,60 L1530,90 L1539,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.649747</text>\n",
       "<path d=\"M1525,125 L1575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,140 L1539,140 L1553,110 L1544,110 L1530,140 L1539,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.062752</text>\n",
       "<path d=\"M1425,175 L1453,175 L1472,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,194 L1497,175 L1525,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,225 L1453,225 L1472,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,206 L1497,225 L1525,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1450,193 L1500,193 L1500,207 L1450,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1475\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1475\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.175829</text>\n",
       "<path d=\"M1450,193 L1500,193 L1500,197 L1450,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1493,200 L1503,200 L1503,210 L1493,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1498\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1525,175 L1575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,190 L1539,190 L1553,160 L1544,160 L1530,190 L1539,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.687919</text>\n",
       "<path d=\"M1525,225 L1575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,240 L1539,240 L1553,210 L1544,210 L1530,240 L1539,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.213766</text>\n",
       "<path d=\"M1425,275 L1453,275 L1472,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,294 L1497,275 L1525,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,325 L1453,325 L1472,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,306 L1497,325 L1525,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1450,293 L1500,293 L1500,307 L1450,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1475\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1475\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.210298</text>\n",
       "<path d=\"M1450,293 L1500,293 L1500,297 L1450,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1493,300 L1503,300 L1503,310 L1493,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1498\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1525,275 L1575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,290 L1539,290 L1553,260 L1544,260 L1530,290 L1539,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.064632</text>\n",
       "<path d=\"M1525,325 L1575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,340 L1539,340 L1553,310 L1544,310 L1530,340 L1539,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.493613</text>\n",
       "<path d=\"M1275,425.0 L1425,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,375 L1453,375 L1472,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,394 L1497,375 L1525,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,425 L1453,425 L1472,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,406 L1497,425 L1525,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1450,393 L1500,393 L1500,407 L1450,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1475\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1475\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.718665</text>\n",
       "<path d=\"M1450,393 L1500,393 L1500,397 L1450,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1493,400 L1503,400 L1503,410 L1493,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1498\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1525,375 L1575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,390 L1539,390 L1553,360 L1544,360 L1530,390 L1539,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.569683</text>\n",
       "<path d=\"M1525,425 L1575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,440 L1539,440 L1553,410 L1544,410 L1530,440 L1539,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.89453</text>\n",
       "<path d=\"M1425,25.0 L1575,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1575,25 L1603,25 L1622,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,44 L1647,25 L1675,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1575,75 L1603,75 L1622,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,56 L1647,75 L1675,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1600,43 L1650,43 L1650,57 L1600,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1625\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1625\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.634541</text>\n",
       "<path d=\"M1600,43 L1650,43 L1650,47 L1600,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1643,50 L1653,50 L1653,60 L1643,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1648\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1675,25 L1725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,40 L1689,40 L1703,10 L1694,10 L1680,40 L1689,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.760593</text>\n",
       "<path d=\"M1675,75 L1725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,90 L1689,90 L1703,60 L1694,60 L1680,90 L1689,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.353634</text>\n",
       "<path d=\"M1575,125 L1603,125 L1622,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,144 L1647,125 L1675,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1575,175 L1603,175 L1622,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,156 L1647,175 L1675,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1600,143 L1650,143 L1650,157 L1600,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1625\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1625\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.020285</text>\n",
       "<path d=\"M1600,143 L1650,143 L1650,147 L1600,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1643,150 L1653,150 L1653,160 L1643,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1648\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1675,125 L1725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,140 L1689,140 L1703,110 L1694,110 L1680,140 L1689,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.949041</text>\n",
       "<path d=\"M1675,175 L1725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,190 L1689,190 L1703,160 L1694,160 L1680,190 L1689,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.243553</text>\n",
       "<path d=\"M1575,225 L1603,225 L1622,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,244 L1647,225 L1675,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1575,275 L1603,275 L1622,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,256 L1647,275 L1675,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1600,243 L1650,243 L1650,257 L1600,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1625\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1625\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.881912</text>\n",
       "<path d=\"M1600,243 L1650,243 L1650,247 L1600,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1643,250 L1653,250 L1653,260 L1643,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1648\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1675,225 L1725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,240 L1689,240 L1703,210 L1694,210 L1680,240 L1689,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.310087</text>\n",
       "<path d=\"M1675,275 L1725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,290 L1689,290 L1703,260 L1694,260 L1680,290 L1689,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.930022</text>\n",
       "<path d=\"M1575,325 L1603,325 L1622,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,344 L1647,325 L1675,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1575,375 L1603,375 L1622,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,356 L1647,375 L1675,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1600,343 L1650,343 L1650,357 L1600,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1625\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1625\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.217344</text>\n",
       "<path d=\"M1600,343 L1650,343 L1650,347 L1600,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1643,350 L1653,350 L1653,360 L1643,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1648\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1675,325 L1725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,340 L1689,340 L1703,310 L1694,310 L1680,340 L1689,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.360392</text>\n",
       "<path d=\"M1675,375 L1725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,390 L1689,390 L1703,360 L1694,360 L1680,390 L1689,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.859537</text>\n",
       "<path d=\"M1725,75 L1753,75 L1772,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,94 L1797,75 L1825,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,125 L1753,125 L1772,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,106 L1797,125 L1825,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1750,93 L1800,93 L1800,107 L1750,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1775\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1775\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.361723</text>\n",
       "<path d=\"M1750,93 L1800,93 L1800,97 L1750,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1793,100 L1803,100 L1803,110 L1793,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1798\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1825,75 L1875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,90 L1839,90 L1853,60 L1844,60 L1830,90 L1839,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.536798</text>\n",
       "<path d=\"M1825,125 L1875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,140 L1839,140 L1853,110 L1844,110 L1830,140 L1839,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.681839</text>\n",
       "<path d=\"M1725,175 L1753,175 L1772,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,194 L1797,175 L1825,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,225 L1753,225 L1772,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,206 L1797,225 L1825,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1750,193 L1800,193 L1800,207 L1750,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1775\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1775\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.606115</text>\n",
       "<path d=\"M1750,193 L1800,193 L1800,197 L1750,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1793,200 L1803,200 L1803,210 L1793,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1798\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1825,175 L1875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,190 L1839,190 L1853,160 L1844,160 L1830,190 L1839,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.592055</text>\n",
       "<path d=\"M1825,225 L1875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,240 L1839,240 L1853,210 L1844,210 L1830,240 L1839,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.345896</text>\n",
       "<path d=\"M1725,275 L1753,275 L1772,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,294 L1797,275 L1825,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,325 L1753,325 L1772,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,306 L1797,325 L1825,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1750,293 L1800,293 L1800,307 L1750,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1775\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1775\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.924232</text>\n",
       "<path d=\"M1750,293 L1800,293 L1800,297 L1750,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1793,300 L1803,300 L1803,310 L1793,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1798\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1825,275 L1875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,290 L1839,290 L1853,260 L1844,260 L1830,290 L1839,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.023483</text>\n",
       "<path d=\"M1825,325 L1875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,340 L1839,340 L1853,310 L1844,310 L1830,340 L1839,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.15965</text>\n",
       "<path d=\"M1575,425.0 L1725,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,375 L1753,375 L1772,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,394 L1797,375 L1825,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,425 L1753,425 L1772,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,406 L1797,425 L1825,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1750,393 L1800,393 L1800,407 L1750,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1775\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1775\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.752626</text>\n",
       "<path d=\"M1750,393 L1800,393 L1800,397 L1750,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1793,400 L1803,400 L1803,410 L1793,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1798\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1825,375 L1875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,390 L1839,390 L1853,360 L1844,360 L1830,390 L1839,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.274389</text>\n",
       "<path d=\"M1825,425 L1875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,440 L1839,440 L1853,410 L1844,410 L1830,440 L1839,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.333678</text>\n",
       "<path d=\"M1725,25.0 L1875,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1875,25 L1903,25 L1922,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,44 L1947,25 L1975,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1875,75 L1903,75 L1922,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,56 L1947,75 L1975,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1900,43 L1950,43 L1950,57 L1900,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1925\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1925\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.109197</text>\n",
       "<path d=\"M1900,43 L1950,43 L1950,47 L1900,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1943,50 L1953,50 L1953,60 L1943,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1948\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1975,25 L2025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,40 L1989,40 L2003,10 L1994,10 L1980,40 L1989,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.593167</text>\n",
       "<path d=\"M1975,75 L2025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,90 L1989,90 L2003,60 L1994,60 L1980,90 L1989,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.485242</text>\n",
       "<path d=\"M1875,125 L1903,125 L1922,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,144 L1947,125 L1975,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1875,175 L1903,175 L1922,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,156 L1947,175 L1975,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1900,143 L1950,143 L1950,157 L1900,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1925\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1925\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.73108</text>\n",
       "<path d=\"M1900,143 L1950,143 L1950,147 L1900,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1943,150 L1953,150 L1953,160 L1943,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1948\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1975,125 L2025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,140 L1989,140 L2003,110 L1994,110 L1980,140 L1989,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.467971</text>\n",
       "<path d=\"M1975,175 L2025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,190 L1989,190 L2003,160 L1994,160 L1980,190 L1989,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.904366</text>\n",
       "<path d=\"M1875,225 L1903,225 L1922,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,244 L1947,225 L1975,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1875,275 L1903,275 L1922,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,256 L1947,275 L1975,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1900,243 L1950,243 L1950,257 L1900,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1925\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1925\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.319049</text>\n",
       "<path d=\"M1900,243 L1950,243 L1950,247 L1900,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1943,250 L1953,250 L1953,260 L1943,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1948\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1975,225 L2025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,240 L1989,240 L2003,210 L1994,210 L1980,240 L1989,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.017944</text>\n",
       "<path d=\"M1975,275 L2025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,290 L1989,290 L2003,260 L1994,260 L1980,290 L1989,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.272163</text>\n",
       "<path d=\"M1875,325 L1903,325 L1922,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,344 L1947,325 L1975,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1875,375 L1903,375 L1922,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,356 L1947,375 L1975,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1900,343 L1950,343 L1950,357 L1900,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1925\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1925\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.001809</text>\n",
       "<path d=\"M1900,343 L1950,343 L1950,347 L1900,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1943,350 L1953,350 L1953,360 L1943,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1948\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1975,325 L2025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,340 L1989,340 L2003,310 L1994,310 L1980,340 L1989,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.241446</text>\n",
       "<path d=\"M1975,375 L2025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,390 L1989,390 L2003,360 L1994,360 L1980,390 L1989,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.767603</text>\n",
       "<path d=\"M2025,75 L2053,75 L2072,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,94 L2097,75 L2125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2025,125 L2053,125 L2072,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,106 L2097,125 L2125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2050,93 L2100,93 L2100,107 L2050,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2075\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2075\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.593237</text>\n",
       "<path d=\"M2050,93 L2100,93 L2100,97 L2050,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2093,100 L2103,100 L2103,110 L2093,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2098\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2125,75 L2175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,90 L2139,90 L2153,60 L2144,60 L2130,90 L2139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.589442</text>\n",
       "<path d=\"M2125,125 L2175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,140 L2139,140 L2153,110 L2144,110 L2130,140 L2139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.316386</text>\n",
       "<path d=\"M2025,175 L2053,175 L2072,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,194 L2097,175 L2125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2025,225 L2053,225 L2072,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,206 L2097,225 L2125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2050,193 L2100,193 L2100,207 L2050,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2075\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2075\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.988129</text>\n",
       "<path d=\"M2050,193 L2100,193 L2100,197 L2050,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2093,200 L2103,200 L2103,210 L2093,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2098\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2125,175 L2175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,190 L2139,190 L2153,160 L2144,160 L2130,190 L2139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.792142</text>\n",
       "<path d=\"M2125,225 L2175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,240 L2139,240 L2153,210 L2144,210 L2130,240 L2139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.662787</text>\n",
       "<path d=\"M2025,275 L2053,275 L2072,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,294 L2097,275 L2125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2025,325 L2053,325 L2072,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,306 L2097,325 L2125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2050,293 L2100,293 L2100,307 L2050,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2075\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2075\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.898814</text>\n",
       "<path d=\"M2050,293 L2100,293 L2100,297 L2050,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2093,300 L2103,300 L2103,310 L2093,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2098\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2125,275 L2175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,290 L2139,290 L2153,260 L2144,260 L2130,290 L2139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.806828</text>\n",
       "<path d=\"M2125,325 L2175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,340 L2139,340 L2153,310 L2144,310 L2130,340 L2139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.696897</text>\n",
       "<path d=\"M1875,425.0 L2025,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2025,375 L2053,375 L2072,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,394 L2097,375 L2125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2025,425 L2053,425 L2072,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,406 L2097,425 L2125,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2050,393 L2100,393 L2100,407 L2050,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2075\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2075\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.035788</text>\n",
       "<path d=\"M2050,393 L2100,393 L2100,397 L2050,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2093,400 L2103,400 L2103,410 L2093,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2098\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2125,375 L2175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,390 L2139,390 L2153,360 L2144,360 L2130,390 L2139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.402143</text>\n",
       "<path d=\"M2125,425 L2175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,440 L2139,440 L2153,410 L2144,410 L2130,440 L2139,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.225302</text>\n",
       "<path d=\"M2025,25.0 L2175,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2175,25 L2203,25 L2222,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2228,44 L2247,25 L2275,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2175,75 L2203,75 L2222,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2228,56 L2247,75 L2275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2200,43 L2250,43 L2250,57 L2200,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2225\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2225\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.125413</text>\n",
       "<path d=\"M2200,43 L2250,43 L2250,47 L2200,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2243,50 L2253,50 L2253,60 L2243,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2248\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2275,25 L2325,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2280,40 L2289,40 L2303,10 L2294,10 L2280,40 L2289,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2297\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.624341</text>\n",
       "<path d=\"M2275,75 L2325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2280,90 L2289,90 L2303,60 L2294,60 L2280,90 L2289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.917953</text>\n",
       "<path d=\"M2175,125 L2203,125 L2222,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2228,144 L2247,125 L2275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2175,175 L2203,175 L2222,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2228,156 L2247,175 L2275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2200,143 L2250,143 L2250,157 L2200,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2225\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2225\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.971201</text>\n",
       "<path d=\"M2200,143 L2250,143 L2250,147 L2200,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2243,150 L2253,150 L2253,160 L2243,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2248\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2275,125 L2325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2280,140 L2289,140 L2303,110 L2294,110 L2280,140 L2289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.501855</text>\n",
       "<path d=\"M2275,175 L2325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2280,190 L2289,190 L2303,160 L2294,160 L2280,190 L2289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.129715</text>\n",
       "<path d=\"M2175,225 L2203,225 L2222,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2228,244 L2247,225 L2275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2175,275 L2203,275 L2222,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2228,256 L2247,275 L2275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2200,243 L2250,243 L2250,257 L2200,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2225\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2225\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.175773</text>\n",
       "<path d=\"M2200,243 L2250,243 L2250,247 L2200,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2243,250 L2253,250 L2253,260 L2243,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2248\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2275,225 L2325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2280,240 L2289,240 L2303,210 L2294,210 L2280,240 L2289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.231505</text>\n",
       "<path d=\"M2275,275 L2325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2280,290 L2289,290 L2303,260 L2294,260 L2280,290 L2289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.970758</text>\n",
       "<path d=\"M2175,325 L2203,325 L2222,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2228,344 L2247,325 L2275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2175,375 L2203,375 L2222,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2228,356 L2247,375 L2275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2200,343 L2250,343 L2250,357 L2200,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2225\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2225\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.164759</text>\n",
       "<path d=\"M2200,343 L2250,343 L2250,347 L2200,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2243,350 L2253,350 L2253,360 L2243,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2248\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2275,325 L2325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2280,340 L2289,340 L2303,310 L2294,310 L2280,340 L2289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.173713</text>\n",
       "<path d=\"M2275,375 L2325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2280,390 L2289,390 L2303,360 L2294,360 L2280,390 L2289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.097295</text>\n",
       "<path d=\"M2325,75 L2353,75 L2372,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2378,94 L2397,75 L2425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2325,125 L2353,125 L2372,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2378,106 L2397,125 L2425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2350,93 L2400,93 L2400,107 L2350,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2375\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2375\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.462066</text>\n",
       "<path d=\"M2350,93 L2400,93 L2400,97 L2350,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2393,100 L2403,100 L2403,110 L2393,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2398\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2425,75 L2475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2430,90 L2439,90 L2453,60 L2444,60 L2430,90 L2439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.42377</text>\n",
       "<path d=\"M2425,125 L2475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2430,140 L2439,140 L2453,110 L2444,110 L2430,140 L2439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.742562</text>\n",
       "<path d=\"M2325,175 L2353,175 L2372,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2378,194 L2397,175 L2425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2325,225 L2353,225 L2372,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2378,206 L2397,225 L2425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2350,193 L2400,193 L2400,207 L2350,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2375\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2375\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.29994</text>\n",
       "<path d=\"M2350,193 L2400,193 L2400,197 L2350,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2393,200 L2403,200 L2403,210 L2393,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2398\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2425,175 L2475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2430,190 L2439,190 L2453,160 L2444,160 L2430,190 L2439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.913839</text>\n",
       "<path d=\"M2425,225 L2475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2430,240 L2439,240 L2453,210 L2444,210 L2430,240 L2439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.094899</text>\n",
       "<path d=\"M2325,275 L2353,275 L2372,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2378,294 L2397,275 L2425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2325,325 L2353,325 L2372,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2378,306 L2397,325 L2425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2350,293 L2400,293 L2400,307 L2350,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2375\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2375\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.28642</text>\n",
       "<path d=\"M2350,293 L2400,293 L2400,297 L2350,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2393,300 L2403,300 L2403,310 L2393,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2398\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2425,275 L2475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2430,290 L2439,290 L2453,260 L2444,260 L2430,290 L2439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.52835</text>\n",
       "<path d=\"M2425,325 L2475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2430,340 L2439,340 L2453,310 L2444,310 L2430,340 L2439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.638891</text>\n",
       "<path d=\"M2175,425.0 L2325,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2325,375 L2353,375 L2372,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2378,394 L2397,375 L2425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2325,425 L2353,425 L2372,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2378,406 L2397,425 L2425,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2350,393 L2400,393 L2400,407 L2350,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2375\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2375\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.489223</text>\n",
       "<path d=\"M2350,393 L2400,393 L2400,397 L2350,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2393,400 L2403,400 L2403,410 L2393,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2398\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2425,375 L2475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2430,390 L2439,390 L2453,360 L2444,360 L2430,390 L2439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.500448</text>\n",
       "<path d=\"M2425,425 L2475,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2430,440 L2439,440 L2453,410 L2444,410 L2430,440 L2439,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2447\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.202006</text>\n",
       "<path d=\"M2325,25.0 L2475,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2475,25.0 L2490,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2475,75.0 L2490,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2475,125.0 L2490,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2475,175.0 L2490,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2475,225.0 L2490,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2475,275.0 L2490,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2475,325.0 L2490,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2475,375.0 L2490,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2475,425.0 L2490,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"2500\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"2500\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"2500\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"2500\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"2500\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"2500\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"2500\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"2500\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"2500\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7b266398f160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "qnn_layers = 2\n",
    "\n",
    "#\n",
    "\n",
    "bs_1 = BosonSampler(m=9, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters * qnn_layers}, and embedding size = {bs_1.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit(qnn_layers=qnn_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 168, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"2823.75\" height=\"531.25\" viewBox=\"-29.5 0 2259.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.038281</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.690869</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.299407</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.346669</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.282931</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.326292</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.343042</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.842271</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.051401</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.935613</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.732531</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.930652</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.990373</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.879918</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.543295</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.671333</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.450625</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.406859</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.755676</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.700902</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.385819</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.84582</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.145802</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.888656</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.999891</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.846128</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.196356</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.50457</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.870308</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.275553</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.626027</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.867051</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.02617</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.566635</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.167306</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.534092</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.003924</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.200033</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.837494</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.313067</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.744762</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.377707</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.883203</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.582249</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.398996</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.183612</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.457196</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.612395</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.154916</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.371</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.781922</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.435465</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.889221</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.937557</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.944137</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.916225</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.966739</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.835664</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.929193</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.574919</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.682323</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.32268</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.233121</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.456391</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.149618</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.691001</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.298969</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.264</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.922331</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.152125</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.802273</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.268748</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.754322</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.600266</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.78429</text>\n",
       "<path d=\"M1075,25 L1125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1080,40 L1089,40 L1103,10 L1094,10 L1080,40 L1089,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1097\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1075,75 L1125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1080,90 L1089,90 L1103,60 L1094,60 L1080,90 L1089,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1097\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1075,125 L1125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1080,140 L1089,140 L1103,110 L1094,110 L1080,140 L1089,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1097\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1075,175 L1125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1080,190 L1089,190 L1103,160 L1094,160 L1080,190 L1089,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1097\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1075,225 L1125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1080,240 L1089,240 L1103,210 L1094,210 L1080,240 L1089,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1097\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1075,275 L1125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1080,290 L1089,290 L1103,260 L1094,260 L1080,290 L1089,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1097\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1075,325 L1125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1080,340 L1089,340 L1103,310 L1094,310 L1080,340 L1089,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1097\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1075,375 L1125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1080,390 L1089,390 L1103,360 L1094,360 L1080,390 L1089,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1097\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M1125,25 L1153,25 L1172,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1178,44 L1197,25 L1225,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1125,75 L1153,75 L1172,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1178,56 L1197,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1150,43 L1200,43 L1200,57 L1150,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1175\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1175\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.277646</text>\n",
       "<path d=\"M1150,43 L1200,43 L1200,47 L1150,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1193,50 L1203,50 L1203,60 L1193,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1198\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1225,25 L1275,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,40 L1239,40 L1253,10 L1244,10 L1230,40 L1239,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.91035</text>\n",
       "<path d=\"M1225,75 L1275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,90 L1239,90 L1253,60 L1244,60 L1230,90 L1239,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.526063</text>\n",
       "<path d=\"M1125,125 L1153,125 L1172,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1178,144 L1197,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1125,175 L1153,175 L1172,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1178,156 L1197,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1150,143 L1200,143 L1200,157 L1150,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1175\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1175\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.258203</text>\n",
       "<path d=\"M1150,143 L1200,143 L1200,147 L1150,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1193,150 L1203,150 L1203,160 L1193,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1198\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1225,125 L1275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,140 L1239,140 L1253,110 L1244,110 L1230,140 L1239,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.5738</text>\n",
       "<path d=\"M1225,175 L1275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,190 L1239,190 L1253,160 L1244,160 L1230,190 L1239,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.973436</text>\n",
       "<path d=\"M1125,225 L1153,225 L1172,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1178,244 L1197,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1125,275 L1153,275 L1172,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1178,256 L1197,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1150,243 L1200,243 L1200,257 L1150,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1175\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1175\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.413578</text>\n",
       "<path d=\"M1150,243 L1200,243 L1200,247 L1150,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1193,250 L1203,250 L1203,260 L1193,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1198\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1225,225 L1275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,240 L1239,240 L1253,210 L1244,210 L1230,240 L1239,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.833067</text>\n",
       "<path d=\"M1225,275 L1275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,290 L1239,290 L1253,260 L1244,260 L1230,290 L1239,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.087518</text>\n",
       "<path d=\"M1125,325 L1153,325 L1172,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1178,344 L1197,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1125,375 L1153,375 L1172,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1178,356 L1197,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1150,343 L1200,343 L1200,357 L1150,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1175\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1175\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.189733</text>\n",
       "<path d=\"M1150,343 L1200,343 L1200,347 L1150,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1193,350 L1203,350 L1203,360 L1193,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1198\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1225,325 L1275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,340 L1239,340 L1253,310 L1244,310 L1230,340 L1239,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.528928</text>\n",
       "<path d=\"M1225,375 L1275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1230,390 L1239,390 L1253,360 L1244,360 L1230,390 L1239,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1247\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.559934</text>\n",
       "<path d=\"M1275,75 L1303,75 L1322,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,94 L1347,75 L1375,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,125 L1303,125 L1322,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,106 L1347,125 L1375,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1300,93 L1350,93 L1350,107 L1300,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1325\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1325\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.866769</text>\n",
       "<path d=\"M1300,93 L1350,93 L1350,97 L1300,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1343,100 L1353,100 L1353,110 L1343,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1348\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1375,75 L1425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,90 L1389,90 L1403,60 L1394,60 L1380,90 L1389,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.509392</text>\n",
       "<path d=\"M1375,125 L1425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,140 L1389,140 L1403,110 L1394,110 L1380,140 L1389,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.349161</text>\n",
       "<path d=\"M1275,175 L1303,175 L1322,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,194 L1347,175 L1375,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,225 L1303,225 L1322,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,206 L1347,225 L1375,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1300,193 L1350,193 L1350,207 L1300,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1325\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1325\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.777938</text>\n",
       "<path d=\"M1300,193 L1350,193 L1350,197 L1300,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1343,200 L1353,200 L1353,210 L1343,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1348\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1375,175 L1425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,190 L1389,190 L1403,160 L1394,160 L1380,190 L1389,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.85572</text>\n",
       "<path d=\"M1375,225 L1425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,240 L1389,240 L1403,210 L1394,210 L1380,240 L1389,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.329754</text>\n",
       "<path d=\"M1275,275 L1303,275 L1322,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,294 L1347,275 L1375,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,325 L1303,325 L1322,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1328,306 L1347,325 L1375,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1300,293 L1350,293 L1350,307 L1300,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1325\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1325\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.430296</text>\n",
       "<path d=\"M1300,293 L1350,293 L1350,297 L1300,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1343,300 L1353,300 L1353,310 L1343,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1348\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1375,275 L1425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,290 L1389,290 L1403,260 L1394,260 L1380,290 L1389,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.991443</text>\n",
       "<path d=\"M1375,325 L1425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1380,340 L1389,340 L1403,310 L1394,310 L1380,340 L1389,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1397\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.940107</text>\n",
       "<path d=\"M1275,25.0 L1425,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,25 L1453,25 L1472,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,44 L1497,25 L1525,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,75 L1453,75 L1472,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,56 L1497,75 L1525,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1450,43 L1500,43 L1500,57 L1450,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1475\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1475\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.250776</text>\n",
       "<path d=\"M1450,43 L1500,43 L1500,47 L1450,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1493,50 L1503,50 L1503,60 L1493,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1498\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1525,25 L1575,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,40 L1539,40 L1553,10 L1544,10 L1530,40 L1539,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.405266</text>\n",
       "<path d=\"M1525,75 L1575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,90 L1539,90 L1553,60 L1544,60 L1530,90 L1539,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.899137</text>\n",
       "<path d=\"M1425,125 L1453,125 L1472,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,144 L1497,125 L1525,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,175 L1453,175 L1472,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,156 L1497,175 L1525,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1450,143 L1500,143 L1500,157 L1450,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1475\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1475\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.1891</text>\n",
       "<path d=\"M1450,143 L1500,143 L1500,147 L1450,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1493,150 L1503,150 L1503,160 L1493,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1498\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1525,125 L1575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,140 L1539,140 L1553,110 L1544,110 L1530,140 L1539,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.898873</text>\n",
       "<path d=\"M1525,175 L1575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,190 L1539,190 L1553,160 L1544,160 L1530,190 L1539,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.32056</text>\n",
       "<path d=\"M1425,225 L1453,225 L1472,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,244 L1497,225 L1525,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,275 L1453,275 L1472,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,256 L1497,275 L1525,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1450,243 L1500,243 L1500,257 L1450,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1475\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1475\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.558072</text>\n",
       "<path d=\"M1450,243 L1500,243 L1500,247 L1450,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1493,250 L1503,250 L1503,260 L1493,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1498\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1525,225 L1575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,240 L1539,240 L1553,210 L1544,210 L1530,240 L1539,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.133977</text>\n",
       "<path d=\"M1525,275 L1575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,290 L1539,290 L1553,260 L1544,260 L1530,290 L1539,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.566394</text>\n",
       "<path d=\"M1275,375.0 L1425,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,325 L1453,325 L1472,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,344 L1497,325 L1525,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1425,375 L1453,375 L1472,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1478,356 L1497,375 L1525,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1450,343 L1500,343 L1500,357 L1450,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1475\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1475\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.620094</text>\n",
       "<path d=\"M1450,343 L1500,343 L1500,347 L1450,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1493,350 L1503,350 L1503,360 L1493,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1498\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1525,325 L1575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,340 L1539,340 L1553,310 L1544,310 L1530,340 L1539,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.362294</text>\n",
       "<path d=\"M1525,375 L1575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1530,390 L1539,390 L1553,360 L1544,360 L1530,390 L1539,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1547\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.771254</text>\n",
       "<path d=\"M1575,75 L1603,75 L1622,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,94 L1647,75 L1675,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1575,125 L1603,125 L1622,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,106 L1647,125 L1675,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1600,93 L1650,93 L1650,107 L1600,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1625\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1625\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.74451</text>\n",
       "<path d=\"M1600,93 L1650,93 L1650,97 L1600,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1643,100 L1653,100 L1653,110 L1643,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1648\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1675,75 L1725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,90 L1689,90 L1703,60 L1694,60 L1680,90 L1689,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.206724</text>\n",
       "<path d=\"M1675,125 L1725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,140 L1689,140 L1703,110 L1694,110 L1680,140 L1689,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.590249</text>\n",
       "<path d=\"M1575,175 L1603,175 L1622,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,194 L1647,175 L1675,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1575,225 L1603,225 L1622,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,206 L1647,225 L1675,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1600,193 L1650,193 L1650,207 L1600,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1625\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1625\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.402677</text>\n",
       "<path d=\"M1600,193 L1650,193 L1650,197 L1600,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1643,200 L1653,200 L1653,210 L1643,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1648\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1675,175 L1725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,190 L1689,190 L1703,160 L1694,160 L1680,190 L1689,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.741231</text>\n",
       "<path d=\"M1675,225 L1725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,240 L1689,240 L1703,210 L1694,210 L1680,240 L1689,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.17842</text>\n",
       "<path d=\"M1575,275 L1603,275 L1622,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,294 L1647,275 L1675,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1575,325 L1603,325 L1622,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1628,306 L1647,325 L1675,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1600,293 L1650,293 L1650,307 L1600,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1625\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1625\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.987462</text>\n",
       "<path d=\"M1600,293 L1650,293 L1650,297 L1600,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1643,300 L1653,300 L1653,310 L1643,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1648\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1675,275 L1725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,290 L1689,290 L1703,260 L1694,260 L1680,290 L1689,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.068288</text>\n",
       "<path d=\"M1675,325 L1725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1680,340 L1689,340 L1703,310 L1694,310 L1680,340 L1689,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1697\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.146816</text>\n",
       "<path d=\"M1575,25.0 L1725,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,25 L1753,25 L1772,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,44 L1797,25 L1825,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,75 L1753,75 L1772,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,56 L1797,75 L1825,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1750,43 L1800,43 L1800,57 L1750,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1775\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1775\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.653769</text>\n",
       "<path d=\"M1750,43 L1800,43 L1800,47 L1750,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1793,50 L1803,50 L1803,60 L1793,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1798\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1825,25 L1875,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,40 L1839,40 L1853,10 L1844,10 L1830,40 L1839,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.701727</text>\n",
       "<path d=\"M1825,75 L1875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,90 L1839,90 L1853,60 L1844,60 L1830,90 L1839,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.864452</text>\n",
       "<path d=\"M1725,125 L1753,125 L1772,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,144 L1797,125 L1825,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,175 L1753,175 L1772,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,156 L1797,175 L1825,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1750,143 L1800,143 L1800,157 L1750,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1775\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1775\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.293675</text>\n",
       "<path d=\"M1750,143 L1800,143 L1800,147 L1750,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1793,150 L1803,150 L1803,160 L1793,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1798\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1825,125 L1875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,140 L1839,140 L1853,110 L1844,110 L1830,140 L1839,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.656475</text>\n",
       "<path d=\"M1825,175 L1875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,190 L1839,190 L1853,160 L1844,160 L1830,190 L1839,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.629992</text>\n",
       "<path d=\"M1725,225 L1753,225 L1772,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,244 L1797,225 L1825,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,275 L1753,275 L1772,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,256 L1797,275 L1825,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1750,243 L1800,243 L1800,257 L1750,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1775\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1775\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.901272</text>\n",
       "<path d=\"M1750,243 L1800,243 L1800,247 L1750,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1793,250 L1803,250 L1803,260 L1793,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1798\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1825,225 L1875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,240 L1839,240 L1853,210 L1844,210 L1830,240 L1839,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.715607</text>\n",
       "<path d=\"M1825,275 L1875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,290 L1839,290 L1853,260 L1844,260 L1830,290 L1839,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.096875</text>\n",
       "<path d=\"M1575,375.0 L1725,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,325 L1753,325 L1772,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,344 L1797,325 L1825,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,375 L1753,375 L1772,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1778,356 L1797,375 L1825,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1750,343 L1800,343 L1800,357 L1750,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1775\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1775\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.03942</text>\n",
       "<path d=\"M1750,343 L1800,343 L1800,347 L1750,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1793,350 L1803,350 L1803,360 L1793,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1798\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1825,325 L1875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,340 L1839,340 L1853,310 L1844,310 L1830,340 L1839,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.358243</text>\n",
       "<path d=\"M1825,375 L1875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1830,390 L1839,390 L1853,360 L1844,360 L1830,390 L1839,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1847\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.037448</text>\n",
       "<path d=\"M1875,75 L1903,75 L1922,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,94 L1947,75 L1975,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1875,125 L1903,125 L1922,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,106 L1947,125 L1975,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1900,93 L1950,93 L1950,107 L1900,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1925\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1925\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.775668</text>\n",
       "<path d=\"M1900,93 L1950,93 L1950,97 L1900,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1943,100 L1953,100 L1953,110 L1943,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1948\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1975,75 L2025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,90 L1989,90 L2003,60 L1994,60 L1980,90 L1989,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.05792</text>\n",
       "<path d=\"M1975,125 L2025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,140 L1989,140 L2003,110 L1994,110 L1980,140 L1989,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.261036</text>\n",
       "<path d=\"M1875,175 L1903,175 L1922,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,194 L1947,175 L1975,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1875,225 L1903,225 L1922,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,206 L1947,225 L1975,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1900,193 L1950,193 L1950,207 L1900,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1925\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1925\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.78899</text>\n",
       "<path d=\"M1900,193 L1950,193 L1950,197 L1900,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1943,200 L1953,200 L1953,210 L1943,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1948\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1975,175 L2025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,190 L1989,190 L2003,160 L1994,160 L1980,190 L1989,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.967014</text>\n",
       "<path d=\"M1975,225 L2025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,240 L1989,240 L2003,210 L1994,210 L1980,240 L1989,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.411872</text>\n",
       "<path d=\"M1875,275 L1903,275 L1922,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,294 L1947,275 L1975,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1875,325 L1903,325 L1922,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1928,306 L1947,325 L1975,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1900,293 L1950,293 L1950,307 L1900,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1925\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1925\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.066608</text>\n",
       "<path d=\"M1900,293 L1950,293 L1950,297 L1900,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1943,300 L1953,300 L1953,310 L1943,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1948\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1975,275 L2025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,290 L1989,290 L2003,260 L1994,260 L1980,290 L1989,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.376273</text>\n",
       "<path d=\"M1975,325 L2025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1980,340 L1989,340 L2003,310 L1994,310 L1980,340 L1989,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1997\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.827704</text>\n",
       "<path d=\"M1875,25.0 L2025,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2025,25 L2053,25 L2072,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,44 L2097,25 L2125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2025,75 L2053,75 L2072,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,56 L2097,75 L2125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2050,43 L2100,43 L2100,57 L2050,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2075\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2075\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.03618</text>\n",
       "<path d=\"M2050,43 L2100,43 L2100,47 L2050,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2093,50 L2103,50 L2103,60 L2093,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2098\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2125,25 L2175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,40 L2139,40 L2153,10 L2144,10 L2130,40 L2139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.581019</text>\n",
       "<path d=\"M2125,75 L2175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,90 L2139,90 L2153,60 L2144,60 L2130,90 L2139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.507041</text>\n",
       "<path d=\"M2025,125 L2053,125 L2072,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,144 L2097,125 L2125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2025,175 L2053,175 L2072,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,156 L2097,175 L2125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2050,143 L2100,143 L2100,157 L2050,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2075\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2075\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.159116</text>\n",
       "<path d=\"M2050,143 L2100,143 L2100,147 L2050,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2093,150 L2103,150 L2103,160 L2093,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2098\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2125,125 L2175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,140 L2139,140 L2153,110 L2144,110 L2130,140 L2139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.952052</text>\n",
       "<path d=\"M2125,175 L2175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,190 L2139,190 L2153,160 L2144,160 L2130,190 L2139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.664586</text>\n",
       "<path d=\"M2025,225 L2053,225 L2072,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,244 L2097,225 L2125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2025,275 L2053,275 L2072,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,256 L2097,275 L2125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2050,243 L2100,243 L2100,257 L2050,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2075\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2075\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.096146</text>\n",
       "<path d=\"M2050,243 L2100,243 L2100,247 L2050,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2093,250 L2103,250 L2103,260 L2093,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2098\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2125,225 L2175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,240 L2139,240 L2153,210 L2144,210 L2130,240 L2139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.5643</text>\n",
       "<path d=\"M2125,275 L2175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,290 L2139,290 L2153,260 L2144,260 L2130,290 L2139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.855493</text>\n",
       "<path d=\"M1875,375.0 L2025,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2025,325 L2053,325 L2072,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,344 L2097,325 L2125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2025,375 L2053,375 L2072,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2078,356 L2097,375 L2125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2050,343 L2100,343 L2100,357 L2050,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2075\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"2075\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.984514</text>\n",
       "<path d=\"M2050,343 L2100,343 L2100,347 L2050,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M2093,350 L2103,350 L2103,360 L2093,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2098\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M2125,325 L2175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,340 L2139,340 L2153,310 L2144,310 L2130,340 L2139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.893095</text>\n",
       "<path d=\"M2125,375 L2175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2130,390 L2139,390 L2153,360 L2144,360 L2130,390 L2139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.206731</text>\n",
       "<path d=\"M2175,25.0 L2190,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2175,75.0 L2190,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2175,125.0 L2190,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2175,175.0 L2190,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2175,225.0 L2190,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2175,275.0 L2190,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2175,325.0 L2190,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2175,375.0 L2190,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"2200\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"2200\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"2200\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"2200\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"2200\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"2200\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"2200\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"2200\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7b26638ad8b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m=8, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters * qnn_layers}, and embedding size = {bs_2.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit(qnn_layers=qnn_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        #     super(CNNModel, self).__init__()\n",
    "        #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "        #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "        #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "        #     self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "        # def forward(self, x):\n",
    "        #     x = self.pool(self.conv1(x))\n",
    "        #     x = self.pool(self.conv2(x))\n",
    "        #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        #     x = self.fc1(x)\n",
    "        #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 70.33%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    class MappingModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_sizes, output_size):\n",
    "            super().__init__()\n",
    "            # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "            self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "            self.hidden_layers = nn.ModuleList(\n",
    "                [\n",
    "                    nn.Linear(hidden_sizes[i], hidden_sizes[i + 1])\n",
    "                    for i in range(len(hidden_sizes) - 1)\n",
    "                ]\n",
    "            )\n",
    "            self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "        def forward(self, X):\n",
    "            # Ensure the input tensor is the same type as the weights\n",
    "            X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "            # Input layer with ReLU activation\n",
    "            X = self.input_layer(X)\n",
    "\n",
    "            # Hidden layers with ReLU activation\n",
    "            for hidden in self.hidden_layers:\n",
    "                X = hidden(X)\n",
    "\n",
    "            # Output layer with linear activation\n",
    "            output = self.output_layer(X)\n",
    "            # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "            return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "        self.MappingNetwork = self.MappingModel(n_qubit + 1, [8], 1).to(device)\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        # self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[\n",
    "            : bs_1.nb_parameters * qnn_layers\n",
    "        ]  # nn.Parameter(q_delta * torch.randn(135)).to(device)\n",
    "        self.q_params_2 = qnn_parameters[bs_1.nb_parameters * qnn_layers :]\n",
    "        device = x.device\n",
    "\n",
    "        res_1 = bs_1.run(\n",
    "            parameters=self.q_params_1, samples=100000, qnn_layers=qnn_layers\n",
    "        )\n",
    "        trans_res_1 = bs_1.translate_results(res=res_1)\n",
    "        trans_res_1 = trans_res_1 / torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)\n",
    "\n",
    "        res_2 = bs_2.run(\n",
    "            parameters=self.q_params_2, samples=100000, qnn_layers=qnn_layers\n",
    "        )\n",
    "        trans_res_2 = bs_2.translate_results(res=res_2)\n",
    "        trans_res_2 = trans_res_2 / torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)\n",
    "\n",
    "        probs_ = (\n",
    "            torch.ger(probs_1, probs_2)\n",
    "            .flatten()\n",
    "            .reshape(bs_1.embedding_size * bs_2.embedding_size, 1)\n",
    "        )\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[: len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), 1, n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  129\n",
      "# of trainable parameter in QNN model:  384\n",
      "# of trainable parameter in full model:  321\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(\n",
    "    bs_1.nb_parameters * qnn_layers + bs_2.nb_parameters * qnn_layers\n",
    ")\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\n",
    "    \"# of trainable parameter in QNN model: \",\n",
    "    (bs_1.nb_parameters + bs_2.nb_parameters) * qnn_layers,\n",
    ")\n",
    "print(\n",
    "    \"# of trainable parameter in full model: \",\n",
    "    num_trainable_params + (bs_1.nb_parameters + bs_2.nb_parameters) * qnn_layers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 443.0473, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 80.3081, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 42.8617, batch time: 0.14, accuracy:  5.47%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 30.9111, batch time: 0.14, accuracy:  7.81%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 23.7226, batch time: 0.14, accuracy:  7.81%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 15.4709, batch time: 0.14, accuracy:  10.16%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 14.1499, batch time: 0.15, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 14.0631, batch time: 0.14, accuracy:  16.41%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 9.5896, batch time: 0.15, accuracy:  15.62%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 9.8351, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 10.585309028625488, accuracy: 5.4 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 8.847777366638184, accuracy: 16.5 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 11.037428855895996, accuracy: 9.7 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 10.489873886108398, accuracy: 15.8 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 8.815422058105469, accuracy: 7.2 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 13.64673900604248, accuracy: 10.3 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 12.033956527709961, accuracy: 7.4 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 9.02641487121582, accuracy: 8.3 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 7.875189304351807, accuracy: 11.5 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 8.448094367980957, accuracy: 10.7 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 7.5793, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 6.3043, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 5.3613, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 5.8303, batch time: 0.15, accuracy:  10.16%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 5.0554, batch time: 0.15, accuracy:  8.59%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 4.8886, batch time: 0.15, accuracy:  16.41%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 4.3763, batch time: 0.15, accuracy:  15.62%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 4.0744, batch time: 0.15, accuracy:  14.06%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 3.6569, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 3.6272, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 3.947962760925293, accuracy: 10.1 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 3.489250898361206, accuracy: 13.4 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 4.0610032081604, accuracy: 13.4 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 3.5286948680877686, accuracy: 16.2 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 3.587449312210083, accuracy: 10.0 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 4.415135860443115, accuracy: 8.4 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 3.539963722229004, accuracy: 18.0 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 4.399837970733643, accuracy: 11.1 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 3.175823211669922, accuracy: 12.9 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 3.435981512069702, accuracy: 9.6 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 2.9629, batch time: 0.15, accuracy:  14.06%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 2.7591, batch time: 0.15, accuracy:  11.72%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 2.7030, batch time: 0.15, accuracy:  9.38%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 2.7708, batch time: 0.15, accuracy:  13.28%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 2.5169, batch time: 0.15, accuracy:  15.62%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 2.6112, batch time: 0.15, accuracy:  14.06%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 2.7166, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 2.4605, batch time: 0.15, accuracy:  13.28%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 2.5857, batch time: 0.15, accuracy:  10.94%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 2.4583, batch time: 0.15, accuracy:  14.06%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 3.3545501232147217, accuracy: 11.2 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 2.500455856323242, accuracy: 13.2 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 2.6557114124298096, accuracy: 15.9 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 2.523303270339966, accuracy: 14.2 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 2.620709180831909, accuracy: 10.1 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 2.4943490028381348, accuracy: 11.8 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 2.484762191772461, accuracy: 13.5 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 2.476837158203125, accuracy: 12.8 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 2.4613938331604004, accuracy: 11.2 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 2.4972286224365234, accuracy: 10.0 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 2.4845, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 2.3696, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 2.4359, batch time: 0.15, accuracy:  7.81%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 2.4751, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 2.3586, batch time: 0.29, accuracy:  14.06%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 2.3505, batch time: 0.15, accuracy:  15.62%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 2.4174, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 2.4333, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 2.3232, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 2.3271, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 3.3750505447387695, accuracy: 10.4 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 2.39205265045166, accuracy: 12.9 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 2.5863873958587646, accuracy: 15.1 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 2.425750255584717, accuracy: 12.4 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 2.39152455329895, accuracy: 11.5 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 2.459287166595459, accuracy: 15.1 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 2.4009060859680176, accuracy: 11.6 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 2.496126890182495, accuracy: 16.1 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 2.581573009490967, accuracy: 17.5 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 3.14638352394104, accuracy: 8.6 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 2.3990, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 2.2699, batch time: 0.07, accuracy:  20.31%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 2.3223, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 2.3088, batch time: 0.07, accuracy:  21.88%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 2.2747, batch time: 0.19, accuracy:  17.97%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 2.2676, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 2.3884, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 2.3694, batch time: 0.07, accuracy:  21.88%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 2.2508, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 2.3146, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 2.969879627227783, accuracy: 8.0 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 2.2831530570983887, accuracy: 13.3 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 2.648480176925659, accuracy: 11.6 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 2.2789804935455322, accuracy: 13.5 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 2.3047378063201904, accuracy: 17.1 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 3.0638201236724854, accuracy: 11.6 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 2.2495317459106445, accuracy: 12.2 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 2.2479429244995117, accuracy: 15.1 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 2.2794742584228516, accuracy: 13.8 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 2.252444267272949, accuracy: 18.1 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 2.2689, batch time: 0.14, accuracy:  12.50%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 2.2908, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 2.1816, batch time: 0.15, accuracy:  17.97%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 2.1957, batch time: 0.15, accuracy:  22.66%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 2.2421, batch time: 0.15, accuracy:  18.75%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 2.2147, batch time: 0.15, accuracy:  22.66%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 2.2274, batch time: 0.15, accuracy:  22.66%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 2.2489, batch time: 0.18, accuracy:  19.53%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 2.1485, batch time: 0.17, accuracy:  26.56%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 2.1671, batch time: 0.30, accuracy:  18.75%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 3.760995626449585, accuracy: 10.8 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 2.1789867877960205, accuracy: 26.2 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 2.831611394882202, accuracy: 15.1 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 2.2880961894989014, accuracy: 23.8 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 2.35960054397583, accuracy: 18.3 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 2.172122001647949, accuracy: 25.0 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 2.4856250286102295, accuracy: 16.7 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 2.181243658065796, accuracy: 22.2 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 2.158876419067383, accuracy: 21.6 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 2.1729726791381836, accuracy: 26.2 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 2.1093, batch time: 0.15, accuracy:  22.66%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 2.1223, batch time: 0.15, accuracy:  27.34%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 2.1995, batch time: 0.15, accuracy:  20.31%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 2.1604, batch time: 0.15, accuracy:  25.78%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 2.1612, batch time: 0.15, accuracy:  17.19%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 2.2073, batch time: 0.15, accuracy:  22.66%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 2.1578, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 2.2384, batch time: 0.14, accuracy:  25.00%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 2.1953, batch time: 0.15, accuracy:  21.09%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 2.0950, batch time: 0.15, accuracy:  31.25%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 4.023351669311523, accuracy: 8.9 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 2.1730668544769287, accuracy: 22.2 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 3.1528100967407227, accuracy: 15.8 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 2.7847750186920166, accuracy: 14.2 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 2.4759154319763184, accuracy: 26.1 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 2.1745212078094482, accuracy: 22.2 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 3.137073516845703, accuracy: 9.9 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 2.3403379917144775, accuracy: 26.1 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 2.1703150272369385, accuracy: 22.2 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 2.169163703918457, accuracy: 22.8 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 2.2587, batch time: 0.18, accuracy:  24.22%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 2.1349, batch time: 0.18, accuracy:  25.00%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 2.2777, batch time: 0.15, accuracy:  15.62%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 2.2082, batch time: 0.18, accuracy:  22.66%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 2.1271, batch time: 0.18, accuracy:  26.56%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 2.1879, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 2.0789, batch time: 0.16, accuracy:  33.59%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 2.1680, batch time: 0.18, accuracy:  30.47%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 2.2103, batch time: 0.18, accuracy:  23.44%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 2.1199, batch time: 0.18, accuracy:  25.78%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 4.068034648895264, accuracy: 9.1 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 2.161632537841797, accuracy: 25.2 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 2.98687481880188, accuracy: 19.3 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 2.701019763946533, accuracy: 16.1 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 2.4100780487060547, accuracy: 22.6 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 2.1617624759674072, accuracy: 25.8 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 3.0732617378234863, accuracy: 10.9 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 2.8138787746429443, accuracy: 17.0 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 2.1763107776641846, accuracy: 25.9 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 2.1668872833251953, accuracy: 25.9 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 2.1271, batch time: 0.18, accuracy:  25.00%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 2.2575, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 2.1996, batch time: 0.15, accuracy:  14.84%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 2.1106, batch time: 0.15, accuracy:  22.66%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 2.0452, batch time: 0.15, accuracy:  29.69%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 2.2647, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 2.2275, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 2.2225, batch time: 0.14, accuracy:  23.44%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 2.2013, batch time: 0.07, accuracy:  23.44%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 2.0707, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 4.1811957359313965, accuracy: 8.8 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 2.138105630874634, accuracy: 23.7 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 3.1491551399230957, accuracy: 18.0 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 2.7137882709503174, accuracy: 16.9 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 2.1377084255218506, accuracy: 23.4 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 2.363039970397949, accuracy: 15.0 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 2.208751916885376, accuracy: 23.7 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 2.4149813652038574, accuracy: 18.8 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 2.2274324893951416, accuracy: 23.9 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 2.1256065368652344, accuracy: 24.3 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 2.1160, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 2.0484, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 2.1553, batch time: 0.06, accuracy:  18.75%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 2.1601, batch time: 0.07, accuracy:  20.31%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 2.0521, batch time: 0.07, accuracy:  25.78%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 2.1209, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 2.1078, batch time: 0.07, accuracy:  21.88%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 2.1520, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 2.2277, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 2.1067, batch time: 0.15, accuracy:  24.22%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 4.461648941040039, accuracy: 9.8 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 2.132176399230957, accuracy: 26.0 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 3.083907127380371, accuracy: 14.5 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 2.13848876953125, accuracy: 24.9 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 2.524184465408325, accuracy: 16.9 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 2.375291585922241, accuracy: 9.3 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 2.1745729446411133, accuracy: 24.2 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 2.1302735805511475, accuracy: 22.3 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 2.1376540660858154, accuracy: 20.9 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 2.1223251819610596, accuracy: 24.1 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 2.2017, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 2.1000, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 2.0874, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 2.1945, batch time: 0.07, accuracy:  21.88%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 2.1604, batch time: 0.15, accuracy:  22.66%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 2.0664, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 2.1893, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 2.1749, batch time: 0.15, accuracy:  21.88%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 2.1345, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 2.0652, batch time: 0.07, accuracy:  21.88%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 4.836560249328613, accuracy: 10.9 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 2.1272833347320557, accuracy: 25.1 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 3.1666016578674316, accuracy: 16.3 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 2.393554925918579, accuracy: 12.3 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 2.7683632373809814, accuracy: 18.0 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 2.5031943321228027, accuracy: 10.6 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 2.3799901008605957, accuracy: 18.9 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 2.5547051429748535, accuracy: 24.4 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 2.181462287902832, accuracy: 24.8 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 2.1224489212036133, accuracy: 24.2 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 2.0906, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 2.2272, batch time: 0.08, accuracy:  17.97%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 2.0437, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 2.0991, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 2.0970, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 2.1471, batch time: 0.07, accuracy:  23.44%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 2.2013, batch time: 0.07, accuracy:  21.88%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 2.1586, batch time: 0.13, accuracy:  22.66%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 2.0462, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 2.1386, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 5.167990684509277, accuracy: 11.4 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 2.0961546897888184, accuracy: 26.7 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 3.1509013175964355, accuracy: 15.5 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 2.3512890338897705, accuracy: 12.9 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 2.7846195697784424, accuracy: 18.9 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 2.486355781555176, accuracy: 10.9 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 2.3775572776794434, accuracy: 19.9 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 2.6100857257843018, accuracy: 18.7 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 2.150847911834717, accuracy: 23.7 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 2.1045455932617188, accuracy: 23.5 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 2.2501, batch time: 0.15, accuracy:  20.31%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 2.1256, batch time: 0.15, accuracy:  29.69%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 2.0433, batch time: 0.15, accuracy:  29.69%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 2.1330, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 2.1941, batch time: 0.07, accuracy:  25.78%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 2.0412, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 2.1669, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 2.0847, batch time: 0.07, accuracy:  28.12%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 2.1048, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 2.2052, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 5.283489227294922, accuracy: 9.0 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 2.1329102516174316, accuracy: 18.9 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 3.434124231338501, accuracy: 15.0 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 2.126863479614258, accuracy: 21.5 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 2.806084632873535, accuracy: 18.2 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 2.126863479614258, accuracy: 21.5 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 2.6755447387695312, accuracy: 9.8 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 2.12406063079834, accuracy: 23.2 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 2.139509677886963, accuracy: 18.8 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 2.1289918422698975, accuracy: 26.1 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 2.2358, batch time: 0.15, accuracy:  17.19%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 2.0822, batch time: 0.15, accuracy:  28.12%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 2.0738, batch time: 0.15, accuracy:  28.12%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 2.0272, batch time: 0.15, accuracy:  35.94%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 2.1163, batch time: 0.15, accuracy:  18.75%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 2.1628, batch time: 0.15, accuracy:  19.53%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 2.1203, batch time: 0.07, accuracy:  28.12%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 2.1119, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 2.0849, batch time: 0.15, accuracy:  24.22%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 2.2059, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 5.334902763366699, accuracy: 8.8 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 2.159756898880005, accuracy: 20.8 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 3.4772253036499023, accuracy: 16.3 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 2.1571478843688965, accuracy: 19.4 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 2.620507001876831, accuracy: 21.2 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 2.1435139179229736, accuracy: 21.3 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 2.642472267150879, accuracy: 17.9 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 2.896721839904785, accuracy: 9.1 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 2.2873375415802, accuracy: 27.3 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 2.5090601444244385, accuracy: 12.8 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 2.2047, batch time: 0.12, accuracy:  21.09%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 2.0643, batch time: 0.08, accuracy:  27.34%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 2.1172, batch time: 0.14, accuracy:  28.12%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 2.1726, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 2.1575, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 2.2376, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 2.1591, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 2.2068, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 2.0297, batch time: 0.15, accuracy:  28.91%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 2.0789, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 4.73970365524292, accuracy: 9.7 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 2.1092031002044678, accuracy: 23.0 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 3.5283970832824707, accuracy: 12.5 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 2.1294891834259033, accuracy: 26.4 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 2.7069971561431885, accuracy: 21.9 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 2.4624409675598145, accuracy: 15.7 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 2.2916836738586426, accuracy: 13.2 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 2.123789072036743, accuracy: 18.4 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 2.1342930793762207, accuracy: 16.9 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 2.1073837280273438, accuracy: 24.0 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 2.0708, batch time: 0.15, accuracy:  34.38%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 2.1931, batch time: 0.12, accuracy:  25.78%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 2.1647, batch time: 0.07, accuracy:  27.34%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 2.2113, batch time: 0.15, accuracy:  21.88%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 1.9966, batch time: 0.12, accuracy:  34.38%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 2.0978, batch time: 0.07, accuracy:  23.44%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 2.2242, batch time: 0.07, accuracy:  21.88%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 2.0932, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 2.1924, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 2.1280, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 4.755187034606934, accuracy: 10.0 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 2.1547412872314453, accuracy: 22.1 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 3.5530083179473877, accuracy: 12.5 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 2.1444342136383057, accuracy: 23.3 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 2.5633485317230225, accuracy: 21.4 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 2.1292083263397217, accuracy: 26.7 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 2.380343198776245, accuracy: 19.3 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 2.5271337032318115, accuracy: 18.9 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 2.6587884426116943, accuracy: 20.8 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 2.114081621170044, accuracy: 25.0 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 2.0740, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 2.1471, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 2.1120, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 2.0559, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 2.0975, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 2.2207, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 2.1456, batch time: 0.07, accuracy:  27.34%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 2.1399, batch time: 0.15, accuracy:  17.19%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 2.0875, batch time: 0.15, accuracy:  23.44%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 2.0846, batch time: 0.15, accuracy:  28.12%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 5.326470375061035, accuracy: 10.5 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 2.1219193935394287, accuracy: 22.1 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 3.6319572925567627, accuracy: 12.4 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 6.631391525268555, accuracy: 8.6 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 2.353316307067871, accuracy: 17.4 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 2.5964467525482178, accuracy: 10.6 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 3.0079445838928223, accuracy: 10.9 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 2.4437360763549805, accuracy: 18.1 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 2.3351619243621826, accuracy: 23.5 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 2.9201223850250244, accuracy: 11.1 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 2.0218, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 2.2202, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 2.0239, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 2.1707, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 2.0947, batch time: 0.07, accuracy:  28.12%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 2.0605, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 2.0513, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 2.1325, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 2.0904, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 2.1358, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 5.156651496887207, accuracy: 8.1 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 2.144524097442627, accuracy: 20.9 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 3.536424160003662, accuracy: 11.6 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 2.1413683891296387, accuracy: 21.7 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 2.4775569438934326, accuracy: 24.5 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 2.1386685371398926, accuracy: 21.3 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 2.4017422199249268, accuracy: 15.6 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 2.909636974334717, accuracy: 9.8 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 2.8363773822784424, accuracy: 17.8 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 2.1464180946350098, accuracy: 20.6 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 2.0993, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 2.1314, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 2.1757, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 2.1222, batch time: 0.06, accuracy:  25.00%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 2.2317, batch time: 0.15, accuracy:  14.84%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 2.0698, batch time: 0.15, accuracy:  26.56%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 2.1236, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 2.0594, batch time: 0.07, accuracy:  25.78%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 2.1287, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 2.1113, batch time: 0.20, accuracy:  22.66%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 4.828477382659912, accuracy: 9.6 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 2.1119894981384277, accuracy: 27.0 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 3.5258312225341797, accuracy: 15.1 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 2.1891353130340576, accuracy: 27.4 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 2.4779396057128906, accuracy: 23.6 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 2.541179895401001, accuracy: 18.0 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 2.4941883087158203, accuracy: 16.8 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 6.1767659187316895, accuracy: 9.4 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 2.1456844806671143, accuracy: 25.1 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 2.0970020294189453, accuracy: 28.8 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 1.9737, batch time: 0.15, accuracy:  28.12%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 2.1131, batch time: 0.15, accuracy:  28.12%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 2.2005, batch time: 0.15, accuracy:  21.88%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 2.0037, batch time: 0.15, accuracy:  27.34%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 2.0393, batch time: 0.12, accuracy:  31.25%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 1.9585, batch time: 0.08, accuracy:  35.94%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 2.1328, batch time: 0.16, accuracy:  17.97%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 2.0301, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 2.2579, batch time: 0.18, accuracy:  5.47%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 2.0907, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 4.268582820892334, accuracy: 9.2 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 2.0687990188598633, accuracy: 29.2 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 3.5811407566070557, accuracy: 13.2 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 2.859941005706787, accuracy: 19.3 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 2.2854714393615723, accuracy: 25.7 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 2.0703842639923096, accuracy: 28.9 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 3.507209300994873, accuracy: 10.7 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 7.411447525024414, accuracy: 11.4 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 2.1866910457611084, accuracy: 26.1 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 2.395747661590576, accuracy: 25.0 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 2.1664, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 2.0962, batch time: 0.11, accuracy:  25.78%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 2.1129, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 2.0666, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 2.2642, batch time: 0.15, accuracy:  10.94%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 2.1887, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 2.0596, batch time: 0.07, accuracy:  28.12%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 2.1577, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 2.0591, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 2.0801, batch time: 0.19, accuracy:  23.44%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 4.578208923339844, accuracy: 10.4 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 2.1132164001464844, accuracy: 25.8 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 3.7999677658081055, accuracy: 10.2 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 2.2066259384155273, accuracy: 18.2 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 3.0404961109161377, accuracy: 11.8 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 2.2539591789245605, accuracy: 15.7 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 2.108288049697876, accuracy: 24.5 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 2.108288049697876, accuracy: 24.5 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 2.277268886566162, accuracy: 9.7 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 2.8009767532348633, accuracy: 14.7 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 2.0623, batch time: 0.15, accuracy:  28.12%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 2.1979, batch time: 0.15, accuracy:  23.44%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 2.0703, batch time: 0.15, accuracy:  21.88%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 2.3140, batch time: 0.15, accuracy:  23.44%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 2.1232, batch time: 0.15, accuracy:  20.31%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 2.2158, batch time: 0.15, accuracy:  28.12%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 2.0671, batch time: 0.15, accuracy:  31.25%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 2.2179, batch time: 0.08, accuracy:  17.97%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 2.1901, batch time: 0.15, accuracy:  23.44%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 2.0904, batch time: 0.14, accuracy:  21.88%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 4.535757541656494, accuracy: 9.8 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 2.0862069129943848, accuracy: 26.7 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 3.5767605304718018, accuracy: 12.0 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 2.2060816287994385, accuracy: 17.5 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 2.5513174533843994, accuracy: 23.0 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 2.3883860111236572, accuracy: 17.7 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 2.355823516845703, accuracy: 18.8 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 2.3441321849823, accuracy: 21.0 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 2.074687957763672, accuracy: 28.9 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 2.0842339992523193, accuracy: 28.0 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 2.2353, batch time: 0.16, accuracy:  24.22%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 2.1079, batch time: 0.18, accuracy:  28.12%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 2.1235, batch time: 0.18, accuracy:  25.78%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 2.1098, batch time: 0.15, accuracy:  25.78%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 2.0279, batch time: 0.15, accuracy:  40.62%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 2.2114, batch time: 0.15, accuracy:  20.31%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 2.0819, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 2.0606, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 2.1767, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 2.1903, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 4.60605001449585, accuracy: 8.3 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 2.1037180423736572, accuracy: 28.8 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 3.5483314990997314, accuracy: 11.1 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 2.241827964782715, accuracy: 21.5 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 2.4415361881256104, accuracy: 21.9 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 2.406235933303833, accuracy: 16.4 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 2.4376699924468994, accuracy: 16.6 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 2.6124274730682373, accuracy: 14.2 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 2.104877233505249, accuracy: 27.6 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 2.09356427192688, accuracy: 24.8 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 2.2331, batch time: 0.15, accuracy:  16.41%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 2.0562, batch time: 0.14, accuracy:  24.22%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 2.1641, batch time: 0.14, accuracy:  27.34%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 2.0803, batch time: 0.07, accuracy:  25.78%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 2.0464, batch time: 0.15, accuracy:  27.34%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 2.0764, batch time: 0.15, accuracy:  29.69%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 2.0711, batch time: 0.15, accuracy:  19.53%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 2.0971, batch time: 0.15, accuracy:  17.97%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 2.0602, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 2.0944, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 4.448968410491943, accuracy: 8.8 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 2.1028990745544434, accuracy: 29.0 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 3.5836970806121826, accuracy: 12.6 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 2.2665748596191406, accuracy: 18.0 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 2.175234317779541, accuracy: 24.1 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 2.0912461280822754, accuracy: 27.5 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 2.5095295906066895, accuracy: 17.8 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 2.2464258670806885, accuracy: 20.2 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 2.108146905899048, accuracy: 27.0 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 2.081403970718384, accuracy: 30.6 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 2.0796, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 2.0957, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 2.1341, batch time: 0.15, accuracy:  23.44%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 2.1238, batch time: 0.15, accuracy:  25.78%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 2.0920, batch time: 0.34, accuracy:  24.22%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 2.0747, batch time: 0.15, accuracy:  26.56%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 2.1022, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 2.0667, batch time: 0.14, accuracy:  18.75%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 2.0504, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 2.1648, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 4.042695999145508, accuracy: 9.8 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 2.1256957054138184, accuracy: 19.3 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 3.719329595565796, accuracy: 9.6 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 3.346587657928467, accuracy: 9.8 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 2.5363779067993164, accuracy: 20.3 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 2.242565870285034, accuracy: 16.5 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 2.115229845046997, accuracy: 27.8 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 3.4879796504974365, accuracy: 9.6 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 2.1049625873565674, accuracy: 21.4 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 2.1056132316589355, accuracy: 24.0 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 2.1056, batch time: 0.15, accuracy:  21.09%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 2.1731, batch time: 0.15, accuracy:  18.75%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 2.1309, batch time: 0.31, accuracy:  25.00%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 2.1274, batch time: 0.15, accuracy:  14.84%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 2.0669, batch time: 0.15, accuracy:  24.22%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 2.1545, batch time: 0.15, accuracy:  12.50%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 2.2213, batch time: 0.14, accuracy:  20.31%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 2.1043, batch time: 0.15, accuracy:  20.31%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 2.0507, batch time: 0.15, accuracy:  18.75%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 2.1432, batch time: 0.16, accuracy:  19.53%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 3.992201089859009, accuracy: 10.2 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 2.1246209144592285, accuracy: 18.8 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 3.778860569000244, accuracy: 9.5 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 2.2112531661987305, accuracy: 12.6 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 2.195162773132324, accuracy: 23.7 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 2.189645528793335, accuracy: 15.0 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 2.3041415214538574, accuracy: 19.5 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 2.2306082248687744, accuracy: 23.1 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 2.2530431747436523, accuracy: 15.8 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 2.111114740371704, accuracy: 25.3 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 2.1513, batch time: 0.07, accuracy:  27.34%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 2.1227, batch time: 0.15, accuracy:  22.66%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 2.0798, batch time: 0.15, accuracy:  28.12%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 2.0327, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 2.0266, batch time: 0.11, accuracy:  28.12%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 2.1798, batch time: 0.06, accuracy:  20.31%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 2.1293, batch time: 0.11, accuracy:  23.44%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 2.1655, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 2.1788, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 2.0951, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 3.600862741470337, accuracy: 9.2 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 2.1248245239257812, accuracy: 26.1 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 3.743969202041626, accuracy: 11.9 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 2.112720251083374, accuracy: 24.7 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 2.740349292755127, accuracy: 11.6 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 2.141129970550537, accuracy: 25.8 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 2.1572036743164062, accuracy: 24.9 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 2.1016178131103516, accuracy: 25.3 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 2.275508403778076, accuracy: 23.5 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 2.2592856884002686, accuracy: 17.7 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 2.0967, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 1.9890, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 2.2082, batch time: 0.14, accuracy:  19.53%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 2.0069, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 2.1316, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 2.2274, batch time: 0.07, accuracy:  17.97%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 2.0293, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 2.0656, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 2.1332, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 2.1611, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 3.450869560241699, accuracy: 8.7 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 2.1361753940582275, accuracy: 23.6 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 3.841867685317993, accuracy: 10.3 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 2.2139382362365723, accuracy: 20.9 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 2.3899946212768555, accuracy: 20.9 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 2.4730358123779297, accuracy: 13.7 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 2.362212657928467, accuracy: 19.2 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 2.3378682136535645, accuracy: 13.4 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 2.1248977184295654, accuracy: 21.5 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 2.1225101947784424, accuracy: 18.5 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 2.1445, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 2.0836, batch time: 0.15, accuracy:  21.88%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 2.1918, batch time: 0.15, accuracy:  21.09%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 2.0202, batch time: 0.15, accuracy:  23.44%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 2.1082, batch time: 0.15, accuracy:  20.31%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 2.1890, batch time: 0.15, accuracy:  14.06%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 2.1416, batch time: 0.15, accuracy:  22.66%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 2.0629, batch time: 0.15, accuracy:  21.88%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 2.0242, batch time: 0.15, accuracy:  23.44%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 2.0905, batch time: 0.15, accuracy:  23.44%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 3.223550319671631, accuracy: 10.5 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 2.0993824005126953, accuracy: 22.5 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 3.727372884750366, accuracy: 8.9 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 2.2743732929229736, accuracy: 20.8 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 2.2372689247131348, accuracy: 20.4 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 2.088970422744751, accuracy: 22.3 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 2.1338977813720703, accuracy: 22.4 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 2.2510664463043213, accuracy: 23.7 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 2.697134017944336, accuracy: 22.1 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 2.1515250205993652, accuracy: 30.6 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 2.2130, batch time: 0.15, accuracy:  17.97%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 2.0225, batch time: 0.15, accuracy:  24.22%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 2.0947, batch time: 0.07, accuracy:  20.31%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 2.1032, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 2.1470, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 2.1618, batch time: 0.07, accuracy:  21.88%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 2.0156, batch time: 0.07, accuracy:  27.34%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 2.1431, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 2.1078, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 2.1479, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 3.8194918632507324, accuracy: 8.5 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 2.0990402698516846, accuracy: 19.6 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 4.0200514793396, accuracy: 9.3 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 4.692720413208008, accuracy: 8.3 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 2.293795585632324, accuracy: 14.8 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 2.307267189025879, accuracy: 14.0 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 2.827866315841675, accuracy: 9.5 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 2.1955013275146484, accuracy: 19.9 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 2.0826380252838135, accuracy: 22.9 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 2.1159350872039795, accuracy: 21.5 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 2.1977, batch time: 0.15, accuracy:  17.19%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 2.1144, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 2.0289, batch time: 0.15, accuracy:  21.88%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 2.0107, batch time: 0.15, accuracy:  22.66%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 2.1353, batch time: 0.07, accuracy:  21.88%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 2.2338, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 2.1373, batch time: 0.07, accuracy:  20.31%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 2.0050, batch time: 0.15, accuracy:  25.78%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 2.1040, batch time: 0.14, accuracy:  14.84%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 2.0887, batch time: 0.15, accuracy:  21.88%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 3.8135180473327637, accuracy: 8.5 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 2.0969038009643555, accuracy: 20.8 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 4.249754905700684, accuracy: 9.9 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 3.383376121520996, accuracy: 9.2 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 2.2564475536346436, accuracy: 12.3 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 2.093625068664551, accuracy: 21.2 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 2.2600791454315186, accuracy: 14.9 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 2.095357894897461, accuracy: 21.8 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 2.107722520828247, accuracy: 19.0 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 2.1512656211853027, accuracy: 19.6 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 2.0980, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 2.1607, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 2.0373, batch time: 0.06, accuracy:  29.69%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 2.0603, batch time: 0.06, accuracy:  21.88%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 2.1491, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 2.0886, batch time: 0.06, accuracy:  32.03%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 2.1852, batch time: 0.07, accuracy:  25.78%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 2.1072, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 2.1000, batch time: 0.06, accuracy:  28.91%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 2.1847, batch time: 0.06, accuracy:  25.78%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 3.336984872817993, accuracy: 12.2 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 2.0655641555786133, accuracy: 27.0 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 3.759124994277954, accuracy: 8.9 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 2.062343120574951, accuracy: 25.6 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 2.2283742427825928, accuracy: 22.3 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 2.165728807449341, accuracy: 26.5 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 2.0447890758514404, accuracy: 27.8 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 2.0378355979919434, accuracy: 24.2 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 2.1041791439056396, accuracy: 32.4 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 2.1463310718536377, accuracy: 19.8 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 2.2167, batch time: 0.15, accuracy:  12.50%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 2.1198, batch time: 0.15, accuracy:  15.62%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 2.0591, batch time: 0.10, accuracy:  29.69%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 2.0988, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 2.2068, batch time: 0.15, accuracy:  14.06%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 2.0842, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 2.2216, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 2.1100, batch time: 0.15, accuracy:  18.75%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 2.1625, batch time: 0.15, accuracy:  15.62%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 2.2195, batch time: 0.06, accuracy:  16.41%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 2.900660753250122, accuracy: 10.7 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 2.078176736831665, accuracy: 23.4 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 3.756230354309082, accuracy: 8.7 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 2.985912561416626, accuracy: 12.9 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 2.2395668029785156, accuracy: 17.1 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 2.543029308319092, accuracy: 17.2 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 2.1713178157806396, accuracy: 17.2 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 2.8797810077667236, accuracy: 13.8 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 2.0956406593322754, accuracy: 19.6 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 2.108720541000366, accuracy: 17.9 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 2.0724, batch time: 0.07, accuracy:  17.97%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 2.1864, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 2.1005, batch time: 0.07, accuracy:  23.44%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 2.0834, batch time: 0.07, accuracy:  25.78%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 2.1543, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 2.1172, batch time: 0.08, accuracy:  18.75%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 2.0905, batch time: 0.10, accuracy:  21.09%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 2.1107, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 2.1234, batch time: 0.15, accuracy:  20.31%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 2.0550, batch time: 0.15, accuracy:  21.88%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 2.8995163440704346, accuracy: 13.5 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 2.132845163345337, accuracy: 19.3 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 3.874965190887451, accuracy: 9.2 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 2.269287109375, accuracy: 16.6 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 2.2776706218719482, accuracy: 16.2 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 2.1209609508514404, accuracy: 19.6 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 2.302788257598877, accuracy: 9.5 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 2.120035409927368, accuracy: 19.4 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 3.7493932247161865, accuracy: 10.5 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 2.461789846420288, accuracy: 19.0 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 1.9837, batch time: 0.15, accuracy:  33.59%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 2.2085, batch time: 0.15, accuracy:  24.22%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 2.0778, batch time: 0.15, accuracy:  26.56%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 2.0235, batch time: 0.06, accuracy:  30.47%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 1.9977, batch time: 0.06, accuracy:  25.00%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 2.1026, batch time: 0.06, accuracy:  19.53%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 1.9838, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 2.2533, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 2.1452, batch time: 0.06, accuracy:  20.31%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 2.0436, batch time: 0.06, accuracy:  24.22%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 2.839381456375122, accuracy: 10.1 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 2.09065318107605, accuracy: 22.2 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 3.8268539905548096, accuracy: 9.7 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 2.1747796535491943, accuracy: 22.4 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 2.548271656036377, accuracy: 11.5 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 2.1258718967437744, accuracy: 19.7 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 2.1154563426971436, accuracy: 25.1 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 2.446873664855957, accuracy: 12.0 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 2.2591946125030518, accuracy: 23.8 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 2.0725975036621094, accuracy: 30.1 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 1.9865, batch time: 0.06, accuracy:  35.16%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 2.1947, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 2.1075, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 2.1068, batch time: 0.07, accuracy:  23.44%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 2.2014, batch time: 0.15, accuracy:  24.22%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 2.1666, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 2.1413, batch time: 0.06, accuracy:  27.34%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 2.0776, batch time: 0.06, accuracy:  25.00%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 2.1858, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 2.1449, batch time: 0.14, accuracy:  21.09%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 3.055093288421631, accuracy: 12.6 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 2.1642346382141113, accuracy: 22.4 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 3.8197946548461914, accuracy: 9.4 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 2.9143877029418945, accuracy: 15.8 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 5.1826276779174805, accuracy: 11.8 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 2.1076059341430664, accuracy: 26.0 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 2.2451741695404053, accuracy: 25.2 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 2.097442626953125, accuracy: 26.5 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 2.196938991546631, accuracy: 24.6 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 2.114973306655884, accuracy: 23.5 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 2.1216, batch time: 0.15, accuracy:  22.66%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 2.0252, batch time: 0.15, accuracy:  29.69%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 2.0649, batch time: 0.15, accuracy:  32.03%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 2.0714, batch time: 0.15, accuracy:  24.22%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 2.1520, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 2.2899, batch time: 0.07, accuracy:  21.88%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 2.2258, batch time: 0.15, accuracy:  23.44%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 2.1569, batch time: 0.15, accuracy:  28.12%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 2.1227, batch time: 0.15, accuracy:  17.19%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 2.1537, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 2.6137073040008545, accuracy: 13.1 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 2.1026999950408936, accuracy: 27.1 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 4.29387903213501, accuracy: 8.9 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 2.566119432449341, accuracy: 13.2 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 2.2238962650299072, accuracy: 17.4 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 2.094438076019287, accuracy: 26.8 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 2.536888360977173, accuracy: 20.6 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 2.2383780479431152, accuracy: 14.6 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 2.2952311038970947, accuracy: 28.6 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 2.1360292434692383, accuracy: 21.9 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 2.0450, batch time: 0.06, accuracy:  29.69%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 2.0984, batch time: 0.06, accuracy:  27.34%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 2.1311, batch time: 0.06, accuracy:  24.22%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 2.0415, batch time: 0.06, accuracy:  24.22%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 2.2113, batch time: 0.06, accuracy:  26.56%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 2.0214, batch time: 0.06, accuracy:  28.12%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 2.2417, batch time: 0.09, accuracy:  19.53%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 2.0986, batch time: 0.06, accuracy:  25.00%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 2.1241, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 1.9477, batch time: 0.06, accuracy:  30.47%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 2.631866931915283, accuracy: 14.0 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 2.0605852603912354, accuracy: 26.7 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 4.185809135437012, accuracy: 9.2 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 2.1941752433776855, accuracy: 24.3 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 2.2014055252075195, accuracy: 19.4 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 2.1660916805267334, accuracy: 17.6 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 2.4294819831848145, accuracy: 13.4 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 2.1547091007232666, accuracy: 26.4 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 2.0546395778656006, accuracy: 26.4 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 2.051842451095581, accuracy: 27.2 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 2.0528, batch time: 0.06, accuracy:  29.69%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 2.0315, batch time: 0.14, accuracy:  29.69%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 2.1992, batch time: 0.06, accuracy:  35.16%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 2.1228, batch time: 0.06, accuracy:  25.78%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 2.0490, batch time: 0.06, accuracy:  24.22%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 2.0530, batch time: 0.06, accuracy:  25.78%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 2.1702, batch time: 0.06, accuracy:  21.09%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 2.1114, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 2.0352, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 1.9179, batch time: 0.15, accuracy:  38.28%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 2.652975082397461, accuracy: 13.7 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 2.0567214488983154, accuracy: 20.6 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 3.7552764415740967, accuracy: 8.9 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 2.0538055896759033, accuracy: 20.0 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 2.3256282806396484, accuracy: 18.6 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 2.2761125564575195, accuracy: 16.7 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 2.045544147491455, accuracy: 20.4 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 2.042982578277588, accuracy: 20.8 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 2.0609638690948486, accuracy: 20.3 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 2.2000715732574463, accuracy: 27.6 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 2.0228, batch time: 0.14, accuracy:  25.78%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 2.0374, batch time: 0.06, accuracy:  25.00%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 2.1156, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 2.1711, batch time: 0.32, accuracy:  17.19%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 2.0353, batch time: 0.06, accuracy:  28.91%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 2.0160, batch time: 0.21, accuracy:  21.88%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 2.0328, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 2.2490, batch time: 0.07, accuracy:  20.31%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 2.1059, batch time: 0.15, accuracy:  29.69%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 2.0432, batch time: 0.15, accuracy:  24.22%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 2.727308511734009, accuracy: 16.5 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 2.060223340988159, accuracy: 24.1 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 2.8529317378997803, accuracy: 12.7 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 2.7592546939849854, accuracy: 16.0 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 2.8156578540802, accuracy: 11.9 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 2.0499989986419678, accuracy: 31.2 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 2.056365489959717, accuracy: 29.3 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 2.0419580936431885, accuracy: 29.8 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 2.0599348545074463, accuracy: 31.1 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 2.110886812210083, accuracy: 23.2 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 2.0562, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 2.1141, batch time: 0.17, accuracy:  17.19%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 2.2142, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 2.1202, batch time: 0.15, accuracy:  21.09%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 2.0726, batch time: 0.15, accuracy:  25.78%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 2.0299, batch time: 0.07, accuracy:  21.09%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 2.1652, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 2.1442, batch time: 0.07, accuracy:  25.78%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 2.0696, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 2.1068, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 3.0059518814086914, accuracy: 19.4 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 2.072145938873291, accuracy: 28.6 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 3.0522117614746094, accuracy: 20.2 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 2.153852701187134, accuracy: 27.2 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 2.1575450897216797, accuracy: 25.9 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 2.3025319576263428, accuracy: 23.3 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 2.037113904953003, accuracy: 29.6 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 2.036520004272461, accuracy: 29.6 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 2.178744316101074, accuracy: 21.9 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 2.0374562740325928, accuracy: 28.8 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 2.0387, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 2.0740, batch time: 0.07, accuracy:  21.88%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 2.0699, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 2.1197, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 2.0201, batch time: 0.10, accuracy:  30.47%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 2.0781, batch time: 0.09, accuracy:  19.53%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 2.0222, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 2.0959, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 2.0104, batch time: 0.16, accuracy:  32.03%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 2.2071, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 2.711371660232544, accuracy: 21.8 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 2.0692014694213867, accuracy: 21.5 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 3.2463090419769287, accuracy: 8.5 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 2.0522618293762207, accuracy: 22.1 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 2.339233636856079, accuracy: 22.8 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 2.05049467086792, accuracy: 21.7 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 2.0583887100219727, accuracy: 20.8 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 2.244476318359375, accuracy: 20.9 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 2.109875202178955, accuracy: 29.9 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 2.213904857635498, accuracy: 29.4 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 2.1293, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 2.1290, batch time: 0.15, accuracy:  16.41%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 2.0480, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 2.1634, batch time: 0.15, accuracy:  21.88%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 1.9834, batch time: 0.15, accuracy:  29.69%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 2.0841, batch time: 0.14, accuracy:  26.56%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 2.0779, batch time: 0.33, accuracy:  28.91%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 1.9907, batch time: 0.15, accuracy:  30.47%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 2.0526, batch time: 0.06, accuracy:  22.66%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 2.1010, batch time: 0.06, accuracy:  16.41%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 2.5787463188171387, accuracy: 18.2 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 2.101649284362793, accuracy: 24.7 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 2.7117676734924316, accuracy: 20.9 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 2.1014206409454346, accuracy: 24.3 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 2.2194488048553467, accuracy: 25.8 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 2.0939502716064453, accuracy: 25.8 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 2.0324339866638184, accuracy: 26.1 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 2.029776096343994, accuracy: 26.0 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 2.0933656692504883, accuracy: 26.7 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 2.1084280014038086, accuracy: 26.8 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 2.0235, batch time: 0.15, accuracy:  17.19%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 2.0776, batch time: 0.15, accuracy:  17.19%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 1.9960, batch time: 0.15, accuracy:  24.22%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 2.0397, batch time: 0.15, accuracy:  26.56%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 2.0877, batch time: 0.14, accuracy:  25.78%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 2.0931, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 2.0524, batch time: 0.07, accuracy:  23.44%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 2.0841, batch time: 0.07, accuracy:  21.88%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 1.9997, batch time: 0.15, accuracy:  25.00%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 2.0325, batch time: 0.15, accuracy:  21.09%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 2.973787784576416, accuracy: 18.3 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 2.0156514644622803, accuracy: 27.7 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 2.7855417728424072, accuracy: 19.0 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 2.0127596855163574, accuracy: 27.0 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 2.060403347015381, accuracy: 26.7 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 1.9972703456878662, accuracy: 28.5 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 2.0420680046081543, accuracy: 30.2 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 1.9868472814559937, accuracy: 31.2 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 2.136160135269165, accuracy: 17.0 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 2.175337076187134, accuracy: 26.6 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 1.9968, batch time: 0.06, accuracy:  31.25%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 2.0995, batch time: 0.06, accuracy:  27.34%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 1.9839, batch time: 0.06, accuracy:  24.22%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 2.0597, batch time: 0.06, accuracy:  26.56%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 1.9962, batch time: 0.06, accuracy:  28.91%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 2.0901, batch time: 0.06, accuracy:  21.09%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 1.8801, batch time: 0.06, accuracy:  34.38%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 1.9331, batch time: 0.06, accuracy:  29.69%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 2.0940, batch time: 0.06, accuracy:  25.78%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 2.0727, batch time: 0.06, accuracy:  23.44%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 2.9232873916625977, accuracy: 19.7 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 1.9797883033752441, accuracy: 33.3 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 2.7382872104644775, accuracy: 22.8 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 2.2473607063293457, accuracy: 14.3 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 2.021683692932129, accuracy: 29.2 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 2.1900670528411865, accuracy: 25.3 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 2.0427639484405518, accuracy: 27.1 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 1.9610564708709717, accuracy: 33.8 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 1.950460433959961, accuracy: 33.0 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 1.9513708353042603, accuracy: 34.2 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 2.0132, batch time: 0.15, accuracy:  21.09%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 2.0211, batch time: 0.21, accuracy:  31.25%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 1.9490, batch time: 0.06, accuracy:  31.25%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 2.0279, batch time: 0.06, accuracy:  31.25%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 2.0519, batch time: 0.06, accuracy:  25.78%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 2.0887, batch time: 0.06, accuracy:  25.78%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 1.9698, batch time: 0.14, accuracy:  17.97%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 2.0258, batch time: 0.06, accuracy:  22.66%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 2.0932, batch time: 0.06, accuracy:  23.44%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 2.0403, batch time: 0.14, accuracy:  25.00%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 2.885533332824707, accuracy: 16.1 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 2.013115882873535, accuracy: 23.5 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 2.4383184909820557, accuracy: 19.6 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 2.012849807739258, accuracy: 23.8 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 2.1192872524261475, accuracy: 19.5 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 2.221731185913086, accuracy: 18.0 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 2.003709077835083, accuracy: 23.1 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 2.0017285346984863, accuracy: 21.9 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 2.026124954223633, accuracy: 19.4 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 2.0405702590942383, accuracy: 25.0 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 2.0189, batch time: 0.06, accuracy:  26.56%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 2.0499, batch time: 0.06, accuracy:  21.88%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 1.9363, batch time: 0.15, accuracy:  28.12%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 2.0203, batch time: 0.06, accuracy:  34.38%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 2.3269, batch time: 0.06, accuracy:  22.66%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 1.9871, batch time: 0.14, accuracy:  22.66%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 1.9327, batch time: 0.15, accuracy:  30.47%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 1.9717, batch time: 0.15, accuracy:  21.09%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 1.9368, batch time: 0.18, accuracy:  23.44%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 2.1180, batch time: 0.14, accuracy:  24.22%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 3.0269055366516113, accuracy: 17.0 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 1.9661623239517212, accuracy: 23.0 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 2.6539103984832764, accuracy: 21.6 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 1.9653384685516357, accuracy: 23.0 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 2.7017507553100586, accuracy: 13.7 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 2.109588384628296, accuracy: 24.6 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 1.973800778388977, accuracy: 30.2 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 1.9416204690933228, accuracy: 28.7 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 1.9492168426513672, accuracy: 24.8 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 2.2430059909820557, accuracy: 24.3 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 1.9029, batch time: 0.08, accuracy:  25.78%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 1.9926, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 1.8176, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 2.0553, batch time: 0.15, accuracy:  14.84%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 1.9530, batch time: 0.06, accuracy:  28.91%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 1.9056, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 1.9253, batch time: 0.15, accuracy:  25.78%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 1.9514, batch time: 0.14, accuracy:  28.12%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 1.9764, batch time: 0.14, accuracy:  23.44%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 1.9269, batch time: 0.13, accuracy:  25.00%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 3.059267997741699, accuracy: 18.9 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 1.9378571510314941, accuracy: 26.9 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 2.7403416633605957, accuracy: 21.4 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 1.93687105178833, accuracy: 26.3 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 2.074573516845703, accuracy: 24.6 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 1.9192352294921875, accuracy: 26.3 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 2.17228627204895, accuracy: 24.0 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 2.0563254356384277, accuracy: 20.6 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 2.147348165512085, accuracy: 29.3 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 2.317532777786255, accuracy: 21.3 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 1.9731, batch time: 0.15, accuracy:  17.97%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 1.9366, batch time: 0.15, accuracy:  28.12%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 2.0318, batch time: 0.18, accuracy:  32.03%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 1.9272, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 1.9009, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 1.9907, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 1.9140, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 2.0779, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 2.0475, batch time: 0.08, accuracy:  25.78%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 1.9161, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 2.6881918907165527, accuracy: 13.9 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 1.8931101560592651, accuracy: 28.3 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 2.973997116088867, accuracy: 16.0 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 2.1476328372955322, accuracy: 21.6 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 2.8387045860290527, accuracy: 21.7 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 1.8908953666687012, accuracy: 28.6 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 2.0231947898864746, accuracy: 21.5 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 3.1356613636016846, accuracy: 12.8 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 2.2816033363342285, accuracy: 22.8 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 1.8942056894302368, accuracy: 26.4 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 2.0477, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 2.1721, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 1.9460, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 1.8964, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 2.0055, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 2.0110, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 1.9529, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 2.0430, batch time: 0.07, accuracy:  23.44%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 1.9012, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 1.9490, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 2.6896605491638184, accuracy: 18.3 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 1.9108269214630127, accuracy: 27.1 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 3.0224404335021973, accuracy: 14.0 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 1.9072723388671875, accuracy: 27.0 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 2.306290626525879, accuracy: 19.4 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 2.0939040184020996, accuracy: 24.4 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 1.903741478919983, accuracy: 26.1 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 1.8886220455169678, accuracy: 29.0 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 1.9424762725830078, accuracy: 32.2 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 1.9455167055130005, accuracy: 24.5 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 1.9317, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 1.8182, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 1.8027, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 2.0221, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 1.9541, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 1.9371, batch time: 0.24, accuracy:  21.09%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 1.9844, batch time: 0.07, accuracy:  17.97%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 1.8799, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 1.8711, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 2.0468, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 2.465043067932129, accuracy: 18.0 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 2.0371127128601074, accuracy: 27.1 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 2.609251022338867, accuracy: 26.0 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 2.2188050746917725, accuracy: 24.8 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 2.008115291595459, accuracy: 26.4 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 1.9522396326065063, accuracy: 27.6 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 2.0027236938476562, accuracy: 24.6 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 1.9445854425430298, accuracy: 26.1 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 2.0485212802886963, accuracy: 22.8 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 2.069133996963501, accuracy: 27.2 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 1.7089, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 1.8734, batch time: 0.07, accuracy:  25.78%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 1.9090, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 1.9148, batch time: 0.17, accuracy:  25.78%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 1.7902, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 1.8211, batch time: 0.07, accuracy:  28.12%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 1.7871, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 1.8391, batch time: 0.07, accuracy:  27.34%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 1.9751, batch time: 0.07, accuracy:  27.34%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 1.9278, batch time: 0.07, accuracy:  20.31%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 2.4741976261138916, accuracy: 25.3 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 1.856550693511963, accuracy: 30.0 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 2.9520859718322754, accuracy: 15.3 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 1.8539472818374634, accuracy: 30.2 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 1.9793795347213745, accuracy: 29.8 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 1.842410922050476, accuracy: 32.1 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 1.8801387548446655, accuracy: 31.3 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 1.909415602684021, accuracy: 31.4 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 2.060248613357544, accuracy: 26.5 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 2.2660186290740967, accuracy: 25.2 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 1.8084, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 1.7966, batch time: 0.07, accuracy:  28.12%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 1.9931, batch time: 0.07, accuracy:  20.31%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 1.9514, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 1.9013, batch time: 0.07, accuracy:  27.34%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 1.9728, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 1.8518, batch time: 0.07, accuracy:  25.78%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 1.8781, batch time: 0.07, accuracy:  28.12%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 2.1072, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 1.9025, batch time: 0.07, accuracy:  23.44%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 2.5522732734680176, accuracy: 22.9 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 1.8940321207046509, accuracy: 30.2 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 3.023315906524658, accuracy: 19.9 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 1.8909521102905273, accuracy: 30.6 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 1.9675546884536743, accuracy: 22.9 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 1.8767566680908203, accuracy: 31.4 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 1.89444899559021, accuracy: 28.5 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 2.0822691917419434, accuracy: 28.4 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 2.198232650756836, accuracy: 17.0 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 1.9058198928833008, accuracy: 24.5 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 1.8722, batch time: 0.16, accuracy:  23.44%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 2.0639, batch time: 0.16, accuracy:  23.44%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 2.0529, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 1.8618, batch time: 0.16, accuracy:  25.78%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 2.0929, batch time: 0.16, accuracy:  17.97%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 1.9514, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 1.8466, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 1.8041, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 1.8376, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 1.8839, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 2.437093734741211, accuracy: 23.1 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 1.8585152626037598, accuracy: 27.8 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 2.906050682067871, accuracy: 20.9 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 1.9910916090011597, accuracy: 26.6 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 1.9072306156158447, accuracy: 27.9 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 1.8977577686309814, accuracy: 25.2 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 1.9817285537719727, accuracy: 28.9 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 2.140284776687622, accuracy: 22.8 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 1.8260122537612915, accuracy: 28.4 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 1.8370431661605835, accuracy: 28.5 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 1.8909, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 1.8781, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 1.9360, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 1.8381, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 1.8730, batch time: 0.08, accuracy:  28.12%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 1.8071, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 1.7614, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 1.9788, batch time: 0.16, accuracy:  23.44%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 1.8865, batch time: 0.17, accuracy:  21.88%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 1.9335, batch time: 0.17, accuracy:  29.69%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 2.616752862930298, accuracy: 22.1 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 1.8358651399612427, accuracy: 32.1 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 2.9583566188812256, accuracy: 18.9 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 2.149528980255127, accuracy: 26.1 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 2.3540523052215576, accuracy: 26.3 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 1.830500841140747, accuracy: 32.3 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 1.9960353374481201, accuracy: 29.8 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 2.154372453689575, accuracy: 24.9 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 1.9084575176239014, accuracy: 32.0 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 1.8890938758850098, accuracy: 29.1 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 1.9144, batch time: 0.16, accuracy:  18.75%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 1.9474, batch time: 0.16, accuracy:  32.03%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 2.0588, batch time: 0.16, accuracy:  28.91%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 1.7588, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 1.7815, batch time: 0.16, accuracy:  35.94%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 1.9625, batch time: 0.07, accuracy:  22.66%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 1.9404, batch time: 0.19, accuracy:  25.00%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 1.8632, batch time: 0.08, accuracy:  39.06%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 1.6838, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 1.8801, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 2.4896490573883057, accuracy: 20.2 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 1.851189136505127, accuracy: 33.4 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 2.7586007118225098, accuracy: 18.2 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 2.183806896209717, accuracy: 20.1 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 2.1405460834503174, accuracy: 25.0 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 1.9849509000778198, accuracy: 23.7 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 1.847243070602417, accuracy: 31.9 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 1.8391311168670654, accuracy: 32.9 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 1.965297818183899, accuracy: 25.6 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 2.003161907196045, accuracy: 29.7 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 1.8333, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 1.7601, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 1.7113, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 1.8371, batch time: 0.07, accuracy:  28.12%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 1.9826, batch time: 0.07, accuracy:  25.78%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 1.7844, batch time: 0.08, accuracy:  33.59%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 1.9360, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 1.9385, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 1.8593, batch time: 0.24, accuracy:  25.78%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 1.8824, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 2.474914312362671, accuracy: 22.5 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 1.8446038961410522, accuracy: 30.1 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 2.9897234439849854, accuracy: 12.5 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 1.818626880645752, accuracy: 32.4 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 1.914099931716919, accuracy: 27.9 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 1.855628490447998, accuracy: 27.6 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 1.825268030166626, accuracy: 34.2 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 1.8504137992858887, accuracy: 29.1 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 1.8191412687301636, accuracy: 32.8 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 1.7898703813552856, accuracy: 31.8 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 1.7938, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 1.7380, batch time: 0.17, accuracy:  25.78%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 1.7957, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 1.8630, batch time: 0.07, accuracy:  23.44%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 1.9014, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 1.7902, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 1.8253, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 1.8575, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 1.7776, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 1.7807, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 2.8586537837982178, accuracy: 17.7 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 1.814883828163147, accuracy: 34.7 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 3.1855626106262207, accuracy: 17.5 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 2.3175995349884033, accuracy: 21.3 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 2.186652421951294, accuracy: 17.0 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 1.814483880996704, accuracy: 33.1 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 1.8643485307693481, accuracy: 32.7 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 2.083014488220215, accuracy: 23.6 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 1.80426824092865, accuracy: 34.7 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 1.7995444536209106, accuracy: 34.5 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 1.6768, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 1.6767, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 1.8437, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 1.9443, batch time: 0.16, accuracy:  37.50%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 1.8615, batch time: 0.08, accuracy:  32.03%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 1.7231, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 1.7070, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 1.9398, batch time: 0.07, accuracy:  27.34%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 1.8701, batch time: 0.19, accuracy:  28.12%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 1.8566, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 2.7486424446105957, accuracy: 22.3 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 1.8310915231704712, accuracy: 36.2 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 2.9574694633483887, accuracy: 15.7 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 1.9274113178253174, accuracy: 33.0 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 1.8979583978652954, accuracy: 31.0 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 1.8251919746398926, accuracy: 30.8 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 2.105191469192505, accuracy: 22.5 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 1.8784197568893433, accuracy: 34.3 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 1.7995058298110962, accuracy: 40.5 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 1.797015905380249, accuracy: 39.9 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 1.9145, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 1.7831, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 1.9324, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 1.8246, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 1.8443, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 1.7952, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 1.6598, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 1.8243, batch time: 0.16, accuracy:  38.28%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 1.9209, batch time: 0.17, accuracy:  38.28%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 1.8689, batch time: 0.16, accuracy:  37.50%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 2.8230087757110596, accuracy: 25.1 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 1.9052807092666626, accuracy: 34.6 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 3.0409975051879883, accuracy: 15.4 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 1.9792786836624146, accuracy: 33.0 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 1.982157826423645, accuracy: 30.3 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 1.9612791538238525, accuracy: 27.5 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 1.846560001373291, accuracy: 38.4 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 1.8251384496688843, accuracy: 39.0 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 1.8897632360458374, accuracy: 29.8 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 1.8410351276397705, accuracy: 39.2 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 1.7850, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 1.7617, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 1.7260, batch time: 0.16, accuracy:  34.38%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 1.9029, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 1.9246, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 1.7546, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 1.8596, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 1.8348, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 1.6477, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 1.7292, batch time: 0.16, accuracy:  44.53%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 2.5649619102478027, accuracy: 22.5 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 1.9078258275985718, accuracy: 37.4 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 3.1959211826324463, accuracy: 20.4 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 1.8808248043060303, accuracy: 40.6 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 1.9429017305374146, accuracy: 33.0 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 1.8014885187149048, accuracy: 38.5 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 1.922256588935852, accuracy: 34.4 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 1.905807614326477, accuracy: 30.8 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 2.1259357929229736, accuracy: 28.7 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 1.9701497554779053, accuracy: 32.4 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 1.8473, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 1.7902, batch time: 0.08, accuracy:  32.81%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 1.8995, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 1.8013, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 1.8723, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 1.7478, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 1.7916, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 1.7664, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 1.7219, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 1.9564, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 2.522998332977295, accuracy: 24.1 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 1.8386179208755493, accuracy: 32.4 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 2.7646241188049316, accuracy: 18.5 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 1.9095995426177979, accuracy: 32.7 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 1.984144687652588, accuracy: 29.7 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 1.8341996669769287, accuracy: 39.2 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 1.917647123336792, accuracy: 32.2 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 1.9962495565414429, accuracy: 33.3 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 1.8897684812545776, accuracy: 34.8 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 1.829867959022522, accuracy: 37.2 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 1.7642, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 1.9369, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 1.8374, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 1.6862, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 1.7808, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 1.7908, batch time: 0.16, accuracy:  34.38%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 1.8215, batch time: 0.16, accuracy:  42.97%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 1.6610, batch time: 0.17, accuracy:  40.62%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 1.6909, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 1.7927, batch time: 0.16, accuracy:  39.84%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 2.493849992752075, accuracy: 23.0 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 1.808849573135376, accuracy: 40.9 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 3.1292357444763184, accuracy: 17.2 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 1.8814598321914673, accuracy: 36.2 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 1.8556431531906128, accuracy: 36.3 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 1.8610469102859497, accuracy: 36.2 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 1.8016293048858643, accuracy: 38.7 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 1.7751010656356812, accuracy: 38.5 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 2.241424322128296, accuracy: 22.7 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 1.812208652496338, accuracy: 35.1 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 1.7772, batch time: 0.08, accuracy:  37.50%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 1.6667, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 1.6286, batch time: 0.08, accuracy:  38.28%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 1.8588, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 1.7677, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 1.9954, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 1.9915, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 1.9789, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 1.7981, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 1.6909, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 2.4990031719207764, accuracy: 25.2 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 1.7160855531692505, accuracy: 41.0 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 3.397578477859497, accuracy: 14.8 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 1.7133241891860962, accuracy: 41.5 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 1.8484179973602295, accuracy: 37.2 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 1.8261491060256958, accuracy: 37.3 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 1.7037571668624878, accuracy: 38.6 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 1.6898528337478638, accuracy: 39.9 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 2.0604288578033447, accuracy: 24.9 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 1.7390409708023071, accuracy: 36.2 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 1.8200, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 1.6076, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 1.7351, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 1.6264, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 1.7552, batch time: 0.07, accuracy:  27.34%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 1.6329, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 1.6013, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 1.6959, batch time: 0.16, accuracy:  39.06%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 1.6656, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 1.8566, batch time: 0.16, accuracy:  35.16%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 2.3360543251037598, accuracy: 24.4 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 1.7003778219223022, accuracy: 39.6 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 3.0784549713134766, accuracy: 18.1 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 1.801169514656067, accuracy: 41.2 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 1.733713984489441, accuracy: 36.1 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 1.7381097078323364, accuracy: 38.3 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 1.8621324300765991, accuracy: 33.2 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 1.8973848819732666, accuracy: 32.7 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 1.6790344715118408, accuracy: 39.8 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 1.6774251461029053, accuracy: 38.3 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 1.6687, batch time: 0.16, accuracy:  38.28%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 1.5561, batch time: 0.19, accuracy:  45.31%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 1.7874, batch time: 0.18, accuracy:  42.19%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 1.7346, batch time: 0.18, accuracy:  38.28%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 1.6116, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 1.6432, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 1.7697, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 1.8302, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 1.7137, batch time: 0.17, accuracy:  38.28%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 1.7419, batch time: 0.16, accuracy:  41.41%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 2.7024099826812744, accuracy: 17.0 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 1.6911894083023071, accuracy: 37.4 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 3.02017879486084, accuracy: 18.2 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 1.6897703409194946, accuracy: 37.4 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 1.8373275995254517, accuracy: 30.9 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 1.6897703409194946, accuracy: 37.4 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 1.8765652179718018, accuracy: 29.4 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 1.826289415359497, accuracy: 28.5 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 1.7020312547683716, accuracy: 34.8 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 1.7097852230072021, accuracy: 35.2 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 1.6919, batch time: 0.16, accuracy:  46.09%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 1.7722, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 1.6497, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 1.6822, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 1.7241, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 1.7560, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 1.7415, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 1.8965, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 1.6481, batch time: 0.16, accuracy:  35.94%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 1.7220, batch time: 0.16, accuracy:  34.38%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 2.9248454570770264, accuracy: 14.0 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 1.7180287837982178, accuracy: 38.9 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 2.7459053993225098, accuracy: 19.1 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 1.920043706893921, accuracy: 27.6 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 1.922000765800476, accuracy: 29.2 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 1.7718034982681274, accuracy: 35.2 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 1.6813715696334839, accuracy: 38.1 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 1.6727086305618286, accuracy: 38.0 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 1.7286477088928223, accuracy: 36.3 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 1.7212730646133423, accuracy: 40.6 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 1.7569, batch time: 0.16, accuracy:  36.72%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 1.8465, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 1.7672, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 1.7052, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 1.7418, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 1.9395, batch time: 0.16, accuracy:  28.91%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 1.6501, batch time: 0.16, accuracy:  35.94%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 1.7646, batch time: 0.17, accuracy:  42.19%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 1.8377, batch time: 0.25, accuracy:  31.25%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 1.8615, batch time: 0.12, accuracy:  42.19%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 2.5394699573516846, accuracy: 17.4 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 1.6542842388153076, accuracy: 43.4 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 2.465588331222534, accuracy: 20.0 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 1.6447224617004395, accuracy: 42.8 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 1.8964074850082397, accuracy: 33.5 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 1.6447224617004395, accuracy: 42.8 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 1.7983345985412598, accuracy: 35.3 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 1.6549720764160156, accuracy: 38.0 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 1.821897268295288, accuracy: 42.7 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 1.6582077741622925, accuracy: 41.5 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 1.7634, batch time: 0.16, accuracy:  37.50%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 1.7137, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 1.7390, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 1.6466, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 1.5635, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 1.6421, batch time: 0.17, accuracy:  41.41%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 1.7443, batch time: 0.08, accuracy:  35.16%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 1.7085, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 1.6846, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 1.7499, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 2.757115125656128, accuracy: 17.4 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 1.6331037282943726, accuracy: 38.6 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 2.7332546710968018, accuracy: 22.7 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 1.6315934658050537, accuracy: 39.2 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 1.8827155828475952, accuracy: 34.7 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 1.6315934658050537, accuracy: 39.2 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 1.7601691484451294, accuracy: 33.9 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 1.693893313407898, accuracy: 39.6 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 1.6635429859161377, accuracy: 40.9 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 1.6927725076675415, accuracy: 39.5 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 1.4415, batch time: 0.16, accuracy:  50.00%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 1.6358, batch time: 0.16, accuracy:  34.38%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 1.7241, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 1.7105, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 1.6957, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 1.7642, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 1.6330, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 1.7757, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 1.7833, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 1.6532, batch time: 0.16, accuracy:  38.28%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 2.5862982273101807, accuracy: 19.6 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 1.6478537321090698, accuracy: 38.2 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 2.7927849292755127, accuracy: 23.9 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 1.647672414779663, accuracy: 38.5 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 1.6811082363128662, accuracy: 41.1 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 1.6521351337432861, accuracy: 42.6 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 1.6162829399108887, accuracy: 43.1 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 1.6114304065704346, accuracy: 44.7 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 1.7092268466949463, accuracy: 40.4 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 1.8278948068618774, accuracy: 28.7 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 1.5811, batch time: 0.17, accuracy:  44.53%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 1.5950, batch time: 0.17, accuracy:  42.19%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 1.7247, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 1.5735, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 1.5981, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 1.6392, batch time: 0.17, accuracy:  46.09%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 1.5102, batch time: 0.19, accuracy:  48.44%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 1.6283, batch time: 0.19, accuracy:  33.59%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 1.7171, batch time: 0.19, accuracy:  36.72%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 1.8455, batch time: 0.18, accuracy:  35.94%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 2.913928985595703, accuracy: 14.1 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 1.6516404151916504, accuracy: 37.9 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 2.6406021118164062, accuracy: 19.9 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 1.649696707725525, accuracy: 38.4 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 2.0179946422576904, accuracy: 26.4 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 1.7740356922149658, accuracy: 32.4 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 1.7104203701019287, accuracy: 33.9 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 1.6195876598358154, accuracy: 40.9 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 1.8897134065628052, accuracy: 30.5 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 1.7362245321273804, accuracy: 38.0 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 1.6223, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 1.5777, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 1.6501, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 1.6430, batch time: 0.16, accuracy:  43.75%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 1.6055, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 1.6376, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 1.5501, batch time: 0.25, accuracy:  44.53%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 1.6770, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 1.4569, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 1.6387, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 3.217209577560425, accuracy: 15.5 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 1.6276297569274902, accuracy: 42.9 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 3.7419862747192383, accuracy: 11.2 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 3.4351913928985596, accuracy: 24.3 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 1.7457937002182007, accuracy: 34.6 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 1.6421455144882202, accuracy: 42.0 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 1.6500442028045654, accuracy: 43.1 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 1.7305420637130737, accuracy: 35.7 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 1.6148937940597534, accuracy: 43.9 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 1.6208860874176025, accuracy: 43.2 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 1.6377, batch time: 0.16, accuracy:  45.31%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 1.7077, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 1.5992, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 1.6158, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 1.7559, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 1.8142, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 1.7720, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 1.6103, batch time: 0.08, accuracy:  46.88%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 1.6347, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 1.5615, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 3.5466229915618896, accuracy: 14.2 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 1.6571531295776367, accuracy: 37.8 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 3.722811460494995, accuracy: 11.1 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 1.674405574798584, accuracy: 36.1 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 2.255136013031006, accuracy: 25.9 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 1.6924190521240234, accuracy: 35.3 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 1.916031002998352, accuracy: 28.5 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 1.7098020315170288, accuracy: 38.0 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 1.6515202522277832, accuracy: 39.6 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 1.6868677139282227, accuracy: 37.7 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 1.5966, batch time: 0.16, accuracy:  44.53%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 1.6191, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 1.7070, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 1.6178, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 1.6627, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 1.5847, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 1.6180, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 1.4911, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 1.5891, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 1.5815, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 3.4779646396636963, accuracy: 13.5 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 1.5689697265625, accuracy: 42.6 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 4.508509159088135, accuracy: 10.1 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 2.5077638626098633, accuracy: 24.5 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 1.5677472352981567, accuracy: 43.0 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 3.0453248023986816, accuracy: 15.4 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 2.3671493530273438, accuracy: 22.0 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 2.4417381286621094, accuracy: 21.3 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 1.5880299806594849, accuracy: 46.2 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 1.544076919555664, accuracy: 46.1 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 1.5937, batch time: 0.16, accuracy:  46.09%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 1.4877, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 1.5829, batch time: 0.16, accuracy:  46.09%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 1.5302, batch time: 0.16, accuracy:  45.31%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 1.7246, batch time: 0.16, accuracy:  36.72%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 1.4163, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 1.5116, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 1.6956, batch time: 0.16, accuracy:  39.06%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 1.5641, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 1.5239, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 3.2848994731903076, accuracy: 16.2 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 1.6482090950012207, accuracy: 39.5 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 4.292886734008789, accuracy: 11.7 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 1.6120045185089111, accuracy: 39.8 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 1.700820803642273, accuracy: 36.9 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 1.6347217559814453, accuracy: 41.3 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 1.6406971216201782, accuracy: 38.8 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 2.6737377643585205, accuracy: 21.7 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 1.6488436460494995, accuracy: 40.2 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 1.6206532716751099, accuracy: 41.0 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 1.5694, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 1.5831, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 1.5723, batch time: 0.16, accuracy:  45.31%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 1.7509, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 1.7019, batch time: 0.08, accuracy:  34.38%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 1.5751, batch time: 0.17, accuracy:  39.06%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 1.7206, batch time: 0.19, accuracy:  35.16%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 1.5161, batch time: 0.08, accuracy:  38.28%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 1.5268, batch time: 0.16, accuracy:  48.44%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 1.6642, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 4.300955295562744, accuracy: 12.2 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 1.5939997434616089, accuracy: 42.3 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 4.805573463439941, accuracy: 9.7 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 1.6280752420425415, accuracy: 40.8 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 2.2193291187286377, accuracy: 29.2 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 1.665869951248169, accuracy: 38.5 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 2.0786800384521484, accuracy: 27.0 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 1.5948020219802856, accuracy: 42.7 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 1.6509630680084229, accuracy: 37.3 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 1.6211177110671997, accuracy: 38.2 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 1.5386, batch time: 0.17, accuracy:  42.19%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 1.5556, batch time: 0.17, accuracy:  46.88%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 1.4498, batch time: 0.17, accuracy:  46.09%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 1.5404, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 1.5653, batch time: 0.17, accuracy:  35.94%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 1.6331, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 1.6540, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 1.7967, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 1.8053, batch time: 0.14, accuracy:  32.03%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 1.5378, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 3.8695151805877686, accuracy: 16.0 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 1.667343258857727, accuracy: 38.5 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 4.022439956665039, accuracy: 11.1 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 1.8637974262237549, accuracy: 32.7 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 1.8326395750045776, accuracy: 37.8 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 1.6610620021820068, accuracy: 41.8 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 1.610150933265686, accuracy: 43.0 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 2.1155812740325928, accuracy: 28.0 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 1.6077959537506104, accuracy: 43.8 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 1.688171625137329, accuracy: 37.8 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 1.5602, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 1.5978, batch time: 0.19, accuracy:  45.31%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 1.4406, batch time: 0.18, accuracy:  52.34%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 1.6207, batch time: 0.16, accuracy:  39.84%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 1.4326, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 1.4571, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 1.4706, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 1.5273, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 1.4645, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 1.5346, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 5.06427001953125, accuracy: 14.2 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 1.527893304824829, accuracy: 43.4 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 4.177067756652832, accuracy: 19.2 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 6.754562854766846, accuracy: 14.7 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 3.206709384918213, accuracy: 24.4 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 1.9701284170150757, accuracy: 33.4 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 1.5552003383636475, accuracy: 44.5 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 2.563842296600342, accuracy: 19.5 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 1.5532503128051758, accuracy: 44.3 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 1.4943275451660156, accuracy: 47.9 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 1.4051, batch time: 0.07, accuracy:  58.59%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 1.4256, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 1.5835, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 1.4212, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 1.4853, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 1.5089, batch time: 0.16, accuracy:  49.22%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 1.4826, batch time: 0.16, accuracy:  47.66%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 1.5050, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 1.4650, batch time: 0.08, accuracy:  52.34%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 1.6628, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 4.871198654174805, accuracy: 11.5 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 1.555397629737854, accuracy: 46.7 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 4.92092752456665, accuracy: 19.8 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 1.8100855350494385, accuracy: 37.4 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 1.8398889303207397, accuracy: 35.1 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 2.0650370121002197, accuracy: 31.3 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 1.9820400476455688, accuracy: 33.3 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 2.6020307540893555, accuracy: 23.2 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 1.8264845609664917, accuracy: 37.2 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 1.5224981307983398, accuracy: 47.4 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 1.3791, batch time: 0.16, accuracy:  47.66%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 1.5783, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 1.4135, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 1.3797, batch time: 0.14, accuracy:  49.22%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 1.4552, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 1.5945, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 1.3042, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 1.3532, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 1.6314, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 1.5317, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 4.468679428100586, accuracy: 13.6 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 1.4901586771011353, accuracy: 49.6 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 5.276215553283691, accuracy: 21.9 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 1.4859405755996704, accuracy: 46.2 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 1.7349642515182495, accuracy: 40.0 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 1.4844958782196045, accuracy: 46.6 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 2.348628520965576, accuracy: 31.8 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 1.585649013519287, accuracy: 47.9 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 1.4805938005447388, accuracy: 49.6 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 1.6034549474716187, accuracy: 43.3 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 1.5247, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 1.4487, batch time: 0.16, accuracy:  53.12%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 1.3470, batch time: 0.19, accuracy:  53.12%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 1.3913, batch time: 0.17, accuracy:  51.56%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 1.4815, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 1.5348, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 1.4102, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 1.4443, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 1.5012, batch time: 0.08, accuracy:  46.88%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 1.4901, batch time: 0.17, accuracy:  48.44%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 4.464468479156494, accuracy: 13.7 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 1.4945787191390991, accuracy: 50.1 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 5.6030592918396, accuracy: 21.7 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 1.5838249921798706, accuracy: 44.2 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 1.7557939291000366, accuracy: 41.3 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 1.4934719800949097, accuracy: 50.4 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 2.75339674949646, accuracy: 28.9 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 1.4954731464385986, accuracy: 50.0 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 1.5257549285888672, accuracy: 49.7 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 1.5029670000076294, accuracy: 50.6 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 1.4195, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 1.6026, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 1.4843, batch time: 0.16, accuracy:  55.47%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 1.3523, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 1.4169, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 1.6270, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 1.4710, batch time: 0.16, accuracy:  46.88%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 1.4429, batch time: 0.16, accuracy:  45.31%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 1.3697, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 1.4393, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 4.030917644500732, accuracy: 14.1 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 1.4379026889801025, accuracy: 51.0 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 5.691345691680908, accuracy: 20.4 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 1.437591552734375, accuracy: 51.9 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 1.6767946481704712, accuracy: 42.2 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 1.437591552734375, accuracy: 51.9 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 2.3857717514038086, accuracy: 31.9 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 1.4940937757492065, accuracy: 50.3 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 1.6744253635406494, accuracy: 36.0 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 1.621423363685608, accuracy: 43.3 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 1.4079, batch time: 0.16, accuracy:  50.00%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 1.4321, batch time: 0.18, accuracy:  46.09%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 1.4490, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 1.5366, batch time: 0.13, accuracy:  48.44%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 1.5361, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 1.3724, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 1.4635, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 1.2868, batch time: 0.07, accuracy:  58.59%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 1.6136, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 1.4688, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 4.31772518157959, accuracy: 14.5 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 1.476304054260254, accuracy: 47.4 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 6.732471466064453, accuracy: 20.2 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 1.725541591644287, accuracy: 41.3 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 2.5279531478881836, accuracy: 28.2 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 1.7891966104507446, accuracy: 41.2 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 2.1956167221069336, accuracy: 34.7 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 2.2309257984161377, accuracy: 30.8 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 1.424882411956787, accuracy: 52.3 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 1.436858892440796, accuracy: 50.2 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 1.4694, batch time: 0.16, accuracy:  50.00%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 1.5060, batch time: 0.16, accuracy:  47.66%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 1.6293, batch time: 0.16, accuracy:  42.97%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 1.2861, batch time: 0.15, accuracy:  46.09%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 1.5554, batch time: 0.15, accuracy:  44.53%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 1.5007, batch time: 0.15, accuracy:  48.44%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 1.4064, batch time: 0.16, accuracy:  55.47%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 1.6089, batch time: 0.15, accuracy:  45.31%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 1.3556, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 1.4654, batch time: 0.15, accuracy:  50.78%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 4.906373500823975, accuracy: 13.5 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 1.3852322101593018, accuracy: 53.8 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 7.049161911010742, accuracy: 13.8 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 1.3809572458267212, accuracy: 54.6 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 2.423748731613159, accuracy: 32.0 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 1.3809572458267212, accuracy: 54.6 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 2.3923494815826416, accuracy: 34.4 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 1.3792352676391602, accuracy: 55.3 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 1.432638168334961, accuracy: 49.7 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 1.3925514221191406, accuracy: 52.3 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 1.3403, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 1.2975, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 1.4663, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 1.4099, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 1.3840, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 1.4383, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 1.5130, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 1.3273, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 1.6133, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 1.3299, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 5.5343546867370605, accuracy: 11.9 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 1.472896933555603, accuracy: 48.5 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 7.734947204589844, accuracy: 12.0 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 1.4684081077575684, accuracy: 49.1 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 1.8124756813049316, accuracy: 38.6 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 1.4684081077575684, accuracy: 49.1 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 2.5968542098999023, accuracy: 33.1 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 1.488044023513794, accuracy: 48.7 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 1.4808484315872192, accuracy: 49.7 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 1.4417115449905396, accuracy: 53.0 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 1.4896, batch time: 0.15, accuracy:  50.78%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 1.2979, batch time: 0.16, accuracy:  63.28%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 1.5925, batch time: 0.16, accuracy:  46.09%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 1.3850, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 1.4087, batch time: 0.16, accuracy:  47.66%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 1.5955, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 1.4867, batch time: 0.15, accuracy:  54.69%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 1.3867, batch time: 0.16, accuracy:  53.91%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 1.4409, batch time: 0.15, accuracy:  48.44%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 1.4368, batch time: 0.15, accuracy:  54.69%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 4.551806926727295, accuracy: 15.6 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 1.383915901184082, accuracy: 52.3 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 6.574474811553955, accuracy: 13.6 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 1.381620168685913, accuracy: 51.8 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 1.5528358221054077, accuracy: 45.4 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 1.381620168685913, accuracy: 51.8 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 2.4195804595947266, accuracy: 35.6 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 1.5336467027664185, accuracy: 42.3 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 1.6302165985107422, accuracy: 41.1 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 1.4876941442489624, accuracy: 47.3 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 1.4116, batch time: 0.15, accuracy:  45.31%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 1.3272, batch time: 0.07, accuracy:  58.59%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 1.5947, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 1.1748, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 1.3092, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 1.5685, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 1.3318, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 1.4268, batch time: 0.09, accuracy:  53.91%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 1.4110, batch time: 0.15, accuracy:  49.22%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 1.2456, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 4.759677410125732, accuracy: 12.6 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 1.4129846096038818, accuracy: 54.9 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 7.649639129638672, accuracy: 13.1 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 1.3983381986618042, accuracy: 54.7 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 3.4726686477661133, accuracy: 26.9 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 1.402082085609436, accuracy: 54.0 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 1.966684341430664, accuracy: 40.7 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 2.70259690284729, accuracy: 24.7 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 1.4259217977523804, accuracy: 52.8 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 1.527120590209961, accuracy: 47.9 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 1.4008, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 1.3121, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 1.3981, batch time: 0.15, accuracy:  49.22%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 1.6859, batch time: 0.15, accuracy:  44.53%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 1.3390, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 1.4328, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 1.3109, batch time: 0.15, accuracy:  56.25%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 1.2461, batch time: 0.18, accuracy:  58.59%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 1.5375, batch time: 0.17, accuracy:  49.22%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 1.3216, batch time: 0.17, accuracy:  53.12%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 4.748722076416016, accuracy: 15.4 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 1.3679039478302002, accuracy: 51.4 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 8.030552864074707, accuracy: 9.7 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 1.4072002172470093, accuracy: 49.5 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 8.577852249145508, accuracy: 13.7 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 1.498787760734558, accuracy: 48.0 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 4.244719982147217, accuracy: 26.6 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 1.3774477243423462, accuracy: 50.9 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 1.3460403680801392, accuracy: 53.0 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 1.368414044380188, accuracy: 53.0 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 1.2984, batch time: 0.15, accuracy:  60.94%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 1.3473, batch time: 0.16, accuracy:  53.12%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 1.3683, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 1.4326, batch time: 0.14, accuracy:  56.25%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 1.4337, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 1.3763, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 1.3301, batch time: 0.07, accuracy:  60.94%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 1.3493, batch time: 0.15, accuracy:  46.88%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 1.4105, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 1.3878, batch time: 0.14, accuracy:  46.09%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 4.534466743469238, accuracy: 14.7 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 1.4290547370910645, accuracy: 50.3 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 7.614997863769531, accuracy: 9.7 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 1.4680237770080566, accuracy: 49.6 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 4.095942974090576, accuracy: 14.3 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 1.5101077556610107, accuracy: 47.7 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 4.258370876312256, accuracy: 21.3 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 1.5465949773788452, accuracy: 45.6 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 1.465653419494629, accuracy: 49.0 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 1.4713581800460815, accuracy: 48.2 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 1.3055, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 1.4746, batch time: 0.15, accuracy:  41.41%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 1.4187, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 1.2463, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 1.4644, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 1.7395, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 1.4073, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 1.5884, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 1.4091, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 1.2769, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 5.327194690704346, accuracy: 12.5 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 1.3965946435928345, accuracy: 51.4 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 7.7698259353637695, accuracy: 15.7 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 1.3781156539916992, accuracy: 52.9 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 2.1842336654663086, accuracy: 34.4 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 1.3890081644058228, accuracy: 52.6 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 2.642254114151001, accuracy: 39.6 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 1.3795149326324463, accuracy: 53.5 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 1.3869686126708984, accuracy: 52.3 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 1.3973408937454224, accuracy: 50.0 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 1.6798, batch time: 0.15, accuracy:  42.19%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 1.4374, batch time: 0.38, accuracy:  48.44%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 1.4151, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 1.4951, batch time: 0.15, accuracy:  45.31%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 1.2789, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 1.4550, batch time: 0.15, accuracy:  46.88%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 1.2362, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 1.6412, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 1.5076, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 1.4070, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 5.657853603363037, accuracy: 13.5 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 1.394197940826416, accuracy: 52.8 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 9.740072250366211, accuracy: 18.4 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 1.8002614974975586, accuracy: 41.8 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 2.0752007961273193, accuracy: 33.8 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 1.6546837091445923, accuracy: 46.2 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 1.8298038244247437, accuracy: 48.1 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 1.619215965270996, accuracy: 43.8 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 1.4132736921310425, accuracy: 52.8 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 1.3718373775482178, accuracy: 55.0 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 1.4359, batch time: 0.15, accuracy:  54.69%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 1.3330, batch time: 0.16, accuracy:  52.34%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 1.3994, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 1.5046, batch time: 0.15, accuracy:  48.44%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 1.3158, batch time: 0.15, accuracy:  60.16%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 1.5337, batch time: 0.15, accuracy:  48.44%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 1.4318, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 1.4303, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 1.5409, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 1.5718, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 5.40000057220459, accuracy: 12.4 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 1.4070369005203247, accuracy: 51.6 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 7.980811595916748, accuracy: 14.3 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 1.3959870338439941, accuracy: 52.0 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 1.937565565109253, accuracy: 32.6 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 1.3959870338439941, accuracy: 52.0 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 1.7052439451217651, accuracy: 36.1 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 3.7153828144073486, accuracy: 19.3 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 2.394491672515869, accuracy: 33.4 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 1.366669774055481, accuracy: 52.4 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 1.2704, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 1.5173, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 1.4045, batch time: 0.15, accuracy:  49.22%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 1.5372, batch time: 0.15, accuracy:  40.62%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 1.5565, batch time: 0.15, accuracy:  42.97%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 1.3560, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 1.6306, batch time: 0.15, accuracy:  48.44%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 1.3558, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 1.3912, batch time: 0.15, accuracy:  49.22%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 1.4191, batch time: 0.15, accuracy:  50.00%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 5.923986911773682, accuracy: 10.8 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 1.4599286317825317, accuracy: 47.5 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 10.483428001403809, accuracy: 15.4 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 1.6155016422271729, accuracy: 42.5 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 3.269498825073242, accuracy: 26.7 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 1.844793677330017, accuracy: 42.4 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 1.6506215333938599, accuracy: 43.4 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 1.508117437362671, accuracy: 46.5 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 1.4101065397262573, accuracy: 52.2 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 1.4048457145690918, accuracy: 51.3 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 1.5675, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 1.3376, batch time: 0.07, accuracy:  59.38%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 1.5166, batch time: 0.18, accuracy:  46.09%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 1.5599, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 1.3973, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 1.6090, batch time: 0.29, accuracy:  49.22%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 1.3457, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 1.5124, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 1.3712, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 1.2397, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 5.523377418518066, accuracy: 13.7 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 1.5236990451812744, accuracy: 46.2 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 8.302661895751953, accuracy: 14.9 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 5.72589635848999, accuracy: 14.0 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 2.5397157669067383, accuracy: 28.3 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 1.9242146015167236, accuracy: 38.9 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 1.8713208436965942, accuracy: 36.6 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 1.534267783164978, accuracy: 46.6 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 1.4821445941925049, accuracy: 51.2 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 1.5041781663894653, accuracy: 47.3 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 1.4329, batch time: 0.17, accuracy:  54.69%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 1.3478, batch time: 0.15, accuracy:  50.78%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 1.4360, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 1.4839, batch time: 0.15, accuracy:  46.88%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 1.4344, batch time: 0.15, accuracy:  46.88%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 1.4301, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 1.4833, batch time: 0.16, accuracy:  46.88%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 1.4986, batch time: 0.15, accuracy:  48.44%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 1.5253, batch time: 0.13, accuracy:  46.09%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 1.3473, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 9.16298770904541, accuracy: 13.0 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 1.4465090036392212, accuracy: 51.7 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 9.148371696472168, accuracy: 15.0 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 1.7535821199417114, accuracy: 44.6 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 2.404895305633545, accuracy: 29.6 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 2.3637828826904297, accuracy: 24.2 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 1.557005524635315, accuracy: 48.5 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 1.9821783304214478, accuracy: 37.3 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 2.14862060546875, accuracy: 30.1 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 1.7399471998214722, accuracy: 41.5 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 1.4963, batch time: 0.15, accuracy:  53.12%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 1.6427, batch time: 0.15, accuracy:  50.78%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 1.3167, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 1.4282, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 1.3362, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 1.3712, batch time: 0.07, accuracy:  57.81%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 1.4494, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 1.5573, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 1.4272, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 1.4630, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 10.145474433898926, accuracy: 12.9 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 1.4008424282073975, accuracy: 54.2 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 9.023605346679688, accuracy: 11.0 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 1.6165908575057983, accuracy: 51.8 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 1.860956072807312, accuracy: 43.6 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 1.741527795791626, accuracy: 40.3 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 1.6521697044372559, accuracy: 43.4 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 1.4196062088012695, accuracy: 51.5 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 1.4009957313537598, accuracy: 51.9 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 1.4033875465393066, accuracy: 52.6 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 1.4125, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 1.3601, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 1.5560, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 1.4391, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 1.3365, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 1.5883, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 1.3786, batch time: 0.15, accuracy:  54.69%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 1.2607, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 1.4068, batch time: 0.16, accuracy:  43.75%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 1.3931, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 10.150885581970215, accuracy: 11.3 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 1.3431724309921265, accuracy: 54.8 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 11.787213325500488, accuracy: 17.3 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 1.891656517982483, accuracy: 39.6 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 1.8093249797821045, accuracy: 42.8 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 2.16853666305542, accuracy: 30.3 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 2.8238186836242676, accuracy: 33.1 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 2.428030014038086, accuracy: 35.8 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 1.400955319404602, accuracy: 49.7 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 1.372492790222168, accuracy: 52.7 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 1.3867, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 1.3630, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 1.4258, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 1.4650, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 1.5068, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 1.4649, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 1.4869, batch time: 0.27, accuracy:  49.22%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 1.4136, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 1.4096, batch time: 0.16, accuracy:  55.47%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 1.4536, batch time: 0.15, accuracy:  46.88%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 9.63895320892334, accuracy: 12.4 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 1.3771510124206543, accuracy: 52.4 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 11.009982109069824, accuracy: 17.2 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 1.7989522218704224, accuracy: 44.2 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 1.7741152048110962, accuracy: 46.7 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 3.013101577758789, accuracy: 25.2 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 2.2814314365386963, accuracy: 33.9 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 2.2051138877868652, accuracy: 35.1 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 1.4398647546768188, accuracy: 46.4 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 1.4663842916488647, accuracy: 49.7 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 1.2421, batch time: 0.15, accuracy:  59.38%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 1.3894, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 1.4322, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 1.4423, batch time: 0.17, accuracy:  49.22%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 1.2495, batch time: 0.17, accuracy:  58.59%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 1.2830, batch time: 0.15, accuracy:  50.78%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 1.3102, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 1.4033, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 1.3840, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 1.6141, batch time: 0.15, accuracy:  45.31%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 9.34375286102295, accuracy: 12.2 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 1.40878427028656, accuracy: 51.1 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 11.186792373657227, accuracy: 17.5 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 1.9630509614944458, accuracy: 39.4 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 2.208556890487671, accuracy: 29.9 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 2.0080184936523438, accuracy: 32.4 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 1.5259462594985962, accuracy: 48.4 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 2.6801908016204834, accuracy: 23.7 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 3.0510025024414062, accuracy: 23.2 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 1.3932106494903564, accuracy: 51.6 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 1.2710, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 1.5490, batch time: 0.15, accuracy:  45.31%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 1.4308, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 1.3578, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 1.4103, batch time: 0.11, accuracy:  47.66%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 1.4093, batch time: 0.15, accuracy:  48.44%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 1.3212, batch time: 0.15, accuracy:  58.59%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 1.3493, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 1.5005, batch time: 0.14, accuracy:  48.44%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 1.3766, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 9.182555198669434, accuracy: 11.4 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 1.4277681112289429, accuracy: 50.8 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 12.221402168273926, accuracy: 16.3 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 1.9957468509674072, accuracy: 38.1 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 2.3746824264526367, accuracy: 29.9 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 2.0531134605407715, accuracy: 31.6 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 3.0242912769317627, accuracy: 27.3 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 2.259830951690674, accuracy: 37.4 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 1.7532622814178467, accuracy: 39.0 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 2.0077221393585205, accuracy: 33.3 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 1.2933, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 1.4654, batch time: 0.11, accuracy:  47.66%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 1.2811, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 1.2797, batch time: 0.15, accuracy:  56.25%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 1.3880, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 1.5567, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 1.2126, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 1.5197, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 1.3232, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 1.5644, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 10.573775291442871, accuracy: 11.5 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 1.468557357788086, accuracy: 50.4 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 11.40992546081543, accuracy: 20.3 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 8.773478507995605, accuracy: 10.3 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 4.354610919952393, accuracy: 30.2 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 3.6217188835144043, accuracy: 21.7 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 1.4826195240020752, accuracy: 49.2 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 3.7197482585906982, accuracy: 27.7 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 2.6906821727752686, accuracy: 31.5 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 1.563821792602539, accuracy: 49.0 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 1.4888, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 1.2387, batch time: 0.18, accuracy:  54.69%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 1.2969, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 1.4798, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 1.3708, batch time: 0.17, accuracy:  45.31%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 1.5090, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 1.3160, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 1.4151, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 1.4108, batch time: 0.15, accuracy:  47.66%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 1.3659, batch time: 0.15, accuracy:  54.69%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 10.21754264831543, accuracy: 14.5 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 1.3812466859817505, accuracy: 54.3 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 11.636677742004395, accuracy: 19.1 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 1.4470629692077637, accuracy: 50.1 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 5.148356914520264, accuracy: 18.8 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 1.522079348564148, accuracy: 47.1 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 11.831117630004883, accuracy: 10.0 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 1.366477608680725, accuracy: 55.1 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 1.3841835260391235, accuracy: 55.3 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 1.3576481342315674, accuracy: 54.6 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 1.4883, batch time: 0.15, accuracy:  53.12%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 1.3765, batch time: 0.15, accuracy:  44.53%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 1.2763, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 1.4253, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 1.3513, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 1.3044, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 1.3514, batch time: 0.15, accuracy:  50.00%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 1.2748, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 1.3804, batch time: 0.14, accuracy:  50.78%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 1.3922, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 10.239039421081543, accuracy: 11.1 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 1.3440465927124023, accuracy: 55.5 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 12.13539981842041, accuracy: 15.3 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 1.8594664335250854, accuracy: 40.5 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 2.082059383392334, accuracy: 36.2 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 1.8505873680114746, accuracy: 34.1 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 2.4631729125976562, accuracy: 33.0 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 2.1490883827209473, accuracy: 33.8 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 1.35960853099823, accuracy: 54.3 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 1.4849148988723755, accuracy: 49.6 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 1.3595, batch time: 0.07, accuracy:  57.81%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 1.3506, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 1.3180, batch time: 0.18, accuracy:  57.03%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 1.4716, batch time: 0.15, accuracy:  48.44%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 1.2396, batch time: 0.07, accuracy:  59.38%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 1.4303, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 1.3343, batch time: 0.17, accuracy:  60.94%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 1.4147, batch time: 0.15, accuracy:  50.78%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 1.4711, batch time: 0.15, accuracy:  49.22%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 1.3365, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 10.350034713745117, accuracy: 13.4 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 1.4255820512771606, accuracy: 52.1 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 11.586642265319824, accuracy: 18.2 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 1.9889386892318726, accuracy: 39.4 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 2.1026668548583984, accuracy: 32.9 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 2.535395622253418, accuracy: 24.7 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 2.25870418548584, accuracy: 38.6 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 2.8188250064849854, accuracy: 28.8 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 1.4165946245193481, accuracy: 53.0 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 1.3980790376663208, accuracy: 54.6 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 1.2957, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 1.4517, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 1.4908, batch time: 0.15, accuracy:  50.78%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 1.3504, batch time: 0.39, accuracy:  54.69%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 1.3290, batch time: 0.15, accuracy:  53.12%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 1.3287, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 1.3299, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 1.4044, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 1.7331, batch time: 0.15, accuracy:  43.75%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 1.4053, batch time: 0.15, accuracy:  60.16%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 10.086845397949219, accuracy: 12.4 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 1.3634133338928223, accuracy: 52.2 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 11.831794738769531, accuracy: 20.3 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 1.4094631671905518, accuracy: 51.5 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 5.165980339050293, accuracy: 21.2 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 1.4645758867263794, accuracy: 50.6 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 11.354219436645508, accuracy: 8.7 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 1.392386794090271, accuracy: 52.8 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 1.4886598587036133, accuracy: 47.7 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 1.36849045753479, accuracy: 53.4 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 1.2616, batch time: 0.07, accuracy:  59.38%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 1.4514, batch time: 0.15, accuracy:  49.22%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 1.3299, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 1.2807, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 1.3821, batch time: 0.15, accuracy:  58.59%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 1.3915, batch time: 0.15, accuracy:  50.78%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 1.4630, batch time: 0.15, accuracy:  53.12%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 1.6084, batch time: 0.15, accuracy:  50.00%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 1.3301, batch time: 0.07, accuracy:  58.59%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 1.6727, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 10.163774490356445, accuracy: 13.2 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 1.411457896232605, accuracy: 51.6 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 11.026134490966797, accuracy: 16.8 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 1.4248002767562866, accuracy: 50.3 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 5.395075798034668, accuracy: 18.4 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 1.4774657487869263, accuracy: 49.3 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 10.68843936920166, accuracy: 8.8 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 1.376702904701233, accuracy: 52.8 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 1.3889448642730713, accuracy: 53.9 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 1.4799354076385498, accuracy: 48.4 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 1.5053, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 1.3071, batch time: 0.15, accuracy:  58.59%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 1.2909, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 1.4462, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 1.4006, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 1.3833, batch time: 0.15, accuracy:  49.22%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 1.4346, batch time: 0.15, accuracy:  49.22%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 1.5434, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 1.4594, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 1.4080, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 10.80168342590332, accuracy: 12.0 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 1.3774104118347168, accuracy: 55.1 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 10.88624095916748, accuracy: 20.4 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 1.3896156549453735, accuracy: 53.6 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 5.925297737121582, accuracy: 19.4 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 1.424081563949585, accuracy: 51.1 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 10.107976913452148, accuracy: 9.3 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 1.5465925931930542, accuracy: 46.8 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 1.3564170598983765, accuracy: 53.0 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 1.3862196207046509, accuracy: 50.2 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 1.4763, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 1.6562, batch time: 0.15, accuracy:  40.62%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 1.6288, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 1.2840, batch time: 0.07, accuracy:  57.81%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 1.4215, batch time: 0.29, accuracy:  54.69%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 1.4880, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 1.3219, batch time: 0.15, accuracy:  54.69%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 1.2172, batch time: 0.15, accuracy:  61.72%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 1.3223, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 1.5214, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 10.20496940612793, accuracy: 11.9 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 1.3414125442504883, accuracy: 54.8 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 10.406425476074219, accuracy: 20.1 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 2.104102611541748, accuracy: 34.8 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 2.616913318634033, accuracy: 31.3 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 1.6178499460220337, accuracy: 48.8 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 2.019865036010742, accuracy: 47.9 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 2.0073373317718506, accuracy: 38.0 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 1.3446907997131348, accuracy: 53.4 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 1.3795686960220337, accuracy: 51.5 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 1.3100, batch time: 0.14, accuracy:  61.72%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 1.4149, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 1.3880, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 1.4384, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 1.4585, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 1.5600, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 1.4582, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 1.3009, batch time: 0.07, accuracy:  60.16%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 1.3785, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 1.4911, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 10.225360870361328, accuracy: 12.0 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 1.4147928953170776, accuracy: 50.9 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 9.599064826965332, accuracy: 21.3 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 1.372520089149475, accuracy: 54.1 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 2.7482616901397705, accuracy: 18.1 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 1.372520089149475, accuracy: 54.1 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 5.645133018493652, accuracy: 11.9 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 1.3956958055496216, accuracy: 53.1 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 1.3923580646514893, accuracy: 51.8 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 1.3890581130981445, accuracy: 51.1 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 1.4014, batch time: 0.15, accuracy:  53.12%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 1.3284, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 1.4038, batch time: 0.15, accuracy:  54.69%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 1.5187, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 1.3781, batch time: 0.15, accuracy:  53.12%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 1.4842, batch time: 0.15, accuracy:  45.31%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 1.3167, batch time: 0.15, accuracy:  63.28%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 1.3409, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 1.4395, batch time: 0.15, accuracy:  46.88%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 1.3420, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 9.892095565795898, accuracy: 13.3 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 1.3329354524612427, accuracy: 53.4 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 9.040894508361816, accuracy: 23.2 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 1.3075313568115234, accuracy: 54.5 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 2.70147705078125, accuracy: 20.1 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 1.3075313568115234, accuracy: 54.5 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 5.487212181091309, accuracy: 11.3 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 1.3174573183059692, accuracy: 54.3 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 1.3476938009262085, accuracy: 52.0 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 1.3323850631713867, accuracy: 54.8 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 1.3332, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 1.5529, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 1.3172, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 1.4464, batch time: 0.16, accuracy:  53.12%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 1.1954, batch time: 0.15, accuracy:  64.84%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 1.4049, batch time: 0.12, accuracy:  53.12%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 1.4716, batch time: 0.15, accuracy:  45.31%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 1.3790, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 1.4836, batch time: 0.15, accuracy:  47.66%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 1.3858, batch time: 0.13, accuracy:  54.69%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 10.82380199432373, accuracy: 10.7 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 1.3731298446655273, accuracy: 52.6 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 9.436074256896973, accuracy: 21.6 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 2.080045461654663, accuracy: 34.1 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 2.3888585567474365, accuracy: 32.3 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 7.5305914878845215, accuracy: 10.0 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 2.1240487098693848, accuracy: 36.9 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 2.422091245651245, accuracy: 28.5 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 1.4039396047592163, accuracy: 51.4 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 1.3795253038406372, accuracy: 52.6 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 1.3467, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 1.4295, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 1.5213, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 1.4026, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 1.3643, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 1.4896, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 1.2977, batch time: 0.07, accuracy:  62.50%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 1.2660, batch time: 0.07, accuracy:  60.94%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 1.4024, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 1.2657, batch time: 0.07, accuracy:  58.59%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 11.009424209594727, accuracy: 13.2 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 1.4428952932357788, accuracy: 53.1 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 8.975768089294434, accuracy: 22.7 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 1.9361616373062134, accuracy: 41.0 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 2.4451911449432373, accuracy: 31.3 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 1.6461313962936401, accuracy: 47.7 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 2.0641963481903076, accuracy: 35.9 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 1.5193592309951782, accuracy: 48.8 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 1.4399800300598145, accuracy: 51.4 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 1.4996124505996704, accuracy: 50.5 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 1.4768, batch time: 0.13, accuracy:  51.56%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 1.5451, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 1.2197, batch time: 0.07, accuracy:  60.16%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 1.2934, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 1.5312, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 1.3647, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 1.5261, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 1.4693, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 1.3306, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 1.5597, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 11.52377700805664, accuracy: 11.6 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 1.388290286064148, accuracy: 54.3 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 9.872150421142578, accuracy: 19.5 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 1.4428504705429077, accuracy: 53.0 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 4.336863994598389, accuracy: 21.1 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 1.5099575519561768, accuracy: 51.3 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 9.9006929397583, accuracy: 9.4 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 1.3674554824829102, accuracy: 55.2 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 1.3752895593643188, accuracy: 53.7 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 1.4043229818344116, accuracy: 52.6 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 1.3458, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 1.2892, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 1.3261, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 1.2928, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 1.4102, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 1.3304, batch time: 0.15, accuracy:  48.44%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 1.6821, batch time: 0.15, accuracy:  42.19%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 1.2612, batch time: 0.15, accuracy:  54.69%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 1.3327, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 1.3898, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 12.427165031433105, accuracy: 11.5 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 1.3234623670578003, accuracy: 54.7 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 11.507603645324707, accuracy: 20.1 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 1.430687665939331, accuracy: 51.6 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 2.107041835784912, accuracy: 38.9 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 1.5861477851867676, accuracy: 47.6 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 2.2624869346618652, accuracy: 40.5 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 3.7003254890441895, accuracy: 17.0 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 1.3314292430877686, accuracy: 54.1 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 1.3400421142578125, accuracy: 55.2 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 1.2668, batch time: 0.15, accuracy:  57.81%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 1.4489, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 1.4232, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 1.4137, batch time: 0.15, accuracy:  47.66%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 1.4616, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 1.4422, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 1.3741, batch time: 0.15, accuracy:  54.69%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 1.4219, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 1.3488, batch time: 0.07, accuracy:  57.81%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 1.3457, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 11.646139144897461, accuracy: 10.9 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 1.3457629680633545, accuracy: 52.2 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 9.589961051940918, accuracy: 18.4 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 1.3730785846710205, accuracy: 53.2 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 2.2200443744659424, accuracy: 33.0 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 1.3571959733963013, accuracy: 54.6 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 1.9148870706558228, accuracy: 40.2 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 3.095324993133545, accuracy: 18.7 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 1.3297048807144165, accuracy: 53.4 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 1.3912924528121948, accuracy: 49.7 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 1.3217, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 1.3646, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 1.3243, batch time: 0.15, accuracy:  61.72%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 1.3022, batch time: 0.15, accuracy:  57.81%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 1.3207, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 1.4004, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 1.3656, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 1.3102, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 1.3202, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 1.3033, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 11.293270111083984, accuracy: 12.9 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 1.3495362997055054, accuracy: 52.0 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 10.940348625183105, accuracy: 22.2 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 1.4208787679672241, accuracy: 52.3 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 4.379755020141602, accuracy: 24.4 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 5.702596664428711, accuracy: 19.4 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 3.5661942958831787, accuracy: 22.8 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 4.224979877471924, accuracy: 25.1 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 1.3569424152374268, accuracy: 51.7 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 2.1034533977508545, accuracy: 32.3 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 1.3104, batch time: 0.07, accuracy:  60.16%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 1.3799, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 1.3559, batch time: 0.15, accuracy:  50.78%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 1.4533, batch time: 0.15, accuracy:  46.88%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 1.3627, batch time: 0.15, accuracy:  54.69%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 1.5345, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 1.3355, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 1.3708, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 1.5551, batch time: 0.15, accuracy:  45.31%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 1.3658, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 11.25226879119873, accuracy: 13.1 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 1.3586796522140503, accuracy: 53.8 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 9.366982460021973, accuracy: 22.4 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 1.8305878639221191, accuracy: 42.9 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 2.2710886001586914, accuracy: 29.4 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 1.4874284267425537, accuracy: 45.9 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 1.926498532295227, accuracy: 35.9 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 2.380065679550171, accuracy: 28.5 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 2.198840856552124, accuracy: 37.8 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 1.9754273891448975, accuracy: 29.1 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 1.4236, batch time: 0.17, accuracy:  53.12%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 1.4929, batch time: 0.18, accuracy:  42.97%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 1.4614, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 1.2423, batch time: 0.07, accuracy:  65.62%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 1.3849, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 1.5070, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 1.3653, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 1.3725, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 1.4421, batch time: 0.15, accuracy:  48.44%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 1.4934, batch time: 0.15, accuracy:  50.00%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 11.7924165725708, accuracy: 9.7 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 1.4495553970336914, accuracy: 52.2 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 9.151185035705566, accuracy: 18.4 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 1.8986525535583496, accuracy: 41.9 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 2.802260398864746, accuracy: 33.0 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 1.749832272529602, accuracy: 40.6 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 1.759058952331543, accuracy: 38.7 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 1.4126709699630737, accuracy: 50.2 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 1.4100431203842163, accuracy: 52.4 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 1.371438980102539, accuracy: 52.4 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 1.3164, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 1.3764, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 1.4390, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 1.4772, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 1.3095, batch time: 0.07, accuracy:  57.81%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 1.2215, batch time: 0.07, accuracy:  57.81%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 1.2321, batch time: 0.15, accuracy:  58.59%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 1.5559, batch time: 0.15, accuracy:  47.66%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 1.3357, batch time: 0.15, accuracy:  50.78%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 1.4498, batch time: 0.16, accuracy:  56.25%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 8.66946029663086, accuracy: 12.7 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 1.2947053909301758, accuracy: 60.0 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 8.825319290161133, accuracy: 22.1 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 1.7110624313354492, accuracy: 44.8 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 1.4840810298919678, accuracy: 52.4 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 2.2521352767944336, accuracy: 39.2 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 1.7385053634643555, accuracy: 46.4 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 2.0225043296813965, accuracy: 35.8 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 1.291491985321045, accuracy: 59.1 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 1.3443756103515625, accuracy: 56.2 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 1.2295, batch time: 0.18, accuracy:  57.81%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 1.1761, batch time: 0.18, accuracy:  64.84%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 1.2752, batch time: 0.18, accuracy:  51.56%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 1.2490, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 1.3978, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 1.3766, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 1.2466, batch time: 0.07, accuracy:  60.16%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 1.4030, batch time: 0.18, accuracy:  50.00%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 1.3790, batch time: 0.18, accuracy:  47.66%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 1.2366, batch time: 0.16, accuracy:  56.25%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 8.518664360046387, accuracy: 12.7 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 1.3822976350784302, accuracy: 53.4 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 8.630489349365234, accuracy: 21.7 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 1.4221550226211548, accuracy: 51.0 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 4.787569522857666, accuracy: 23.4 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 5.463119029998779, accuracy: 15.5 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 2.2790067195892334, accuracy: 23.0 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 1.4183317422866821, accuracy: 49.7 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 1.459269404411316, accuracy: 48.3 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 1.3705649375915527, accuracy: 52.4 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 1.3601, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 1.3794, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 1.3893, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 1.4603, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 1.3133, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 1.4016, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 1.4915, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 1.1959, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 1.5205, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 1.4442, batch time: 0.15, accuracy:  50.78%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 9.599770545959473, accuracy: 11.9 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 1.3993808031082153, accuracy: 52.7 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 8.112344741821289, accuracy: 22.0 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 1.841678500175476, accuracy: 44.0 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 2.243220329284668, accuracy: 32.4 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 3.265322685241699, accuracy: 25.9 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 1.9132184982299805, accuracy: 34.3 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 1.9982558488845825, accuracy: 42.0 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 2.0166146755218506, accuracy: 34.4 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 1.895941138267517, accuracy: 35.5 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 1.3992, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 1.5042, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 1.3232, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 1.2396, batch time: 0.07, accuracy:  60.16%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 1.3230, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 1.3630, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 1.4615, batch time: 0.12, accuracy:  46.09%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 1.4961, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 1.3174, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 1.5473, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 9.11681079864502, accuracy: 11.5 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 1.3698558807373047, accuracy: 53.1 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 8.450566291809082, accuracy: 20.1 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 1.9587557315826416, accuracy: 42.1 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 1.9742977619171143, accuracy: 43.8 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 1.668742299079895, accuracy: 46.6 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 1.3522571325302124, accuracy: 55.0 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 2.8520610332489014, accuracy: 26.6 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 1.3697865009307861, accuracy: 51.9 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 1.455403208732605, accuracy: 48.0 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 1.2167, batch time: 0.07, accuracy:  59.38%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 1.4248, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 1.6254, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 1.4247, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 1.3422, batch time: 0.15, accuracy:  53.12%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 1.3573, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 1.2711, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 1.5668, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 1.3980, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 1.4223, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 10.225828170776367, accuracy: 13.0 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 1.349019169807434, accuracy: 53.6 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 8.794746398925781, accuracy: 23.1 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 1.969734787940979, accuracy: 41.6 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 2.6585123538970947, accuracy: 35.8 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 2.1426427364349365, accuracy: 32.1 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 2.1707921028137207, accuracy: 31.1 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 1.3418000936508179, accuracy: 53.0 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 1.5456063747406006, accuracy: 45.1 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 1.5131566524505615, accuracy: 48.0 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 1.3432, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 1.4117, batch time: 0.16, accuracy:  50.00%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 1.3134, batch time: 0.15, accuracy:  54.69%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 1.4009, batch time: 0.16, accuracy:  50.78%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 1.2924, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 1.4327, batch time: 0.18, accuracy:  46.09%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 1.4868, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 1.3088, batch time: 0.16, accuracy:  51.56%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 1.4104, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 1.2688, batch time: 0.18, accuracy:  61.72%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 9.398517608642578, accuracy: 12.7 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 1.3599731922149658, accuracy: 55.6 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 8.598435401916504, accuracy: 21.0 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 1.8752533197402954, accuracy: 46.0 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 2.2726738452911377, accuracy: 32.7 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 2.128324508666992, accuracy: 39.3 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 1.5295183658599854, accuracy: 47.3 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 2.8848299980163574, accuracy: 35.5 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 1.3398785591125488, accuracy: 56.0 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 1.476129412651062, accuracy: 48.4 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 1.2565, batch time: 0.07, accuracy:  60.94%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 1.3512, batch time: 0.07, accuracy:  58.59%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 1.2917, batch time: 0.15, accuracy:  57.81%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 1.3920, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 1.3480, batch time: 0.18, accuracy:  51.56%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 1.2688, batch time: 0.18, accuracy:  62.50%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 1.2281, batch time: 0.16, accuracy:  60.16%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 1.2641, batch time: 0.18, accuracy:  60.94%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 1.6845, batch time: 0.15, accuracy:  47.66%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 1.3094, batch time: 0.18, accuracy:  54.69%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 10.74301815032959, accuracy: 11.7 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 1.4042915105819702, accuracy: 52.2 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 9.366280555725098, accuracy: 20.7 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 1.5237305164337158, accuracy: 49.0 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 1.8746551275253296, accuracy: 34.2 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 1.359368920326233, accuracy: 53.6 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 1.6512826681137085, accuracy: 43.5 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 2.2001209259033203, accuracy: 32.8 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 1.8234320878982544, accuracy: 44.4 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 1.575015902519226, accuracy: 47.2 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 1.4738, batch time: 0.18, accuracy:  51.56%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 1.2758, batch time: 0.18, accuracy:  51.56%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 1.3395, batch time: 0.18, accuracy:  53.91%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 1.4076, batch time: 0.17, accuracy:  53.12%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 1.2837, batch time: 0.18, accuracy:  57.03%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 1.4564, batch time: 0.18, accuracy:  52.34%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 1.1694, batch time: 0.17, accuracy:  57.81%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 1.4830, batch time: 0.15, accuracy:  53.12%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 1.3478, batch time: 0.16, accuracy:  60.94%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 1.2796, batch time: 0.18, accuracy:  56.25%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 8.908429145812988, accuracy: 11.6 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 1.3615143299102783, accuracy: 53.7 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 8.907118797302246, accuracy: 21.6 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 1.7898449897766113, accuracy: 42.9 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 2.2846646308898926, accuracy: 34.5 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 1.7849642038345337, accuracy: 39.3 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 1.7213244438171387, accuracy: 40.9 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 1.3481813669204712, accuracy: 54.4 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 1.3809746503829956, accuracy: 51.8 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 1.378507375717163, accuracy: 53.5 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 1.2887, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 1.3970, batch time: 0.15, accuracy:  56.25%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 1.3826, batch time: 0.16, accuracy:  61.72%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 1.2683, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 1.3649, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 1.1758, batch time: 0.07, accuracy:  61.72%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 1.4974, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 1.4296, batch time: 0.15, accuracy:  46.88%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 1.3910, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 1.4211, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 7.739757537841797, accuracy: 11.1 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 1.437032699584961, accuracy: 49.5 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 6.688009262084961, accuracy: 21.2 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 1.4547699689865112, accuracy: 48.8 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 2.54789400100708, accuracy: 34.8 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 1.9619507789611816, accuracy: 42.2 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 8.33326530456543, accuracy: 11.1 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 2.9853649139404297, accuracy: 24.8 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 1.4275795221328735, accuracy: 53.9 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 1.6349749565124512, accuracy: 44.5 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 1.3759, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 1.4016, batch time: 0.07, accuracy:  58.59%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 1.6236, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 1.4069, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 1.4954, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 1.3739, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 1.3473, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 1.3967, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 1.3306, batch time: 0.15, accuracy:  58.59%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 1.4168, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 8.647171974182129, accuracy: 11.2 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 1.4455575942993164, accuracy: 51.8 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 6.7079081535339355, accuracy: 21.6 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 1.5160304307937622, accuracy: 48.6 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 4.61474084854126, accuracy: 22.0 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 1.5404636859893799, accuracy: 48.9 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 2.064911127090454, accuracy: 40.6 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 1.7176527976989746, accuracy: 47.4 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 1.449299931526184, accuracy: 53.5 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 2.052854061126709, accuracy: 33.5 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 1.3188, batch time: 0.17, accuracy:  54.69%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 1.2552, batch time: 0.18, accuracy:  57.81%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 1.4307, batch time: 0.17, accuracy:  51.56%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 1.5019, batch time: 0.15, accuracy:  44.53%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 1.2592, batch time: 0.15, accuracy:  60.16%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 1.3629, batch time: 0.15, accuracy:  49.22%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 1.3460, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 1.2138, batch time: 0.16, accuracy:  60.94%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 1.3864, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 1.3926, batch time: 0.15, accuracy:  49.22%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 7.940761566162109, accuracy: 11.3 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 1.418135404586792, accuracy: 49.6 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 7.226656913757324, accuracy: 20.8 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 1.3953334093093872, accuracy: 50.9 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 4.563780784606934, accuracy: 22.1 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 1.4941949844360352, accuracy: 47.0 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 2.1228599548339844, accuracy: 37.9 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 1.534902811050415, accuracy: 45.6 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 1.541803240776062, accuracy: 41.0 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 1.4214704036712646, accuracy: 49.4 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 1.2989, batch time: 0.07, accuracy:  60.94%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 1.3530, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 1.4340, batch time: 0.07, accuracy:  58.59%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 1.3904, batch time: 0.07, accuracy:  57.81%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 1.4197, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 1.3305, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 1.3374, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 1.4899, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 1.3617, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 1.4507, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 8.62453842163086, accuracy: 11.5 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 1.396983027458191, accuracy: 53.5 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 7.8188676834106445, accuracy: 20.5 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 1.6074755191802979, accuracy: 47.3 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 1.6177200078964233, accuracy: 42.0 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 1.393083930015564, accuracy: 53.2 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 1.8733720779418945, accuracy: 39.7 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 1.6167504787445068, accuracy: 41.3 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 1.753912091255188, accuracy: 42.3 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 3.2894790172576904, accuracy: 26.7 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 1.2581, batch time: 0.07, accuracy:  60.94%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 1.2268, batch time: 0.07, accuracy:  59.38%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 1.4414, batch time: 0.16, accuracy:  47.66%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 1.2459, batch time: 0.07, accuracy:  59.38%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 1.2723, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 1.5018, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 1.3947, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 1.3967, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 1.3402, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 1.4050, batch time: 0.15, accuracy:  56.25%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 7.615492343902588, accuracy: 14.1 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 1.4075011014938354, accuracy: 51.0 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 7.8522210121154785, accuracy: 20.7 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 1.3479158878326416, accuracy: 53.9 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 2.207066059112549, accuracy: 32.3 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 1.3479158878326416, accuracy: 53.9 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 2.1522114276885986, accuracy: 29.3 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 2.24397349357605, accuracy: 33.4 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 2.946997880935669, accuracy: 28.0 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 1.343172550201416, accuracy: 52.6 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 1.7492, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 1.4291, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 1.3990, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 1.2985, batch time: 0.15, accuracy:  57.81%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 1.4252, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 1.4050, batch time: 0.31, accuracy:  53.12%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 1.2997, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 1.4379, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 1.3914, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 1.3743, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 8.430468559265137, accuracy: 11.5 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 1.3816936016082764, accuracy: 52.6 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 9.185248374938965, accuracy: 19.3 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 1.6055293083190918, accuracy: 48.6 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 2.535104990005493, accuracy: 31.6 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 1.8956685066223145, accuracy: 37.0 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 2.885021209716797, accuracy: 42.7 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 3.5311520099639893, accuracy: 26.5 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 1.4612723588943481, accuracy: 50.3 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 1.390384316444397, accuracy: 52.2 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 1.4724, batch time: 0.15, accuracy:  50.00%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 1.3801, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 1.3779, batch time: 0.07, accuracy:  61.72%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 1.2989, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 1.3454, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 1.5456, batch time: 0.15, accuracy:  46.09%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 1.4740, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 1.2541, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 1.4994, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 1.5202, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 7.979430675506592, accuracy: 12.6 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 1.3814723491668701, accuracy: 53.5 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 9.047821044921875, accuracy: 21.9 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 1.96034574508667, accuracy: 35.9 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 2.033675193786621, accuracy: 35.5 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 1.9989029169082642, accuracy: 34.9 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 1.6254252195358276, accuracy: 42.3 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 2.08955979347229, accuracy: 34.3 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 1.393822193145752, accuracy: 52.7 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 1.4000663757324219, accuracy: 53.4 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 1.3812, batch time: 0.15, accuracy:  53.12%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 1.3219, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 1.2331, batch time: 0.15, accuracy:  60.16%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 1.5264, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 1.5720, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 1.3043, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 1.4092, batch time: 0.16, accuracy:  53.91%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 1.3188, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 1.5465, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 1.4979, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 7.658069133758545, accuracy: 13.9 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 1.3790507316589355, accuracy: 52.4 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 9.927305221557617, accuracy: 22.8 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 1.9285386800765991, accuracy: 37.7 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 2.4250986576080322, accuracy: 31.4 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 1.8202035427093506, accuracy: 42.5 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 2.654770612716675, accuracy: 39.9 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 2.398334264755249, accuracy: 31.3 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 1.3567255735397339, accuracy: 53.4 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 1.537031888961792, accuracy: 46.2 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 1.3841, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 1.4842, batch time: 0.15, accuracy:  47.66%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 1.4174, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 1.3633, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 1.4913, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 1.5574, batch time: 0.15, accuracy:  48.44%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 1.2764, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 1.3117, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 1.3159, batch time: 0.15, accuracy:  56.25%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 1.4720, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 8.483297348022461, accuracy: 10.9 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 1.4058705568313599, accuracy: 51.7 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 11.03170108795166, accuracy: 18.2 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 2.1288387775421143, accuracy: 37.7 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 2.314704179763794, accuracy: 33.8 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 2.7217206954956055, accuracy: 35.9 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 1.6308847665786743, accuracy: 45.9 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 2.776214838027954, accuracy: 26.4 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 1.4271880388259888, accuracy: 53.2 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 1.3467386960983276, accuracy: 55.2 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 1.3542, batch time: 0.15, accuracy:  58.59%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 1.3757, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 1.3692, batch time: 0.15, accuracy:  54.69%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 1.4518, batch time: 0.12, accuracy:  51.56%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 1.4771, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 1.3624, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 1.5364, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 1.3088, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 1.2848, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 1.4571, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 10.308794021606445, accuracy: 11.8 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 1.329911708831787, accuracy: 56.6 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 11.456916809082031, accuracy: 22.2 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 1.8608133792877197, accuracy: 44.1 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 1.990848422050476, accuracy: 40.6 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 3.2410824298858643, accuracy: 28.0 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 2.425070285797119, accuracy: 35.4 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 1.6432782411575317, accuracy: 41.3 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 1.4369615316390991, accuracy: 54.4 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 1.3179051876068115, accuracy: 55.8 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 1.2414, batch time: 0.07, accuracy:  60.94%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 1.3431, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 1.2007, batch time: 0.15, accuracy:  63.28%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 1.3541, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 1.4401, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 1.3245, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 1.3447, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 1.3499, batch time: 0.15, accuracy:  64.06%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 1.2964, batch time: 0.14, accuracy:  58.59%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 1.3914, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 9.390292167663574, accuracy: 12.9 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 1.372841477394104, accuracy: 55.2 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 11.031883239746094, accuracy: 20.4 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 1.412972331047058, accuracy: 54.0 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 2.116929531097412, accuracy: 34.4 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 1.7188377380371094, accuracy: 42.6 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 2.9616105556488037, accuracy: 32.3 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 2.699587345123291, accuracy: 32.3 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 1.3138725757598877, accuracy: 55.9 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 1.2710707187652588, accuracy: 60.2 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 1.2470, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 1.3390, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 1.2862, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 1.4250, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 1.4011, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 1.3929, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 1.4507, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 1.3395, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 1.2516, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 1.2881, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 8.512290954589844, accuracy: 13.8 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 1.4252992868423462, accuracy: 52.5 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 9.04586410522461, accuracy: 22.4 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 1.7713595628738403, accuracy: 46.7 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 3.7313544750213623, accuracy: 17.7 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 1.5451054573059082, accuracy: 44.4 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 2.91549015045166, accuracy: 32.3 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 2.288651466369629, accuracy: 30.4 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 1.3760570287704468, accuracy: 54.4 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 1.3821861743927002, accuracy: 53.8 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 1.5842, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 1.4723, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 1.3501, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 1.3850, batch time: 0.18, accuracy:  50.00%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 1.1949, batch time: 0.15, accuracy:  56.25%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 1.2543, batch time: 0.15, accuracy:  60.16%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 1.3243, batch time: 0.31, accuracy:  56.25%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 1.4779, batch time: 0.13, accuracy:  52.34%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 1.2940, batch time: 0.15, accuracy:  59.38%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 1.5249, batch time: 0.15, accuracy:  51.56%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 10.224878311157227, accuracy: 11.1 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 1.36029851436615, accuracy: 56.2 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 11.07361888885498, accuracy: 21.5 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 1.662522554397583, accuracy: 44.1 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 5.95884370803833, accuracy: 14.6 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 1.3335833549499512, accuracy: 56.7 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 3.354250192642212, accuracy: 25.8 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 1.352997899055481, accuracy: 56.1 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 1.3249443769454956, accuracy: 57.0 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 1.3695985078811646, accuracy: 54.0 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 1.3194, batch time: 0.07, accuracy:  57.81%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 1.4824, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 1.4425, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 1.2942, batch time: 0.07, accuracy:  60.16%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 1.2568, batch time: 0.14, accuracy:  57.81%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 1.3498, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 1.3193, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 1.3672, batch time: 0.14, accuracy:  60.94%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 1.2717, batch time: 0.14, accuracy:  57.81%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 1.5333, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 9.970741271972656, accuracy: 12.4 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 1.351853847503662, accuracy: 54.6 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 10.527263641357422, accuracy: 21.3 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 1.6259219646453857, accuracy: 47.3 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 1.5748032331466675, accuracy: 49.7 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 2.1931982040405273, accuracy: 35.9 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 1.6542131900787354, accuracy: 46.6 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 2.0744972229003906, accuracy: 33.0 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 2.7105460166931152, accuracy: 29.8 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 1.7598406076431274, accuracy: 46.2 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 1.3057, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 1.4441, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 1.4495, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 1.2668, batch time: 0.06, accuracy:  62.50%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 1.3773, batch time: 0.07, accuracy:  60.16%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 1.4027, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 1.3001, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 1.3354, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 1.4856, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 1.2843, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 9.300119400024414, accuracy: 12.6 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 1.3244751691818237, accuracy: 54.4 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 8.873538970947266, accuracy: 20.9 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 1.6097042560577393, accuracy: 46.5 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 3.090442180633545, accuracy: 27.9 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 3.0198867321014404, accuracy: 26.8 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 2.0636672973632812, accuracy: 38.7 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 2.118926763534546, accuracy: 27.9 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 1.2975330352783203, accuracy: 54.9 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 1.3038100004196167, accuracy: 53.8 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 1.3039, batch time: 0.14, accuracy:  57.81%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 1.3779, batch time: 0.06, accuracy:  61.72%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 1.4963, batch time: 0.15, accuracy:  49.22%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 1.3123, batch time: 0.14, accuracy:  55.47%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 1.3851, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 1.3256, batch time: 0.15, accuracy:  62.50%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 1.1512, batch time: 0.06, accuracy:  61.72%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 1.3064, batch time: 0.12, accuracy:  52.34%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 1.4271, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 1.4211, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 9.302447319030762, accuracy: 12.7 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 1.3764655590057373, accuracy: 54.9 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 9.702780723571777, accuracy: 22.4 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 1.7621464729309082, accuracy: 42.6 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 3.1894009113311768, accuracy: 26.2 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 2.387255907058716, accuracy: 26.1 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 1.8433239459991455, accuracy: 41.4 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 2.6102733612060547, accuracy: 29.0 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 1.4288722276687622, accuracy: 50.7 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 1.4121159315109253, accuracy: 53.2 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 1.2554, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 1.4003, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 1.2768, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 1.4327, batch time: 0.08, accuracy:  48.44%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 1.3105, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 1.3968, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 1.3172, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 1.2151, batch time: 0.06, accuracy:  63.28%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 1.4164, batch time: 0.14, accuracy:  53.91%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 1.3576, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 9.848788261413574, accuracy: 11.0 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 1.3653720617294312, accuracy: 55.3 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 9.959121704101562, accuracy: 20.7 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 1.660415768623352, accuracy: 48.1 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 1.6457161903381348, accuracy: 49.2 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 2.247760057449341, accuracy: 38.2 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 1.4339810609817505, accuracy: 50.1 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 2.348228931427002, accuracy: 30.9 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 1.752659797668457, accuracy: 41.6 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 1.4985328912734985, accuracy: 47.2 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 1.4716, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 1.3396, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 1.3208, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 1.4655, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 1.3454, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 1.3734, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 1.2900, batch time: 0.06, accuracy:  61.72%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 1.4802, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 1.1987, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 1.3908, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 10.182109832763672, accuracy: 12.5 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 1.347173810005188, accuracy: 56.6 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 10.670860290527344, accuracy: 20.3 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 1.70414400100708, accuracy: 44.2 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 1.6634674072265625, accuracy: 48.5 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 2.277772903442383, accuracy: 35.8 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 1.8580049276351929, accuracy: 43.5 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 2.801539421081543, accuracy: 23.1 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 2.272960662841797, accuracy: 35.4 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 1.3427730798721313, accuracy: 56.4 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 1.4317, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 1.4063, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 1.4790, batch time: 0.12, accuracy:  48.44%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 1.1115, batch time: 0.06, accuracy:  61.72%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 1.3556, batch time: 0.15, accuracy:  52.34%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 1.3464, batch time: 0.15, accuracy:  56.25%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 1.4215, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 1.4188, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 1.1477, batch time: 0.15, accuracy:  62.50%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 1.4204, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 9.307467460632324, accuracy: 12.7 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 1.381269097328186, accuracy: 53.4 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 9.719317436218262, accuracy: 21.8 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 1.7364798784255981, accuracy: 44.5 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 3.4888954162597656, accuracy: 24.7 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 1.4526755809783936, accuracy: 49.7 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 1.9521534442901611, accuracy: 35.0 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 2.5865318775177, accuracy: 24.4 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 1.7629978656768799, accuracy: 40.5 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 1.879608154296875, accuracy: 43.8 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 1.2463, batch time: 0.14, accuracy:  58.59%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 1.2370, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 1.4303, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 1.3090, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 1.2630, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 1.2799, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 1.2719, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 1.2307, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 1.3487, batch time: 0.30, accuracy:  53.91%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 1.3746, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 9.940568923950195, accuracy: 11.4 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 1.3688197135925293, accuracy: 53.3 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 10.52454948425293, accuracy: 20.3 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 1.6813629865646362, accuracy: 46.8 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 1.6226613521575928, accuracy: 49.0 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 2.184065103530884, accuracy: 35.1 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 2.0201220512390137, accuracy: 39.4 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 1.621370792388916, accuracy: 42.7 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 4.147578716278076, accuracy: 29.0 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 1.4902012348175049, accuracy: 49.9 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 1.4637, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 1.4022, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 1.3800, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 1.4058, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 1.4799, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 1.3851, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 1.3127, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 1.2752, batch time: 0.06, accuracy:  60.94%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 1.2450, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 1.4731, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 9.664392471313477, accuracy: 10.7 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 1.387170672416687, accuracy: 53.9 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 9.560770034790039, accuracy: 19.4 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 1.689847707748413, accuracy: 48.7 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 3.30539870262146, accuracy: 24.1 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 2.700745105743408, accuracy: 27.3 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 2.223557949066162, accuracy: 36.4 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 3.879603862762451, accuracy: 15.3 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 1.6330127716064453, accuracy: 46.8 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 1.3771557807922363, accuracy: 53.5 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 1.2065, batch time: 0.06, accuracy:  65.62%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 1.3557, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 1.3286, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 1.5165, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 1.2929, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 1.3406, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 1.3279, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 1.3645, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 1.2466, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 1.3680, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 10.338210105895996, accuracy: 12.0 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 1.3681341409683228, accuracy: 53.3 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 10.323410987854004, accuracy: 21.2 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 1.666167140007019, accuracy: 45.0 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 1.6055808067321777, accuracy: 47.6 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 2.3198013305664062, accuracy: 33.9 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 1.5419832468032837, accuracy: 45.6 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 1.801320195198059, accuracy: 41.5 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 2.0036070346832275, accuracy: 40.7 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 1.4058442115783691, accuracy: 52.1 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 1.2388, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 1.4357, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 1.3806, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 1.2958, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 1.3872, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 1.4542, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 1.4039, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 1.3939, batch time: 0.06, accuracy:  46.09%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 1.2338, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 1.4748, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 9.12377643585205, accuracy: 11.8 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 1.3331420421600342, accuracy: 56.3 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 9.95077896118164, accuracy: 19.6 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 1.6170129776000977, accuracy: 48.4 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 3.409263849258423, accuracy: 24.3 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 2.5166804790496826, accuracy: 31.8 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 1.8898745775222778, accuracy: 44.5 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 1.7050209045410156, accuracy: 40.9 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 1.3267055749893188, accuracy: 56.8 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 1.388329267501831, accuracy: 50.9 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 1.3552, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 1.1076, batch time: 0.06, accuracy:  64.06%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 1.2537, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 1.3704, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 1.3266, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 1.4918, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 1.4122, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 1.4851, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 1.3747, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 1.4440, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 8.788366317749023, accuracy: 12.6 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 1.45337975025177, accuracy: 51.7 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 9.874293327331543, accuracy: 19.5 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 5.105693340301514, accuracy: 16.4 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 1.5665663480758667, accuracy: 46.1 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 2.0686447620391846, accuracy: 34.7 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 1.8240344524383545, accuracy: 40.4 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 2.3175363540649414, accuracy: 33.2 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 1.414534330368042, accuracy: 52.8 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 1.519343614578247, accuracy: 48.6 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 1.2967, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 1.4188, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 1.4792, batch time: 0.06, accuracy:  46.09%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 1.2845, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 1.5168, batch time: 0.06, accuracy:  46.88%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 1.2993, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 1.3336, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 1.4620, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 1.3314, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 1.4364, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 8.106958389282227, accuracy: 12.7 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 1.3973077535629272, accuracy: 52.2 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 8.815438270568848, accuracy: 22.7 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 1.736889362335205, accuracy: 39.5 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 1.615111231803894, accuracy: 45.9 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 1.3838648796081543, accuracy: 53.6 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 1.5058625936508179, accuracy: 50.9 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 1.497678518295288, accuracy: 48.4 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 1.4296176433563232, accuracy: 51.0 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 1.4631038904190063, accuracy: 49.8 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 1.3987, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 1.3533, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 1.5455, batch time: 0.06, accuracy:  45.31%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 1.2786, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 1.4247, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 1.3487, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 1.1988, batch time: 0.06, accuracy:  63.28%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 1.2665, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 1.5234, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 1.3737, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 7.229113578796387, accuracy: 13.0 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 1.434058427810669, accuracy: 53.4 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 8.057015419006348, accuracy: 21.0 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 1.6644095182418823, accuracy: 46.7 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 1.611863136291504, accuracy: 48.1 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 2.5466089248657227, accuracy: 23.8 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 2.0846753120422363, accuracy: 35.4 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 2.023286819458008, accuracy: 38.9 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 1.5079786777496338, accuracy: 48.8 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 1.4539690017700195, accuracy: 51.2 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 1.2503, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 1.4258, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 1.2541, batch time: 0.06, accuracy:  63.28%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 1.3079, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 1.4475, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 1.3522, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 1.5419, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 1.2398, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 1.4617, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 1.3627, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 7.567201137542725, accuracy: 13.7 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 1.3748453855514526, accuracy: 52.9 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 8.322510719299316, accuracy: 22.1 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 1.621277928352356, accuracy: 48.8 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 2.6294069290161133, accuracy: 28.9 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 2.4555914402008057, accuracy: 29.2 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 2.0094549655914307, accuracy: 37.9 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 2.350750684738159, accuracy: 24.0 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 1.4639869928359985, accuracy: 47.9 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 4.036011695861816, accuracy: 18.6 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 1.4659, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 1.2730, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 1.3119, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 1.3983, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 1.2879, batch time: 0.06, accuracy:  63.28%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 1.5257, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 1.2503, batch time: 0.06, accuracy:  63.28%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 1.3125, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 1.3085, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 1.2788, batch time: 0.06, accuracy:  61.72%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 6.780277252197266, accuracy: 13.7 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 1.351538896560669, accuracy: 54.9 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 7.703188419342041, accuracy: 22.6 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 1.5711838006973267, accuracy: 50.4 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 1.5299075841903687, accuracy: 52.0 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 2.284327745437622, accuracy: 37.6 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 1.8757450580596924, accuracy: 43.0 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 2.1052491664886475, accuracy: 39.9 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 1.360431432723999, accuracy: 54.3 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 1.3854498863220215, accuracy: 54.3 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 1.5583, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 1.4401, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 1.2756, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 1.4721, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 1.3573, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 1.2478, batch time: 0.06, accuracy:  63.28%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 1.4961, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 1.3230, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 1.2186, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 1.4667, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 7.0179829597473145, accuracy: 12.1 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 1.4031387567520142, accuracy: 56.1 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 7.720462799072266, accuracy: 20.4 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 1.6969809532165527, accuracy: 48.0 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 1.6596102714538574, accuracy: 50.8 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 2.3751308917999268, accuracy: 27.5 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 1.9343284368515015, accuracy: 37.4 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 1.9978281259536743, accuracy: 38.6 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 1.398040533065796, accuracy: 55.7 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 1.4030834436416626, accuracy: 54.8 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 1.1910, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 1.4794, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 1.2280, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 1.4106, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 1.3902, batch time: 0.06, accuracy:  46.88%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 1.3459, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 1.3648, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 1.3136, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 1.3331, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 1.4505, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 6.7786030769348145, accuracy: 12.4 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 1.3615978956222534, accuracy: 53.8 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 6.435731887817383, accuracy: 22.4 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 1.4634023904800415, accuracy: 49.9 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 4.257762432098389, accuracy: 24.3 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 1.6123020648956299, accuracy: 45.4 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 1.8074800968170166, accuracy: 40.5 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 2.1551673412323, accuracy: 39.8 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 1.3436018228530884, accuracy: 54.6 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 1.3633681535720825, accuracy: 52.2 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 1.3402, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 1.3775, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 1.3553, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 1.4729, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 1.3307, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 1.2820, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 1.4276, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 1.3178, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 1.4337, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 1.5522, batch time: 0.06, accuracy:  46.09%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 6.942595481872559, accuracy: 11.7 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 1.450476884841919, accuracy: 53.2 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 7.109534740447998, accuracy: 22.2 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 1.857224702835083, accuracy: 42.6 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 1.8567200899124146, accuracy: 43.7 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 2.5216078758239746, accuracy: 26.4 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 2.0649242401123047, accuracy: 34.7 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 1.8696786165237427, accuracy: 41.7 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 1.444169521331787, accuracy: 52.4 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 1.423377513885498, accuracy: 54.1 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 1.4789, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 1.4878, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 1.3146, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 1.3384, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 1.3840, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 1.3267, batch time: 0.06, accuracy:  63.28%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 1.2947, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 1.4745, batch time: 0.06, accuracy:  42.97%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 1.3910, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 1.4316, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 6.293578624725342, accuracy: 13.0 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 1.4414236545562744, accuracy: 50.1 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 7.2278852462768555, accuracy: 22.7 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 2.0382816791534424, accuracy: 33.6 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 1.6169400215148926, accuracy: 45.6 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 1.9245710372924805, accuracy: 41.8 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 1.4898648262023926, accuracy: 45.1 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 1.9253419637680054, accuracy: 41.7 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 1.396707534790039, accuracy: 52.4 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 1.3978278636932373, accuracy: 52.5 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 1.4576, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 1.5666, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 1.3948, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 1.2467, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 1.1343, batch time: 0.06, accuracy:  62.50%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 1.4211, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 1.3416, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 1.4447, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 1.5511, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 1.3189, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 7.130572319030762, accuracy: 11.8 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 1.4139044284820557, accuracy: 54.6 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 7.450860977172852, accuracy: 21.5 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 1.6706748008728027, accuracy: 43.0 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 1.8908089399337769, accuracy: 40.1 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 1.6138546466827393, accuracy: 46.0 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 2.5740957260131836, accuracy: 34.4 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 1.8307076692581177, accuracy: 40.2 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 1.4075648784637451, accuracy: 53.7 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 1.4054999351501465, accuracy: 54.5 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 1.4339, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 1.5148, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 1.5071, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 1.5808, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 1.4995, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 1.3003, batch time: 0.06, accuracy:  61.72%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 1.3320, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 1.4419, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 1.4242, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 1.2584, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 7.379867076873779, accuracy: 13.1 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 1.3445706367492676, accuracy: 55.0 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 7.871385097503662, accuracy: 21.6 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 1.3445706367492676, accuracy: 55.0 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 1.5896533727645874, accuracy: 46.7 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 1.8529303073883057, accuracy: 36.8 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 1.7747057676315308, accuracy: 39.1 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 2.0480947494506836, accuracy: 32.8 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 1.3629566431045532, accuracy: 53.3 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 1.31672203540802, accuracy: 55.7 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 1.5791, batch time: 0.06, accuracy:  39.06%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 1.2925, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 1.3613, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 1.2243, batch time: 0.06, accuracy:  61.72%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 1.4969, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 1.3651, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 1.2843, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 1.3949, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 1.2826, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 1.3492, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 8.27991008758545, accuracy: 13.6 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 1.3538438081741333, accuracy: 57.2 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 7.023934364318848, accuracy: 24.1 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 3.4687094688415527, accuracy: 19.3 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 2.4967520236968994, accuracy: 29.0 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 1.6842049360275269, accuracy: 45.7 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 1.386776089668274, accuracy: 56.5 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 2.235029935836792, accuracy: 36.3 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 1.3524675369262695, accuracy: 55.1 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 1.3513978719711304, accuracy: 55.5 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 1.3152, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 1.3427, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 1.4170, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 1.1921, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 1.4071, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 1.3403, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 1.3319, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 1.4503, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 1.3615, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 1.4531, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 7.690682888031006, accuracy: 12.5 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 1.4401637315750122, accuracy: 52.1 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 6.63423490524292, accuracy: 21.1 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 1.7576769590377808, accuracy: 44.0 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 2.056011438369751, accuracy: 36.2 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 2.004188060760498, accuracy: 36.8 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 1.6564364433288574, accuracy: 45.7 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 2.2572691440582275, accuracy: 31.0 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 1.5287206172943115, accuracy: 48.6 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 1.4128224849700928, accuracy: 54.5 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 1.3221, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 1.5649, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 1.4166, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 1.3840, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 1.5092, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 1.3604, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 1.4079, batch time: 0.06, accuracy:  46.09%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 1.1616, batch time: 0.06, accuracy:  61.72%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 1.3322, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 1.5751, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 7.597079277038574, accuracy: 12.5 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 1.3812044858932495, accuracy: 55.1 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 7.719028949737549, accuracy: 20.3 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 1.7877651453018188, accuracy: 43.3 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 1.9801677465438843, accuracy: 41.7 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 1.466989278793335, accuracy: 49.7 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 2.5981154441833496, accuracy: 31.6 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 1.3888286352157593, accuracy: 52.3 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 1.4101214408874512, accuracy: 51.7 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 1.5494511127471924, accuracy: 48.5 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 1.2124, batch time: 0.06, accuracy:  62.50%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 1.4973, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 1.3694, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 1.4735, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 1.4003, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 1.3844, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 1.2756, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 1.2424, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 1.2577, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 1.1852, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 8.20821475982666, accuracy: 12.3 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 1.395095705986023, accuracy: 51.0 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 8.08996868133545, accuracy: 21.1 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 1.8009417057037354, accuracy: 40.1 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 1.9746472835540771, accuracy: 39.2 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 1.4280128479003906, accuracy: 49.3 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 2.57029128074646, accuracy: 32.7 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 1.93434739112854, accuracy: 35.9 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 1.4145596027374268, accuracy: 49.4 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 1.400864601135254, accuracy: 51.8 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 1.2558, batch time: 0.06, accuracy:  60.94%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 1.3341, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 1.3279, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 1.3106, batch time: 0.06, accuracy:  60.94%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 1.4495, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 1.3924, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 1.5298, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 1.4189, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 1.2590, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 1.4056, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 7.147711753845215, accuracy: 11.2 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 1.3732414245605469, accuracy: 54.4 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 7.399397850036621, accuracy: 19.8 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 1.7507575750350952, accuracy: 43.4 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 1.9405601024627686, accuracy: 37.8 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 1.4209730625152588, accuracy: 49.8 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 2.7237539291381836, accuracy: 30.6 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 1.3976682424545288, accuracy: 51.4 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 1.4922987222671509, accuracy: 46.9 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 1.4964983463287354, accuracy: 48.5 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 1.2936, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 1.3884, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 1.2878, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 1.3612, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 1.4431, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 1.2614, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 1.3188, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 1.4232, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 1.2982, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 1.2918, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 7.008108139038086, accuracy: 12.0 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 1.3581355810165405, accuracy: 54.7 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 7.499227523803711, accuracy: 18.6 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 1.6424140930175781, accuracy: 43.9 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 1.9372143745422363, accuracy: 41.1 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 1.4429700374603271, accuracy: 49.7 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 2.7852914333343506, accuracy: 30.5 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 1.3571571111679077, accuracy: 53.2 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 1.3577375411987305, accuracy: 54.4 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 1.3513710498809814, accuracy: 54.0 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 1.3625, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 1.2284, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 1.5975, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 1.5994, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 1.4174, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 1.4014, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 1.5490, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 1.3066, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 1.5001, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 1.4684, batch time: 0.06, accuracy:  46.09%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 7.425914287567139, accuracy: 12.5 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 1.4346563816070557, accuracy: 49.9 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 7.772571563720703, accuracy: 18.5 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 1.7370797395706177, accuracy: 44.2 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 2.3118343353271484, accuracy: 36.4 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 1.4999140501022339, accuracy: 50.8 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 2.9993085861206055, accuracy: 31.1 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 5.952703952789307, accuracy: 12.7 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 1.4574940204620361, accuracy: 50.0 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 1.3935599327087402, accuracy: 54.6 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 1.5386, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 1.2822, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 1.4765, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 1.3954, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 1.3097, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 1.4828, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 1.3795, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 1.1995, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 1.4894, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 1.3489, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 7.3338117599487305, accuracy: 13.1 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 1.340281367301941, accuracy: 57.6 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 7.062019348144531, accuracy: 23.2 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 1.6820683479309082, accuracy: 44.9 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 2.9449825286865234, accuracy: 22.2 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 1.3216612339019775, accuracy: 57.0 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 1.5853546857833862, accuracy: 42.0 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 1.3391391038894653, accuracy: 56.8 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 1.5362660884857178, accuracy: 47.4 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 1.3242900371551514, accuracy: 58.0 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 1.5310, batch time: 0.06, accuracy:  46.88%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 1.3771, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 1.6446, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 1.4110, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 1.4907, batch time: 0.06, accuracy:  44.53%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 1.3195, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 1.3819, batch time: 0.06, accuracy:  64.06%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 1.2501, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 1.2426, batch time: 0.06, accuracy:  60.94%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 1.4615, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 7.7871270179748535, accuracy: 12.0 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 1.4434494972229004, accuracy: 50.9 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 7.821139812469482, accuracy: 19.9 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 1.6789697408676147, accuracy: 46.5 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 2.2211763858795166, accuracy: 28.8 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 2.3767454624176025, accuracy: 28.6 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 1.6241748332977295, accuracy: 43.5 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 1.519445538520813, accuracy: 48.2 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 1.468861699104309, accuracy: 46.8 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 1.425217866897583, accuracy: 52.4 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 1.4792, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 1.4319, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 1.4272, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 1.4637, batch time: 0.06, accuracy:  42.97%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 1.4216, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 1.3570, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 1.3978, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 1.2850, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 1.1732, batch time: 0.06, accuracy:  63.28%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 1.3483, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 8.58608627319336, accuracy: 10.9 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 1.4030226469039917, accuracy: 52.8 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 7.763497829437256, accuracy: 18.7 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 1.9010591506958008, accuracy: 39.7 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 1.8281610012054443, accuracy: 42.6 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 1.9298691749572754, accuracy: 34.3 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 3.0815720558166504, accuracy: 34.3 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 1.4860600233078003, accuracy: 46.4 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 1.4611306190490723, accuracy: 49.4 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 1.512473225593567, accuracy: 48.4 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 1.6759, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 1.4394, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 1.4801, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 1.3244, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 1.3451, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 1.3829, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 1.4152, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 1.5813, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 1.3915, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 1.5623, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 8.112656593322754, accuracy: 12.9 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 1.3775644302368164, accuracy: 54.3 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 6.834643840789795, accuracy: 22.4 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 1.8401010036468506, accuracy: 40.4 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 1.9142751693725586, accuracy: 40.3 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 1.661070704460144, accuracy: 43.4 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 2.980868339538574, accuracy: 34.0 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 1.3967061042785645, accuracy: 53.6 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 1.4586760997772217, accuracy: 47.1 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 1.4133844375610352, accuracy: 52.5 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 1.1848, batch time: 0.06, accuracy:  66.41%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 1.4998, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 1.2664, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 1.2608, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 1.6376, batch time: 0.06, accuracy:  42.97%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 1.4585, batch time: 0.06, accuracy:  46.88%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 1.3178, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 1.6437, batch time: 0.06, accuracy:  44.53%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 1.5387, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 1.3264, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 7.734210968017578, accuracy: 13.4 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 1.4583019018173218, accuracy: 51.4 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 6.529606342315674, accuracy: 24.8 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 1.9353617429733276, accuracy: 42.4 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 2.154146909713745, accuracy: 29.1 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 1.6791633367538452, accuracy: 46.7 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 1.5535916090011597, accuracy: 46.2 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 2.693547248840332, accuracy: 34.1 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 1.4667202234268188, accuracy: 52.1 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 1.5142475366592407, accuracy: 45.2 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 1.3876, batch time: 0.06, accuracy:  42.97%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 1.4333, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 1.5055, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 1.2595, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 1.3393, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 1.5158, batch time: 0.06, accuracy:  44.53%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 1.5201, batch time: 0.06, accuracy:  44.53%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 1.2953, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 1.5369, batch time: 0.06, accuracy:  43.75%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 1.4372, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 8.022110939025879, accuracy: 13.1 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 1.3631837368011475, accuracy: 52.1 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 5.655737400054932, accuracy: 28.8 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 1.7156518697738647, accuracy: 45.8 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 2.2998769283294678, accuracy: 30.5 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 1.4495291709899902, accuracy: 49.1 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 2.8731508255004883, accuracy: 34.5 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 1.3604120016098022, accuracy: 51.0 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 1.362750768661499, accuracy: 49.0 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 1.4157296419143677, accuracy: 50.1 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 1.4755, batch time: 0.06, accuracy:  46.88%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 1.3485, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 1.4381, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 1.3823, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 1.2388, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 1.3879, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 1.3107, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 1.4621, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 1.3505, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 1.4679, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 8.022106170654297, accuracy: 12.6 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 1.3348309993743896, accuracy: 51.0 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 6.338527202606201, accuracy: 24.1 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 1.643162727355957, accuracy: 47.9 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 2.1207406520843506, accuracy: 32.3 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 1.6639838218688965, accuracy: 44.2 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 3.117499589920044, accuracy: 33.0 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 1.380491852760315, accuracy: 46.5 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 1.450469732284546, accuracy: 44.4 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 1.3044427633285522, accuracy: 57.1 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 1.4026, batch time: 0.06, accuracy:  42.97%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 1.3025, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 1.3934, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 1.4421, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 1.4794, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 1.3239, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 1.3873, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 1.6687, batch time: 0.06, accuracy:  39.06%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 1.3897, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 1.3772, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 8.004290580749512, accuracy: 13.2 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 1.3571109771728516, accuracy: 55.5 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 7.7036309242248535, accuracy: 21.4 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 1.688834547996521, accuracy: 46.0 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 1.8892689943313599, accuracy: 37.6 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 1.4293009042739868, accuracy: 52.5 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 2.826307535171509, accuracy: 33.6 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 1.3863954544067383, accuracy: 56.3 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 1.3537684679031372, accuracy: 54.9 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 1.3341262340545654, accuracy: 57.7 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 1.2889, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 1.3354, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 1.3592, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 1.3023, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 1.3820, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 1.4646, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 1.3671, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 1.4715, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 1.4239, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 1.3571, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 8.428437232971191, accuracy: 13.7 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 1.2982183694839478, accuracy: 56.4 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 8.383208274841309, accuracy: 21.2 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 1.754955530166626, accuracy: 45.6 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 1.9011274576187134, accuracy: 42.4 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 1.6263604164123535, accuracy: 45.6 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 2.8515138626098633, accuracy: 36.7 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 1.3004975318908691, accuracy: 57.2 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 1.3095519542694092, accuracy: 54.7 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 1.2827552556991577, accuracy: 56.6 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 1.4941, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 1.5019, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 1.4165, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 1.4221, batch time: 0.31, accuracy:  53.12%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 1.3128, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 1.2947, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 1.3435, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 1.3764, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 1.3863, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 1.4065, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 7.485208988189697, accuracy: 13.5 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 1.3735730648040771, accuracy: 53.4 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 8.10397720336914, accuracy: 21.8 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 1.6750041246414185, accuracy: 46.7 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 1.9514015913009644, accuracy: 39.6 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 1.977409839630127, accuracy: 37.2 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 2.769717216491699, accuracy: 35.5 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 1.3853354454040527, accuracy: 52.2 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 1.487941026687622, accuracy: 48.2 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 1.3729357719421387, accuracy: 54.9 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 1.3807, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 1.2702, batch time: 0.06, accuracy:  61.72%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 1.4136, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 1.4738, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 1.3400, batch time: 0.31, accuracy:  53.91%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 1.1489, batch time: 0.06, accuracy:  65.62%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 1.4523, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 1.2571, batch time: 0.06, accuracy:  65.62%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 1.3426, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 1.2452, batch time: 0.06, accuracy:  45.31%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 7.866541862487793, accuracy: 12.4 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 1.4055980443954468, accuracy: 51.1 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 7.831455230712891, accuracy: 17.1 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 1.8263671398162842, accuracy: 44.5 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 2.131068468093872, accuracy: 34.7 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 1.7800182104110718, accuracy: 35.6 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 2.7229397296905518, accuracy: 32.8 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 2.0627143383026123, accuracy: 37.2 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 1.446769118309021, accuracy: 47.1 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 1.4027057886123657, accuracy: 50.1 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 1.2861, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 1.2685, batch time: 0.06, accuracy:  62.50%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 1.3913, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 1.4476, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 1.3334, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 1.6037, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 1.3315, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 1.4581, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 1.3547, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 1.3511, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 8.396500587463379, accuracy: 13.5 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 1.32941472530365, accuracy: 52.8 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 9.43396282196045, accuracy: 20.5 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 1.585483193397522, accuracy: 47.1 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 3.269562005996704, accuracy: 29.0 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 1.7879395484924316, accuracy: 38.5 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 2.4826204776763916, accuracy: 32.2 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 1.3077183961868286, accuracy: 55.5 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 2.7129766941070557, accuracy: 32.7 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 1.311214566230774, accuracy: 55.5 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 1.4222, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 1.3787, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 1.3433, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 1.4123, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 1.4580, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 1.3019, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 1.3331, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 1.4983, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 1.2678, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 1.4399, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 8.003589630126953, accuracy: 12.7 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 1.303909420967102, accuracy: 54.3 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 8.536197662353516, accuracy: 20.0 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 1.5665521621704102, accuracy: 48.1 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 2.908836603164673, accuracy: 28.8 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 5.764796257019043, accuracy: 13.1 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 2.571734666824341, accuracy: 37.4 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 1.6303898096084595, accuracy: 47.4 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 1.4053544998168945, accuracy: 48.7 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 1.2968002557754517, accuracy: 55.5 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 1.3638, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 1.4139, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 1.2683, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 1.2602, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 1.4428, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 1.2342, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 1.2197, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 1.3520, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 1.2088, batch time: 0.06, accuracy:  62.50%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 1.2813, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 8.244772911071777, accuracy: 12.6 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 1.3032176494598389, accuracy: 57.5 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 8.744277954101562, accuracy: 20.2 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 1.614991307258606, accuracy: 47.8 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 1.5204026699066162, accuracy: 50.2 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 1.9151570796966553, accuracy: 41.9 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 1.5578235387802124, accuracy: 47.6 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 2.243811845779419, accuracy: 40.8 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 1.3342700004577637, accuracy: 57.0 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 1.430432915687561, accuracy: 47.0 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 1.3385, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 1.4408, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 1.3799, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 1.2809, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 1.3180, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 1.2641, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 1.1876, batch time: 0.06, accuracy:  61.72%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 1.2947, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 1.3187, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 1.2693, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 7.878722667694092, accuracy: 11.0 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 1.3166202306747437, accuracy: 54.3 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 8.267863273620605, accuracy: 18.4 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 1.590912938117981, accuracy: 48.6 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 5.51132345199585, accuracy: 19.0 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 1.7622737884521484, accuracy: 37.6 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 1.756008267402649, accuracy: 45.8 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 2.25504469871521, accuracy: 30.1 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 1.3212265968322754, accuracy: 54.0 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 1.3855353593826294, accuracy: 49.5 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 1.2821, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 1.3363, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 1.3886, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 1.5693, batch time: 0.06, accuracy:  42.97%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 1.3301, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 1.1543, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 1.3425, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 1.4827, batch time: 0.06, accuracy:  45.31%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 1.4941, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 1.2877, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 8.285979270935059, accuracy: 14.1 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 1.358087420463562, accuracy: 51.8 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 8.614774703979492, accuracy: 21.6 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 1.6786171197891235, accuracy: 45.2 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 1.893803358078003, accuracy: 41.0 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 2.1465439796447754, accuracy: 35.1 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 2.799401044845581, accuracy: 34.7 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 1.410969853401184, accuracy: 50.1 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 1.345379114151001, accuracy: 53.4 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 1.411906361579895, accuracy: 50.4 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 1.4790, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 1.2537, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 1.4170, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 1.3077, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 1.2985, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 1.3309, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 1.3754, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 1.2571, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 1.3323, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 1.2874, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 8.462919235229492, accuracy: 12.0 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 1.4478960037231445, accuracy: 47.8 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 8.79492473602295, accuracy: 19.4 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 1.6784348487854004, accuracy: 43.4 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 2.3480772972106934, accuracy: 38.0 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 2.276022434234619, accuracy: 42.4 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 1.961541771888733, accuracy: 47.4 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 2.651888370513916, accuracy: 29.2 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 1.384674310684204, accuracy: 51.2 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 1.4377105236053467, accuracy: 50.5 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 1.5065, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 1.4098, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 1.3138, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 1.2212, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 1.4609, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 1.4944, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 1.3453, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 1.1493, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 1.3037, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 1.3585, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 8.017291069030762, accuracy: 12.3 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 1.446725606918335, accuracy: 52.7 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 7.777667045593262, accuracy: 18.4 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 1.4892263412475586, accuracy: 49.2 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 5.4042134284973145, accuracy: 14.8 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 1.51984441280365, accuracy: 49.5 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 5.939220905303955, accuracy: 10.5 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 1.475838541984558, accuracy: 48.2 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 1.4072469472885132, accuracy: 53.5 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 1.376222014427185, accuracy: 51.4 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 1.2094, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 1.2377, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 1.2919, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 1.3099, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 1.4224, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 1.3674, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 1.5337, batch time: 0.06, accuracy:  44.53%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 1.2141, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 1.6113, batch time: 0.06, accuracy:  42.19%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 1.3786, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 7.144319534301758, accuracy: 13.3 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 1.3360244035720825, accuracy: 56.8 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 9.153099060058594, accuracy: 16.8 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 1.6576482057571411, accuracy: 47.3 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 1.963064193725586, accuracy: 42.1 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 1.3300598859786987, accuracy: 56.5 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 1.753958821296692, accuracy: 39.8 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 2.354529857635498, accuracy: 37.1 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 1.3361914157867432, accuracy: 56.0 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 1.3869843482971191, accuracy: 50.6 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 1.3697, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 1.3045, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 1.3277, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 1.3274, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 1.4200, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 1.3803, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 1.3295, batch time: 0.06, accuracy:  60.94%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 1.3596, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 1.5320, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 1.4014, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 6.964041233062744, accuracy: 12.7 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 1.3730665445327759, accuracy: 54.4 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 9.304887771606445, accuracy: 17.9 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 1.7315007448196411, accuracy: 45.2 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 1.6767323017120361, accuracy: 47.6 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 2.377636432647705, accuracy: 34.6 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 4.140138626098633, accuracy: 21.3 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 2.8440423011779785, accuracy: 26.8 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 1.3619194030761719, accuracy: 54.6 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 1.3879125118255615, accuracy: 50.9 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 1.1911, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 1.4448, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 1.2200, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 1.3241, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 1.2874, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 1.5420, batch time: 0.06, accuracy:  44.53%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 1.3936, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 1.4446, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 1.2598, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 1.2565, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 7.036900520324707, accuracy: 12.3 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 1.3162952661514282, accuracy: 56.3 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 8.858327865600586, accuracy: 19.1 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 1.6292328834533691, accuracy: 47.7 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 1.5324482917785645, accuracy: 51.2 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 2.053297519683838, accuracy: 33.0 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 3.4571855068206787, accuracy: 27.4 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 1.6867634057998657, accuracy: 44.0 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 1.3674323558807373, accuracy: 55.5 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 1.331669569015503, accuracy: 54.2 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 1.3097, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 1.2643, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 1.3906, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 1.3624, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 1.5474, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 1.4375, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 1.2827, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 1.4446, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 1.3875, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 1.2656, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 7.408668041229248, accuracy: 11.6 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 1.362763524055481, accuracy: 51.6 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 10.008040428161621, accuracy: 18.7 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 1.5654948949813843, accuracy: 46.3 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 2.3703160285949707, accuracy: 33.8 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 2.3372950553894043, accuracy: 33.5 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 2.6720476150512695, accuracy: 34.6 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 2.593214750289917, accuracy: 32.9 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 1.4140677452087402, accuracy: 48.9 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 1.4125308990478516, accuracy: 50.3 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 1.1231, batch time: 0.06, accuracy:  63.28%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 1.3805, batch time: 0.06, accuracy:  46.09%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 1.4299, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 1.1497, batch time: 0.06, accuracy:  60.94%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 1.5712, batch time: 0.06, accuracy:  46.88%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 1.3430, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 1.3738, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 1.3558, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 1.3806, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 1.3925, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 8.019380569458008, accuracy: 11.4 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 1.3709948062896729, accuracy: 51.3 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 9.076887130737305, accuracy: 18.9 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 1.5636260509490967, accuracy: 45.9 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 2.106365442276001, accuracy: 35.9 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 2.2887532711029053, accuracy: 33.6 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 2.3849740028381348, accuracy: 35.7 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 1.6183092594146729, accuracy: 44.8 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 1.3468070030212402, accuracy: 54.3 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 1.3637803792953491, accuracy: 51.5 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 1.3306, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 1.4314, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 1.4715, batch time: 0.06, accuracy:  45.31%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 1.2314, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 1.1871, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 1.1844, batch time: 0.06, accuracy:  61.72%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 1.2517, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 1.3666, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 1.3508, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 1.3601, batch time: 0.31, accuracy:  53.12%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 7.91967248916626, accuracy: 11.8 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 1.3792166709899902, accuracy: 50.6 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 9.587703704833984, accuracy: 20.3 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 2.17325758934021, accuracy: 39.5 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 2.2643470764160156, accuracy: 33.4 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 2.494964361190796, accuracy: 31.6 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 2.6157431602478027, accuracy: 32.0 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 1.446151614189148, accuracy: 47.3 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 1.3938771486282349, accuracy: 48.3 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 1.5008400678634644, accuracy: 44.5 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 1.3744, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 1.2330, batch time: 0.06, accuracy:  62.50%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 1.2761, batch time: 0.32, accuracy:  52.34%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 1.5289, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 1.5459, batch time: 0.06, accuracy:  46.09%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 1.2449, batch time: 0.33, accuracy:  59.38%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 1.2861, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 1.2892, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 1.3465, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 1.3206, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 8.701025009155273, accuracy: 11.3 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 1.3125183582305908, accuracy: 54.2 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 8.903863906860352, accuracy: 19.0 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 2.1915230751037598, accuracy: 40.8 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 2.2938764095306396, accuracy: 38.0 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 2.352679967880249, accuracy: 33.9 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 2.499223232269287, accuracy: 33.2 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 1.3413928747177124, accuracy: 53.8 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 1.4526314735412598, accuracy: 46.6 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 1.3568052053451538, accuracy: 53.4 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 1.3003, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 1.5102, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 1.4317, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 1.2881, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 1.3186, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 1.3097, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 1.4068, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 1.1908, batch time: 0.06, accuracy:  60.94%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 1.3750, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 1.2948, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 8.8975830078125, accuracy: 12.2 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 1.3513036966323853, accuracy: 54.9 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 8.85334587097168, accuracy: 19.1 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 2.237814426422119, accuracy: 41.4 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 2.7117385864257812, accuracy: 30.7 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 2.2777578830718994, accuracy: 34.9 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 2.549692392349243, accuracy: 35.5 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 1.3597581386566162, accuracy: 53.5 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 1.368708848953247, accuracy: 53.8 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 1.7688896656036377, accuracy: 39.2 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 1.3656, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 1.2086, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 1.1600, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 1.4807, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 1.4285, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 1.3063, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 1.1718, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 1.4806, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 1.3018, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 1.3874, batch time: 0.06, accuracy:  50.00%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 8.701266288757324, accuracy: 12.7 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 1.3521199226379395, accuracy: 54.0 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 8.392367362976074, accuracy: 20.7 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 1.3367643356323242, accuracy: 54.8 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 1.4833751916885376, accuracy: 50.5 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 1.3367643356323242, accuracy: 54.8 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 2.508335590362549, accuracy: 35.8 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 2.617307662963867, accuracy: 31.8 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 3.5854814052581787, accuracy: 20.9 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 1.4151041507720947, accuracy: 46.3 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 1.3843, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 1.2937, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 1.2222, batch time: 0.06, accuracy:  62.50%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 1.3358, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 1.2336, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 1.4477, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 1.6424, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 1.4040, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 1.3000, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 1.3280, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 9.436087608337402, accuracy: 10.4 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 1.424536943435669, accuracy: 52.0 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 8.444945335388184, accuracy: 19.7 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 2.1949238777160645, accuracy: 42.4 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 2.6734719276428223, accuracy: 32.5 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 1.833146572113037, accuracy: 34.7 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 1.4102030992507935, accuracy: 50.5 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 2.117603302001953, accuracy: 40.9 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 1.5538018941879272, accuracy: 45.1 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 1.391487717628479, accuracy: 52.6 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 1.3618, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 1.3520, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 1.3978, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 1.1563, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 1.3959, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 1.2807, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 1.3556, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 1.4567, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 1.3062, batch time: 0.32, accuracy:  58.59%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 1.3425, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 7.2132978439331055, accuracy: 10.9 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 1.472616195678711, accuracy: 50.2 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 6.067198276519775, accuracy: 20.3 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 2.113128185272217, accuracy: 41.6 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 1.8946501016616821, accuracy: 40.9 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 1.9034768342971802, accuracy: 41.4 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 1.5915824174880981, accuracy: 44.4 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 2.919828414916992, accuracy: 29.9 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 1.4372892379760742, accuracy: 50.1 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 1.4612560272216797, accuracy: 49.8 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 1.3797, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 1.4248, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 1.2825, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 1.4069, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 1.3284, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 1.2654, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 1.1995, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 1.3597, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 1.2978, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 1.4614, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 7.308145999908447, accuracy: 12.9 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 1.3569133281707764, accuracy: 56.2 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 6.107179641723633, accuracy: 21.8 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 2.0151708126068115, accuracy: 42.5 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 1.8628095388412476, accuracy: 41.4 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 1.4437602758407593, accuracy: 49.7 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 2.9347727298736572, accuracy: 25.9 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 1.3436193466186523, accuracy: 52.7 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 1.348376750946045, accuracy: 55.9 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 1.3522106409072876, accuracy: 51.6 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 1.3490, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 1.3104, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 1.3864, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 1.4761, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 1.4180, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 1.4755, batch time: 0.06, accuracy:  49.22%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 1.2637, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 1.5997, batch time: 0.06, accuracy:  45.31%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 1.5717, batch time: 0.06, accuracy:  44.53%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 1.4185, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 7.403726100921631, accuracy: 12.0 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 1.3862546682357788, accuracy: 53.9 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 7.008868217468262, accuracy: 18.3 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 1.7890604734420776, accuracy: 46.1 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 1.8309754133224487, accuracy: 40.7 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 1.9500213861465454, accuracy: 34.6 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 2.7052807807922363, accuracy: 18.1 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 1.4957655668258667, accuracy: 49.4 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 1.3883548974990845, accuracy: 56.0 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 1.4403804540634155, accuracy: 51.9 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 1.2718, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 1.1847, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 1.3575, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 1.3753, batch time: 0.33, accuracy:  54.69%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 1.4082, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 1.3986, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 1.3005, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 1.2827, batch time: 0.06, accuracy:  52.34%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 1.3703, batch time: 0.06, accuracy:  53.12%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 1.2900, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 8.098358154296875, accuracy: 13.6 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 1.3245819807052612, accuracy: 56.0 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 7.119030475616455, accuracy: 20.4 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 1.99686861038208, accuracy: 37.5 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 2.068652391433716, accuracy: 34.6 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 1.4407471418380737, accuracy: 51.3 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 2.466226816177368, accuracy: 31.0 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 1.9876540899276733, accuracy: 41.9 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 1.3580646514892578, accuracy: 53.8 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 1.4549891948699951, accuracy: 51.1 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 1.4234, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 1.4437, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 1.4515, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 1.3839, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 1.2307, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 1.1192, batch time: 0.06, accuracy:  60.94%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 1.2027, batch time: 0.06, accuracy:  54.69%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 1.2211, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 1.3121, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 1.3490, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 8.223082542419434, accuracy: 11.6 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 1.368180751800537, accuracy: 53.7 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 7.958698749542236, accuracy: 18.4 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 2.145683765411377, accuracy: 33.4 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 2.4653241634368896, accuracy: 27.4 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 2.299140691757202, accuracy: 31.4 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 4.088112831115723, accuracy: 18.4 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 1.4958397150039673, accuracy: 47.3 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 1.3623028993606567, accuracy: 54.7 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 1.4449745416641235, accuracy: 48.7 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0\n",
    "\n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter)\n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "\n",
    "            qnn_train_step += 1\n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\"\n",
    "                )\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA\n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(\n",
    "            qnn_minimize_loss,\n",
    "            init_param,\n",
    "            method=\"COBYLA\",\n",
    "            options={\"maxiter\": 1000, \"adaptive\": True},\n",
    "        )\n",
    "\n",
    "        qnn_parameters = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.ylim(0.5, 2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 55.30%\n",
      "Loss on the train set: 1.34\n",
      "Accuracy on the test set: 52.50%\n",
      "Loss on the test set: 1.37\n",
      "Generalization error: 0.032086372\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
