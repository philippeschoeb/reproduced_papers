{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1637.5\" height=\"593.75\" viewBox=\"-30.0 0 1310.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.712786</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.454394</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.815665</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.760799</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.739333</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.188883</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.881617</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.529577</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.389572</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.059202</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.4876</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.797591</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.366008</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.212789</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.687682</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.468862</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.966084</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.552723</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.819097</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.832759</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.04017</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.540891</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.981145</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.19679</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.131353</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.305151</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.820728</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.520399</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.39381</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.103879</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.292053</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.231528</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.213526</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.240797</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.579043</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.347657</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.969993</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.81797</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.531233</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.372418</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.348703</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.993519</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.95265</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.698165</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.967428</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.348456</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.71717</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.118074</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.351415</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.097247</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.255362</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.826677</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.813074</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.031438</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.577695</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.861169</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.849707</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.799205</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.008815</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.73985</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.946965</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.482694</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.08112</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.245334</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.856655</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.350134</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.792473</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.945751</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.89718</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.959394</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.144529</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.316364</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.443464</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.655192</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.934558</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.136064</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.047063</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.853571</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.175297</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.543911</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.088155</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.614022</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.628253</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.968956</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.190694</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.165813</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.413504</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.557778</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.201032</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.29443</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.768362</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.500617</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.892879</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.376635</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.349632</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.275161</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25.0 L1240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,125.0 L1240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,175.0 L1240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,225.0 L1240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,275.0 L1240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,325.0 L1240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,375.0 L1240,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,425.0 L1240,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1250\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1250\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1250\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1250\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1250\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1250\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1250\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1250\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1250\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x74fe86986d00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m=9, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.367198</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.75661</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.213914</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.670674</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.92593</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.098344</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.23896</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.005717</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.393276</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.872934</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.40211</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.230353</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.756845</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.252311</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.235656</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.95062</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.906488</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.734585</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.066871</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.049723</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.711769</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.514757</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.168175</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.48745</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.632605</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.798552</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.266463</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.857698</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.290923</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.421301</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.628098</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.537623</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.773309</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.455675</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.88905</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.09249</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.500716</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.131211</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.416744</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.42424</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.352081</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.04299</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.408336</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.975894</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.920053</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.523927</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.424631</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.014187</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.778164</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.722318</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.513907</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.309876</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.360569</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.010313</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.973984</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.496954</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.863286</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.243149</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.469448</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.666316</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.755968</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.361156</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.615043</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.561294</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.445674</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.023353</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.190038</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.478611</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.251547</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.621455</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.977251</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.548658</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.817475</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.233182</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.889983</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x74fe869261f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m=8, n=4, session=session)\n",
    "print(\n",
    "    f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\"\n",
    ")\n",
    "# to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        #     super(CNNModel, self).__init__()\n",
    "        #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "        #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "        #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "        #     self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "        # def forward(self, x):\n",
    "        #     x = self.pool(self.conv1(x))\n",
    "        #     x = self.pool(self.conv2(x))\n",
    "        #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        #     x = self.fc1(x)\n",
    "        #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 73.50%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    class MappingModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_sizes, output_size):\n",
    "            super().__init__()\n",
    "            # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "            self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "            self.hidden_layers = nn.ModuleList(\n",
    "                [\n",
    "                    nn.Linear(hidden_sizes[i], hidden_sizes[i + 1])\n",
    "                    for i in range(len(hidden_sizes) - 1)\n",
    "                ]\n",
    "            )\n",
    "            self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "        def forward(self, X):\n",
    "            # Ensure the input tensor is the same type as the weights\n",
    "            X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "            # Input layer with ReLU activation\n",
    "            X = self.input_layer(X)\n",
    "\n",
    "            # Hidden layers with ReLU activation\n",
    "            for hidden in self.hidden_layers:\n",
    "                X = hidden(X)\n",
    "\n",
    "            # Output layer with linear activation\n",
    "            output = self.output_layer(X)\n",
    "            # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "            return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "        self.MappingNetwork = self.MappingModel(n_qubit + 1, [8], 1).to(device)\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        # self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[\n",
    "            :108\n",
    "        ]  # nn.Parameter(q_delta * torch.randn(135)).to(device)\n",
    "        self.q_params_2 = qnn_parameters[108:]\n",
    "        device = x.device\n",
    "\n",
    "        res_1 = bs_1.run(parameters=self.q_params_1, samples=100000)\n",
    "        trans_res_1 = bs_1.translate_results(res=res_1)\n",
    "        trans_res_1 = trans_res_1 / torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)\n",
    "\n",
    "        res_2 = bs_2.run(parameters=self.q_params_2, samples=100000)\n",
    "        trans_res_2 = bs_2.translate_results(res=res_2)\n",
    "        trans_res_2 = trans_res_2 / torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)\n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(126 * 70, 1)\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[: len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), 1, n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  129\n",
      "# of trainable parameter in QNN model:  192\n",
      "# of trainable parameter in full model:  321\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108 + 84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\n",
    "    \"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters\n",
    ")\n",
    "print(\n",
    "    \"# of trainable parameter in full model: \",\n",
    "    num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 156.2843, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 63.0830, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 29.0417, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 17.0332, batch time: 0.04, accuracy:  2.34%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 11.7162, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 10.6249, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 7.3694, batch time: 0.09, accuracy:  3.91%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 6.7550, batch time: 0.09, accuracy:  1.56%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 5.2962, batch time: 0.04, accuracy:  1.56%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 4.4055, batch time: 0.04, accuracy:  1.56%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 3.7317562103271484, accuracy: 5.4 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 29.011211395263672, accuracy: 9.8 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 3.2632625102996826, accuracy: 15.0 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 10.031027793884277, accuracy: 9.9 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 2.891739845275879, accuracy: 15.2 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 2.860931873321533, accuracy: 9.7 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 2.7424328327178955, accuracy: 11.2 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 2.7133030891418457, accuracy: 13.4 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 2.6981008052825928, accuracy: 16.3 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 2.6929736137390137, accuracy: 11.6 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 2.4627, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 2.6439, batch time: 0.09, accuracy:  17.19%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 2.6206, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 2.5623, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 2.4909, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 2.5856, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 2.4341, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 2.4990, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 2.5185, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 2.4908, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 2.46278977394104, accuracy: 14.8 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 9.749407768249512, accuracy: 9.2 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 2.482133150100708, accuracy: 15.2 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 3.149094820022583, accuracy: 10.4 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 2.406757354736328, accuracy: 18.5 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 4.72717809677124, accuracy: 13.3 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 3.3234541416168213, accuracy: 15.9 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 2.8986873626708984, accuracy: 16.3 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 2.3601298332214355, accuracy: 17.3 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 2.3555562496185303, accuracy: 17.7 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 2.3375, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 2.3564, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 2.3724, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 2.2443, batch time: 0.09, accuracy:  18.75%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 2.2091, batch time: 0.09, accuracy:  19.53%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 2.3047, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 2.3449, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 2.2319, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 2.3356, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 2.3278, batch time: 0.09, accuracy:  16.41%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 2.3105130195617676, accuracy: 15.8 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 2.3788816928863525, accuracy: 14.6 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 2.2892885208129883, accuracy: 17.4 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 2.2816731929779053, accuracy: 16.7 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 2.2996315956115723, accuracy: 16.9 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 3.4293031692504883, accuracy: 12.2 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 2.2959542274475098, accuracy: 16.4 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 2.247316837310791, accuracy: 16.9 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 2.2594356536865234, accuracy: 17.2 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 2.2349584102630615, accuracy: 18.4 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 2.2597, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 2.2460, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 2.2124, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 2.2975, batch time: 0.09, accuracy:  16.41%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 2.2194, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 2.2188, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 2.1956, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 2.2472, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 2.0733, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 2.1908, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 2.1893537044525146, accuracy: 17.3 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 3.843698024749756, accuracy: 12.5 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 2.4957382678985596, accuracy: 11.5 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 2.8929030895233154, accuracy: 13.2 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 2.181135654449463, accuracy: 17.6 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 2.8676297664642334, accuracy: 16.8 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 2.2862436771392822, accuracy: 16.8 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 2.2163949012756348, accuracy: 19.1 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 3.0549731254577637, accuracy: 16.5 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 2.212217330932617, accuracy: 19.6 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 2.1852, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 2.1594, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 2.3003, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 2.0900, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 2.0675, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 2.1785, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 2.1430, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 2.0088, batch time: 0.09, accuracy:  21.88%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 2.0631, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 2.0144, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 2.1239383220672607, accuracy: 20.9 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 2.141601085662842, accuracy: 21.7 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 2.117262840270996, accuracy: 21.1 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 2.172056198120117, accuracy: 19.6 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 2.116909980773926, accuracy: 21.1 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 2.2322850227355957, accuracy: 18.4 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 2.106722831726074, accuracy: 21.1 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 2.120189905166626, accuracy: 20.3 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 2.1025166511535645, accuracy: 22.0 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 2.0967965126037598, accuracy: 21.5 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 2.0079, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 2.0954, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 2.1249, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 2.1524, batch time: 0.07, accuracy:  24.22%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 2.0930, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 2.1051, batch time: 0.09, accuracy:  21.09%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 2.1234, batch time: 0.09, accuracy:  21.88%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 2.0671, batch time: 0.09, accuracy:  20.31%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 2.1178, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 2.1123, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 2.1335272789001465, accuracy: 19.2 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 2.21409010887146, accuracy: 17.8 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 2.1264169216156006, accuracy: 19.7 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 2.1208417415618896, accuracy: 19.9 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 2.1213157176971436, accuracy: 19.1 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 2.377920389175415, accuracy: 18.2 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 2.118129253387451, accuracy: 19.1 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 2.114442825317383, accuracy: 19.4 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 2.1122357845306396, accuracy: 18.9 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 2.1107194423675537, accuracy: 19.3 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 2.1657, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 1.9711, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 2.0656, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 2.1482, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 2.1054, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 2.1213, batch time: 0.09, accuracy:  23.44%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 1.9625, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 2.0588, batch time: 0.09, accuracy:  23.44%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 2.0744, batch time: 0.09, accuracy:  16.41%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 2.0168, batch time: 0.09, accuracy:  20.31%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 2.0953688621520996, accuracy: 22.0 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 2.144139289855957, accuracy: 18.4 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 2.0940167903900146, accuracy: 22.7 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 2.0939934253692627, accuracy: 22.7 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 2.667815685272217, accuracy: 16.1 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 2.091041326522827, accuracy: 22.8 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 2.144052505493164, accuracy: 21.5 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 2.1099443435668945, accuracy: 20.9 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 2.087627410888672, accuracy: 23.5 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 2.379948377609253, accuracy: 15.6 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 1.9746, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 2.0020, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 2.0398, batch time: 0.09, accuracy:  21.88%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 1.9416, batch time: 0.08, accuracy:  24.22%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 2.0145, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 2.0549, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 2.1260, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 1.9946, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 1.9174, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 2.0906, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 2.034872531890869, accuracy: 21.9 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 2.8011720180511475, accuracy: 19.5 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 2.0513548851013184, accuracy: 22.0 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 2.3221006393432617, accuracy: 16.6 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 2.025669813156128, accuracy: 23.4 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 2.0247297286987305, accuracy: 23.9 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 2.023887872695923, accuracy: 23.8 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 2.0917916297912598, accuracy: 24.8 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 2.1259374618530273, accuracy: 25.2 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 2.017624616622925, accuracy: 24.1 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 2.1725, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 2.0590, batch time: 0.10, accuracy:  17.19%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 2.1068, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 2.0100, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 2.0173, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 2.0366, batch time: 0.07, accuracy:  27.34%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 1.9367, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 2.0062, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 1.9398, batch time: 0.08, accuracy:  32.03%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 2.0601, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 2.0400662422180176, accuracy: 26.2 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 2.0792922973632812, accuracy: 23.6 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 2.0358939170837402, accuracy: 26.0 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 2.030531644821167, accuracy: 26.5 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 2.04416823387146, accuracy: 25.0 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 3.0880496501922607, accuracy: 13.8 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 2.0278875827789307, accuracy: 26.8 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 2.0275933742523193, accuracy: 27.4 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 2.021658182144165, accuracy: 27.0 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 2.0225579738616943, accuracy: 26.8 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 2.0715, batch time: 0.09, accuracy:  21.88%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 2.0419, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 2.0329, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 2.0216, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 2.0718, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 1.8862, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 2.0698, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 1.9808, batch time: 0.05, accuracy:  29.69%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 2.1130, batch time: 0.06, accuracy:  18.75%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 2.0398, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 2.005873441696167, accuracy: 26.8 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 8.171795845031738, accuracy: 10.5 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 2.4487967491149902, accuracy: 18.3 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 2.3213369846343994, accuracy: 18.6 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 2.027662515640259, accuracy: 25.9 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 1.992801308631897, accuracy: 27.6 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 1.9936541318893433, accuracy: 27.2 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 1.9873727560043335, accuracy: 27.9 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 1.9866582155227661, accuracy: 27.5 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 1.9847986698150635, accuracy: 27.4 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 1.9985, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 1.9491, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 1.9174, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 1.9593, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 2.0168, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 2.0042, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 1.9914, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 1.9189, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 2.1279, batch time: 0.09, accuracy:  17.97%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 1.9943, batch time: 0.05, accuracy:  28.12%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 1.9505720138549805, accuracy: 28.7 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 1.9550937414169312, accuracy: 28.5 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 1.9677358865737915, accuracy: 28.8 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 2.2533910274505615, accuracy: 25.4 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 1.945077896118164, accuracy: 28.6 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 1.9482313394546509, accuracy: 28.7 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 1.9429118633270264, accuracy: 28.5 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 1.9395695924758911, accuracy: 29.0 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 1.9384645223617554, accuracy: 29.5 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 1.9389680624008179, accuracy: 29.5 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 1.8869, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 1.8448, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 2.0584, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 1.9395, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 1.9106, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 1.8901, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 1.8843, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 1.9057, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 2.0724, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 2.1008, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 1.8849942684173584, accuracy: 34.1 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 1.8868982791900635, accuracy: 34.2 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 1.8833796977996826, accuracy: 34.6 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 2.204165458679199, accuracy: 24.4 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 1.8791978359222412, accuracy: 35.2 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 1.874814748764038, accuracy: 33.8 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 1.8753970861434937, accuracy: 34.5 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 1.8711553812026978, accuracy: 34.8 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 1.919719934463501, accuracy: 33.8 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 1.861304521560669, accuracy: 34.1 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 1.9904, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 1.8895, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 2.0877, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 1.8216, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 1.9650, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 1.9716, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 1.8706, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 1.8410, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 1.9459, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 1.8535, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 1.9436273574829102, accuracy: 31.8 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 1.9626420736312866, accuracy: 29.9 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 1.9663771390914917, accuracy: 30.4 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 3.250380754470825, accuracy: 10.6 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 1.9378994703292847, accuracy: 31.1 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 1.9355140924453735, accuracy: 31.7 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 1.9362552165985107, accuracy: 31.1 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 1.9370594024658203, accuracy: 30.5 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 1.9295341968536377, accuracy: 31.5 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 1.9402155876159668, accuracy: 31.4 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 1.9003, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 1.9786, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 2.0464, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 2.0645, batch time: 0.07, accuracy:  28.12%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 1.8769, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 1.9249, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 1.8626, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 2.0011, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 1.7790, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 1.8666, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 1.9236929416656494, accuracy: 30.9 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 1.9376640319824219, accuracy: 27.9 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 1.937052607536316, accuracy: 29.1 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 2.289486885070801, accuracy: 23.2 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 1.9264779090881348, accuracy: 30.5 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 1.9159903526306152, accuracy: 31.1 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 1.9157849550247192, accuracy: 31.7 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 1.911469578742981, accuracy: 32.4 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 1.930587887763977, accuracy: 29.0 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 1.9150511026382446, accuracy: 31.8 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 1.9578, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 1.8723, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 1.8782, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 1.9232, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 1.8951, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 1.8799, batch time: 0.06, accuracy:  32.81%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 1.8501, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 1.6969, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 1.8086, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 1.8063, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 1.8815025091171265, accuracy: 35.4 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 1.8839659690856934, accuracy: 34.7 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 1.8803859949111938, accuracy: 35.8 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 1.972374677658081, accuracy: 36.0 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 1.8764618635177612, accuracy: 35.6 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 1.8712371587753296, accuracy: 35.6 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 1.8762158155441284, accuracy: 35.5 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 1.86808443069458, accuracy: 35.5 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 1.8712646961212158, accuracy: 34.8 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 1.8638700246810913, accuracy: 35.8 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 1.9259, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 1.8024, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 1.9116, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 1.9112, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 1.9624, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 1.8296, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 1.8585, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 2.0528, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 2.0517, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 1.8952, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 1.896787405014038, accuracy: 33.2 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 1.8967843055725098, accuracy: 32.9 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 1.9377537965774536, accuracy: 30.1 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 2.021827459335327, accuracy: 30.9 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 1.8765521049499512, accuracy: 34.5 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 1.8637385368347168, accuracy: 34.4 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 1.8629640340805054, accuracy: 35.4 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 1.8646007776260376, accuracy: 33.7 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 1.854811429977417, accuracy: 35.2 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 1.863322377204895, accuracy: 34.4 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 1.8882, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 1.9102, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 1.9067, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 1.8756, batch time: 0.08, accuracy:  32.03%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 1.8918, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 1.7667, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 1.9999, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 1.7894, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 1.8014, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 1.8841, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 1.8451128005981445, accuracy: 35.9 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 1.9079008102416992, accuracy: 32.0 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 1.8393523693084717, accuracy: 35.7 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 2.2541706562042236, accuracy: 25.4 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 1.8361320495605469, accuracy: 36.6 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 1.8359479904174805, accuracy: 37.8 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 1.8482048511505127, accuracy: 37.2 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 1.8385182619094849, accuracy: 36.6 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 1.9449180364608765, accuracy: 34.8 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 1.8415400981903076, accuracy: 36.4 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 1.8255, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 1.8688, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 1.8445, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 1.7398, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 1.7516, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 1.8230, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 1.7775, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 1.8570, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 1.7397, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 1.8375, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 1.8091344833374023, accuracy: 36.5 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 1.8222211599349976, accuracy: 34.3 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 1.8493952751159668, accuracy: 34.7 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 2.315143346786499, accuracy: 20.8 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 1.8184454441070557, accuracy: 34.3 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 1.8098819255828857, accuracy: 34.4 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 1.8106873035430908, accuracy: 36.0 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 1.8447214365005493, accuracy: 36.3 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 1.7948700189590454, accuracy: 36.0 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 1.7939143180847168, accuracy: 36.2 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 1.6872, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 1.7981, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 1.8179, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 1.8658, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 1.8826, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 1.8300, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 1.7491, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 1.7559, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 1.7114, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 2.0353, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 1.802843451499939, accuracy: 35.5 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 1.8119300603866577, accuracy: 34.5 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 1.8130767345428467, accuracy: 34.9 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 2.3925201892852783, accuracy: 22.3 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 1.8046150207519531, accuracy: 34.2 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 1.790460467338562, accuracy: 35.6 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 1.7870094776153564, accuracy: 35.4 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 1.7853431701660156, accuracy: 36.2 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 1.793656349182129, accuracy: 35.9 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 1.8236972093582153, accuracy: 36.3 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 1.7675, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 1.7251, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 1.7565, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 1.5645, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 1.7666, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 1.6165, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 1.7360, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 1.7524, batch time: 0.18, accuracy:  42.19%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 1.7477, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 1.8734, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 1.7860593795776367, accuracy: 37.3 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 2.267993688583374, accuracy: 23.6 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 1.8028088808059692, accuracy: 36.4 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 2.315213680267334, accuracy: 22.7 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 1.8040598630905151, accuracy: 37.8 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 1.7983709573745728, accuracy: 36.8 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 1.8946095705032349, accuracy: 34.4 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 1.7718065977096558, accuracy: 39.4 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 1.77178955078125, accuracy: 39.3 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 1.7688409090042114, accuracy: 39.7 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 1.7955, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 1.6708, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 1.7610, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 1.6647, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 1.7518, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 1.9408, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 1.8648, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 1.6787, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 1.7981, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 1.7407, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 1.7694880962371826, accuracy: 36.9 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 2.1636476516723633, accuracy: 25.7 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 1.820061206817627, accuracy: 34.9 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 2.160813093185425, accuracy: 26.2 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 1.8209329843521118, accuracy: 33.3 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 1.8776065111160278, accuracy: 34.1 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 1.8005149364471436, accuracy: 35.1 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 1.8160619735717773, accuracy: 32.2 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 1.7581146955490112, accuracy: 37.2 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 1.7692657709121704, accuracy: 35.7 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 1.8348, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 1.6748, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 1.8408, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 1.6946, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 1.7256, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 1.8412, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 1.8190, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 1.7750, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 1.7666, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 1.6536, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 1.7625964879989624, accuracy: 35.1 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 2.641650438308716, accuracy: 21.3 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 1.7918100357055664, accuracy: 35.5 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 1.8778165578842163, accuracy: 32.0 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 1.7577823400497437, accuracy: 34.9 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 1.8979573249816895, accuracy: 34.7 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 1.8166128396987915, accuracy: 35.8 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 1.8074675798416138, accuracy: 38.3 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 1.742569088935852, accuracy: 36.6 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 1.7447644472122192, accuracy: 37.3 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 1.6435, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 1.7109, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 1.7722, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 1.6685, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 1.8118, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 1.7575, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 1.8085, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 1.8664, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 1.8948, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 1.7524, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 1.7405197620391846, accuracy: 38.6 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 2.782778263092041, accuracy: 18.6 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 1.7596018314361572, accuracy: 36.9 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 6.227227210998535, accuracy: 9.5 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 1.7955565452575684, accuracy: 35.3 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 1.732601523399353, accuracy: 39.1 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 1.7605866193771362, accuracy: 36.8 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 1.7289073467254639, accuracy: 38.7 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 1.7257413864135742, accuracy: 39.5 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 1.7234126329421997, accuracy: 39.0 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 1.8335, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 1.7434, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 1.7408, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 1.6743, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 1.8088, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 1.7151, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 1.6949, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 1.8207, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 1.5959, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 1.7269, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 1.7735595703125, accuracy: 36.6 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 1.8888368606567383, accuracy: 29.6 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 1.8027461767196655, accuracy: 35.1 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 2.5913498401641846, accuracy: 24.1 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 1.8041653633117676, accuracy: 35.7 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 1.766947865486145, accuracy: 37.1 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 1.7937135696411133, accuracy: 37.2 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 1.7733503580093384, accuracy: 37.4 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 1.7902796268463135, accuracy: 37.1 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 1.7657731771469116, accuracy: 38.1 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 1.8281, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 1.7948, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 1.9488, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 1.7152, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 1.8407, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 1.6546, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 1.7254, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 1.7612, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 1.7533, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 1.6936, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 1.7608468532562256, accuracy: 34.9 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 2.549022674560547, accuracy: 19.4 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 1.783264398574829, accuracy: 33.8 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 5.9966230392456055, accuracy: 9.8 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 1.786062479019165, accuracy: 35.1 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 1.8204115629196167, accuracy: 35.5 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 1.757311224937439, accuracy: 36.6 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 1.7521218061447144, accuracy: 36.1 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 1.7516627311706543, accuracy: 36.2 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 1.7496843338012695, accuracy: 36.4 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 1.7447, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 1.6232, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 1.6721, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 1.7006, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 1.6515, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 1.7980, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 1.6717, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 1.6534, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 1.8129, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 1.7033, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 1.712380051612854, accuracy: 39.4 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 2.6452579498291016, accuracy: 19.6 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 1.7211835384368896, accuracy: 39.6 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 1.8066775798797607, accuracy: 34.5 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 1.7038402557373047, accuracy: 39.2 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 1.6979420185089111, accuracy: 39.9 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 1.6980351209640503, accuracy: 39.9 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 1.695885419845581, accuracy: 41.5 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 1.6947561502456665, accuracy: 40.7 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 1.6935756206512451, accuracy: 40.7 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 1.7287, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 1.6484, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 1.8164, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 1.7799, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 1.7760, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 1.6058, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 1.8824, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 1.7521, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 1.6846, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 1.8800, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 1.7726922035217285, accuracy: 36.7 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 2.452792167663574, accuracy: 21.4 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 1.7940514087677002, accuracy: 36.8 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 2.9093434810638428, accuracy: 23.6 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 1.8785545825958252, accuracy: 32.8 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 1.774965763092041, accuracy: 37.2 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 1.7615677118301392, accuracy: 37.2 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 1.7565760612487793, accuracy: 36.9 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 1.7563025951385498, accuracy: 36.9 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 1.7544909715652466, accuracy: 36.1 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 1.8254, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 1.6843, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 1.6632, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 1.7251, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 1.7962, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 1.6119, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 1.7337, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 1.7856, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 1.8216, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 1.5962, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 1.7067172527313232, accuracy: 39.5 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 2.2722415924072266, accuracy: 21.8 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 1.7246525287628174, accuracy: 38.5 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 2.6462182998657227, accuracy: 22.1 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 1.7042087316513062, accuracy: 39.8 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 1.7038103342056274, accuracy: 39.6 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 1.7070318460464478, accuracy: 39.8 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 1.6996963024139404, accuracy: 39.3 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 1.7027703523635864, accuracy: 39.7 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 1.6981089115142822, accuracy: 40.4 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 1.7536, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 1.7420, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 1.7862, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 1.8024, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 1.5815, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 1.6516, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 1.6850, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 1.7851, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 1.6539, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 1.6601, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 1.6961222887039185, accuracy: 39.7 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 2.487480878829956, accuracy: 22.4 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 1.7269619703292847, accuracy: 37.5 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 1.7349016666412354, accuracy: 36.7 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 1.6778314113616943, accuracy: 39.8 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 1.6761789321899414, accuracy: 40.7 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 1.7372089624404907, accuracy: 34.8 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 1.9133617877960205, accuracy: 28.5 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 1.679847240447998, accuracy: 39.7 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 2.1063008308410645, accuracy: 24.7 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 1.6259, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 1.8255, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 1.7000, batch time: 0.05, accuracy:  34.38%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 1.6296, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 1.6863, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 1.7810, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 1.6451, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 1.7314, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 1.6969, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 1.8210, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 1.7793062925338745, accuracy: 35.4 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 1.7933143377304077, accuracy: 34.7 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 1.768526554107666, accuracy: 37.3 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 2.519024610519409, accuracy: 24.9 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 1.763033151626587, accuracy: 36.5 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 1.7738299369812012, accuracy: 35.1 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 1.7583802938461304, accuracy: 37.0 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 1.7570456266403198, accuracy: 37.2 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 1.7589432001113892, accuracy: 37.4 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 1.7687747478485107, accuracy: 36.8 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 1.8224, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 1.6043, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 1.7328, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 1.6378, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 1.8533, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 1.6940, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 1.7229, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 1.6587, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 1.7446, batch time: 0.06, accuracy:  37.50%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 1.6426, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 1.7129418849945068, accuracy: 40.6 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 1.7159901857376099, accuracy: 40.9 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 1.7309859991073608, accuracy: 40.2 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 5.015927314758301, accuracy: 10.1 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 1.7838773727416992, accuracy: 38.9 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 1.738914132118225, accuracy: 41.3 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 1.713707685470581, accuracy: 40.9 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 1.7019548416137695, accuracy: 41.2 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 1.6991522312164307, accuracy: 40.7 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 1.6956119537353516, accuracy: 40.4 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 1.6376, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 1.7222, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 1.6953, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 1.7833, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 1.7492, batch time: 0.10, accuracy:  34.38%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 1.8393, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 1.5457, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 1.8353, batch time: 0.08, accuracy:  34.38%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 1.7571, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 1.7001, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 1.737350344657898, accuracy: 37.0 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 1.7815419435501099, accuracy: 35.0 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 1.7776622772216797, accuracy: 37.1 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 2.4283440113067627, accuracy: 24.1 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 1.7581919431686401, accuracy: 36.9 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 1.7258038520812988, accuracy: 37.0 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 1.7485705614089966, accuracy: 37.6 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 1.761651635169983, accuracy: 37.6 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 2.2128775119781494, accuracy: 22.6 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 1.7148101329803467, accuracy: 37.5 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 2.0234, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 1.5657, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 1.6468, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 1.7061, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 1.7093, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 1.6507, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 1.7957, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 1.8286, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 1.7312, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 1.7034, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 1.711456298828125, accuracy: 38.9 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 1.8304420709609985, accuracy: 35.2 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 1.7161433696746826, accuracy: 37.3 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 2.2175183296203613, accuracy: 28.7 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 1.7368978261947632, accuracy: 36.6 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 1.7475749254226685, accuracy: 38.1 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 1.7321135997772217, accuracy: 37.5 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 1.928141474723816, accuracy: 33.6 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 1.6969951391220093, accuracy: 39.9 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 1.704928994178772, accuracy: 39.1 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 1.7206, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 1.6737, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 1.6594, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 1.7035, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 1.7589, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 1.6123, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 1.6433, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 1.6841, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 1.6668, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 1.7832, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 1.7422035932540894, accuracy: 36.5 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 2.2207536697387695, accuracy: 24.8 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 1.8206229209899902, accuracy: 35.6 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 3.0889036655426025, accuracy: 18.9 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 1.724168300628662, accuracy: 38.2 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 1.7458229064941406, accuracy: 37.3 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 1.8127012252807617, accuracy: 37.3 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 1.7111352682113647, accuracy: 39.6 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 1.7197118997573853, accuracy: 38.1 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 1.6999640464782715, accuracy: 38.6 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 1.5019, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 1.9222, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 1.8041, batch time: 0.06, accuracy:  38.28%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 1.6919, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 1.8441, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 1.7436, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 1.6210, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 1.7344, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 1.6481, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 1.6187, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 1.7096861600875854, accuracy: 39.5 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 2.508741855621338, accuracy: 21.3 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 1.726281762123108, accuracy: 37.9 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 1.8126347064971924, accuracy: 36.2 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 1.6953480243682861, accuracy: 40.0 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 1.7062106132507324, accuracy: 39.5 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 1.6931027173995972, accuracy: 40.4 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 1.6903889179229736, accuracy: 39.8 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 1.6886118650436401, accuracy: 39.7 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 1.68779456615448, accuracy: 39.5 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 1.5962, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 1.6746, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 1.7336, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 1.5865, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 1.7445, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 1.7172, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 1.7043, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 1.6975, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 1.5918, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 1.7069, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 1.7149909734725952, accuracy: 39.0 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 2.6219351291656494, accuracy: 21.4 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 1.74386465549469, accuracy: 38.3 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 2.257526397705078, accuracy: 20.2 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 1.7013332843780518, accuracy: 40.5 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 1.7649505138397217, accuracy: 35.5 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 1.721853256225586, accuracy: 40.6 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 1.6946995258331299, accuracy: 40.6 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 1.6924901008605957, accuracy: 41.1 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 1.6943966150283813, accuracy: 41.3 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 1.5285, batch time: 0.06, accuracy:  39.84%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 1.7046, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 1.6954, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 1.6816, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 1.7070, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 1.7444, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 1.6947, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 1.6815, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 1.7397, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 1.6443, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 1.6446160078048706, accuracy: 43.9 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 1.7884467840194702, accuracy: 37.4 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 1.6642450094223022, accuracy: 41.5 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 1.6498041152954102, accuracy: 40.3 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 1.625295639038086, accuracy: 43.4 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 1.6282150745391846, accuracy: 43.4 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 1.6175804138183594, accuracy: 43.5 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 1.6223458051681519, accuracy: 44.2 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 1.6196651458740234, accuracy: 43.6 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 1.6123048067092896, accuracy: 44.4 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 1.7653, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 1.7771, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 1.5758, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 1.7226, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 1.7164, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 1.7201, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 1.7009, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 1.7795, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 1.5651, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 1.6466, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 1.656612515449524, accuracy: 41.6 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 1.826465368270874, accuracy: 32.9 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 1.6930828094482422, accuracy: 39.3 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 4.3144307136535645, accuracy: 16.8 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 1.6699532270431519, accuracy: 39.4 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 1.8494452238082886, accuracy: 35.5 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 1.6520092487335205, accuracy: 42.0 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 1.6468126773834229, accuracy: 41.6 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 1.6462022066116333, accuracy: 41.6 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 1.6448442935943604, accuracy: 41.9 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 1.7208, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 1.5196, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 1.5738, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 1.6952, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 1.6741, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 1.5607, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 1.6843, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 1.6351, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 1.6163, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 1.7250, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 1.6628029346466064, accuracy: 41.9 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 1.752576470375061, accuracy: 38.9 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 1.704047679901123, accuracy: 40.0 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 4.336474895477295, accuracy: 15.5 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 1.6545754671096802, accuracy: 41.1 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 1.6468157768249512, accuracy: 42.2 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 1.643272876739502, accuracy: 42.7 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 1.6636019945144653, accuracy: 41.7 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 1.6604918241500854, accuracy: 41.6 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 1.6372488737106323, accuracy: 43.5 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 1.6451, batch time: 0.06, accuracy:  44.53%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 1.6329, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 1.6722, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 1.6797, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 1.7408, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 1.6504, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 1.6759, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 1.5579, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 1.7065, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 1.6446, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 1.680886149406433, accuracy: 42.4 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 1.8760384321212769, accuracy: 34.4 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 1.7152879238128662, accuracy: 40.1 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 1.8540005683898926, accuracy: 35.1 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 1.6662530899047852, accuracy: 42.0 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 1.6628305912017822, accuracy: 41.9 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 1.6712652444839478, accuracy: 41.6 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 1.6520551443099976, accuracy: 42.1 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 1.6966722011566162, accuracy: 42.3 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 1.6712191104888916, accuracy: 42.2 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 1.7708, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 1.6601, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 1.6012, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 1.7379, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 1.4705, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 1.5609, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 1.6759, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 1.6160, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 1.5898, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 1.8221, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 1.593011498451233, accuracy: 44.9 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 1.7442519664764404, accuracy: 40.6 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 1.6168500185012817, accuracy: 43.7 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 4.1633620262146, accuracy: 15.3 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 1.636132836341858, accuracy: 44.1 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 1.6024309396743774, accuracy: 45.4 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 1.580731987953186, accuracy: 46.5 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 1.5794460773468018, accuracy: 46.4 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 1.5804051160812378, accuracy: 47.0 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 1.5786556005477905, accuracy: 47.4 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 1.8396, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 1.7496, batch time: 0.23, accuracy:  40.62%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 1.5737, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 1.5464, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 1.6586, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 1.5965, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 1.5042, batch time: 0.09, accuracy:  48.44%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 1.6424, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 1.6918, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 1.6297, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 1.5898572206497192, accuracy: 45.3 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 6.232390880584717, accuracy: 15.5 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 1.6091926097869873, accuracy: 44.7 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 6.955781936645508, accuracy: 13.5 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 1.590844750404358, accuracy: 45.3 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 1.8416202068328857, accuracy: 41.5 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 1.5806779861450195, accuracy: 45.4 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 1.5758646726608276, accuracy: 45.9 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 1.5739115476608276, accuracy: 45.7 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 1.572325348854065, accuracy: 45.9 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 1.5700, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 1.6813, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 1.5671, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 1.6738, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 1.5828, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 1.8281, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 1.5445, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 1.7609, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 1.6676, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 1.5051, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 1.5982831716537476, accuracy: 43.5 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 1.6462862491607666, accuracy: 42.2 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 1.6219935417175293, accuracy: 43.8 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 2.490865468978882, accuracy: 32.3 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 1.5772249698638916, accuracy: 45.4 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 1.582214117050171, accuracy: 45.6 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 1.5709218978881836, accuracy: 45.3 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 1.56615149974823, accuracy: 45.8 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 1.6495792865753174, accuracy: 44.6 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 1.7572517395019531, accuracy: 41.0 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 1.7905, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 1.5054, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 1.6905, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 1.5601, batch time: 0.09, accuracy:  48.44%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 1.5600, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 1.6700, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 1.5117, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 1.5901, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 1.5708, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 1.7445, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 1.5967285633087158, accuracy: 45.8 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 1.836119532585144, accuracy: 39.9 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 1.5947535037994385, accuracy: 45.4 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 3.1566596031188965, accuracy: 19.1 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 1.603615403175354, accuracy: 45.6 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 1.5883159637451172, accuracy: 45.5 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 1.644718885421753, accuracy: 43.6 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 1.6802711486816406, accuracy: 42.2 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 1.596816062927246, accuracy: 44.5 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 1.5580416917800903, accuracy: 46.6 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 1.6811, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 1.5778, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 1.6173, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 1.5406, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 1.5571, batch time: 0.09, accuracy:  51.56%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 1.5648, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 1.7692, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 1.5211, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 1.6171, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 1.6277, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 1.5706653594970703, accuracy: 47.6 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 1.8550795316696167, accuracy: 40.0 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 1.5861732959747314, accuracy: 47.9 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 2.0289182662963867, accuracy: 35.2 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 1.593239426612854, accuracy: 46.4 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 1.5852041244506836, accuracy: 45.9 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 1.5610476732254028, accuracy: 46.9 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 1.5545891523361206, accuracy: 47.4 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 1.553749442100525, accuracy: 47.5 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 1.5518848896026611, accuracy: 47.4 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 1.4640, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 1.5606, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 1.4764, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 1.6810, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 1.5623, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 1.7097, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 1.5283, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 1.6130, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 1.5190, batch time: 0.09, accuracy:  48.44%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 1.5197, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 1.617180347442627, accuracy: 46.5 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 1.9214582443237305, accuracy: 40.3 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 1.6194766759872437, accuracy: 44.6 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 4.735485553741455, accuracy: 29.8 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 1.6234943866729736, accuracy: 45.4 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 1.5846048593521118, accuracy: 48.0 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 1.6002562046051025, accuracy: 48.4 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 1.6053906679153442, accuracy: 47.7 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 1.5764415264129639, accuracy: 48.9 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 1.5797948837280273, accuracy: 48.7 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 1.5252, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 1.6420, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 1.6108, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 1.5927, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 1.4599, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 1.5316, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 1.6144, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 1.4231, batch time: 0.09, accuracy:  51.56%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 1.5100, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 1.6281, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 1.5856971740722656, accuracy: 45.8 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 1.8409487009048462, accuracy: 40.8 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 1.606042504310608, accuracy: 45.5 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 3.0702643394470215, accuracy: 20.6 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 1.5830557346343994, accuracy: 46.4 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 1.8696506023406982, accuracy: 40.1 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 1.6751405000686646, accuracy: 44.9 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 1.568027377128601, accuracy: 47.6 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 1.569023847579956, accuracy: 48.0 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 1.5595396757125854, accuracy: 47.9 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 1.5045, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 1.7316, batch time: 0.08, accuracy:  46.09%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 1.4950, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 1.5177, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 1.4867, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 1.7272, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 1.7828, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 1.5911, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 1.4346, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 1.3598, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 1.530714750289917, accuracy: 47.3 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 1.8415733575820923, accuracy: 41.7 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 1.56654691696167, accuracy: 46.5 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 4.605673789978027, accuracy: 18.4 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 1.638832449913025, accuracy: 45.2 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 1.528665542602539, accuracy: 47.4 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 1.5162208080291748, accuracy: 47.6 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 1.5137287378311157, accuracy: 48.4 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 1.5125192403793335, accuracy: 49.0 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 1.5100501775741577, accuracy: 48.5 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 1.5724, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 1.3570, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 1.3642, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 1.5244, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 1.5449, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 1.5761, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 1.5406, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 1.8198, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 1.5298, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 1.5435, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 1.59694242477417, accuracy: 45.1 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 1.8577170372009277, accuracy: 37.1 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 1.5413931608200073, accuracy: 48.0 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 2.4204089641571045, accuracy: 31.0 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 1.5566333532333374, accuracy: 46.9 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 1.496748685836792, accuracy: 50.3 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 1.5480152368545532, accuracy: 50.5 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 1.4864071607589722, accuracy: 51.1 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 1.487557053565979, accuracy: 51.4 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 1.4827468395233154, accuracy: 50.8 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 1.5189, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 1.4746, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 1.6177, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 1.6628, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 1.2992, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 1.6635, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 1.3615, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 1.5116, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 1.4363, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 1.6226, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 1.5169339179992676, accuracy: 50.8 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 1.8950889110565186, accuracy: 41.4 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 1.5469722747802734, accuracy: 48.9 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 6.461296081542969, accuracy: 18.1 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 1.5282106399536133, accuracy: 50.0 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 1.7264366149902344, accuracy: 42.9 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 1.516048550605774, accuracy: 52.1 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 1.4963688850402832, accuracy: 51.5 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 1.49324631690979, accuracy: 52.8 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 1.4893162250518799, accuracy: 52.2 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 1.7625, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 1.5188, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 1.4307, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 1.4696, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 1.3835, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 1.4347, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 1.6349, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 1.4524, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 1.5672, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 1.5404, batch time: 0.21, accuracy:  51.56%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 1.5286378860473633, accuracy: 53.0 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 1.5938150882720947, accuracy: 48.6 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 1.5395594835281372, accuracy: 51.6 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 2.2415833473205566, accuracy: 33.4 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 1.5472042560577393, accuracy: 52.4 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 1.5208317041397095, accuracy: 52.0 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 1.5890588760375977, accuracy: 49.0 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 1.5794035196304321, accuracy: 49.5 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 1.5035722255706787, accuracy: 53.1 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 1.5003302097320557, accuracy: 53.0 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 1.6143, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 1.4893, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 1.4985, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 1.5792, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 1.5349, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 1.5260, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 1.3846, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 1.4342, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 1.6921, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 1.4257, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 1.4906493425369263, accuracy: 49.9 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 2.0406382083892822, accuracy: 38.9 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 1.4959272146224976, accuracy: 49.9 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 1.76692533493042, accuracy: 43.2 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 1.5034141540527344, accuracy: 48.7 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 1.7839552164077759, accuracy: 45.5 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 1.4812703132629395, accuracy: 50.2 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 1.4830255508422852, accuracy: 50.3 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 1.4788471460342407, accuracy: 50.4 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 1.4770673513412476, accuracy: 50.8 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 1.3633, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 1.6602, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 1.5045, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 1.3787, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 1.4648, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 1.3676, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 1.5120, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 1.7691, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 1.4654, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 1.5342, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 1.5365397930145264, accuracy: 51.3 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 1.7085843086242676, accuracy: 47.7 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 1.552518367767334, accuracy: 50.0 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 5.180240154266357, accuracy: 15.9 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 1.5235326290130615, accuracy: 52.4 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 1.5230762958526611, accuracy: 53.1 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 1.5077154636383057, accuracy: 52.9 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 1.5049896240234375, accuracy: 52.5 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 1.5028027296066284, accuracy: 53.9 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 1.5037113428115845, accuracy: 54.7 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 1.5930, batch time: 0.09, accuracy:  50.00%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 1.4520, batch time: 0.31, accuracy:  53.12%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 1.5957, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 1.8117, batch time: 0.09, accuracy:  48.44%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 1.5516, batch time: 0.09, accuracy:  48.44%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 1.6014, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 1.3120, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 1.5897, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 1.6064, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 1.3697, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 1.4714425802230835, accuracy: 53.2 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 1.7106812000274658, accuracy: 44.9 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 1.476863145828247, accuracy: 53.3 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 4.3016886711120605, accuracy: 19.1 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 1.5950191020965576, accuracy: 48.4 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 1.66887629032135, accuracy: 50.0 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 1.4941409826278687, accuracy: 52.7 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 1.4591484069824219, accuracy: 54.2 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 1.449416160583496, accuracy: 55.3 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 1.447886347770691, accuracy: 54.7 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 1.5394, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 1.5297, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 1.5071, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 1.3749, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 1.4868, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 1.4058, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 1.4026, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 1.5268, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 1.2944, batch time: 0.07, accuracy:  60.16%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 1.4083, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 1.4861418008804321, accuracy: 51.7 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 1.7542937994003296, accuracy: 42.5 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 1.5151560306549072, accuracy: 50.1 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 2.280982494354248, accuracy: 32.3 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 1.4637759923934937, accuracy: 53.0 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 1.4693914651870728, accuracy: 51.7 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 1.4808112382888794, accuracy: 52.4 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 1.455606460571289, accuracy: 52.8 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 1.4516397714614868, accuracy: 53.2 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 1.4492788314819336, accuracy: 53.0 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 1.4413, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 1.3650, batch time: 0.08, accuracy:  58.59%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 1.4593, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 1.5367, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 1.5874, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 1.3000, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 1.5210, batch time: 0.08, accuracy:  52.34%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 1.5830, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 1.4607, batch time: 0.09, accuracy:  50.00%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 1.2687, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 1.4891388416290283, accuracy: 51.4 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 1.858249545097351, accuracy: 42.1 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 1.4891388416290283, accuracy: 51.4 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 1.4891388416290283, accuracy: 51.4 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 1.4713917970657349, accuracy: 51.0 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 1.467078685760498, accuracy: 52.7 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 1.4662312269210815, accuracy: 52.2 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 1.4672788381576538, accuracy: 51.9 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 1.4630837440490723, accuracy: 51.9 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 1.5018408298492432, accuracy: 51.1 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 1.4949, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 1.4533, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 1.4540, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 1.2478, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 1.3801, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 1.2954, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 1.4657, batch time: 0.09, accuracy:  51.56%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 1.3936, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 1.3707, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 1.2936, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 1.4932104349136353, accuracy: 53.6 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 1.8972975015640259, accuracy: 40.7 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 1.4892770051956177, accuracy: 53.0 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 1.4892770051956177, accuracy: 53.0 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 1.4988172054290771, accuracy: 51.4 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 1.4832004308700562, accuracy: 53.6 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 1.4975948333740234, accuracy: 53.1 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 1.4820044040679932, accuracy: 52.8 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 1.5045640468597412, accuracy: 52.6 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 1.4947971105575562, accuracy: 52.9 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 1.3432, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 1.5888, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 1.3365, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 1.2744, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 1.2805, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 1.3774, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 1.3387, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 1.6079, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 1.4887, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 1.3443, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 1.5006487369537354, accuracy: 54.3 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 1.7463171482086182, accuracy: 47.6 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 1.5615874528884888, accuracy: 50.1 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 1.6080116033554077, accuracy: 48.4 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 1.5020692348480225, accuracy: 53.2 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 1.4830293655395508, accuracy: 54.0 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 1.486362338066101, accuracy: 53.0 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 1.490309238433838, accuracy: 52.8 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 1.4810203313827515, accuracy: 53.9 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 1.4781842231750488, accuracy: 54.5 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 1.5151, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 1.4555, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 1.2982, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 1.4842, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 1.4205, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 1.4909, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 1.4563, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 1.3648, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 1.4250, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 1.5913, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 1.50839364528656, accuracy: 52.5 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 2.1829960346221924, accuracy: 41.7 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 1.4843299388885498, accuracy: 55.1 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 1.6112089157104492, accuracy: 50.3 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 1.466084599494934, accuracy: 54.2 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 1.4846583604812622, accuracy: 55.0 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 1.4593966007232666, accuracy: 54.2 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 1.4577264785766602, accuracy: 56.4 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 1.4519622325897217, accuracy: 55.4 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 1.4507662057876587, accuracy: 55.4 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 1.3185, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 1.5326, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 1.4073, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 1.4104, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 1.5396, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 1.4147, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 1.4050, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 1.5377, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 1.3566, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 1.5533, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 1.3431954383850098, accuracy: 56.8 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 4.786501884460449, accuracy: 18.5 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 1.3578782081604004, accuracy: 55.7 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 1.6345502138137817, accuracy: 44.9 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 1.3248809576034546, accuracy: 57.5 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 1.3273028135299683, accuracy: 57.7 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 1.3891080617904663, accuracy: 55.3 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 1.3317238092422485, accuracy: 56.3 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 1.3148118257522583, accuracy: 58.8 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 1.3847943544387817, accuracy: 54.6 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 1.4409, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 1.3962, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 1.5273, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 1.5119, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 1.4083, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 1.5242, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 1.4532, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 1.4347, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 1.3926, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 1.2994, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 1.414014458656311, accuracy: 53.1 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 1.6809533834457397, accuracy: 45.0 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 1.4745765924453735, accuracy: 51.9 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 1.9409470558166504, accuracy: 42.9 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 1.447424054145813, accuracy: 51.4 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 1.4680591821670532, accuracy: 51.6 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 1.392566204071045, accuracy: 54.5 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 1.3856959342956543, accuracy: 54.7 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 1.3825334310531616, accuracy: 54.5 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 1.3786921501159668, accuracy: 54.7 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 1.1895, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 1.4288, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 1.1782, batch time: 0.09, accuracy:  64.84%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 1.3766, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 1.4152, batch time: 0.09, accuracy:  51.56%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 1.5024, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 1.5409, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 1.2571, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 1.4825, batch time: 0.09, accuracy:  53.91%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 1.7335, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 1.4932143688201904, accuracy: 52.8 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 1.7292091846466064, accuracy: 44.7 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 1.7203798294067383, accuracy: 40.2 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 3.8531839847564697, accuracy: 27.8 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 1.4994826316833496, accuracy: 53.1 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 1.4740244150161743, accuracy: 53.1 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 1.4719862937927246, accuracy: 52.1 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 1.4678200483322144, accuracy: 52.6 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 1.4633210897445679, accuracy: 52.7 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 1.4604624509811401, accuracy: 53.4 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 1.4144, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 1.3872, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 1.2836, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 1.3168, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 1.5421, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 1.3866, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 1.2727, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 1.4928, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 1.4496, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 1.5865, batch time: 0.08, accuracy:  52.34%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 1.475665807723999, accuracy: 52.5 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 2.235521078109741, accuracy: 40.6 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 1.4877879619598389, accuracy: 51.1 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 1.5343677997589111, accuracy: 49.2 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 1.4847557544708252, accuracy: 51.8 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 1.6060162782669067, accuracy: 47.7 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 1.4374113082885742, accuracy: 52.5 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 1.4385473728179932, accuracy: 52.9 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 1.4395055770874023, accuracy: 52.3 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 1.4352566003799438, accuracy: 52.4 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 1.4335, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 1.4547, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 1.3850, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 1.1412, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 1.4056, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 1.2464, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 1.5045, batch time: 0.09, accuracy:  50.00%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 1.3290, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 1.5773, batch time: 0.09, accuracy:  48.44%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 1.3616, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 1.392280101776123, accuracy: 54.0 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 1.5722090005874634, accuracy: 47.7 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 1.4371135234832764, accuracy: 52.1 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 4.783043384552002, accuracy: 25.7 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 1.4385236501693726, accuracy: 52.3 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 1.4658786058425903, accuracy: 52.7 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 1.3837194442749023, accuracy: 54.6 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 1.3786847591400146, accuracy: 54.2 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 1.380089521408081, accuracy: 54.7 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 1.378883719444275, accuracy: 54.3 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 1.5055, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 1.4728, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 1.4813, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 1.5103, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 1.3832, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 1.2795, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 1.3485, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 1.4558, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 1.3718, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 1.3712, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 1.3955426216125488, accuracy: 54.5 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 2.0710232257843018, accuracy: 42.2 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 1.426737666130066, accuracy: 53.7 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 1.4869660139083862, accuracy: 49.7 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 1.3837546110153198, accuracy: 57.1 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 1.3802047967910767, accuracy: 56.4 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 1.3783513307571411, accuracy: 55.4 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 1.3794411420822144, accuracy: 55.5 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 1.37174654006958, accuracy: 55.0 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 1.3685470819473267, accuracy: 55.7 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 1.3594, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 1.4633, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 1.4447, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 1.4534, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 1.4245, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 1.3531, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 1.4436, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 1.3696, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 1.3082, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 1.5106, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 1.4346696138381958, accuracy: 54.5 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 1.5605263710021973, accuracy: 50.0 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 1.625882863998413, accuracy: 47.4 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 4.300551891326904, accuracy: 27.8 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 1.4131884574890137, accuracy: 55.4 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 1.4195631742477417, accuracy: 54.5 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 1.399207353591919, accuracy: 54.8 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 1.3936400413513184, accuracy: 55.5 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 1.394420862197876, accuracy: 55.2 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 1.3943815231323242, accuracy: 55.5 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 1.4011, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 1.3306, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 1.5280, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 1.3193, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 1.3237, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 1.4187, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 1.4244, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 1.4274, batch time: 0.09, accuracy:  51.56%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 1.3936, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 1.4595, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 1.366988182067871, accuracy: 56.5 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 2.1434719562530518, accuracy: 42.8 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 1.4220174551010132, accuracy: 56.3 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 5.9230499267578125, accuracy: 13.5 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 1.3679476976394653, accuracy: 57.0 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 1.3658205270767212, accuracy: 55.7 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 1.3535867929458618, accuracy: 57.2 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 1.3505820035934448, accuracy: 57.2 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 1.3514302968978882, accuracy: 57.0 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 1.3519423007965088, accuracy: 56.6 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 1.5806, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 1.3150, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 1.4990, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 1.3060, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 1.5089, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 1.4613, batch time: 0.09, accuracy:  50.00%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 1.3192, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 1.3346, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 1.3083, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 1.4516, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 1.403971791267395, accuracy: 54.3 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 2.283905267715454, accuracy: 38.0 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 1.4599051475524902, accuracy: 52.2 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 1.4286867380142212, accuracy: 52.5 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 1.4055622816085815, accuracy: 54.9 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 1.4008928537368774, accuracy: 53.8 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 1.3925286531448364, accuracy: 55.8 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 1.3792717456817627, accuracy: 54.9 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 1.3820747137069702, accuracy: 55.6 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 1.3792997598648071, accuracy: 55.2 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 1.4392, batch time: 0.36, accuracy:  56.25%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 1.3261, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 1.5380, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 1.4644, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 1.2817, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 1.3961, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 1.3951, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 1.3405, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 1.4252, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 1.5400, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 1.3265453577041626, accuracy: 56.7 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 2.359142780303955, accuracy: 40.6 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 1.3703069686889648, accuracy: 55.5 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 1.4322878122329712, accuracy: 52.6 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 1.3351225852966309, accuracy: 56.6 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 1.3757054805755615, accuracy: 56.4 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 1.308318018913269, accuracy: 58.4 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 1.3009052276611328, accuracy: 57.7 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 1.3047581911087036, accuracy: 58.0 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 1.2999173402786255, accuracy: 58.4 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 1.3738, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 1.3990, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 1.2693, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 1.3404, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 1.2589, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 1.3307, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 1.5395, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 1.4571, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 1.3081, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 1.6662, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 1.3833870887756348, accuracy: 55.2 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 1.6005487442016602, accuracy: 49.4 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 1.6212067604064941, accuracy: 45.8 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 4.815924644470215, accuracy: 28.8 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 1.3892048597335815, accuracy: 54.0 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 1.4102680683135986, accuracy: 53.6 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 1.3678158521652222, accuracy: 55.3 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 1.3637545108795166, accuracy: 55.3 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 1.3639012575149536, accuracy: 55.7 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 1.3616570234298706, accuracy: 55.9 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 1.2286, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 1.5621, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 1.3310, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 1.4872, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 1.2759, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 1.3281, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 1.4723, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 1.3022, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 1.4037, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 1.7030, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 1.5113258361816406, accuracy: 50.5 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 2.598940134048462, accuracy: 37.3 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 1.5294080972671509, accuracy: 51.4 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 6.7352495193481445, accuracy: 21.2 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 1.459667682647705, accuracy: 53.9 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 1.4541288614273071, accuracy: 54.0 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 1.412406325340271, accuracy: 54.9 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 1.407522201538086, accuracy: 56.4 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 1.436379075050354, accuracy: 53.8 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 1.405009150505066, accuracy: 56.5 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 1.5133, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 1.3734, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 1.4174, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 1.4169, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 1.4384, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 1.2497, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 1.4252, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 1.4795, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 1.2862, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 1.4831, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 1.329215168952942, accuracy: 57.7 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 1.7233706712722778, accuracy: 46.5 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 1.6289223432540894, accuracy: 43.3 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 4.419029712677002, accuracy: 24.1 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 1.3754191398620605, accuracy: 56.1 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 1.4307150840759277, accuracy: 54.6 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 1.3195691108703613, accuracy: 58.7 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 1.3249329328536987, accuracy: 58.0 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 1.3142179250717163, accuracy: 58.8 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 1.3176943063735962, accuracy: 58.6 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 1.6130, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 1.5143, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 1.2672, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 1.2140, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 1.4635, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 1.2791, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 1.3712, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 1.3226, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 1.3456, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 1.3250, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 1.3451173305511475, accuracy: 57.7 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 1.7841733694076538, accuracy: 45.5 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 1.6329295635223389, accuracy: 42.2 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 4.098775863647461, accuracy: 29.7 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 1.4477256536483765, accuracy: 51.6 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 1.362177848815918, accuracy: 56.3 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 1.4777594804763794, accuracy: 51.4 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 1.4017826318740845, accuracy: 56.2 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 1.3297241926193237, accuracy: 58.7 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 1.3263527154922485, accuracy: 58.6 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 1.5250, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 1.4564, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 1.5079, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 1.7268, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 1.2766, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 1.3612, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 1.4069, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 1.4305, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 1.3866, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 1.3048, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 1.389178991317749, accuracy: 54.3 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 2.2779414653778076, accuracy: 38.0 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 1.460628867149353, accuracy: 52.8 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 10.030973434448242, accuracy: 14.0 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 1.403259515762329, accuracy: 53.9 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 1.4278960227966309, accuracy: 53.6 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 1.3826377391815186, accuracy: 54.8 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 1.3820855617523193, accuracy: 54.9 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 1.3817331790924072, accuracy: 55.2 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 1.3769716024398804, accuracy: 54.9 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 1.3555, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 1.2418, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 1.3984, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 1.2205, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 1.2968, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 1.5439, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 1.2765, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 1.3210, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 1.4644, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 1.3353, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 1.3889633417129517, accuracy: 54.7 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 2.527750253677368, accuracy: 36.5 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 1.471189022064209, accuracy: 51.7 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 1.9017689228057861, accuracy: 41.6 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 1.3837331533432007, accuracy: 53.6 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 1.4569995403289795, accuracy: 51.0 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 1.364748477935791, accuracy: 54.2 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 1.3594732284545898, accuracy: 54.1 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 1.360756754875183, accuracy: 54.1 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 1.3636664152145386, accuracy: 53.9 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 1.2268, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 1.4691, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 1.3485, batch time: 0.09, accuracy:  53.91%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 1.5423, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 1.4882, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 1.4643, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 1.4270, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 1.2526, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 1.3478, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 1.4623, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 1.3677959442138672, accuracy: 56.5 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 1.675133466720581, accuracy: 47.3 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 1.7036799192428589, accuracy: 42.9 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 4.824002742767334, accuracy: 23.6 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 1.4147359132766724, accuracy: 54.8 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 1.3789063692092896, accuracy: 56.7 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 1.346723198890686, accuracy: 57.8 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 1.3421717882156372, accuracy: 57.1 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 1.3447368144989014, accuracy: 57.4 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 1.3412299156188965, accuracy: 57.0 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 1.1080, batch time: 0.04, accuracy:  67.97%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 1.3617, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 1.2474, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 1.4969, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 1.1630, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 1.4452, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 1.0518, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 1.1847, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 1.3796, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 1.2317, batch time: 0.08, accuracy:  61.72%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 1.3509303331375122, accuracy: 57.5 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 1.6352217197418213, accuracy: 48.3 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 1.6722928285598755, accuracy: 42.2 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 5.828412055969238, accuracy: 28.1 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 1.3287041187286377, accuracy: 58.3 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 1.3246127367019653, accuracy: 58.0 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 1.3291741609573364, accuracy: 58.6 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 1.3198484182357788, accuracy: 59.1 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 1.318868637084961, accuracy: 59.1 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 1.3176051378250122, accuracy: 59.3 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 1.4551, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 1.3787, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 1.5201, batch time: 0.09, accuracy:  53.91%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 1.2081, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 1.2073, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 1.1852, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 1.2971, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 1.5057, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 1.5456, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 1.3428, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 1.4101632833480835, accuracy: 55.7 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 1.7632417678833008, accuracy: 45.0 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 1.664404034614563, accuracy: 43.7 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 5.405622482299805, accuracy: 18.4 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 1.4682673215866089, accuracy: 51.7 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 1.4032392501831055, accuracy: 56.2 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 1.3915389776229858, accuracy: 56.4 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 1.3889919519424438, accuracy: 56.2 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 1.3858273029327393, accuracy: 56.2 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 1.384684681892395, accuracy: 56.6 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 1.3698, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 1.1409, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 1.3147, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 1.2662, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 1.3309, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 1.5905, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 1.2893, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 1.1819, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 1.3860, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 1.3309, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 1.3667349815368652, accuracy: 57.0 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 1.8049869537353516, accuracy: 45.6 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 1.6641300916671753, accuracy: 42.3 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 4.024997234344482, accuracy: 29.8 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 1.3636584281921387, accuracy: 57.1 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 1.3712069988250732, accuracy: 56.1 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 1.327637791633606, accuracy: 58.8 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 1.322752594947815, accuracy: 59.0 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 1.3234503269195557, accuracy: 58.6 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 1.3205065727233887, accuracy: 58.9 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 1.4012, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 1.3456, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 1.4540, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 1.3159, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 1.2667, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 1.2243, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 1.5064, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 1.3483, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 1.4529, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 1.2061, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 1.3414876461029053, accuracy: 57.2 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 1.6158175468444824, accuracy: 50.5 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 1.6850603818893433, accuracy: 42.6 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 1.7786482572555542, accuracy: 46.7 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 1.3348639011383057, accuracy: 57.4 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 1.3153266906738281, accuracy: 58.1 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 1.3271251916885376, accuracy: 57.4 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 1.3321936130523682, accuracy: 57.5 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 1.325892686843872, accuracy: 58.5 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 1.3188878297805786, accuracy: 57.6 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 1.2446, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 1.5532, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 1.4147, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 1.3858, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 1.1963, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 1.5427, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 1.3980, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 1.3777, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 1.6339, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 1.2432, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 1.3454035520553589, accuracy: 58.4 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 4.203616619110107, accuracy: 19.6 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 1.3408349752426147, accuracy: 58.2 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 1.3408349752426147, accuracy: 58.2 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 1.340844988822937, accuracy: 57.6 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 1.334118366241455, accuracy: 57.8 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 1.341304063796997, accuracy: 58.9 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 1.3334999084472656, accuracy: 59.4 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 1.3359133005142212, accuracy: 58.4 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 1.3216887712478638, accuracy: 58.8 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 1.2632, batch time: 0.12, accuracy:  60.94%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 1.2457, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 1.3614, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 1.2109, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 1.3400, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 1.1869, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 1.1264, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 1.2842, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 1.5399, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 1.2145, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 1.3099164962768555, accuracy: 58.8 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 1.742739200592041, accuracy: 45.5 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 1.6575736999511719, accuracy: 45.6 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 4.6631364822387695, accuracy: 30.7 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 1.3540095090866089, accuracy: 56.2 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 1.3236013650894165, accuracy: 57.4 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 1.2997097969055176, accuracy: 58.9 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 1.297208309173584, accuracy: 58.0 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 1.2969141006469727, accuracy: 58.9 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 1.3000544309616089, accuracy: 58.1 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 1.2369, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 1.2591, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 1.3154, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 1.3992, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 1.4927, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 1.3787, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 1.3579, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 1.3927, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 1.4864, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 1.4542, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 1.310591459274292, accuracy: 57.7 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 4.245234489440918, accuracy: 23.0 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 1.6363767385482788, accuracy: 47.1 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 10.768715858459473, accuracy: 12.3 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 1.3321313858032227, accuracy: 56.9 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 1.306169033050537, accuracy: 59.1 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 1.2924635410308838, accuracy: 58.5 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 1.2886215448379517, accuracy: 59.1 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 1.2934253215789795, accuracy: 58.6 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 1.2879493236541748, accuracy: 58.6 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 1.2325, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 1.3341, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 1.2215, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 1.2799, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 1.5623, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 1.4384, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 1.2417, batch time: 0.09, accuracy:  67.97%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 1.3957, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 1.3952, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 1.4088, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 1.3992512226104736, accuracy: 57.7 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 5.145995140075684, accuracy: 18.5 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 1.7333437204360962, accuracy: 43.7 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 10.937562942504883, accuracy: 13.2 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 1.417324423789978, accuracy: 56.0 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 1.390014886856079, accuracy: 56.3 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 1.3812463283538818, accuracy: 56.7 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 1.3817017078399658, accuracy: 55.2 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 1.3836716413497925, accuracy: 57.4 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 1.3763161897659302, accuracy: 56.2 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 1.7029, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 1.3711, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 1.1477, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 1.3055, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 1.4404, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 1.4390, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 1.3903, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 1.3535, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 1.3240, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 1.3155, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 1.3773210048675537, accuracy: 55.2 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 4.947600364685059, accuracy: 21.7 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 1.7221962213516235, accuracy: 42.9 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 4.652928829193115, accuracy: 23.4 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 1.3829594850540161, accuracy: 54.7 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 1.4215517044067383, accuracy: 53.5 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 1.3653223514556885, accuracy: 56.9 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 1.3603532314300537, accuracy: 57.8 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 1.3603510856628418, accuracy: 57.9 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 1.3582218885421753, accuracy: 57.2 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 1.2509, batch time: 0.12, accuracy:  59.38%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 1.2509, batch time: 0.12, accuracy:  57.03%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 1.3839, batch time: 0.12, accuracy:  53.91%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 1.3273, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 1.4646, batch time: 0.11, accuracy:  45.31%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 1.2654, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 1.3217, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 1.4116, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 1.0882, batch time: 0.06, accuracy:  62.50%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 1.3228, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 1.3299055099487305, accuracy: 59.0 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 5.219444751739502, accuracy: 19.1 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 1.6327195167541504, accuracy: 47.6 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 3.0880603790283203, accuracy: 26.8 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 1.4673770666122437, accuracy: 53.4 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 1.4044289588928223, accuracy: 58.0 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 1.3060128688812256, accuracy: 58.7 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 1.3048415184020996, accuracy: 58.3 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 1.3026925325393677, accuracy: 59.4 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 1.3353379964828491, accuracy: 57.6 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 1.1787, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 1.2142, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 1.3419, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 1.2082, batch time: 0.09, accuracy:  64.84%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 1.2345, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 1.1780, batch time: 0.09, accuracy:  60.94%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 1.4406, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 1.2386, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 1.5296, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 1.4138, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 1.2393289804458618, accuracy: 62.3 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 1.9804530143737793, accuracy: 45.7 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 1.5693657398223877, accuracy: 48.9 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 1.3969048261642456, accuracy: 54.8 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 1.246889352798462, accuracy: 59.6 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 1.2710344791412354, accuracy: 59.4 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 1.2367507219314575, accuracy: 60.0 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 1.2276533842086792, accuracy: 61.5 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 1.224331259727478, accuracy: 61.3 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 1.2227275371551514, accuracy: 61.3 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 1.1617, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 1.4273, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 1.3629, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 1.3130, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 1.0961, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 1.1764, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 1.3581, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 1.4030, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 1.2675, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 1.4704, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 1.2911161184310913, accuracy: 56.7 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 5.395168781280518, accuracy: 19.3 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 1.644905686378479, accuracy: 43.6 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 10.911970138549805, accuracy: 13.0 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 1.3050663471221924, accuracy: 55.3 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 1.355695366859436, accuracy: 54.6 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 1.2768585681915283, accuracy: 57.3 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 1.2746306657791138, accuracy: 56.9 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 1.2721132040023804, accuracy: 57.7 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 1.2745561599731445, accuracy: 57.7 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 1.2625, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 1.1980, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 1.5014, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 1.2386, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 1.1828, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 1.3711, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 1.3029, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 1.2410, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 1.2624, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 1.2360, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 1.3290832042694092, accuracy: 56.1 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 5.1395063400268555, accuracy: 20.0 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 1.7496508359909058, accuracy: 46.7 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 8.776576042175293, accuracy: 12.9 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 1.3575025796890259, accuracy: 56.4 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 1.43553626537323, accuracy: 53.2 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 1.320712924003601, accuracy: 57.1 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 1.3182998895645142, accuracy: 58.2 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 1.3231667280197144, accuracy: 57.9 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 1.3198622465133667, accuracy: 56.6 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 1.3571, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 1.2619, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 1.2587, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 1.1766, batch time: 0.06, accuracy:  62.50%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 1.1343, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 1.1733, batch time: 0.04, accuracy:  67.19%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 1.4399, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 1.2335, batch time: 0.08, accuracy:  54.69%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 1.1635, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 1.5103, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 1.3220244646072388, accuracy: 57.2 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 2.6473891735076904, accuracy: 36.8 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 1.439442753791809, accuracy: 51.6 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 3.646430015563965, accuracy: 23.6 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 1.3268427848815918, accuracy: 56.6 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 1.3436272144317627, accuracy: 57.2 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 1.3102236986160278, accuracy: 57.7 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 1.3088593482971191, accuracy: 56.9 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 1.304416537284851, accuracy: 57.9 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 1.3045598268508911, accuracy: 57.9 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 1.3369, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 1.3336, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 1.1371, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 1.3102, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 1.3830, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 1.2913, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 1.5271, batch time: 0.11, accuracy:  46.09%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 1.2574, batch time: 0.09, accuracy:  51.56%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 1.2532, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 1.2841, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 1.258807897567749, accuracy: 60.1 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 4.871330261230469, accuracy: 24.8 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 1.6095936298370361, accuracy: 46.3 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 7.296493053436279, accuracy: 20.7 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 1.5653505325317383, accuracy: 50.3 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 1.497810959815979, accuracy: 52.7 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 1.2528733015060425, accuracy: 60.5 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 1.2497122287750244, accuracy: 60.3 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 1.2515813112258911, accuracy: 60.9 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 1.249950647354126, accuracy: 59.4 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 1.3390, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 1.4230, batch time: 0.08, accuracy:  55.47%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 1.3093, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 1.4754, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 1.3588, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 1.0864, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 1.5822, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 1.2719, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 1.2554, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 1.3573, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 1.3001561164855957, accuracy: 59.2 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 1.8100287914276123, accuracy: 44.1 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 1.6909916400909424, accuracy: 45.0 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 7.0366668701171875, accuracy: 22.2 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 1.2995473146438599, accuracy: 60.0 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 1.4400314092636108, accuracy: 57.1 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 1.2910312414169312, accuracy: 59.5 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 1.2882888317108154, accuracy: 58.9 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 1.2874127626419067, accuracy: 59.1 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 1.2899872064590454, accuracy: 58.9 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 1.3403, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 1.4744, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 1.1905, batch time: 0.09, accuracy:  63.28%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 1.2005, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 1.3121, batch time: 0.09, accuracy:  53.91%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 1.2127, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 1.5426, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 1.3708, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 1.3476, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 1.1639, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 1.3202208280563354, accuracy: 58.0 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 2.0187177658081055, accuracy: 41.2 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 1.7710264921188354, accuracy: 43.3 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 2.010990858078003, accuracy: 43.2 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 1.5722960233688354, accuracy: 49.2 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 1.407869815826416, accuracy: 55.0 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 1.3135364055633545, accuracy: 57.4 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 1.312941312789917, accuracy: 59.2 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 1.3187916278839111, accuracy: 58.6 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 1.310439109802246, accuracy: 58.4 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 1.3959, batch time: 0.09, accuracy:  63.28%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 1.4610, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 1.2374, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 1.3829, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 1.6342, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 1.2993, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 1.3789, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 1.3451, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 1.2914, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 1.1915, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 1.3147367238998413, accuracy: 57.2 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 2.50038743019104, accuracy: 37.0 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 1.4338775873184204, accuracy: 50.8 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 1.7165281772613525, accuracy: 46.5 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 1.3954381942749023, accuracy: 54.8 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 1.3440425395965576, accuracy: 55.9 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 1.3021284341812134, accuracy: 57.6 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 1.2973991632461548, accuracy: 57.9 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 1.301867961883545, accuracy: 57.6 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 1.297045111656189, accuracy: 58.1 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 1.1391, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 1.2377, batch time: 0.09, accuracy:  64.84%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 1.3916, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 1.3011, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 1.1568, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 1.2699, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 1.2239, batch time: 0.09, accuracy:  66.41%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 1.1407, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 1.1278, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 1.3017, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 1.3914717435836792, accuracy: 56.5 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 3.0464651584625244, accuracy: 35.5 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 1.490492820739746, accuracy: 51.6 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 2.0053539276123047, accuracy: 43.2 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 1.367192029953003, accuracy: 55.9 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 1.4797172546386719, accuracy: 55.2 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 1.3781795501708984, accuracy: 55.7 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 1.390854001045227, accuracy: 55.7 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 1.3601830005645752, accuracy: 56.6 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 1.355897307395935, accuracy: 56.5 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 1.3653, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 1.3294, batch time: 0.09, accuracy:  53.91%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 1.2259, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 1.3208, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 1.5867, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 1.3427, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 1.4653, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 1.2585, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 1.1258, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 1.4134, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 1.3489251136779785, accuracy: 57.1 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 5.249207973480225, accuracy: 23.6 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 1.7941926717758179, accuracy: 42.2 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 7.924081802368164, accuracy: 17.5 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 1.3567982912063599, accuracy: 57.1 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 1.4132628440856934, accuracy: 53.4 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 1.336133599281311, accuracy: 58.0 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 1.331333041191101, accuracy: 58.2 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 1.3305611610412598, accuracy: 57.6 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 1.3295958042144775, accuracy: 57.6 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 1.4983, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 1.3360, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 1.3625, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 1.3160, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 1.2765, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 1.2569, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 1.1871, batch time: 0.08, accuracy:  61.72%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 1.2999, batch time: 0.08, accuracy:  58.59%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 1.1733, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 1.2921, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 1.2561308145523071, accuracy: 59.9 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 5.465659141540527, accuracy: 21.5 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 1.7207040786743164, accuracy: 43.2 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 3.7012112140655518, accuracy: 25.5 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 1.287549614906311, accuracy: 58.4 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 1.2502578496932983, accuracy: 60.5 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 1.2483646869659424, accuracy: 60.8 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 1.2472089529037476, accuracy: 60.2 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 1.2479599714279175, accuracy: 60.3 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 1.2434078454971313, accuracy: 60.6 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 1.1726, batch time: 0.09, accuracy:  60.94%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 1.4800, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 1.0394, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 1.4711, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 1.4217, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 1.2715, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 1.1804, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 1.1932, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 1.2930, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 1.3746, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 1.2603720426559448, accuracy: 57.9 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 5.277376174926758, accuracy: 24.6 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 1.7422269582748413, accuracy: 46.1 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 6.601379871368408, accuracy: 25.9 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 1.27353036403656, accuracy: 57.9 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 1.2858225107192993, accuracy: 57.1 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 1.2597837448120117, accuracy: 58.2 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 1.25770902633667, accuracy: 59.0 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 1.2546952962875366, accuracy: 58.7 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 1.2547667026519775, accuracy: 59.1 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 1.1791, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 1.4030, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 1.2610, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 1.3483, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 1.3263, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 1.3019, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 1.4412, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 1.5018, batch time: 0.09, accuracy:  53.91%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 1.3966, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 1.4277, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 1.206626534461975, accuracy: 61.8 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 5.586991786956787, accuracy: 22.5 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 1.6663776636123657, accuracy: 48.5 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 8.490396499633789, accuracy: 18.9 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 1.2444446086883545, accuracy: 59.9 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 1.3544974327087402, accuracy: 56.4 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 1.1983237266540527, accuracy: 61.3 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 1.1984905004501343, accuracy: 61.7 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 1.1948041915893555, accuracy: 61.3 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 1.1992684602737427, accuracy: 60.7 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 1.0260, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 1.2465, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 1.0510, batch time: 0.04, accuracy:  67.19%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 1.2765, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 1.4402, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 1.1682, batch time: 0.09, accuracy:  63.28%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 1.3173, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 1.5367, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 1.4589, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 1.4951, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 1.2385236024856567, accuracy: 62.3 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 5.112542152404785, accuracy: 24.0 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 1.774135947227478, accuracy: 43.0 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 4.875151634216309, accuracy: 25.4 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 1.619242548942566, accuracy: 46.4 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 1.5130839347839355, accuracy: 53.4 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 1.2324273586273193, accuracy: 62.3 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 1.2277752161026, accuracy: 62.2 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 1.229555368423462, accuracy: 62.3 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 1.225347638130188, accuracy: 62.6 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 1.3858, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 1.3713, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 1.3132, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 1.1267, batch time: 0.04, accuracy:  67.97%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 1.3031, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 1.1703, batch time: 0.09, accuracy:  64.84%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 1.2742, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 1.3549, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 1.0887, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 1.2189, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 1.2357999086380005, accuracy: 61.4 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 4.923885822296143, accuracy: 22.0 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 1.4025341272354126, accuracy: 53.9 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 4.35222864151001, accuracy: 32.9 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 1.2671542167663574, accuracy: 58.7 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 1.2472094297409058, accuracy: 60.5 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 1.2275588512420654, accuracy: 61.1 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 1.2243434190750122, accuracy: 61.7 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 1.2251781225204468, accuracy: 61.6 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 1.2228763103485107, accuracy: 61.3 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 1.2520, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 1.6096, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 1.2709, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 1.1885, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 1.2584, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 1.0348, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 1.2033, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 1.3963, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 1.2042, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 1.2106, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 1.2405225038528442, accuracy: 60.4 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 5.185499668121338, accuracy: 20.8 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 1.6616867780685425, accuracy: 49.0 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 9.221410751342773, accuracy: 11.4 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 1.3288404941558838, accuracy: 59.5 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 1.3131310939788818, accuracy: 58.9 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 1.2279276847839355, accuracy: 60.8 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 1.23360276222229, accuracy: 61.4 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 1.2222398519515991, accuracy: 60.5 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 1.2222844362258911, accuracy: 60.5 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 1.1873, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 1.2059, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 1.1326, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 1.2149, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 1.1861, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 1.4350, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 1.3170, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 1.2698, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 1.4808, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 1.3285, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 1.2172455787658691, accuracy: 62.6 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 5.146845817565918, accuracy: 22.3 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 1.3434075117111206, accuracy: 56.1 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 6.088824272155762, accuracy: 30.1 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 1.256814956665039, accuracy: 60.4 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 1.5542293787002563, accuracy: 50.5 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 1.206676721572876, accuracy: 62.8 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 1.2029474973678589, accuracy: 62.0 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 1.2979997396469116, accuracy: 60.1 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 1.1966843605041504, accuracy: 62.5 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 1.4753, batch time: 0.09, accuracy:  60.94%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 1.2681, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 1.2352, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 1.2348, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 1.3760, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 1.2927, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 1.5068, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 1.2392, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 1.1072, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 1.1018, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 1.2275733947753906, accuracy: 60.1 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 5.638225078582764, accuracy: 18.2 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 1.7740693092346191, accuracy: 47.5 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 6.813719272613525, accuracy: 26.0 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 1.249306321144104, accuracy: 58.9 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 1.3706122636795044, accuracy: 59.2 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 1.2123876810073853, accuracy: 60.3 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 1.2107081413269043, accuracy: 60.1 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 1.224186658859253, accuracy: 60.1 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 1.2151219844818115, accuracy: 60.4 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 1.4021, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 1.2245, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 1.2792, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 1.2128, batch time: 0.09, accuracy:  66.41%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 1.1582, batch time: 0.09, accuracy:  63.28%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 1.5068, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 1.1830, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 1.2361, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 1.2377, batch time: 0.09, accuracy:  60.94%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 1.2229, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 1.2918692827224731, accuracy: 59.8 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 5.7152838706970215, accuracy: 18.0 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 1.8750836849212646, accuracy: 44.8 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 6.667051315307617, accuracy: 26.4 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 1.3569183349609375, accuracy: 57.3 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 1.4490981101989746, accuracy: 54.8 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 1.2653412818908691, accuracy: 60.4 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 1.2711520195007324, accuracy: 60.3 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 1.2600889205932617, accuracy: 60.8 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 1.2775055170059204, accuracy: 59.6 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 1.1454, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 1.0565, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 1.2261, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 1.1713, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 1.3008, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 1.1746, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 1.4040, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 1.4744, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 1.0958, batch time: 0.09, accuracy:  67.19%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 1.2403, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 1.2094721794128418, accuracy: 61.1 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 6.402655124664307, accuracy: 17.6 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 1.6126644611358643, accuracy: 51.3 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 11.28049373626709, accuracy: 13.1 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 1.2621406316757202, accuracy: 59.1 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 1.2438825368881226, accuracy: 59.4 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 1.1839500665664673, accuracy: 63.0 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 1.1796878576278687, accuracy: 63.4 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 1.1787121295928955, accuracy: 63.4 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 1.1785727739334106, accuracy: 62.7 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 1.2965, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 1.2818, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 1.2924, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 1.1485, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 1.2971, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 1.4455, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 1.4291, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 1.2253, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 1.0727, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 1.1307, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 1.2083295583724976, accuracy: 60.8 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 5.724282741546631, accuracy: 20.2 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 1.4067487716674805, accuracy: 53.0 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 11.869986534118652, accuracy: 13.6 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 1.6263676881790161, accuracy: 47.3 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 1.2359983921051025, accuracy: 59.3 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 1.197946548461914, accuracy: 61.6 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 1.1912919282913208, accuracy: 61.7 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 1.1901715993881226, accuracy: 62.1 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 1.188161849975586, accuracy: 62.0 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 1.2189, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 1.2713, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 1.4372, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 1.1202, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 1.1777, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 1.1121, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 1.2833, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 1.0700, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 1.4619, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 1.2585, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 1.2654969692230225, accuracy: 59.5 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 5.9161810874938965, accuracy: 16.9 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 1.640087604522705, accuracy: 50.2 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 10.838504791259766, accuracy: 12.7 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 2.0178282260894775, accuracy: 40.0 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 1.4392948150634766, accuracy: 55.0 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 1.2405307292938232, accuracy: 59.9 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 1.2398101091384888, accuracy: 60.2 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 1.2404286861419678, accuracy: 59.8 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 1.2371100187301636, accuracy: 60.5 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 1.4424, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 1.1488, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 1.2052, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 1.4586, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 1.1886, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 1.3189, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 1.0012, batch time: 0.10, accuracy:  69.53%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 1.2327, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 1.4346, batch time: 0.09, accuracy:  60.94%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 1.5067, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 1.2162449359893799, accuracy: 61.1 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 6.73417329788208, accuracy: 18.5 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 1.6374094486236572, accuracy: 51.7 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 12.141412734985352, accuracy: 12.7 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 1.2214759588241577, accuracy: 60.1 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 1.4063913822174072, accuracy: 57.3 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 1.2067384719848633, accuracy: 61.5 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 1.2021386623382568, accuracy: 61.5 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 1.2079763412475586, accuracy: 61.1 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 1.1987755298614502, accuracy: 61.4 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 1.3577, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 1.3434, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 1.2188, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 1.2150, batch time: 0.09, accuracy:  60.94%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 1.3214, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 1.3344, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 1.1411, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 1.2619, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 1.0794, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 1.4222, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 1.1973419189453125, accuracy: 62.5 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 5.9468793869018555, accuracy: 16.8 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 1.6279089450836182, accuracy: 52.7 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 10.260643005371094, accuracy: 12.8 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 1.385357141494751, accuracy: 55.9 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 1.3590549230575562, accuracy: 58.0 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 1.1834933757781982, accuracy: 62.9 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 1.1860309839248657, accuracy: 62.6 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 1.1896255016326904, accuracy: 62.4 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 1.188985824584961, accuracy: 62.7 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 1.3571, batch time: 0.08, accuracy:  55.47%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 1.1244, batch time: 0.04, accuracy:  67.19%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 1.1353, batch time: 0.09, accuracy:  63.28%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 1.1488, batch time: 0.04, accuracy:  69.53%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 1.2694, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 1.0437, batch time: 0.08, accuracy:  68.75%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 1.1263, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 1.3734, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 1.2816, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 1.2811, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 1.229615330696106, accuracy: 60.1 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 5.479887008666992, accuracy: 20.8 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 1.6737282276153564, accuracy: 52.0 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 8.559894561767578, accuracy: 15.9 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 1.4567101001739502, accuracy: 52.4 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 1.2626993656158447, accuracy: 57.8 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 1.2222477197647095, accuracy: 60.5 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 1.2157447338104248, accuracy: 60.6 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 1.2157586812973022, accuracy: 61.7 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 1.2112007141113281, accuracy: 62.3 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 1.2953, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 1.1485, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 1.3139, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 1.3339, batch time: 0.09, accuracy:  60.94%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 1.1407, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 1.1513, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 1.2808, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 1.2789, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 1.2860, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 1.2525, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 1.2428507804870605, accuracy: 59.5 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 5.595120429992676, accuracy: 18.5 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 1.5007827281951904, accuracy: 51.8 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 2.7833526134490967, accuracy: 33.9 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 1.2650141716003418, accuracy: 59.2 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 1.2757676839828491, accuracy: 59.7 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 1.2232393026351929, accuracy: 60.1 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 1.2192590236663818, accuracy: 60.9 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 1.2235047817230225, accuracy: 60.5 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 1.216995358467102, accuracy: 61.4 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 1.1405, batch time: 0.09, accuracy:  60.94%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 1.0454, batch time: 0.09, accuracy:  65.62%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 1.3786, batch time: 0.09, accuracy:  53.91%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 1.2560, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 1.1875, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 1.3849, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 1.1227, batch time: 0.09, accuracy:  63.28%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 1.1028, batch time: 0.09, accuracy:  64.84%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 1.3336, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 1.2622, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 1.2447853088378906, accuracy: 61.4 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 6.26382303237915, accuracy: 19.2 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 1.6630178689956665, accuracy: 52.3 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 10.008711814880371, accuracy: 14.3 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 1.2531784772872925, accuracy: 60.3 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 1.3236112594604492, accuracy: 60.8 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 1.337503433227539, accuracy: 60.1 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 1.2749712467193604, accuracy: 61.0 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 1.2392734289169312, accuracy: 61.7 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 1.2359809875488281, accuracy: 61.4 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 1.1750, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 1.1992, batch time: 0.49, accuracy:  61.72%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 1.3205, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 1.0411, batch time: 0.09, accuracy:  71.09%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 1.1021, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 1.1523, batch time: 0.04, accuracy:  67.19%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 1.3454, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 1.1676, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 1.2028, batch time: 0.09, accuracy:  65.62%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 1.0765, batch time: 0.07, accuracy:  66.41%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 1.2066797018051147, accuracy: 61.4 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 5.907883644104004, accuracy: 17.5 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 1.6482325792312622, accuracy: 50.6 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 10.312641143798828, accuracy: 11.7 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 1.2299288511276245, accuracy: 60.3 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 1.2449458837509155, accuracy: 59.1 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 1.1990755796432495, accuracy: 60.0 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 1.1945858001708984, accuracy: 60.0 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 1.1934089660644531, accuracy: 60.5 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 1.1922494173049927, accuracy: 60.6 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 1.2965, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 1.1901, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 1.3867, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 1.2102, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 1.0945, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 1.1757, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 1.1281, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 1.4629, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 1.2871, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 1.2508, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 1.2380225658416748, accuracy: 59.9 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 6.379364490509033, accuracy: 18.2 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 1.785232663154602, accuracy: 50.5 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 2.7347593307495117, accuracy: 38.1 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 1.2692592144012451, accuracy: 58.9 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 1.243333339691162, accuracy: 60.2 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 1.218528389930725, accuracy: 60.1 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 1.2175320386886597, accuracy: 59.8 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 1.2133450508117676, accuracy: 60.7 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 1.2141207456588745, accuracy: 60.6 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 1.2462, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 1.1663, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 1.2494, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 1.1916, batch time: 0.09, accuracy:  63.28%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 1.3661, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 1.1428, batch time: 0.09, accuracy:  65.62%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 1.2213, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 1.3310, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 1.1520, batch time: 0.09, accuracy:  67.19%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 1.4346, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 1.270482063293457, accuracy: 61.1 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 5.979542255401611, accuracy: 19.3 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 1.7305574417114258, accuracy: 51.2 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 10.099483489990234, accuracy: 11.5 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 1.2820450067520142, accuracy: 60.7 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 1.858545184135437, accuracy: 42.0 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 1.249313235282898, accuracy: 62.0 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 1.2488681077957153, accuracy: 61.8 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 1.2472031116485596, accuracy: 61.6 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 1.2405657768249512, accuracy: 61.3 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 1.2818, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 1.3124, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 1.0837, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 1.1234, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 1.2390, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 1.2455, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 1.0431, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 1.3086, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 1.3363, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 1.3914, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 1.2382721900939941, accuracy: 61.2 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 5.554906845092773, accuracy: 18.6 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 1.7896195650100708, accuracy: 47.0 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 8.668810844421387, accuracy: 13.3 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 1.2636271715164185, accuracy: 59.4 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 1.2427157163619995, accuracy: 61.0 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 1.2312250137329102, accuracy: 61.1 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 1.2278634309768677, accuracy: 60.3 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 1.2288309335708618, accuracy: 61.0 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 1.2245116233825684, accuracy: 60.6 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 1.1948, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 1.3343, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 1.0973, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 1.1541, batch time: 0.09, accuracy:  65.62%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 1.1522, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 1.1837, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 1.1723, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 1.4011, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 1.3278, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 1.0912, batch time: 0.04, accuracy:  68.75%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 1.212929368019104, accuracy: 60.5 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 5.227490425109863, accuracy: 19.2 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 1.7325388193130493, accuracy: 49.0 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 9.074034690856934, accuracy: 13.3 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 1.2604377269744873, accuracy: 58.6 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 1.3245381116867065, accuracy: 56.2 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 1.2049033641815186, accuracy: 61.4 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 1.2181391716003418, accuracy: 59.4 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 1.2018325328826904, accuracy: 61.2 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 1.2000759840011597, accuracy: 61.4 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 1.0482, batch time: 0.06, accuracy:  67.19%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 1.0912, batch time: 0.09, accuracy:  66.41%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 1.4164, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 1.1825, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 1.1520, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 1.2304, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 1.4312, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 1.2084, batch time: 0.07, accuracy:  60.16%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 1.4020, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 1.2182, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 1.2071921825408936, accuracy: 59.8 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 5.5506486892700195, accuracy: 21.4 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 1.732957363128662, accuracy: 49.8 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 6.847012996673584, accuracy: 24.3 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 1.2758959531784058, accuracy: 57.9 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 1.335054636001587, accuracy: 54.3 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 1.1913400888442993, accuracy: 61.0 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 1.200080394744873, accuracy: 60.3 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 1.1903069019317627, accuracy: 61.1 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 1.1885120868682861, accuracy: 60.9 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 1.1641, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 1.0765, batch time: 0.12, accuracy:  67.19%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 1.3246, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 1.0729, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 1.2306, batch time: 0.12, accuracy:  60.16%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 1.2807, batch time: 0.13, accuracy:  57.03%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 1.2176, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 1.0788, batch time: 0.06, accuracy:  65.62%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 1.2780, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 1.1168, batch time: 0.04, accuracy:  67.19%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 1.2327046394348145, accuracy: 60.9 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 5.131711006164551, accuracy: 20.3 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 1.7435225248336792, accuracy: 50.4 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 3.651994466781616, accuracy: 30.2 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 1.2241495847702026, accuracy: 61.9 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 1.227407455444336, accuracy: 61.2 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 1.219238042831421, accuracy: 61.4 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 1.2152230739593506, accuracy: 61.2 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 1.2223351001739502, accuracy: 61.1 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 1.2405954599380493, accuracy: 60.0 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 1.1532, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 1.2720, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 1.2846, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 1.3070, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 1.2075, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 1.2603, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 1.1554, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 1.2866, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 1.2522, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 1.2485, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 1.272065281867981, accuracy: 59.6 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 5.242342472076416, accuracy: 19.9 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 1.4000276327133179, accuracy: 55.5 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 8.592257499694824, accuracy: 22.3 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 1.269514560699463, accuracy: 58.9 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 1.281594157218933, accuracy: 58.6 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 1.2482409477233887, accuracy: 60.2 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 1.246549367904663, accuracy: 60.1 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 1.2443230152130127, accuracy: 60.8 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 1.2474502325057983, accuracy: 60.1 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 1.1496, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 1.2669, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 1.2096, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 1.1714, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 1.3838, batch time: 0.28, accuracy:  61.72%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 1.3072, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 1.2285, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 1.0407, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 1.0825, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 1.1293, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 1.2859671115875244, accuracy: 58.4 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 5.572245121002197, accuracy: 19.9 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 1.8171247243881226, accuracy: 48.6 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 9.98410701751709, accuracy: 11.0 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 1.3099839687347412, accuracy: 57.8 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 1.402452826499939, accuracy: 54.2 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 1.2785536050796509, accuracy: 58.0 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 1.2742207050323486, accuracy: 58.5 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 1.2751494646072388, accuracy: 58.0 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 1.2738161087036133, accuracy: 58.8 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 1.1769, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 1.1587, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 1.3324, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 1.0983, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 1.2431, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 1.0796, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 1.3078, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 1.5751, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 1.2885, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 1.0612, batch time: 0.04, accuracy:  68.75%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 1.2346630096435547, accuracy: 61.1 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 5.520914554595947, accuracy: 19.8 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 1.7151780128479004, accuracy: 50.5 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 11.170609474182129, accuracy: 12.9 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 1.2507190704345703, accuracy: 60.0 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 1.3149226903915405, accuracy: 58.3 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 1.2109205722808838, accuracy: 60.4 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 1.2231996059417725, accuracy: 59.8 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 1.20976722240448, accuracy: 60.5 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 1.2088346481323242, accuracy: 59.7 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 1.2474, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 1.0763, batch time: 0.04, accuracy:  67.97%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 1.2634, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 1.2780, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 1.4233, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 1.0939, batch time: 0.09, accuracy:  63.28%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 1.0529, batch time: 0.09, accuracy:  67.97%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 1.1968, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 1.4448, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 1.0936, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 1.2206846475601196, accuracy: 62.4 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 5.544677257537842, accuracy: 19.0 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 1.6932185888290405, accuracy: 50.8 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 9.201590538024902, accuracy: 14.1 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 1.2392313480377197, accuracy: 61.1 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 1.3162416219711304, accuracy: 58.4 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 1.219383955001831, accuracy: 60.6 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 1.2103301286697388, accuracy: 61.9 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 1.2196787595748901, accuracy: 61.2 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 1.20907723903656, accuracy: 61.9 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 1.1922, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 1.2367, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 1.0769, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 1.3833, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 1.3069, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 1.1877, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 1.1601, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 1.1790, batch time: 0.04, accuracy:  67.19%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 1.1968, batch time: 0.09, accuracy:  60.94%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 1.3924, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 1.2224136590957642, accuracy: 63.1 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 6.263818264007568, accuracy: 18.6 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 1.693920373916626, accuracy: 50.5 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 9.681395530700684, accuracy: 13.0 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 1.2490296363830566, accuracy: 60.8 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 1.2487754821777344, accuracy: 62.1 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 1.2085213661193848, accuracy: 63.3 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 1.2108559608459473, accuracy: 62.4 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 1.2077422142028809, accuracy: 62.3 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 1.2096259593963623, accuracy: 63.0 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 1.1698, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 1.2034, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 1.2352, batch time: 0.09, accuracy:  63.28%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 1.1985, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 1.2161, batch time: 0.09, accuracy:  60.94%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 1.2089, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 1.1681, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 1.3349, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 1.2348, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 1.1713, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 1.1952996253967285, accuracy: 60.9 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 5.207220554351807, accuracy: 21.3 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 1.7102274894714355, accuracy: 51.7 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 8.857259750366211, accuracy: 13.7 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 1.226271390914917, accuracy: 59.4 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 1.2263519763946533, accuracy: 59.6 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 1.1854145526885986, accuracy: 60.8 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 1.1764259338378906, accuracy: 61.2 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 1.1772743463516235, accuracy: 60.7 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 1.1778216361999512, accuracy: 61.2 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 1.3021, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 1.1856, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 1.1339, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 1.2712, batch time: 0.11, accuracy:  64.84%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 1.2184, batch time: 0.09, accuracy:  60.94%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 1.2337, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 1.1446, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 1.0346, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 1.2754, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 1.2930, batch time: 0.08, accuracy:  64.84%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 1.2313705682754517, accuracy: 62.4 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 5.544610977172852, accuracy: 18.9 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 1.7027825117111206, accuracy: 50.9 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 10.415860176086426, accuracy: 12.5 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 1.2617439031600952, accuracy: 61.2 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 1.5352332592010498, accuracy: 53.5 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 1.2224717140197754, accuracy: 62.0 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 1.218959093093872, accuracy: 61.4 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 1.2175499200820923, accuracy: 61.9 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 1.211284875869751, accuracy: 61.5 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 1.1679, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 1.0593, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 1.3057, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 1.3927, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 1.3437, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 1.2987, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 1.2347, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 1.2283, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 1.0128, batch time: 0.09, accuracy:  68.75%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 1.2571, batch time: 0.08, accuracy:  61.72%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 1.2214717864990234, accuracy: 61.4 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 5.3214569091796875, accuracy: 17.7 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 1.5795053243637085, accuracy: 52.0 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 9.618917465209961, accuracy: 13.5 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 1.2598716020584106, accuracy: 60.8 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 1.4114590883255005, accuracy: 52.1 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 1.1943470239639282, accuracy: 62.4 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 1.1975171566009521, accuracy: 61.8 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 1.1898424625396729, accuracy: 62.3 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 1.1895145177841187, accuracy: 62.8 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 1.2325, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 1.1811, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 1.3649, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 1.1663, batch time: 0.09, accuracy:  64.84%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 1.4286, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 1.4287, batch time: 0.09, accuracy:  60.94%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 1.3016, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 1.1975, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 1.1417, batch time: 0.04, accuracy:  67.19%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 1.1656, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 1.2545571327209473, accuracy: 59.2 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 5.247594833374023, accuracy: 22.9 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 1.708221673965454, accuracy: 52.7 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 7.73907470703125, accuracy: 12.0 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 1.2520041465759277, accuracy: 59.8 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 1.6382887363433838, accuracy: 51.3 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 1.234320044517517, accuracy: 60.1 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 1.231000542640686, accuracy: 60.8 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 1.2323435544967651, accuracy: 61.0 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 1.2270140647888184, accuracy: 60.5 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 1.3895, batch time: 0.09, accuracy:  51.56%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 1.2721, batch time: 0.09, accuracy:  65.62%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 1.2155, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 1.1179, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 1.1022, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 1.1745, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 1.1227, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 1.1183, batch time: 0.09, accuracy:  66.41%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 1.2304, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 1.1184, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 1.1975688934326172, accuracy: 62.3 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 5.104940414428711, accuracy: 22.4 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 1.7071709632873535, accuracy: 49.5 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 9.912338256835938, accuracy: 13.0 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 1.2576044797897339, accuracy: 57.4 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 1.4028840065002441, accuracy: 57.3 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 1.1897451877593994, accuracy: 62.6 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 1.1858136653900146, accuracy: 63.2 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 1.1886502504348755, accuracy: 62.0 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 1.1842631101608276, accuracy: 62.7 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 0.9663, batch time: 0.09, accuracy:  67.19%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 1.1402, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 1.2452, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 1.1644, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 1.2712, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 1.1409, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 1.5594, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 1.3254, batch time: 0.08, accuracy:  62.50%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 1.1951, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 1.2986, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 1.1579612493515015, accuracy: 62.3 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 4.340895652770996, accuracy: 26.6 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 1.532657504081726, accuracy: 53.6 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 8.262344360351562, accuracy: 14.2 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 1.163572907447815, accuracy: 62.2 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 1.2451354265213013, accuracy: 59.8 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 1.1407673358917236, accuracy: 64.0 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 1.1410706043243408, accuracy: 64.0 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 1.1625158786773682, accuracy: 62.1 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 1.136074423789978, accuracy: 65.3 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 1.2803, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 1.1916, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 1.3173, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 1.3238, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 1.2027, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 1.1015, batch time: 0.09, accuracy:  63.28%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 1.3621, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 1.0068, batch time: 0.09, accuracy:  71.88%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 1.3441, batch time: 0.09, accuracy:  58.59%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 1.0895, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 1.2055103778839111, accuracy: 62.4 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 5.037836074829102, accuracy: 23.6 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 1.7327443361282349, accuracy: 50.2 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 6.729345798492432, accuracy: 21.4 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 1.3137191534042358, accuracy: 58.2 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 1.285083532333374, accuracy: 61.5 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 1.1987477540969849, accuracy: 61.8 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 1.1950581073760986, accuracy: 62.3 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 1.1974318027496338, accuracy: 62.2 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 1.1943331956863403, accuracy: 62.8 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 1.1879, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 1.1213, batch time: 0.08, accuracy:  67.97%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 1.1917, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 1.2235, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 1.2907, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 1.1402, batch time: 0.08, accuracy:  64.84%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 1.1844, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 1.1677, batch time: 0.10, accuracy:  67.97%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 1.0546, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 1.2524, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 1.2425005435943604, accuracy: 60.4 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 4.811052322387695, accuracy: 23.6 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 1.756198763847351, accuracy: 49.3 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 8.762852668762207, accuracy: 13.9 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 1.3568168878555298, accuracy: 55.7 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 1.317966103553772, accuracy: 58.2 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 1.228594183921814, accuracy: 61.2 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 1.222418189048767, accuracy: 61.7 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 1.3079352378845215, accuracy: 57.4 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 1.259221076965332, accuracy: 59.4 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 1.3550, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 1.3249, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 1.1010, batch time: 0.10, accuracy:  68.75%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 1.3328, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 1.2295, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 1.0790, batch time: 0.09, accuracy:  61.72%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 1.1390, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 1.1626, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 1.1056, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 1.0710, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 1.1828908920288086, accuracy: 61.6 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 5.118216037750244, accuracy: 22.7 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 1.6322212219238281, accuracy: 53.1 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 8.359010696411133, accuracy: 13.6 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 1.198235034942627, accuracy: 61.5 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 1.2106267213821411, accuracy: 62.4 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 1.171434760093689, accuracy: 63.6 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 1.1767281293869019, accuracy: 63.0 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 1.1717220544815063, accuracy: 62.8 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 1.1712268590927124, accuracy: 62.4 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 1.2481, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 1.3970, batch time: 0.06, accuracy:  57.03%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 1.3672, batch time: 0.19, accuracy:  55.47%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 1.2377, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 1.1573, batch time: 0.18, accuracy:  59.38%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 1.1386, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 1.2218, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 1.3061, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 1.1633, batch time: 0.06, accuracy:  61.72%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 1.2359, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 1.2655386924743652, accuracy: 60.7 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 5.32745361328125, accuracy: 23.2 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 1.6538403034210205, accuracy: 53.7 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 8.416841506958008, accuracy: 14.6 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 1.3636764287948608, accuracy: 56.7 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 1.2594001293182373, accuracy: 62.7 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 1.241668701171875, accuracy: 62.1 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 1.241141676902771, accuracy: 62.1 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 1.2750810384750366, accuracy: 60.8 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 1.2377817630767822, accuracy: 61.7 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 1.1843, batch time: 0.11, accuracy:  64.84%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 1.1473, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 1.0931, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 1.1864, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 1.1571, batch time: 0.12, accuracy:  65.62%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 1.2178, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 1.4064, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 0.9599, batch time: 0.12, accuracy:  68.75%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 1.1744, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 1.4331, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 1.253326177597046, accuracy: 59.7 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 5.47133731842041, accuracy: 18.6 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 1.6885496377944946, accuracy: 51.4 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 9.498125076293945, accuracy: 14.7 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 1.3770095109939575, accuracy: 57.1 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 1.3134307861328125, accuracy: 58.3 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 1.2381800413131714, accuracy: 61.0 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 1.2350975275039673, accuracy: 61.0 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 1.239113211631775, accuracy: 60.7 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 1.2333225011825562, accuracy: 61.2 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 1.1981, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 1.3975, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 1.0113, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 1.0887, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 1.2752, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 0.9772, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 1.2962, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 1.2386, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 1.3332, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 1.2060, batch time: 0.07, accuracy:  64.06%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 1.233680248260498, accuracy: 61.7 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 5.133017063140869, accuracy: 22.3 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 1.7221245765686035, accuracy: 51.1 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 6.095546245574951, accuracy: 24.1 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 1.4187480211257935, accuracy: 53.4 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 1.240981101989746, accuracy: 62.0 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 1.2269033193588257, accuracy: 62.5 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 1.2189879417419434, accuracy: 62.0 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 1.2162846326828003, accuracy: 62.1 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 1.2171939611434937, accuracy: 61.6 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 1.0257, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 1.1386, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 1.4307, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 1.2240, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 1.1713, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 1.2493, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 1.0688, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 1.3281, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 1.2210, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 1.2862, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 1.2491581439971924, accuracy: 60.4 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 5.90441370010376, accuracy: 20.8 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 1.7257106304168701, accuracy: 50.0 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 10.964044570922852, accuracy: 13.1 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 1.8951526880264282, accuracy: 43.5 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 1.4982374906539917, accuracy: 51.8 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 1.2246979475021362, accuracy: 61.9 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 1.2202444076538086, accuracy: 61.1 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 1.2203288078308105, accuracy: 61.7 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 1.2181012630462646, accuracy: 60.7 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 1.1823, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 1.2063, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 1.4289, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 1.0065, batch time: 0.04, accuracy:  69.53%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 1.4563, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 1.2000, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 1.2762, batch time: 0.04, accuracy:  69.53%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 1.1467, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 1.1418, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 1.2353, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 1.1978535652160645, accuracy: 62.5 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 5.71923828125, accuracy: 20.7 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 1.7408980131149292, accuracy: 51.0 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 11.128288269042969, accuracy: 14.2 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 1.2087087631225586, accuracy: 62.8 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 1.7070281505584717, accuracy: 51.9 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 1.1773360967636108, accuracy: 65.1 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 1.1776577234268188, accuracy: 63.8 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 1.2055586576461792, accuracy: 61.6 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 1.1763007640838623, accuracy: 64.0 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 1.3901, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 1.2892, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 1.2910, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 1.1986, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 0.9936, batch time: 0.04, accuracy:  68.75%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 1.1620, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 0.9750, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 1.3991, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 1.0894, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 1.3034, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 1.2159888744354248, accuracy: 61.0 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 4.948849678039551, accuracy: 22.8 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 1.713836669921875, accuracy: 53.8 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 9.367427825927734, accuracy: 14.5 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 1.3159250020980835, accuracy: 60.0 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 1.2487213611602783, accuracy: 59.8 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 1.2094124555587769, accuracy: 60.2 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 1.2061588764190674, accuracy: 60.8 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 1.2066453695297241, accuracy: 60.6 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 1.2135666608810425, accuracy: 61.8 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 1.2481, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 1.2813, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 1.1023, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 0.9916, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 1.2579, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 1.2845, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 1.0574, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 1.2039, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 1.1257, batch time: 0.33, accuracy:  60.94%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 1.2603, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 1.257948875427246, accuracy: 59.9 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 4.960395812988281, accuracy: 26.2 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 1.8572348356246948, accuracy: 47.6 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 10.496920585632324, accuracy: 15.3 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 1.4638457298278809, accuracy: 52.7 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 1.7607187032699585, accuracy: 49.7 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 1.2395011186599731, accuracy: 60.6 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 1.2388012409210205, accuracy: 60.9 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 1.255976676940918, accuracy: 59.3 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 1.2341235876083374, accuracy: 60.7 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 1.3158, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 1.1183, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 1.1554, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 1.2686, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 1.1863, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 1.1148, batch time: 0.04, accuracy:  67.19%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 1.1853, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 1.2177, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 1.2575, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 1.1179, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 1.2116341590881348, accuracy: 61.5 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 5.529685020446777, accuracy: 23.3 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 1.6858415603637695, accuracy: 52.5 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 10.114489555358887, accuracy: 13.6 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 1.2408239841461182, accuracy: 60.9 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 1.2955217361450195, accuracy: 59.6 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 1.199765920639038, accuracy: 61.0 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 1.1873843669891357, accuracy: 61.8 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 1.1857481002807617, accuracy: 62.4 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 1.2054986953735352, accuracy: 61.9 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 1.0139, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 1.2103, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 1.2367, batch time: 0.12, accuracy:  57.03%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 1.2366, batch time: 0.12, accuracy:  53.12%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 1.2685, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 1.3048, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 1.2130, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 1.3160, batch time: 0.12, accuracy:  64.06%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 1.0860, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 1.2567, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 1.2498406171798706, accuracy: 62.5 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 5.030781269073486, accuracy: 23.0 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 1.307457685470581, accuracy: 59.9 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 7.893870830535889, accuracy: 14.3 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 1.248658299446106, accuracy: 62.7 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 1.2467119693756104, accuracy: 63.2 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 1.2631837129592896, accuracy: 62.4 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 1.3087893724441528, accuracy: 58.5 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 1.2464520931243896, accuracy: 63.4 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 1.242548942565918, accuracy: 63.1 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 0.9527, batch time: 0.04, accuracy:  75.00%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 1.1822, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 1.2368, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 1.2787, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 1.3434, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 1.3152, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 1.1374, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 1.1232, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 1.1448, batch time: 0.10, accuracy:  67.97%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 1.1052, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 1.2086553573608398, accuracy: 62.6 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 4.811047554016113, accuracy: 26.8 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 1.6979316473007202, accuracy: 49.9 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 6.035752773284912, accuracy: 28.6 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 1.2253880500793457, accuracy: 62.1 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 1.2743864059448242, accuracy: 61.1 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 1.21189546585083, accuracy: 62.4 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 1.2034192085266113, accuracy: 61.9 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 1.1998738050460815, accuracy: 63.1 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 1.1967575550079346, accuracy: 63.0 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 1.1546, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 1.3709, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 1.2832, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 1.1949, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 1.3860, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 1.0557, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 1.0364, batch time: 0.10, accuracy:  68.75%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 1.2635, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 1.2119, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 1.0626, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 1.1451460123062134, accuracy: 62.9 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 4.888796806335449, accuracy: 27.0 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 1.5863393545150757, accuracy: 52.0 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 5.956716537475586, accuracy: 24.9 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 1.183880090713501, accuracy: 62.1 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 1.48375403881073, accuracy: 51.9 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 1.14480459690094, accuracy: 63.8 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 1.148932695388794, accuracy: 63.0 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 1.1522891521453857, accuracy: 63.5 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 1.1393784284591675, accuracy: 64.3 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 1.2452, batch time: 0.12, accuracy:  60.16%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 1.3038, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 1.0488, batch time: 0.11, accuracy:  70.31%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 1.1190, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 1.0712, batch time: 0.10, accuracy:  67.97%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 1.1831, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 0.9872, batch time: 0.12, accuracy:  75.78%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 1.1389, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 1.2177, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 1.5001, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 1.207973837852478, accuracy: 62.3 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 4.933587074279785, accuracy: 23.9 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 1.7659682035446167, accuracy: 49.7 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 1.5582315921783447, accuracy: 49.4 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 1.20671808719635, accuracy: 62.7 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 1.3219218254089355, accuracy: 57.7 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 1.2013884782791138, accuracy: 61.9 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 1.1979799270629883, accuracy: 62.4 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 1.2115883827209473, accuracy: 62.6 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 1.193274736404419, accuracy: 61.9 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 1.4002, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 0.9830, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 1.3032, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 1.0003, batch time: 0.04, accuracy:  69.53%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 1.0002, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 1.1611, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 1.1701, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 1.2224, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 1.1141, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 1.3480, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 1.1756548881530762, accuracy: 63.8 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 5.515201091766357, accuracy: 21.7 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 1.224308729171753, accuracy: 62.1 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 3.7660601139068604, accuracy: 25.2 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 1.2794468402862549, accuracy: 59.1 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 1.33181893825531, accuracy: 58.5 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 1.1631932258605957, accuracy: 64.3 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 1.1612880229949951, accuracy: 64.4 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 1.159193992614746, accuracy: 65.2 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 1.161410927772522, accuracy: 64.3 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 1.2300, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 1.1106, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 1.1366, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 1.2056, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 1.2997, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 1.1314, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 1.2134, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 1.1687, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 0.9907, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 1.0514, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 1.2376714944839478, accuracy: 62.0 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 5.400189399719238, accuracy: 22.6 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 1.2683721780776978, accuracy: 61.2 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 6.964724540710449, accuracy: 19.7 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 1.3022594451904297, accuracy: 60.1 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 1.2730361223220825, accuracy: 61.2 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 1.2058627605438232, accuracy: 63.5 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 1.20331609249115, accuracy: 64.2 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 1.2087578773498535, accuracy: 63.1 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 1.2066229581832886, accuracy: 62.7 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 1.2668, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 1.0626, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 1.2071, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 1.2866, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 1.1059, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 1.0924, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 1.0014, batch time: 0.04, accuracy:  67.97%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 1.2677, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 1.2412, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 1.0836, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 1.1772613525390625, accuracy: 61.7 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 5.284428119659424, accuracy: 22.0 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 1.2449290752410889, accuracy: 57.6 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 6.083955764770508, accuracy: 28.5 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 1.1698297262191772, accuracy: 62.0 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 1.1882529258728027, accuracy: 61.4 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 1.172458529472351, accuracy: 62.0 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 1.1639755964279175, accuracy: 61.9 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 1.1670175790786743, accuracy: 61.0 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 1.1580784320831299, accuracy: 62.0 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 1.3020, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 1.4698, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 1.1313, batch time: 0.11, accuracy:  66.41%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 1.1658, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 1.0037, batch time: 0.04, accuracy:  74.22%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 1.1031, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 1.1184, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 1.0455, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 1.2867, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 1.2051, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 1.1780444383621216, accuracy: 62.2 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 5.5663580894470215, accuracy: 22.0 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 1.2362555265426636, accuracy: 59.1 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 5.795830249786377, accuracy: 28.5 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 1.1962671279907227, accuracy: 61.2 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 1.1748583316802979, accuracy: 62.8 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 1.1726295948028564, accuracy: 62.8 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 1.166378378868103, accuracy: 63.3 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 1.1686291694641113, accuracy: 64.2 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 1.1612945795059204, accuracy: 63.5 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 1.0425, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 0.9322, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 1.3519, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 1.1504, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 1.3292, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 1.1811, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 1.2612, batch time: 0.12, accuracy:  54.69%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 1.0230, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 1.2232, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 1.2405, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 1.1342931985855103, accuracy: 62.6 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 5.939906597137451, accuracy: 20.7 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 1.2226159572601318, accuracy: 58.3 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 6.204230785369873, accuracy: 28.6 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 1.2076144218444824, accuracy: 60.2 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 1.177048683166504, accuracy: 60.3 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 1.1170846223831177, accuracy: 63.3 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 1.1196836233139038, accuracy: 64.7 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 1.1142860651016235, accuracy: 64.5 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 1.1109693050384521, accuracy: 63.7 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 1.0017, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 1.0850, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 1.3342, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 1.1153, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 1.1786, batch time: 0.12, accuracy:  60.94%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 1.1306, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 1.1230, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 1.0188, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 1.3750, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 1.1729, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 1.135077714920044, accuracy: 63.6 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 5.7112717628479, accuracy: 22.6 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 1.2874467372894287, accuracy: 57.6 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 9.320245742797852, accuracy: 14.0 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 1.2285314798355103, accuracy: 62.3 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 1.2097399234771729, accuracy: 59.9 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 1.129300594329834, accuracy: 63.0 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 1.123411774635315, accuracy: 64.6 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 1.1623793840408325, accuracy: 64.5 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 1.1247167587280273, accuracy: 64.2 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 1.0963, batch time: 0.11, accuracy:  66.41%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 1.2927, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 1.2517, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 1.1459, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 1.4007, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 1.1763, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 1.1513, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 1.2748, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 1.0682, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 1.0991, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 1.1507937908172607, accuracy: 61.7 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 6.242379665374756, accuracy: 19.2 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 1.7462153434753418, accuracy: 51.7 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 8.429157257080078, accuracy: 24.7 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 1.189551830291748, accuracy: 60.5 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 1.1803650856018066, accuracy: 61.6 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 1.1426818370819092, accuracy: 62.4 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 1.1417282819747925, accuracy: 62.1 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 1.1416049003601074, accuracy: 61.9 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 1.1355193853378296, accuracy: 62.5 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 1.5914, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 1.2319, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 1.1397, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 1.0831, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 1.3969, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 1.2781, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 1.1504, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 1.1979, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 1.3623, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 1.1532, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 1.2013543844223022, accuracy: 61.4 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 6.046477317810059, accuracy: 19.4 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 2.0593674182891846, accuracy: 44.9 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 21.01222801208496, accuracy: 11.7 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 1.2444000244140625, accuracy: 59.7 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 1.6537240743637085, accuracy: 55.2 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 1.2197891473770142, accuracy: 60.5 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 1.1896272897720337, accuracy: 61.8 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 1.1891497373580933, accuracy: 62.3 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 1.1861660480499268, accuracy: 62.5 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 1.1328, batch time: 0.12, accuracy:  67.19%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 1.3101, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 1.3283, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 1.3298, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 1.0472, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 1.1212, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 1.2141, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 1.2806, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 1.1989, batch time: 0.09, accuracy:  68.75%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 1.2122, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 1.1919236183166504, accuracy: 63.0 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 5.975170135498047, accuracy: 22.2 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 1.3419585227966309, accuracy: 53.8 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 6.549308776855469, accuracy: 19.9 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 1.4492151737213135, accuracy: 50.1 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 1.278540015220642, accuracy: 59.9 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 1.1640381813049316, accuracy: 63.5 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 1.1728432178497314, accuracy: 62.6 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 1.1586732864379883, accuracy: 64.5 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 1.1517897844314575, accuracy: 64.3 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 1.3226, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 1.1407, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 1.1513, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 1.1899, batch time: 0.06, accuracy:  64.84%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 1.3572, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 0.9826, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 1.0781, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 1.2092, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 1.2200, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 0.9668, batch time: 0.04, accuracy:  67.97%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 1.164505958557129, accuracy: 64.5 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 6.450556755065918, accuracy: 21.1 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 1.3694509267807007, accuracy: 54.2 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 9.280346870422363, accuracy: 13.4 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 1.2422969341278076, accuracy: 61.5 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 1.2137792110443115, accuracy: 64.2 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 1.1620460748672485, accuracy: 64.2 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 1.160818099975586, accuracy: 63.7 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 1.1581109762191772, accuracy: 63.7 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 1.1669057607650757, accuracy: 63.8 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 0.8803, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 1.4281, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 0.9560, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 1.2222, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 1.1746, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 1.1125, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 1.1128, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 1.2071, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 1.0559, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 1.2596, batch time: 0.08, accuracy:  57.81%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 1.1523499488830566, accuracy: 65.7 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 6.020829200744629, accuracy: 21.9 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 1.3772462606430054, accuracy: 54.2 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 8.8800630569458, accuracy: 12.0 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 1.2157994508743286, accuracy: 63.7 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 1.2320634126663208, accuracy: 63.0 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 1.1453498601913452, accuracy: 67.2 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 1.1421098709106445, accuracy: 66.5 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 1.1495729684829712, accuracy: 65.9 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 1.137947678565979, accuracy: 66.1 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 1.2954, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 1.3003, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 1.0496, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 1.1736, batch time: 0.10, accuracy:  71.88%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 1.1983, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 0.9988, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 1.2923, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 1.1968, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 1.0575, batch time: 0.04, accuracy:  67.97%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 1.1968, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 1.1885429620742798, accuracy: 64.3 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 5.995851039886475, accuracy: 22.2 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 1.4017436504364014, accuracy: 53.2 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 8.522107124328613, accuracy: 12.0 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 1.2725108861923218, accuracy: 61.8 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 1.358211636543274, accuracy: 56.6 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 1.180944800376892, accuracy: 64.7 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 1.1797983646392822, accuracy: 65.1 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 1.1775773763656616, accuracy: 64.7 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 1.183074712753296, accuracy: 63.0 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 1.1613, batch time: 0.04, accuracy:  67.19%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 1.2846, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 1.2605, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 1.1866, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 1.0335, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 1.2005, batch time: 0.09, accuracy:  64.06%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 0.9602, batch time: 0.04, accuracy:  69.53%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 1.0692, batch time: 0.04, accuracy:  70.31%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 1.0835, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 1.0906, batch time: 0.04, accuracy:  70.31%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 1.21114981174469, accuracy: 62.7 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 5.6676483154296875, accuracy: 22.7 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 1.817969560623169, accuracy: 50.9 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 8.499783515930176, accuracy: 14.7 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 1.329322338104248, accuracy: 57.8 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 1.3114542961120605, accuracy: 58.9 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 1.187989592552185, accuracy: 64.2 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 1.185017466545105, accuracy: 64.5 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 1.185713291168213, accuracy: 65.2 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 1.1820156574249268, accuracy: 64.8 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 1.1200, batch time: 0.11, accuracy:  67.97%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 1.2923, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 0.9437, batch time: 0.11, accuracy:  69.53%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 1.2736, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 0.9339, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 1.2120, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 1.2541, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 1.2126, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 1.3096, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 1.1772, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 1.159654974937439, accuracy: 63.2 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 6.0783610343933105, accuracy: 23.9 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 1.4640239477157593, accuracy: 51.4 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 9.494179725646973, accuracy: 12.5 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 1.184658169746399, accuracy: 63.3 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 1.2718050479888916, accuracy: 60.4 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 1.1544846296310425, accuracy: 63.7 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 1.1490216255187988, accuracy: 64.1 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 1.1493169069290161, accuracy: 63.9 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 1.1468619108200073, accuracy: 64.3 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 1.2288, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 1.1983, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 1.0797, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 1.1154, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 1.0976, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 1.1858, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 1.3024, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 1.0318, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 1.2131, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 1.1432, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 1.2088332176208496, accuracy: 63.1 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 5.9087138175964355, accuracy: 23.2 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 1.45940363407135, accuracy: 52.0 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 9.204940795898438, accuracy: 12.0 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 1.231277346611023, accuracy: 61.5 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 1.3319543600082397, accuracy: 57.9 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 1.214607834815979, accuracy: 62.7 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 1.2038151025772095, accuracy: 63.2 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 1.2006703615188599, accuracy: 62.7 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 1.2000449895858765, accuracy: 62.7 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 1.1411, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 1.2907, batch time: 0.12, accuracy:  65.62%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 1.2339, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 1.0879, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 1.1280, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 0.9716, batch time: 0.04, accuracy:  68.75%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 1.1486, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 1.2429, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 1.3039, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 1.3029, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 1.1991890668869019, accuracy: 62.9 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 6.2655839920043945, accuracy: 22.1 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 1.4822596311569214, accuracy: 52.5 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 9.747958183288574, accuracy: 11.9 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 1.199746012687683, accuracy: 63.1 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 1.201172947883606, accuracy: 63.3 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 1.1900607347488403, accuracy: 63.6 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 1.2046408653259277, accuracy: 61.5 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 1.2030571699142456, accuracy: 62.6 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 1.19245445728302, accuracy: 63.1 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 1.0351, batch time: 0.10, accuracy:  67.97%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 1.0834, batch time: 0.10, accuracy:  70.31%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 1.2483, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 1.1218, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 1.1579, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 1.1458, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 1.2517, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 0.9827, batch time: 0.10, accuracy:  71.09%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 1.1352, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 1.1619, batch time: 0.06, accuracy:  62.50%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 1.1926976442337036, accuracy: 62.0 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 5.871694564819336, accuracy: 25.7 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 1.481187343597412, accuracy: 51.2 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 9.894375801086426, accuracy: 11.3 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 1.4701783657073975, accuracy: 52.6 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 1.239502191543579, accuracy: 61.8 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 1.1886630058288574, accuracy: 62.9 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 1.1812292337417603, accuracy: 64.1 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 1.1819934844970703, accuracy: 63.9 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 1.176827073097229, accuracy: 63.7 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 1.2767, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 1.2800, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 1.1140, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 1.2481, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 1.1161, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 1.1522, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 1.1120, batch time: 0.04, accuracy:  67.97%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 1.1447, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 1.2956, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 1.1704, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 1.1913894414901733, accuracy: 63.8 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 5.952365875244141, accuracy: 26.2 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 1.4088188409805298, accuracy: 51.9 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 9.903581619262695, accuracy: 12.8 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 1.3702739477157593, accuracy: 56.6 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 1.3671371936798096, accuracy: 58.1 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 1.1746267080307007, accuracy: 64.5 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 1.1785519123077393, accuracy: 63.9 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 1.1765072345733643, accuracy: 64.1 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 1.170209527015686, accuracy: 64.3 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 1.1980, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 1.2137, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 1.1173, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 1.1539, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 0.9946, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 1.2627, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 1.2641, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 1.3089, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 1.2352, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 1.2942, batch time: 0.12, accuracy:  59.38%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 1.2338736057281494, accuracy: 62.2 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 6.222152233123779, accuracy: 26.0 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 1.586906909942627, accuracy: 49.0 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 10.392057418823242, accuracy: 12.7 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 1.2430108785629272, accuracy: 61.9 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 1.2314304113388062, accuracy: 61.8 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 1.2498427629470825, accuracy: 61.4 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 1.2257808446884155, accuracy: 62.6 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 1.2371829748153687, accuracy: 62.8 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 1.2233835458755493, accuracy: 62.8 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 1.2059, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 1.1628, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 0.9224, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 1.3508, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 1.0330, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 1.3643, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 1.0329, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 0.9704, batch time: 0.13, accuracy:  68.75%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 0.9251, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 0.9734, batch time: 0.04, accuracy:  68.75%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 1.1219322681427002, accuracy: 63.6 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 6.221871852874756, accuracy: 24.7 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 1.403769850730896, accuracy: 53.0 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 9.576098442077637, accuracy: 10.3 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 1.1218242645263672, accuracy: 62.9 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 1.1892739534378052, accuracy: 62.5 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 1.1181550025939941, accuracy: 63.3 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 1.1169277429580688, accuracy: 63.4 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 1.1189703941345215, accuracy: 62.1 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 1.1161795854568481, accuracy: 63.4 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 1.2062, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 1.2835, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 0.9541, batch time: 0.12, accuracy:  66.41%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 1.1289, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 1.1862, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 1.1034, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 1.1313, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 1.2518, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 1.0965, batch time: 0.11, accuracy:  67.19%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 1.2065, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 1.1776190996170044, accuracy: 64.0 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 5.407200336456299, accuracy: 27.2 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 1.9052484035491943, accuracy: 46.6 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 6.953782558441162, accuracy: 26.6 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 1.3058314323425293, accuracy: 59.8 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 1.7216532230377197, accuracy: 50.7 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 1.1796159744262695, accuracy: 63.5 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 1.1727795600891113, accuracy: 62.5 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 1.1748942136764526, accuracy: 62.4 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 1.168044090270996, accuracy: 63.5 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 1.2048, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 1.1877, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 1.3223, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 1.1177, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 1.3822, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 1.2485, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 1.0929, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 1.0456, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 1.1720, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 1.0483, batch time: 0.04, accuracy:  71.88%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 1.2116042375564575, accuracy: 61.7 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 5.537335395812988, accuracy: 25.2 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 1.4502229690551758, accuracy: 52.7 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 9.883925437927246, accuracy: 12.3 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 1.2626945972442627, accuracy: 58.6 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 1.2795524597167969, accuracy: 58.8 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 1.2003483772277832, accuracy: 61.9 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 1.191975712776184, accuracy: 63.0 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 1.1909371614456177, accuracy: 61.3 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 1.1851187944412231, accuracy: 63.3 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 1.0053, batch time: 0.10, accuracy:  67.97%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 1.0058, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 1.1897, batch time: 0.06, accuracy:  63.28%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 1.1666, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 0.9527, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 1.0747, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 1.1863, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 1.0070, batch time: 0.04, accuracy:  69.53%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 1.2762, batch time: 0.13, accuracy:  63.28%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 1.0552, batch time: 0.13, accuracy:  64.84%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 1.180559515953064, accuracy: 63.1 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 5.702293395996094, accuracy: 28.7 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 1.4036624431610107, accuracy: 54.2 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 7.7570929527282715, accuracy: 27.2 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 1.2681050300598145, accuracy: 60.5 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 1.227691650390625, accuracy: 60.4 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 1.1743552684783936, accuracy: 63.0 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 1.1735846996307373, accuracy: 62.8 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 1.1655473709106445, accuracy: 63.4 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 1.1652021408081055, accuracy: 63.3 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 1.0545, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 1.4333, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 1.1770, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 1.2618, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 1.2845, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 1.2750, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 1.4321, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 0.9602, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 1.1230, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 1.1227, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 1.1330546140670776, accuracy: 61.4 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 6.0035200119018555, accuracy: 26.1 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 1.8091318607330322, accuracy: 47.3 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 9.20875072479248, accuracy: 12.8 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 1.190630316734314, accuracy: 60.8 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 1.1779214143753052, accuracy: 61.1 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 1.1282591819763184, accuracy: 62.9 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 1.119667887687683, accuracy: 62.5 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 1.1215978860855103, accuracy: 62.0 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 1.1131877899169922, accuracy: 63.3 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 1.0339, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 1.3042, batch time: 0.12, accuracy:  62.50%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 1.0205, batch time: 0.11, accuracy:  66.41%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 0.9830, batch time: 0.11, accuracy:  66.41%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 1.2483, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 1.2351, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 1.0781, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 1.2044, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 1.0529, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 1.1422, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 1.1943459510803223, accuracy: 61.7 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 5.054455280303955, accuracy: 29.1 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 1.947458028793335, accuracy: 47.3 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 7.59909725189209, accuracy: 25.9 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 1.29229736328125, accuracy: 58.0 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 1.3135499954223633, accuracy: 57.5 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 1.1632413864135742, accuracy: 64.0 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 1.176109790802002, accuracy: 63.3 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 1.1625064611434937, accuracy: 63.6 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 1.165573000907898, accuracy: 64.1 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 1.0784, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 1.1952, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 1.0957, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 1.1088, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 1.1585, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 1.2127, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 1.1368, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 1.2162, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 1.3243, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 1.0983, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 1.169169545173645, accuracy: 63.6 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 6.266593933105469, accuracy: 24.1 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 1.3909974098205566, accuracy: 53.2 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 9.186433792114258, accuracy: 11.5 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 1.2093793153762817, accuracy: 61.1 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 1.330079436302185, accuracy: 56.8 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 1.1638237237930298, accuracy: 64.5 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 1.1703495979309082, accuracy: 65.1 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 1.1645410060882568, accuracy: 64.2 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 1.1626869440078735, accuracy: 64.0 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 1.2176, batch time: 0.08, accuracy:  66.41%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 1.1642, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 1.0780, batch time: 0.04, accuracy:  68.75%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 1.2258, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 1.1892, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 1.2015, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 1.1831, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 1.1348, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 1.2016, batch time: 0.11, accuracy:  64.84%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 1.1315, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 1.1582965850830078, accuracy: 63.1 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 6.448469638824463, accuracy: 28.6 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 1.4218218326568604, accuracy: 53.0 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 8.354409217834473, accuracy: 27.0 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 1.3298672437667847, accuracy: 56.3 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 1.227527379989624, accuracy: 61.1 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 1.1545146703720093, accuracy: 63.0 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 1.1581143140792847, accuracy: 63.6 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 1.1617335081100464, accuracy: 62.8 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 1.1515141725540161, accuracy: 63.9 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 1.2575, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 1.0814, batch time: 0.04, accuracy:  71.09%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 1.3767, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 1.3096, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 1.1970, batch time: 0.10, accuracy:  69.53%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 1.2589, batch time: 0.09, accuracy:  60.16%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 1.0383, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 1.3774, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 1.2595, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 1.3107, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 1.1298785209655762, accuracy: 63.8 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 5.989992618560791, accuracy: 26.4 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 1.3285837173461914, accuracy: 56.2 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 7.990198612213135, accuracy: 25.7 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 1.2708454132080078, accuracy: 58.6 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 1.37796151638031, accuracy: 57.0 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 1.1171433925628662, accuracy: 64.7 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 1.1137900352478027, accuracy: 65.5 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 1.1152790784835815, accuracy: 64.6 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 1.1187267303466797, accuracy: 65.3 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 1.1497, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 1.2062, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 1.1955, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 1.3881, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 1.0604, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 1.0679, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 1.2533, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 1.2417, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 1.2081, batch time: 0.36, accuracy:  62.50%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 1.1486, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 1.1404451131820679, accuracy: 64.8 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 5.520030975341797, accuracy: 29.0 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 1.413172721862793, accuracy: 53.4 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 9.128233909606934, accuracy: 13.8 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 1.1890944242477417, accuracy: 62.6 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 1.177471399307251, accuracy: 61.9 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 1.1249966621398926, accuracy: 65.0 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 1.1127426624298096, accuracy: 65.9 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 1.1137555837631226, accuracy: 65.3 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 1.1133077144622803, accuracy: 65.5 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 1.1775, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 1.1849, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 1.2545, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 1.1150, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 1.1136, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 1.1858, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 1.0262, batch time: 0.07, accuracy:  62.50%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 1.3957, batch time: 0.13, accuracy:  54.69%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 0.8882, batch time: 0.12, accuracy:  74.22%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 1.2284, batch time: 0.12, accuracy:  64.06%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 1.1747230291366577, accuracy: 62.2 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 6.08366060256958, accuracy: 26.1 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 1.4221642017364502, accuracy: 52.9 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 9.053038597106934, accuracy: 26.0 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 1.3524383306503296, accuracy: 56.5 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 1.5416240692138672, accuracy: 50.3 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 1.1692754030227661, accuracy: 61.3 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 1.1760942935943604, accuracy: 61.8 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 1.1613494157791138, accuracy: 62.1 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 1.1564706563949585, accuracy: 62.4 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 1.1431, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 1.1987, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 1.0179, batch time: 0.04, accuracy:  72.66%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 1.0529, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 1.1793, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 1.2108, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 1.1236, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 0.9585, batch time: 0.04, accuracy:  72.66%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 0.9149, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 1.1326, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 1.1136208772659302, accuracy: 63.3 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 5.363398551940918, accuracy: 28.2 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 1.3052905797958374, accuracy: 56.0 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 7.8959174156188965, accuracy: 27.6 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 1.11911940574646, accuracy: 63.1 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 1.1415749788284302, accuracy: 62.1 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 1.1133309602737427, accuracy: 63.8 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 1.1033198833465576, accuracy: 64.3 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 1.1044453382492065, accuracy: 65.6 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 1.0985013246536255, accuracy: 65.2 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 1.2677, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 1.1355, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 0.9852, batch time: 0.04, accuracy:  69.53%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 1.4186, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 1.1227, batch time: 0.04, accuracy:  69.53%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 1.4113, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 1.0654, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 1.3001, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 1.1945, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 0.8916, batch time: 0.04, accuracy:  67.19%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 1.1615467071533203, accuracy: 64.9 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 6.8127031326293945, accuracy: 26.3 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 1.5355404615402222, accuracy: 51.1 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 6.595780849456787, accuracy: 29.3 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 1.2603487968444824, accuracy: 58.1 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 1.1965335607528687, accuracy: 60.6 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 1.1398247480392456, accuracy: 63.9 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 1.1384636163711548, accuracy: 64.6 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 1.144493579864502, accuracy: 63.3 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 1.1370093822479248, accuracy: 64.6 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 1.1626, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 0.9143, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 1.1989, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 1.3718, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 1.3267, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 1.1407, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 1.2142, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 1.2536, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 1.0492, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 1.1330, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 1.117403507232666, accuracy: 63.4 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 5.994133472442627, accuracy: 25.7 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 1.8446874618530273, accuracy: 49.8 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 6.699165344238281, accuracy: 30.7 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 1.1255789995193481, accuracy: 62.9 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 1.120261311531067, accuracy: 63.4 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 1.1130868196487427, accuracy: 64.4 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 1.2171587944030762, accuracy: 61.0 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 1.109058141708374, accuracy: 63.8 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 1.1258715391159058, accuracy: 61.2 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 1.1437, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 1.1101, batch time: 0.13, accuracy:  67.19%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 0.9437, batch time: 0.11, accuracy:  64.84%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 0.9820, batch time: 0.08, accuracy:  67.97%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 1.1918, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 0.9315, batch time: 0.10, accuracy:  74.22%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 1.2066, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 1.0963, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 1.1961, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 1.1144, batch time: 0.12, accuracy:  63.28%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 1.1096177101135254, accuracy: 65.0 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 6.269595146179199, accuracy: 28.0 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 1.392266869544983, accuracy: 54.5 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 5.738354206085205, accuracy: 31.0 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 1.1321982145309448, accuracy: 63.9 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 1.6608023643493652, accuracy: 52.4 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 1.11488938331604, accuracy: 64.7 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 1.1096242666244507, accuracy: 63.9 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 1.103728175163269, accuracy: 64.9 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 1.0987597703933716, accuracy: 64.9 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 1.2005, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 1.1260, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 1.2386, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 1.0879, batch time: 0.13, accuracy:  64.84%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 1.0882, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 1.0764, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 1.0783, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 1.2510, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 1.0402, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 1.0376, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 1.159793496131897, accuracy: 64.3 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 5.95795202255249, accuracy: 26.3 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 1.455496907234192, accuracy: 51.6 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 7.1363677978515625, accuracy: 28.5 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 1.1555308103561401, accuracy: 64.9 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 1.1609418392181396, accuracy: 63.5 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 1.1554981470108032, accuracy: 64.6 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 1.1533031463623047, accuracy: 64.7 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 1.156643271446228, accuracy: 64.6 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 1.1502795219421387, accuracy: 65.5 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 1.0561, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 1.1290, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 1.3402, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 1.0000, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 1.0820, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 1.0157, batch time: 0.04, accuracy:  70.31%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 0.9406, batch time: 0.04, accuracy:  69.53%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 1.0898, batch time: 0.04, accuracy:  70.31%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 1.0450, batch time: 0.05, accuracy:  71.88%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 1.2637, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 1.182407259941101, accuracy: 64.8 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 6.017775535583496, accuracy: 24.5 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 1.4983359575271606, accuracy: 52.3 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 7.096474647521973, accuracy: 27.0 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 1.4117149114608765, accuracy: 56.8 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 1.3489428758621216, accuracy: 58.1 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 1.1723647117614746, accuracy: 66.3 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 1.1704957485198975, accuracy: 66.2 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 1.171175479888916, accuracy: 66.2 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 1.1752034425735474, accuracy: 65.2 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 1.1309, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 1.1559, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 0.9370, batch time: 0.11, accuracy:  72.66%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 1.2706, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 1.1653, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 1.0863, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 1.0566, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 1.0713, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 1.0729, batch time: 0.05, accuracy:  71.88%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 1.0144, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 1.1358921527862549, accuracy: 63.4 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 5.59453010559082, accuracy: 29.8 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 1.8254543542861938, accuracy: 52.1 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 7.648593425750732, accuracy: 30.0 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 1.1353405714035034, accuracy: 63.6 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 1.1294429302215576, accuracy: 64.1 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 1.1463299989700317, accuracy: 63.5 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 1.126520037651062, accuracy: 63.7 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 1.1314029693603516, accuracy: 64.5 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 1.125429391860962, accuracy: 64.3 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 1.0886, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 1.1028, batch time: 0.11, accuracy:  66.41%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 1.2087, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 1.4174, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 1.2987, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 1.2929, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 1.1631, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 1.0393, batch time: 0.04, accuracy:  72.66%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 1.1392, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 1.1580, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 1.1436491012573242, accuracy: 62.5 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 5.443612098693848, accuracy: 29.0 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 1.9109004735946655, accuracy: 48.5 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 8.51054859161377, accuracy: 26.2 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 1.2198807001113892, accuracy: 61.1 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 1.2888367176055908, accuracy: 56.0 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 1.1461317539215088, accuracy: 61.9 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 1.1265816688537598, accuracy: 62.9 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 1.1265544891357422, accuracy: 62.1 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 1.1222870349884033, accuracy: 62.8 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 1.0942, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 1.1815, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 1.0206, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 1.0272, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 1.2518, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 1.1666, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 1.1169, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 1.2562, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 1.0307, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 1.2222, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 1.120822787284851, accuracy: 62.9 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 5.679143905639648, accuracy: 27.5 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 2.0651934146881104, accuracy: 41.7 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 1.8780816793441772, accuracy: 41.3 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 1.2562822103500366, accuracy: 57.7 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 1.1613222360610962, accuracy: 62.6 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 1.0945905447006226, accuracy: 64.6 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 1.140560507774353, accuracy: 62.3 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 1.0888532400131226, accuracy: 64.7 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 1.0983021259307861, accuracy: 64.7 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 1.2246, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 0.9062, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 0.9624, batch time: 0.10, accuracy:  71.09%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 1.0074, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 0.9869, batch time: 0.11, accuracy:  69.53%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 1.1255, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 1.1539, batch time: 0.12, accuracy:  62.50%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 1.0931, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 1.0878, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 1.0789, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 1.1910287141799927, accuracy: 62.7 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 6.511720657348633, accuracy: 24.2 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 1.8224492073059082, accuracy: 50.3 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 10.122467994689941, accuracy: 25.4 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 1.5234953165054321, accuracy: 49.8 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 1.2659707069396973, accuracy: 57.9 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 1.1758441925048828, accuracy: 62.0 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 1.1688591241836548, accuracy: 62.7 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 1.1731641292572021, accuracy: 62.7 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 1.1651476621627808, accuracy: 62.8 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 1.2522, batch time: 0.11, accuracy:  68.75%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 1.0356, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 1.0618, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 1.0945, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 1.1070, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 1.1352, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 1.2981, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 1.1149, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 1.1434, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 1.1707, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 1.1649996042251587, accuracy: 63.9 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 5.782817840576172, accuracy: 25.5 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 1.772099256515503, accuracy: 52.8 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 10.468901634216309, accuracy: 23.4 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 1.2653518915176392, accuracy: 59.9 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 1.5771554708480835, accuracy: 47.9 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 1.1589902639389038, accuracy: 63.5 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 1.1531312465667725, accuracy: 64.4 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 1.1703284978866577, accuracy: 63.0 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 1.1513360738754272, accuracy: 64.8 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 1.0979, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 1.1659, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 1.1195, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 1.1039, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 1.0269, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 1.0200, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 1.1289, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 1.1851, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 1.2308, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 1.2374, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 1.166131854057312, accuracy: 62.5 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 5.8760666847229, accuracy: 27.2 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 1.471564769744873, accuracy: 54.0 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 10.402637481689453, accuracy: 24.5 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 1.2554380893707275, accuracy: 61.8 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 1.1838918924331665, accuracy: 62.7 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 1.1531962156295776, accuracy: 64.5 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 1.1525046825408936, accuracy: 63.8 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 1.1497215032577515, accuracy: 64.0 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 1.1490907669067383, accuracy: 64.2 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 1.2271, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 0.9445, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 1.2118, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 1.0759, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 0.8934, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 1.1552, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 0.9400, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 0.9973, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 1.2415, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 1.1467, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 1.123769998550415, accuracy: 63.7 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 6.233734607696533, accuracy: 26.4 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 1.8069616556167603, accuracy: 50.6 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 9.487208366394043, accuracy: 27.5 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 1.1587461233139038, accuracy: 61.7 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 1.349324107170105, accuracy: 56.2 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 1.1040794849395752, accuracy: 64.5 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 1.1034163236618042, accuracy: 64.2 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 1.1040215492248535, accuracy: 65.3 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 1.1050665378570557, accuracy: 66.0 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 1.0206, batch time: 0.11, accuracy:  73.44%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 1.1133, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 1.1382, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 1.1690, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 1.2183, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 1.1915, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 1.0690, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 1.0765, batch time: 0.11, accuracy:  67.19%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 1.2870, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 1.2898, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 1.119983196258545, accuracy: 63.3 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 5.752903938293457, accuracy: 29.2 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 1.7460275888442993, accuracy: 50.4 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 10.995129585266113, accuracy: 24.5 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 1.2412422895431519, accuracy: 57.4 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 1.1365009546279907, accuracy: 62.5 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 1.116753339767456, accuracy: 63.9 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 1.1112334728240967, accuracy: 63.7 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 1.1122159957885742, accuracy: 63.6 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 1.1099257469177246, accuracy: 63.3 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 1.3038, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 0.9700, batch time: 0.10, accuracy:  68.75%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 1.1863, batch time: 0.06, accuracy:  64.84%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 1.2221, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 1.0134, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 1.0000, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 1.0112, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 1.0473, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 1.0599, batch time: 0.04, accuracy:  67.97%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 0.8936, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 1.1593645811080933, accuracy: 63.4 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 5.966479778289795, accuracy: 28.7 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 1.829042673110962, accuracy: 50.2 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 7.717709064483643, accuracy: 29.4 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 1.1593645811080933, accuracy: 63.4 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 1.1684942245483398, accuracy: 63.5 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 1.1516057252883911, accuracy: 63.1 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 1.150586724281311, accuracy: 63.1 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 1.1495013236999512, accuracy: 62.6 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 1.1437137126922607, accuracy: 62.6 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 1.0625, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 1.3108, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 1.2046, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 1.2084, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 1.1222, batch time: 0.04, accuracy:  67.97%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 1.1879, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 1.2940, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 1.1601, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 1.0133, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 1.0599, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 1.0985257625579834, accuracy: 65.2 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 6.156591415405273, accuracy: 28.4 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 1.698918342590332, accuracy: 50.8 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 8.245613098144531, accuracy: 27.0 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 1.0973159074783325, accuracy: 65.1 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 1.0979423522949219, accuracy: 64.4 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 1.0930049419403076, accuracy: 65.6 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 1.096731185913086, accuracy: 64.9 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 1.090897560119629, accuracy: 64.8 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 1.0895453691482544, accuracy: 65.5 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 1.0305, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 1.1074, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 1.1798, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 0.9141, batch time: 0.04, accuracy:  71.09%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 1.0456, batch time: 0.04, accuracy:  68.75%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 1.2510, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 1.3391, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 1.0141, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 1.0916, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 1.1498, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 1.1430855989456177, accuracy: 65.1 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 6.428647518157959, accuracy: 27.6 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 1.2628282308578491, accuracy: 59.4 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 10.408596992492676, accuracy: 22.8 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 1.1435942649841309, accuracy: 62.8 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 1.3697361946105957, accuracy: 57.9 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 1.131369948387146, accuracy: 65.0 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 1.1809200048446655, accuracy: 61.4 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 1.1325734853744507, accuracy: 63.8 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 1.1710165739059448, accuracy: 62.5 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 1.1786, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 1.0681, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 1.0452, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 1.3629, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 1.1397, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 1.0492, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 1.4028, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 1.1681, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 1.2472, batch time: 0.12, accuracy:  64.06%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 1.1748, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 1.1763592958450317, accuracy: 64.9 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 7.376456260681152, accuracy: 26.2 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 1.9776872396469116, accuracy: 46.9 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 10.453655242919922, accuracy: 22.0 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 1.301663875579834, accuracy: 59.7 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 1.2341656684875488, accuracy: 62.2 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 1.1696786880493164, accuracy: 64.7 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 1.1639246940612793, accuracy: 65.0 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 1.1643081903457642, accuracy: 65.1 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 1.1605743169784546, accuracy: 65.5 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 1.1213, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 1.1459, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 1.1203, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 0.9399, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 0.9290, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 1.2032, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 1.1247, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 1.3191, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 1.2500, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 1.3551, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 1.1475944519042969, accuracy: 62.5 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 6.4560227394104, accuracy: 27.6 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 1.2787044048309326, accuracy: 57.7 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 9.751648902893066, accuracy: 22.0 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 1.1466341018676758, accuracy: 62.3 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 1.1561641693115234, accuracy: 61.8 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 1.1415884494781494, accuracy: 61.6 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 1.1461749076843262, accuracy: 62.9 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 1.1420706510543823, accuracy: 62.2 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 1.1358058452606201, accuracy: 62.5 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 1.1330, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 1.0200, batch time: 0.10, accuracy:  70.31%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 1.0620, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 0.9770, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 1.0262, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 1.1552, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 1.1129, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 1.3410, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 0.9434, batch time: 0.06, accuracy:  71.09%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 1.1862, batch time: 0.38, accuracy:  62.50%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 1.1402438879013062, accuracy: 63.7 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 6.339608192443848, accuracy: 27.6 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 1.4876106977462769, accuracy: 52.8 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 9.863426208496094, accuracy: 23.4 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 1.4129905700683594, accuracy: 53.0 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 1.530149221420288, accuracy: 56.4 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 1.1373072862625122, accuracy: 63.5 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 1.1305382251739502, accuracy: 63.6 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 1.1350476741790771, accuracy: 64.3 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 1.1267415285110474, accuracy: 64.0 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 1.2708, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 1.1422, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 0.8446, batch time: 0.11, accuracy:  71.88%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 0.9753, batch time: 0.12, accuracy:  70.31%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 1.2010, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 1.1179, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 1.1329, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 1.4335, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 0.9895, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 1.2538, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 1.1927584409713745, accuracy: 63.5 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 7.150688648223877, accuracy: 25.7 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 1.559952735900879, accuracy: 48.7 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 7.034516334533691, accuracy: 28.4 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 1.2080347537994385, accuracy: 62.6 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 1.272923231124878, accuracy: 61.1 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 1.1862316131591797, accuracy: 63.0 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 1.1796828508377075, accuracy: 64.1 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 1.184080958366394, accuracy: 63.5 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 1.1765543222427368, accuracy: 63.4 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 1.2624, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 1.0769, batch time: 0.10, accuracy:  67.97%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 1.1338, batch time: 0.12, accuracy:  66.41%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 1.0320, batch time: 0.05, accuracy:  71.88%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 0.9386, batch time: 0.10, accuracy:  71.09%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 1.1541, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 1.4054, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 1.4967, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 1.1476, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 1.1198, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 1.1415410041809082, accuracy: 65.6 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 6.275357723236084, accuracy: 27.8 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 1.5213230848312378, accuracy: 51.0 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 9.63154125213623, accuracy: 22.9 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 1.1382145881652832, accuracy: 65.6 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 1.1564010381698608, accuracy: 64.3 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 1.1371303796768188, accuracy: 65.3 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 1.1388781070709229, accuracy: 65.3 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 1.1293306350708008, accuracy: 65.0 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 1.1319817304611206, accuracy: 65.6 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 1.0217, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 1.2009, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 1.1937, batch time: 0.10, accuracy:  68.75%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 0.9151, batch time: 0.11, accuracy:  67.97%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 1.2194, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 1.2720, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 1.2068, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 1.4985, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 0.7892, batch time: 0.05, accuracy:  75.00%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 1.1689, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 1.1127197742462158, accuracy: 64.4 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 6.252365589141846, accuracy: 29.9 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 1.2208290100097656, accuracy: 61.2 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 8.312753677368164, accuracy: 25.1 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 1.296036720275879, accuracy: 57.2 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 1.327008843421936, accuracy: 58.2 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 1.1149256229400635, accuracy: 64.8 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 1.108575701713562, accuracy: 65.4 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 1.1053943634033203, accuracy: 65.0 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 1.1023948192596436, accuracy: 65.1 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 1.0017, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 1.0289, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 1.0516, batch time: 0.04, accuracy:  70.31%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 0.9808, batch time: 0.04, accuracy:  64.84%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 1.0529, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 1.0470, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 1.3585, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 1.2180, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 1.0862, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 1.0548, batch time: 0.04, accuracy:  69.53%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 1.0851529836654663, accuracy: 65.1 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 6.5955491065979, accuracy: 28.0 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 1.484729290008545, accuracy: 51.6 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 7.515077590942383, accuracy: 28.6 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 1.126501202583313, accuracy: 62.7 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 1.2760614156723022, accuracy: 58.7 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 1.080774188041687, accuracy: 65.7 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 1.0775679349899292, accuracy: 65.8 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 1.0788408517837524, accuracy: 65.6 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 1.0769273042678833, accuracy: 65.5 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0\n",
    "\n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter)\n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "\n",
    "            qnn_train_step += 1\n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\"\n",
    "                )\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA\n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(\n",
    "            qnn_minimize_loss,\n",
    "            init_param,\n",
    "            method=\"COBYLA\",\n",
    "            options={\"maxiter\": 1000, \"adaptive\": True},\n",
    "        )\n",
    "\n",
    "        qnn_parameters = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.ylim(0.5, 2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 65.13%\n",
      "Loss on the train set: 1.11\n",
      "Accuracy on the test set: 60.67%\n",
      "Loss on the test set: 1.16\n",
      "Generalization error: 0.05048871\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
