{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 72.67%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "def generate_random_qubit_state_torch(n_qubit):\n",
    "    # Generate a single random state of size (n_qubit,)\n",
    "    random_state = torch.randint(0, 2, (n_qubit,)) * 2 - 1  # Converts {0,1} â†’ {-1,1}\n",
    "\n",
    "    # Repeat this state 2^N times\n",
    "    repeated_states = random_state.repeat((2**n_qubit, 1))\n",
    "\n",
    "    return repeated_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "def generate_random_tensor():\n",
    "    return torch.randn(\n",
    "        126 * 70, 1\n",
    "    ).cuda()  # Generates a tensor with standard normal distribution\n",
    "\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit + 1, output_dim=1, bond_dim=10)\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "\n",
    "        probs_ = generate_random_tensor()\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_random_qubit_state_torch(n_qubit)[\n",
    "            : len(nw_list_normal)\n",
    "        ]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  3100\n",
      "# of trainable parameter in full model:  3100\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108 + 84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "# print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.3044, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.3036, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.3033, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.3022, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 2.3037, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 2.3011, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 2.3036, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 2.3031, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  17.97%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  17.97%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 2.3017, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 2.3020, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 2.3017, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 2.3021, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 2.3008, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 2.3032, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  17.97%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 2.3007, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 2.3019, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  1.56%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 2.3020, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  19.53%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 2.3021, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 2.3017, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 2.3017, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 2.3035, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 2.3020, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 2.3032, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 2.3033, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 2.2998, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 2.3031, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 2.3014, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 2.2924, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 2.3040, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 2.3022, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 2.3032, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 2.3021, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 2.3022, batch time: 0.01, accuracy:  21.09%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 2.3031, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 2.3017, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 2.3015, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 2.3002, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  17.97%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 2.3031, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 2.3045, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  1.56%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  17.97%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 2.3001, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 2.3019, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 2.3021, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 2.3033, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 2.3022, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 2.3000, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  17.19%\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 2.3051, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 2.3029, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  3.12%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  15.62%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  3.91%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  4.69%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 2.3039, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  3.91%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 2.3023, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 2.3020, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 2.3032, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 2.3029, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  18.75%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 2.3033, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  3.12%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  6.25%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 2.3029, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  14.84%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 2.3034, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.12%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 2.3023, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 2.3022, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  16.41%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  16.41%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 2.3032, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 2.3021, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 2.3017, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 2.3033, batch time: 0.06, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 2.3020, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 2.3031, batch time: 0.04, accuracy:  3.12%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 2.3021, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  3.91%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  17.97%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 2.3030, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 2.3030, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  17.19%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 2.3022, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.12%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 2.3018, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  4.69%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 2.3032, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 2.3030, batch time: 0.08, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 2.3021, batch time: 0.09, accuracy:  14.84%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 2.3031, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 2.3022, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 2.3030, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 2.3030, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.10, accuracy:  7.03%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  17.19%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 2.3015, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  20.31%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 2.3022, batch time: 0.02, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 2.3030, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  17.97%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  5.47%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 2.3022, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 2.3023, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 2.3031, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  4.69%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  17.97%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 2.3038, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 2.3031, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 2.2950, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 2.3029, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 2.3031, batch time: 0.07, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 2.3034, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  19.53%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  16.41%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.12%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  17.19%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  8.59%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  3.12%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  4.69%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.14, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.11, accuracy:  6.25%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  5.47%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.12, accuracy:  11.72%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.12, accuracy:  7.03%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  13.28%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  3.91%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  3.12%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  13.28%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  7.81%\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "loss_list_epoch = []\n",
    "acc_list_epoch = []\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3026788234710693, 2.302734851837158, 2.297424793243408, 2.302274703979492, 2.3026015758514404, 2.302739381790161, 2.3024404048919678, 2.3027408123016357, 2.3025765419006348, 2.3025104999542236, 2.3022499084472656, 2.3018155097961426, 2.3033854961395264, 2.302595376968384, 2.3024842739105225, 2.3024628162384033, 2.302637815475464, 2.3027942180633545, 2.302586317062378, 2.302619457244873, 2.302593231201172, 2.302513599395752, 2.3025739192962646, 2.3024542331695557, 2.302847146987915, 2.302706241607666, 2.302485227584839, 2.3025310039520264, 2.3024017810821533, 2.3027007579803467, 2.3025338649749756, 2.302553176879883, 2.3026528358459473, 2.3025810718536377, 2.3026111125946045, 2.3025856018066406, 2.3023645877838135, 2.302621603012085, 2.302650213241577, 2.3025779724121094, 2.3022639751434326, 2.302565813064575, 2.302586317062378, 2.302558660507202, 2.3025803565979004, 2.3027331829071045, 2.302565097808838, 2.3025596141815186, 2.3025920391082764, 2.3025829792022705, 2.3024537563323975, 2.302658796310425, 2.3025834560394287, 2.3025457859039307, 2.3025646209716797, 2.3026301860809326, 2.302579164505005, 2.30253529548645, 2.3024513721466064, 2.3025734424591064, 2.302649974822998, 2.302711009979248, 2.3025355339050293, 2.3025856018066406, 2.3025834560394287, 2.302586793899536, 2.30259108543396, 2.3025872707366943, 2.3025858402252197, 2.302565336227417, 2.302546262741089, 2.3025901317596436, 2.3025832176208496, 2.3026769161224365, 2.302478313446045, 2.302614212036133, 2.3025856018066406, 2.3026602268218994, 2.3025760650634766, 2.3025925159454346, 2.3025894165039062, 2.3025898933410645, 2.302563190460205, 2.302105665206909, 2.302520751953125, 2.3026022911071777, 2.3025529384613037, 2.302511215209961, 2.3025758266448975, 2.302584171295166, 2.3024938106536865, 2.3026044368743896, 2.3025906085968018, 2.302502155303955, 2.3025991916656494, 2.3025929927825928, 2.302686929702759, 2.302661418914795, 2.302670955657959, 2.3026084899902344, 2.3025877475738525, 2.302602767944336, 2.3025825023651123, 2.3025972843170166, 2.3026485443115234, 2.3025856018066406, 2.3023998737335205, 2.3022689819335938, 2.302577495574951, 2.302600145339966, 2.302586793899536, 2.302584171295166, 2.3022971153259277, 2.3025803565979004, 2.3025550842285156, 2.302583694458008, 2.3025851249694824, 2.3027379512786865, 2.3027260303497314, 2.3025600910186768, 2.3025920391082764, 2.3025810718536377, 2.302628993988037, 2.3025832176208496, 2.30260968208313, 2.3026013374328613, 2.3026161193847656, 2.3025176525115967, 2.3020522594451904, 2.30259370803833, 2.3025729656219482, 2.3026182651519775, 2.3026022911071777, 2.302565336227417, 2.302586078643799, 2.3026185035705566, 2.302558183670044, 2.3025882244110107, 2.302593946456909, 2.302591323852539, 2.3025660514831543, 2.3025810718536377, 2.302593231201172, 2.3025834560394287, 2.302522659301758, 2.30259108543396, 2.3025779724121094, 2.3025434017181396, 2.3025333881378174, 2.3024096488952637, 2.3025927543640137, 2.302672863006592, 2.3025875091552734, 2.302605390548706, 2.302588939666748, 2.3025810718536377, 2.302583932876587, 2.3025155067443848, 2.302579164505005, 2.302583694458008, 2.3025548458099365, 2.3025898933410645, 2.302584171295166, 2.30259108543396, 2.302586317062378, 2.30255126953125, 2.302586793899536, 2.3027780055999756, 2.3025832176208496, 2.302549362182617, 2.3024144172668457, 2.302598476409912, 2.302574396133423, 2.3022243976593018, 2.302682876586914, 2.3026413917541504, 2.302597761154175, 2.3025801181793213, 2.3026320934295654, 2.3025834560394287, 2.302586078643799, 2.302619457244873, 2.3025901317596436, 2.3025920391082764, 2.3025801181793213, 2.3025856018066406, 2.3025755882263184, 2.302595853805542, 2.3025879859924316, 2.3025169372558594, 2.3025002479553223, 2.302607297897339, 2.3025872707366943, 2.30259108543396, 2.3024771213531494, 2.302584171295166, 2.3025851249694824, 2.3025853633880615, 2.302543878555298, 2.3026623725891113]\n",
      "[9.821428571428571, 10.714285714285714, 18.75, 16.071428571428573, 8.035714285714286, 4.464285714285714, 22.321428571428573, 5.357142857142857, 7.142857142857143, 8.928571428571429, 12.5, 15.178571428571429, 10.714285714285714, 8.035714285714286, 12.5, 11.607142857142858, 8.035714285714286, 8.928571428571429, 7.142857142857143, 10.714285714285714, 11.607142857142858, 19.642857142857142, 7.142857142857143, 13.392857142857142, 9.821428571428571, 12.5, 13.392857142857142, 16.964285714285715, 14.285714285714286, 6.25, 12.5, 8.928571428571429, 13.392857142857142, 9.821428571428571, 11.607142857142858, 9.821428571428571, 8.928571428571429, 8.035714285714286, 6.25, 12.5, 13.392857142857142, 10.714285714285714, 4.464285714285714, 8.928571428571429, 10.714285714285714, 7.142857142857143, 8.035714285714286, 9.821428571428571, 9.821428571428571, 10.714285714285714, 14.285714285714286, 7.142857142857143, 9.821428571428571, 7.142857142857143, 14.285714285714286, 7.142857142857143, 8.035714285714286, 6.25, 14.285714285714286, 12.5, 12.5, 9.821428571428571, 12.5, 8.035714285714286, 9.821428571428571, 8.035714285714286, 7.142857142857143, 7.142857142857143, 9.821428571428571, 12.5, 12.5, 8.928571428571429, 12.5, 8.035714285714286, 14.285714285714286, 9.821428571428571, 8.928571428571429, 10.714285714285714, 11.607142857142858, 9.821428571428571, 9.821428571428571, 12.5, 7.142857142857143, 14.285714285714286, 15.178571428571429, 8.928571428571429, 16.071428571428573, 12.5, 16.964285714285715, 8.035714285714286, 10.714285714285714, 6.25, 8.928571428571429, 8.928571428571429, 13.392857142857142, 10.714285714285714, 8.928571428571429, 10.714285714285714, 4.464285714285714, 8.928571428571429, 8.035714285714286, 8.035714285714286, 8.928571428571429, 12.5, 7.142857142857143, 11.607142857142858, 10.714285714285714, 13.392857142857142, 10.714285714285714, 6.25, 7.142857142857143, 8.928571428571429, 9.821428571428571, 10.714285714285714, 8.928571428571429, 8.928571428571429, 13.392857142857142, 8.928571428571429, 4.464285714285714, 9.821428571428571, 8.928571428571429, 10.714285714285714, 8.928571428571429, 13.392857142857142, 6.25, 6.25, 7.142857142857143, 9.821428571428571, 8.928571428571429, 7.142857142857143, 11.607142857142858, 9.821428571428571, 8.928571428571429, 16.071428571428573, 10.714285714285714, 8.035714285714286, 11.607142857142858, 7.142857142857143, 11.607142857142858, 9.821428571428571, 10.714285714285714, 11.607142857142858, 8.928571428571429, 8.928571428571429, 13.392857142857142, 7.142857142857143, 6.25, 12.5, 8.928571428571429, 11.607142857142858, 8.035714285714286, 8.928571428571429, 5.357142857142857, 6.25, 8.928571428571429, 4.464285714285714, 9.821428571428571, 14.285714285714286, 8.928571428571429, 9.821428571428571, 12.5, 7.142857142857143, 9.821428571428571, 7.142857142857143, 7.142857142857143, 11.607142857142858, 8.035714285714286, 9.821428571428571, 10.714285714285714, 15.178571428571429, 9.821428571428571, 7.142857142857143, 5.357142857142857, 16.964285714285715, 10.714285714285714, 6.25, 7.142857142857143, 11.607142857142858, 12.5, 6.25, 6.25, 11.607142857142858, 7.142857142857143, 6.25, 8.035714285714286, 5.357142857142857, 14.285714285714286, 8.928571428571429, 2.6785714285714284, 16.071428571428573, 12.5, 1.7857142857142858, 5.357142857142857, 9.821428571428571, 12.5, 9.821428571428571, 8.035714285714286, 7.142857142857143, 15.178571428571429, 7.142857142857143]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [0.841748058795929, 0.5383376479148865, 0.37141960859298706, 0.2189747840166092, 0.2170722633600235, 0.2683789134025574, 0.1937561184167862, 0.2995546758174896, 0.13230514526367188, 0.12556131184101105, 0.08791607618331909, 0.13517722487449646, 0.1180429607629776, 0.2700677216053009, 0.23012836277484894, 0.11778731644153595, 0.08971132338047028, 0.0745047926902771, 0.044976893812417984, 0.030214795842766762, 0.14274518191814423, 0.16257527470588684, 0.13489486277103424, 0.22497442364692688, 0.04410076141357422, 0.0439407117664814, 0.0999048724770546, 0.09295899420976639, 0.05333646386861801, 0.042801376432180405, 0.0852958932518959, 0.035196453332901, 0.09896297752857208, 0.09667126089334488, 0.11132311820983887, 0.07094293087720871, 0.11317868530750275, 0.17386971414089203, 0.04825839400291443, 0.1526862233877182, 0.12213451415300369, 0.0335562527179718, 0.14572270214557648, 0.14732243120670319, 0.08901072293519974, 0.10628568381071091, 0.1219853013753891, 0.04227989539504051, 0.1546023041009903, 0.07231778651475906, 0.08872615545988083, 0.06031284108757973, 0.11893129348754883, 0.07610543072223663, 0.05435555428266525, 0.03299633413553238, 0.06796611100435257, 0.09908641129732132, 0.1245361715555191, 0.13339823484420776, 0.044910043478012085, 0.039106521755456924, 0.08405368030071259, 0.03416334092617035, 0.18436889350414276, 0.06167331337928772, 0.05363277718424797, 0.03776988759636879, 0.010305949486792088, 0.08863425254821777, 0.11051689833402634, 0.03690870478749275, 0.021718373522162437, 0.08610344678163528, 0.08286675065755844, 0.05776119977235794, 0.09465332329273224, 0.032651614397764206, 0.07205092906951904, 0.0745658427476883, 0.08170061558485031, 0.10555801540613174, 0.016445361077785492, 0.12694816291332245, 0.11931197345256805, 0.08286337554454803, 0.07604096084833145, 0.04736681655049324, 0.07517056912183762, 0.13407494127750397, 0.02461135759949684, 0.026882896199822426, 0.050736844539642334, 0.03605273738503456, 0.056351643055677414, 0.09767205268144608, 0.07290007919073105, 0.08676333725452423, 0.0794496163725853, 0.04368472844362259, 0.050167299807071686, 0.04737326130270958, 0.05501176789402962, 0.08879045397043228, 0.01769072189927101, 0.11385718733072281, 0.045953329652547836, 0.057710688561201096, 0.03719104081392288, 0.07977698743343353, 0.02595260553061962, 0.1046842560172081, 0.06301649659872055, 0.02800893224775791, 0.024529291316866875, 0.020508909597992897, 0.14025148749351501, 0.05224132165312767, 0.02634393982589245, 0.03067580796778202, 0.010352589190006256, 0.030206164345145226, 0.09297139197587967, 0.1973668485879898, 0.11294060945510864, 0.10930002480745316, 0.0792819932103157, 0.11282505095005035, 0.06902279704809189, 0.034222979098558426, 0.01758032664656639, 0.20883719623088837, 0.0871180072426796, 0.021445829421281815, 0.058817390352487564, 0.11408091336488724, 0.04319537431001663, 0.028295835480093956, 0.009734376333653927, 0.0865861177444458, 0.013264675624668598, 0.03975219279527664, 0.03132316842675209, 0.07329122722148895, 0.031415101140737534, 0.057007454335689545, 0.07466187328100204, 0.03515228256583214, 0.01828647591173649, 0.034930113703012466, 0.04921986907720566, 0.05617351084947586, 0.025701504200696945, 0.07073844969272614, 0.0677885115146637, 0.0442965142428875, 0.08668070286512375, 0.01085565984249115, 0.10640285909175873, 0.042185988277196884, 0.045891039073467255, 0.010602300986647606, 0.07824820280075073, 0.029184645041823387, 0.1528889238834381, 0.0852082297205925, 0.01046351995319128, 0.26733046770095825, 0.008088228292763233, 0.1218838021159172, 0.06059052422642708, 0.17010393738746643, 0.09900021553039551, 0.027551589533686638, 0.009467942640185356, 0.0559978224337101, 0.015254249796271324, 0.06907999515533447, 0.026691734790802002, 0.09885875135660172, 0.01129892561584711, 0.03152812644839287, 0.08123517781496048, 0.04274165257811546, 0.03844240680336952, 0.06572488695383072, 0.10163140296936035, 0.020722707733511925, 0.016591958701610565, 0.10138952732086182, 0.10918857157230377, 0.028943251818418503, 0.04512939602136612, 0.040990330278873444, 0.04000023752450943, 0.045494887977838516, 0.011356256902217865, 0.05481533333659172, 0.013076278381049633, 0.04331720620393753]\n",
    "# acc_list_epoch_ = [71.42857142857143, 83.03571428571429, 84.82142857142857, 95.53571428571429, 91.07142857142857, 91.96428571428571, 93.75, 91.96428571428571, 96.42857142857143, 94.64285714285714, 98.21428571428571, 93.75, 96.42857142857143, 92.85714285714286, 94.64285714285714, 96.42857142857143, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 95.53571428571429, 95.53571428571429, 97.32142857142857, 91.96428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 97.32142857142857, 98.21428571428571, 95.53571428571429, 98.21428571428571, 96.42857142857143, 96.42857142857143, 95.53571428571429, 98.21428571428571, 95.53571428571429, 97.32142857142857, 99.10714285714286, 93.75, 95.53571428571429, 98.21428571428571, 94.64285714285714, 95.53571428571429, 97.32142857142857, 95.53571428571429, 94.64285714285714, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 98.21428571428571, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 96.42857142857143, 98.21428571428571, 98.21428571428571, 95.53571428571429, 99.10714285714286, 94.64285714285714, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 97.32142857142857, 95.53571428571429, 98.21428571428571, 100.0, 97.32142857142857, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 96.42857142857143, 99.10714285714286, 98.21428571428571, 94.64285714285714, 97.32142857142857, 96.42857142857143, 98.21428571428571, 95.53571428571429, 93.75, 100.0, 99.10714285714286, 98.21428571428571, 99.10714285714286, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 99.10714285714286, 95.53571428571429, 98.21428571428571, 96.42857142857143, 98.21428571428571, 98.21428571428571, 99.10714285714286, 97.32142857142857, 97.32142857142857, 98.21428571428571, 99.10714285714286, 99.10714285714286, 93.75, 97.32142857142857, 99.10714285714286, 98.21428571428571, 100.0, 99.10714285714286, 95.53571428571429, 91.07142857142857, 95.53571428571429, 95.53571428571429, 95.53571428571429, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 94.64285714285714, 98.21428571428571, 100.0, 98.21428571428571, 97.32142857142857, 98.21428571428571, 98.21428571428571, 100.0, 96.42857142857143, 100.0, 98.21428571428571, 98.21428571428571, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 99.10714285714286, 95.53571428571429, 98.21428571428571, 99.10714285714286, 98.21428571428571, 100.0, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 96.42857142857143, 99.10714285714286, 96.42857142857143, 97.32142857142857, 100.0, 91.96428571428571, 100.0, 96.42857142857143, 97.32142857142857, 91.96428571428571, 97.32142857142857, 99.10714285714286, 100.0, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 96.42857142857143, 100.0, 99.10714285714286, 99.10714285714286, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 100.0, 100.0, 95.53571428571429, 94.64285714285714, 99.10714285714286, 97.32142857142857, 98.21428571428571, 98.21428571428571, 98.21428571428571, 100.0, 98.21428571428571, 100.0, 99.10714285714286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 10.07%\n",
      "Loss on the train set: 2.30\n",
      "Accuracy on the test set: 8.17%\n",
      "Loss on the test set: 2.30\n",
      "Generalization error: 2.3841858e-07\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
