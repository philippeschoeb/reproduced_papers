{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 76.50%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "def generate_random_qubit_state_torch(n_qubit):\n",
    "    # Generate a single random state of size (n_qubit,)\n",
    "    random_state = torch.randint(0, 2, (n_qubit,)) * 2 - 1  # Converts {0,1} â†’ {-1,1}\n",
    "\n",
    "    # Repeat this state 2^N times\n",
    "    repeated_states = random_state.repeat((2**n_qubit, 1))\n",
    "\n",
    "    return repeated_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "def generate_random_tensor():\n",
    "    return torch.randn(\n",
    "        126 * 70, 1\n",
    "    ).cuda()  # Generates a tensor with standard normal distribution\n",
    "\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit + 1, output_dim=1, bond_dim=1)\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "\n",
    "        probs_ = generate_random_tensor()\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_random_qubit_state_torch(n_qubit)[\n",
    "            : len(nw_list_normal)\n",
    "        ]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  31\n",
      "# of trainable parameter in full model:  31\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108 + 84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "# print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.3022, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.3019, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.3016, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 2.3021, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 2.3019, batch time: 0.02, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  15.62%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 2.3033, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 2.3018, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  18.75%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 2.3034, batch time: 0.03, accuracy:  4.69%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  3.91%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 2.3018, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 2.3014, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 2.3033, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  2.34%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  3.91%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 2.3029, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  15.62%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  4.69%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  4.69%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  19.53%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 2.3011, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 2.3023, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 2.3032, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 2.3035, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 2.3030, batch time: 0.06, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  17.97%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  16.41%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  3.91%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  4.69%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 2.3030, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  20.31%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 2.3018, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 2.3000, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 2.3018, batch time: 0.06, accuracy:  17.19%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 2.3005, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 2.3023, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.10, accuracy:  13.28%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  3.91%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.08, accuracy:  15.62%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.08, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.12%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  17.19%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  17.97%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  5.47%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  17.19%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  3.12%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  17.97%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  17.19%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  4.69%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  4.69%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  17.97%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.12%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.12%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  16.41%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  20.31%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  2.34%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  3.91%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.91%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  4.69%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.03%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  3.91%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.84%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  10.16%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  4.69%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  3.12%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  3.91%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  18.75%\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  9.38%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  14.84%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  10.16%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  5.47%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  4.69%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  14.84%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  17.97%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  18.75%\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  17.97%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  3.12%\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  16.41%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  17.19%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  16.41%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  6.25%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  17.19%\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  13.28%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.12%\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  8.59%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  4.69%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  4.69%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  3.91%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.91%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  4.69%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  3.91%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  2.34%\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.12%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  17.97%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  19.53%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  15.62%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.91%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  7.81%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  17.97%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  17.97%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  5.47%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  3.12%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  17.97%\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  3.91%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  10.16%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "loss_list_epoch = []\n",
    "acc_list_epoch = []\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAADOaElEQVR4nO29ebhkVXku/u69azhDn3N6nuhuaHBABqFRJIgiXrlgX0TUJEbDVaJJjAY1ipdLSKKJ5ppWvDFGw5XEJGKuU5JfFI25alQmUUAZWsWhpaGBpukB6O5zTp+ppv37Y9e39rfWXnuqs3fVrlPrfZ5+Tp+qOlWr9rDWt97v/d7Pcl3XhYGBgYGBgYFBl2D3egAGBgYGBgYGgwUTfBgYGBgYGBh0FSb4MDAwMDAwMOgqTPBhYGBgYGBg0FWY4MPAwMDAwMCgqzDBh4GBgYGBgUFXYYIPAwMDAwMDg67CBB8GBgYGBgYGXUWp1wNQ0Wq18MQTT2BsbAyWZfV6OAYGBgYGBgYJ4LoupqensXHjRth2NLdRuODjiSeewObNm3s9DAMDAwMDA4MOsHfvXmzatCnyNYULPsbGxgB4gx8fH+/xaAwMDAwMDAySYGpqCps3bxbreBQKF3xQqmV8fNwEHwYGBgYGBn2GJJIJIzg1MDAwMDAw6CpM8GFgYGBgYGDQVZjgw8DAwMDAwKCrMMGHgYGBgYGBQVdhgg8DAwMDAwODrsIEHwYGBgYGBgZdRerg4/bbb8ell16KjRs3wrIs3HTTTdLzx44dw9vf/nZs2rQJw8PDOOWUU3DDDTdkNV4DAwMDAwODPkfq4GNmZgZnnHEGrr/+eu3zV111Fb7xjW/gs5/9LH7+85/jXe96F97+9rfjq1/96qIHa2BgYGBgYND/SG0ytn37dmzfvj30+e9///u44oorcMEFFwAA3vKWt+Bv//Zv8YMf/ACvfOUrOx6ogYGBgYGBwdJA5pqPF77whfjqV7+Kffv2wXVd3HLLLfjlL3+Jiy66SPv6hYUFTE1NSf8MDAwMDAwMli4yDz4+8YlP4JRTTsGmTZtQqVTw8pe/HNdffz3OP/987et37NiBiYkJ8c80lTMwMDAwMFjayCX4uOuuu/DVr34V9957L/7yL/8SV155Jb797W9rX3/ttddicnJS/Nu7d2/WQzIwMDAwMDAoEDJtLDc3N4c/+qM/wpe//GVccsklAIDnPve52LlzJ/73//7fuPDCCwN/U61WUa1WsxyGgYFBgTE9X8fn734M/+30Ddi8cqTXwzEwMOgBMmU+6vU66vU6bFt+W8dx0Gq1svwoAwODPsXXfrwfO77+C1x/y+5eD8XAwKBHSM18HDt2DLt3+5PGnj17sHPnTqxcuRJbtmzBS17yElx99dUYHh7G8ccfj9tuuw3/9E//hI9+9KOZDtzAwKA/MT1fb/9s9HgkBgYGvULq4OOee+7BS1/6UvH7VVddBQC44oorcOONN+KLX/wirr32Wlx++eU4fPgwjj/+eHzwgx/EW9/61uxGbWBg0LdotknQetOwoQYGg4rUwccFF1wA13VDn1+/fj0+/elPL2pQBgYGSxet9vzRbIXPIwYGBksbpreLgYFBV9FqBx11E3wYGAwsTPBhYGDQVTQF82HSLgYGgwoTfBgYGHQVgvloGubDwGBQYYIPAwODrqJpNB8GBgMPE3wYGBh0FVTk0jDBh4HBwMIEHwYGBl0FVcs1TKmtgcHAwgQfBgYGXQWlW0zaxcBgcGGCDwMDg66CNB/GZMzAYHBhgg8DA4OuomWYDwODgYcJPgwMDLoKn/kwwYeBwaDCBB8GBgZdBWVbDPNhYDC4MMGHgYFBVyGqXUzwYWAwsDDBh4GBQVdBjEfD2KsbGAwsTPBhYGDQVQiHU6P5MDAYWJjgw8AgZ+x5agav/Js78I0H9vd6KIWA39XWMB9x+MYDB3DpJ+7Aw08e6/VQDAwyhQk+DAxyxu2/fBI/fnwSN93/RK+HUggQ4WEEp/G46f59+Mm+Sdz8i0O9HoqBQaYwwYeBQc4gMy2jcfDAu9qS+NRAj4VGEwAwNd/o8UgMDLKFCT4MDHIG+VmY6g4PLRZwmEMSjYWGF7BOz9d7PBIDg2xhgg8Dg5xBDdQaRmAJQE63GIv1aFDwMTVnmA+DpQUTfBgY5AyTdpHBmQ+j+4gGpV0M82Gw1GCCDwODnFEnXwvDfACQAw6TiopGjZgPE3wYLDGY4MPAIGeItItZaAH41S6Af2wM9DBpF4OlChN8GBjkDBKcmhSDB9ekXRJjod4WnC4Y5sNgacEEHwYGOYO0HkZc6UESnJrgIxKi1NYwHwZLDCb4MDDIGQ3DfEjgx8FYrEeDl9oaTxSDpQQTfBgY5Iya0XxI4NUuxmI9GiQ4bbnATK3Z49EYGGQHE3wYGOSMhjAZMwstoDAfJiALRaPZkgJWU25rsJRggg8Dg5xBQYcptfXAD4PRwYSjphwbo/swWEowwYeBQc4w9uoyTLVLMlClC8EwHwZLCSb4MDDIGeRlYRZaD8ZkLBkCzIcJPgyWEEzwYWCQM4j5MCkGD1LwYVJRoVCZD5N2MVhKSB183H777bj00kuxceNGWJaFm266KfCan//853jlK1+JiYkJjI6O4uyzz8Zjjz2WxXgNDPoOdcN8SODVLkaEGw7y+CCYtIvBUkLq4GNmZgZnnHEGrr/+eu3zDz30EF70ohfh5JNPxq233oof//jHeO9734uhoaFFD9bAoB/RML1dJBjmIxnI44MwNT94zMfBqXnM1/MtMX7i6JwoaTboHkpp/2D79u3Yvn176PN//Md/jP/23/4brrvuOvHYSSed1NnoDAyWABqmq60ETgAZNigcweBjsJiPA5PzeNGHb8a5J63C//3tc3L5jAcPTuO//tXtuPSMjfjE67fl8hkGemSq+Wi1WviP//gPPOtZz8LFF1+MtWvX4pxzztGmZggLCwuYmpqS/hkYLCWQ5qPlAi2z2MomY0YHEwo17TJomo/HDs+i0XLx8JMzuX3GI0/PAgAefvJYbp9hoEemwcehQ4dw7NgxfOhDH8LLX/5y/Od//ide/epX4zWveQ1uu+027d/s2LEDExMT4t/mzZuzHJKBQc/BGQ9T3WFMxpJCZT4GTfNBjKFa9ZMlmsaDp2fInPkAgMsuuwzvfve7ceaZZ+IP//AP8YpXvAI33HCD9m+uvfZaTE5Oin979+7NckgGBj1HvWkElhwtU2qbCIFqlwHTfFDTwTzZMbr+jM1/95Fa8xGF1atXo1Qq4ZRTTpEef85znoM77rhD+zfVahXVajXLYRgYFAp88jSLLdA01S6JMOjVLoL5yFEM2jRi8J4hU+ajUqng7LPPxq5du6THf/nLX+L444/P8qMMDPoGfGIzXVwBvpE1k344aNEdKnvT9NTcYAUf3fDHEX2XjPao60jNfBw7dgy7d+8Wv+/Zswc7d+7EypUrsWXLFlx99dX4jd/4DZx//vl46Utfim984xv493//d9x6661ZjtvAoG/Ad/eG3pXt1Q0TFA7SfKwZq2Lv4bmBS7vQfVNvunBdF5ZlZf4ZTZF2Mddht5Ga+bjnnnuwbds2bNvmlSVdddVV2LZtG973vvcBAF796lfjhhtuwHXXXYfTTz8df//3f49/+7d/w4te9KJsR25g0Cfgmg8jsFTTLuZ4hIGCj9XLvLT0oKVdOONRz4kha3RBV2KgR2rm44ILLpB2Ljq8+c1vxpvf/OaOB2VgsJQgaT5MmkExGTOTfhhI80HBx3y9hVqjhUppMLpi8ICj1szne1MgbO7L7mMwrmIDgx6i0TQ7fY6WKbVNhJpgPirisUFiP/h9U89JdNpsUmrHBMHdhgk+DAxyBtd5mJ2+nHbJi05fCqC0y3C5hGVVj6QeJN2HpJXK6b4RrQ9MENx1mODDwCBHNFsueJbSTHIA19w2jQA3FOTzUSnZGB/ygo9BYj7UtEseIOat2XKN+3CXYYIPA4Mcoe7YTJpB7WprjkcYSPNRLdkYGyoDGCyL9W4KTgFTidZtmODDwCBHqIuryS0r1S4m7RIK0nxUyzbGhweP+eApyryMxkyH5d7BBB8GBjlCFcoNOvPhuiYNlRSk+aiWHJ/5GKDgg7MdeWs+ABN8dBsm+DAwyBEqlTvoAks1+DIC3HBQ2kXWfAxO2oULTvPTfBgDwF7BBB8GBjlC3U0NOvPRVDyCDPMRDp/54JqPwWE+ulFqa5iP3sEEHwYGOUKd0AZ9d6V+fdNYLhw1FnyQ5mOQSm3ltEs+gQGvcDF6rO7CBB8Fxa27DuGm+/f1ehiZ4d5Hj+Cf7nwk1h13qUENNnrZWO7YQgM33PYQHnt6NtHrv7JzH275xaFMx9By0zNBN92/D7fsynYc/QCj+eBpl2bEKztHwwQfPUNqe3WD7uCdX7gf0wsNnP+sNVg5Won/g4Ljj7/8E/ziwDSed/wKnLpxotfD6RpU5qOXaYb/+PET+NDXf4GHDh3DR379jMjXTs7W8e5/3omRSgkPvP/izMagpl3idrRHZmp497/sxLJqCT/5s+zG0Q8QpbZlW5iMDazmo5HPfSNVu5gUYFdhmI8CwnVdTM034LrAzMLSmGwoVz1IPgVAcDfVyzTDJJ2DBLvn2XoDLddjS7KEauQUx3wcW/Dug+n5xsDpZchkrOrYqDjeVD1Ix6Db1S6G+eguTPBRQPAJRqWp+xW15mB2jyySyRhN5kmEddI1mOGYA9UuMe/Nn8/L66GoWGA+H47ttZMfpN15QzIZy6u3ixGc9gom+Cgg6kuwEVmtTSEP2gISNBnr3fmkxSxJ2SInaLIMgAPVLjFjaUrU+2BdOzWm+Sg5XvAxSBbg9S4EnlK1ixE/dxUm+CgguEhxqdCsdcN8AOhtLxMaSyLmw+XsW3ZjCFa7RL85D9ZIAzEo4PbqPvMxOPcPL6/Njfnogq7EQA8TfBQQjSVIBdLkkZdZUFERKLXt4fmkyTzJAsYn5SyZD/W94pkPHnwM1rVD37dSslFqBx9LZTOSBFLKrQu9XQYpsCsCTPBRQPAJeSlMNq2WK27yQXP4LJbmo9X+mUTz4f8/07RLSs0HP36Dx3z4aRfH9qbqpZKGTYJ6NzQfxmSsZzDBRwFRX2LROE8jDV7apTiN5Wj3mIz5cLX/XyyCzEf0ew8q89FotsR3rw4q89EFh1N+PAdtbuo1TPBRQPAbbSlMNlwsNmiiQXWh7+X5pGNfT5DbbuWk+VC/f9zxaAxo8MHTk9WyDZs0HwO0O+9Ob5elJ+7vF5jgo4DgN91SuCG6Ua9fVBTJZEykXVIyH1m60gaYj5ix8ONHvheDAP5dK85gMh983sgr+DA+H72DCT4KCH7TLYXJRrZJHqwbPGAy1kvBaYfVLtmmXeTf430+BlPzQSyPY1soOQNa7cI1H11wOB00PVqvYYKPAqKxxIIPnmrJaxIpKtTFtRiltkl8PrqTdokLhPjzg5Sy403lAAjmYwlMB4nR6AJjKrHMA7Yx6jVM8FFALDWfj26o1osK9fvWe6n5IK+VBGPIK+0SrHaJSbsMqOaDe3wAGEzmowtCdYn5WAJzbT/BBB8FBBecLgXNR22g0y7pBJZ5glxmk+zwpLRLrpqPNGmXwbl2uMcHAJTapba97IrcbXSD9ZJ8PgZsbuo1TPBRQPAbopc0fVbgqZZBos6B4ITWS+bHd5lN2dulh2kXudR2kDQfxHw4ADDwvV26Uu0yQIFdEWCCjwKCL1BLYbKpDXDaJaj56L3gNMk5yKuxnMp8xJbaDqjmQ3S0JebDGcBqly5UojS6UFFjoIcJPgqIpSY4NZoPH70MJmvCXj2tz0d+1S5x18PApl2afkdbYDCZD3neyOd782vbMB/dhQk+CghZgd3/N8Qgm4wFS2176XDqfXaz5caKSGV79ezGsCiTsQH0+ag47eDDGjzmo+uajyWQ4u4nmOCjgEjr8/Htnx3EK//mDuw+NJ3bmG66fx8uu/572D85l/pvk+5gPvP9R/Ca//M9HJ2tdTTGNLj9l0/iFZ/4Ln76xGSun1NEkzHv/8m1Fpn6fLTfK2wn/52fH8Sln7gDDx70rmXJZMxoPqQF8vpbduN1f3cn5utL87h0wx9osT4fuw8dwyv/5g78508PZDmsgYAJPgqItJqPr/7oCfz48UncuuvJ3Mb0b/c9jh/tPYrv7X469d8mnUT++Yd7cd9jR/HdB5/qaIxp8B8/3o8H9k3hmz89mOvn0IRGufuemow1ku/yOB2daalt+71oR68yQV/90RP4yT7/Wh7cUls57aLTfHzxh4/hrocP46dPTHV/gF1AN9xHF+vzceuuQ/jx45P4yo+eyHJYAwETfBQQkuYjwcSfpltpp6BJr5NJoJbQLGiuvYPbdzQ9u5J+TN44pufruX4OTW5DZW8HWwTBKRBv9iYxHzn4fFAJqRpcE71O50eqeBig4EM1GXM09up0DpeijqrVcrvS9I2XLnfCSlKQOEgpwayQOvi4/fbbcemll2Ljxo2wLAs33XRT6Gvf+ta3wrIsfOxjH1vEEAcPkslYgpuObpo8y3IXE3xw35Kov5+tNQAA+450M/ho5Po5FBAOt4OP3na1ZechBfOR5WVF71sNCT5UC3iZ+Via6QUdBPPRTruQz0fL9VNXdGyWgi5MhXp95uWMzK+vTlI7C+0N0yBdm1khdfAxMzODM844A9dff33k67785S/jrrvuwsaNGzse3KCikTIab3SB+aBFo5PdZy3h7nWu1kXmoz2OqbmcmY8mMR9tk6gCVLsA6fw1Mq12aQ+BmA9V/LogKnKCfWgGK+3i3QsVhfkAfCaKjlGSRoH9BvX67I7PRwfBBzEfA3RtZoVS2j/Yvn07tm/fHvmaffv24R3veAe++c1v4pJLLul4cIMKvjtOslj5zEd+Cxt9RieTgKz5CB/jfJu67AbzUe8a8yGnXYojOE1ua55l8NFUmA/6rHJb00Dj8itzWKntAFHbAZ8PHny0XJQdP2VQX4ILXyD46IrD6SLSLkvwHOSN1MFHHFqtFt7whjfg6quvxqmnnhr7+oWFBSwsLIjfp6aWpngqDeqpmY/2JJTjDoio3k7oT7mxnH6MjWZLLDj7js7BdV1YlqV9bRagRW4qZ80HGSX5wUdvJqlmy5VKZuOuq7way9H7VtrpBBpb+/CIa1+XdhkkEyj6rmq1C+AfE7rfl6L3RyDtUtDeLhR0DJIeKStkLjj98Ic/jFKphHe+852JXr9jxw5MTEyIf5s3b856SH2HRkrmg16TZ98H2rF2pPlIIDidY+WCxxYamJrLmZFoB1F5Bx90Lknz0av8fFq/Eam3S4aLm6h2UZgPgtp5d2A1H8R8lDVpl6bMdC5Fwal6n3Qj+Ogs7WI0H50i0+Dj3nvvxV//9V/jxhtvTLxrvfbaazE5OSn+7d27N8sh9SV4BJ6I+ejCDojuy8WmXZIEHwDw+NHZ1J+TBt0SnNIkOlzpbdpFPW9x55EzH3l0ta06LPjQaILoHpA0H4OUdiHNh2IyBgTv9yUpOA30RMrnOy62osZUu3SOTIOP7373uzh06BC2bNmCUqmEUqmERx99FO95z3twwgknaP+mWq1ifHxc+jfokJmP5NUueVL6tBh1JDhN4HBKYlNC3roPGsf0fCPTxVWFn3bRV3d0C+pxTyc4zW4cdKjDmA+1xHZg7dUVnw/btkDkR7NdhkrHcik6c6qBQH6aD74x6iDtUjeaj06RqebjDW94Ay688ELpsYsvvhhveMMb8KY3vSnLj1rSaKRlPhQaNg8sLu0SLzgNMB85Bx80pmbLxWytidFq5vInALzaxZF+7zaCPWbi0i7s/1mmXdrvZdsWHNtCs+VKgVBUqe0g5dXVUlvAK7etNVtouq50/qJE3P2KgP9Ls5W5DqwV0EF1nnapmbRLaqSecY8dO4bdu3eL3/fs2YOdO3di5cqV2LJlC1atWiW9vlwuY/369Xj2s5+9+NEOCPhCkaSjqCi5y7PUdlEmYwnSLirzkXO5LR/H1Hw9t+BDrXbpVamtKhSOu1ZyS7u038uxvAqOZkteSGmcOpOxQcqr14S9us8QObYFNL3ATCrHX4KaD/++sUUVHK+KygKqeV4n82fNVLt0jNRpl3vuuQfbtm3Dtm3bAABXXXUVtm3bhve9732ZD25QkdZevRultj7zkf4zEmk+upx24d8jT91HUUzGVI1HbNqFC04z9floBx+2JcpHkzIfgzTB03fl6akSczldbIlo0UHfaaTibwqyvnfU+XKxPh95pm+XIlJv9y644IJUB/mRRx5J+xEDD8lePU2pbY4LG40jN81HvbvMB1/I8jQao139cI+ZD/W4x5Vl56X5oEDGtiyUHBtAU5taGXiTMcXnAwAcx2/GxxfKJWkyptw3gHdtjFSy/Aw38vck4NdkrdmS0mQG0TC9XQqItD4fzS4wH0JwushS20bL1aaSKPgYH/Li4W6mXfJkPmjx7LXgNFA9ELOQyz4f2TMftsWYj5Y8gQP+NdPUBCaDALWrLSAzH80lznzUGv59QzKPrH1eVGuCTq4vngocpOszC5jgo4Dgk3ES7w5BVXfB4XSxmg9Av1ObbaddnrluDABweKYmer3kAVXzkffnDBXN5yPmWpEcTjO8ruitnLbgFAhJu7Tkn8CAaT7IZKysaD7gHROpHH8Jaj7ovJcdW5QbZ61pUwWmncyfPOAYJGYuC5jgo4BI29uFdkF5TkKtxVS7qJS/ZhKZbzMf68arGGuLP5/Ikf2Qgo8c0y51wXwUy+cj7jxKjeWyTLuwapeyI/e74S6sJDyVAxO3Z2mrbkOkXZgfCnl9NFuutClZktUu7e8kBR8ZL+6qlmkxmg/1/wbxMMFHAcEXinQ+HzkKThdhr56E8ifB6XC5hONWDAPIr9zWdV0pAJrKNe0i56575cmgBnw9ayzHql0cJe1S1+gYAiWXAzLBqz4fgKL5YNfRUmQ+6FooORbKJVt6LCuogWxnPh9N7f8N4mGCjwKCTyZputrmSenTjbqQcALYe3jWF6kmcNektMtwxcZxy73gIy/dh/r5uaZdlN4uSdJoh2dqmY8pYDKmBEGtlou9h31XWb4rzDLtwpmPkiOnXfjO0a92kcc5KKkXvebDZ4rCvID2HZ2LDUb2T84V/jjSdyrbtiivzZpZUOfLznw+gnolgnpPZYEDk/OCJe53mOCjgOCTSVG62vp0ePwN+v3dT+HF192C//UfP2v/TfzulW6okYrPfORVbqvucPIVnLaZj0p79xYzwS00mnjZX96KV3z8jkzHEXCMVI7BJ27ejRdfdwu+8cB+APk1lpOqXWx/J6+OUS25FeMeEOajpim1dXiprUYn85PHJ3Heh27GH335J6Hvu+epGbzwQzfjnV+4P49hZwbOfFS6xHyk3by5risFHKrF+sdvfhAvvu4WfPOnBzofJMPjR2Zx3odvxu9/7r5M3q/XMMFHAVGX0i7Jg488S+7SNLHa/eQx7+ch72cSvQExH0NlB+NDZemxrKEGULmW2iqaj7jzOTlbx5HZOh5jzFEWiGss9+ChaQDAnqdm2+P0n8vF58OyxE5eF3yEpRIHJa8ugg8nzOcjyBI9/JR3vz3yVPhue89Tx+C6/r1ZVNAGoeTYQhuUveBUCWxTBjf1pm9xDwSvzYeenAGQ3bGmOeGhJ4t97pLCBB8FRBqfD9d1u1Jqm8ZenYIG0nEkaRJFpbbDZUdMNnm1UFfHk6vJWEupdklRZZKlPiSutwudK9IYcZ1HluZJ9PXktEtb88EYMl1XW2Bw0i50j+iYj4aSdqHrWfVI0YF256qpX9FA579sW6zapVjMh3otqr/TJierqj06rUuliZ0JPgqINF1t5Ukox7RLCpMxmtgooAgGHxrBqUi7OD7NmtMuV92h5Ftq6x03Epy6bnSQKNtmZ8l8KOI6ZYGi469L4WUpOKX3dWx5MQWAWtOfvH2fD3mc80tk4o0Cp/PLWuajJaddBHMUvwmha1819Ssa6DuVGfOR9WYkWGqb7v3VeSRg5NekQC+bcdMGcKkE4Cb4KCD4ohvHZvDnk1TGdAq68JOU9ZF+gyY49abUUed+tYsjBGb9znxwVmqIOTVGTXISnZ4hk6U2vgowH3ViPtoLGLdXz/A0+NUuFsqUdmlSYBvczQc0H0uwskMFDxR52oX7ouiqXegcR103tT4JPhpM8yHmg6xLbdvHifuIpGH51HksEIw0sz3WtAFcKqlHE3wUEPICFH2hpe2A2wlaLT+32VnaRS1pCw8+hjjzkVvwIY8nL80H/xxuEx3FaMg9O7L7/sFSW4X5qCnMB3t9HsyHzU3GNKW2oZqPAWA++HEol/xGalK1i+J/wn9GMx/eeZ6vtzKtYsoaks9HTvNBQ2wM/GUwTeo6uKlqap+fyyjt0kjBPvcDTPBRQKTRfEhluTmlXfguOMkEMKcyH+2/IZvkyLQL13x04CmSBOrn55V24YGjFHwkTLtkqeEJljsnZz4yLbWVerv4AkogrNpl8Ept+XHgzEc79kBDtVdvX2eiE3CCtAsAzBf4WFJasMTM6LIOPloaVjJN6jqg+VAC43rGzEeTBeRLwdvFBB8FRD0F9Z62LLcT8PdNFXwogtORiM6uIu1ScXITmBFokqY+MvP1Vi67CT6RcbOoqIkjr7RLXLWLYD7aY86r1Daqq21NE0g32OuBpUM5R4EH6/S9gQifD6WxZBLNB1Bs0SmJj0uSw2k+1S783kxTMagGG+q1Sff/XEZsHWcgl0L60QQfBUQ65iNdYNAJWhLzoW8Mx0GT2kKjhWbLFRqW0bZtum6hp4BlqOwIR8O86EV631XLquKx6RzYD34+qiUbtI5ECk41i0oWCJqM6atd6FxLzEce1S6iq62eTlY1HyMVJ/CapQr6jmXHhmX5wYfs8+EfB1qIklW7+AFHXqXsWYC+Q8XxmY+kBodJIfRYpWQpURVxgtOs0y583lgK6UcTfBQQ9RSpFKkJXReYDyB+d8B3VPP1ppgcl1HwEVFqO1JxUGnT8flpPrz3HSo7GG0vanmITuncObYFi/la1CPOk45OzwJxFUd+tUtw95xXtYva1Vbtfuy6/g5/tOJdO4PAfIgyW0eenmWfj6A2iM5p1GXDF/AiO2VKPh85Vb8JF1XH3xikSWfEaT6yTrsY5sMgd9RTiP26wnwobxuXF51Tdlf0+pFqO+0SW+2St+DU31WND3uGZnnoPoRLY3tmExqHiOOnE11mMxbvvSwxybKJrNEKlNi2ctJ88GoXwXwoaQMC72FC184gaT64xweg+nwEr5O6SFVFMR/+c4VmPrjDaW4+H/5n0LUYtTFQEfT5CKl2yeg4G+bDIHek6e3SFc2HEgDF7UD4zcYX9ZH27lWdRFzX9U3GKtxkLJ/vQ0LWsmNjrK37yIX5YDsrINhITYdmXmkXVXfDxsCDRfpMqYQ7w9Mg9XaJqHahsVCgJpiPJTDpxsFPu1jS475At6WtdqFznFjzUWDmg/d2qZTyYUI5M1kRgXAKzUdMqW09z+BjCQThJvgoIOopAoq8BIoc6hjiKD8+qfEyVkpx6BxP6TOGu1Jq6+fUyco9j3Jb4dLYXjTUXib6v8kp7dKeGIdFAOh/Dqfffbdc/2+zdTj1q11Uk7HA5N3yGZnRNvOxFOjmOPDrk8NhdvTatIvQfEQFH/65LnLwUWPMR16bEbrWS8xtN82cE1ZaS/AFp9mnXZZC+tEEHwWEzHxEX2QNJU+eB9TUT5zoj9O5kzz4qOrz9nxnINmr5yw4rZTyZT543pr/TOzzkUOpLS3i/Brj54s+s5WX4LT9sY7tm0c1w9IuzExrEJmPpJoPYa9OzEfE9cXvqSJXuzRYAJbXfMArqYQeK0WAk9TnI6v0Fr89DPNhkDmaLVcqbYxrwd5UWJIsd6kEdRGM2x3wnTQFH45tiXp69QannQHV9OddaisxH13QfJRtlfkI/155+baIcmcN88EXIe4l4D+W2TAknw9iPoQ9uIa2pnGMiMC1/yfdONC5UZkP22KaD8kTRQ7ekvp8FDv4oGOQo8+HS8yHLQLhxVS7qIExBYMLjWwM3biDtWE+DDKHTnQXhWB/guyDD/XGidodcP0GAEy1GYWoSYQaLw230zLlnHK8BF/QZ/lpl1w0H0QdE/ORIO2SU7UL6VyoZLURpvmgxnI5Vbv4Ph/ctyJY7eKNuSWcdSlltxQm3TiECU4586E1GWsE9Toq+kXzUW/5gUFuDqdNpj+itEtGPh+u60rjzcLQTdZ89P99YIKPgkFdmNL4fCR5fScIlNpGTAK1Zkt6PWkpPEZDH1Twjrb0WiDHtAvbWVLaJQ/Nh592IeYjPu2iMlnZjYWYD0q7RDMf/LOzZNMkh9MIkzFAXhyjPGKWGvymcrLg1HHCSm1V5iOq2oVpPgrNfPjHIK/Se675KCdIiaogFo4qyHhA4LHQ/muzSL3woS2F9KMJPgoGVW2dptoFyIctUKtdoqLueaWDIy3qlYjc7TyrdKHXAvmJC7mJU55pF0Edt4OOJGmXNB4vaUDfeVjjMjunE5zm1FjO9/mINhkD5PSdz3wUd8HMCmGCUy5YltMucrVQyw0PGGsh571okHw+yGQsR81H2U7PrtB4lmlSgoFAOoPgoyUxH8U9d0lhgo+CQaWe43KFaZmSThBMu4TfoOqENsmZj5I+qJitycyHT7PGfxfXdfHZux7FD/Ycjn0tgdPauQpO20EGpZG4Q2UYZDrd+/+h6Xl88taH8NSxBfHcf/70AP7jx/uTj0UIToPlznLapS04zSvtomU+5MVTjItN2CMhYuU0uOUXh3DT/fs6/vtugQuiOfzrpwWdMLmm7Lx14DtmOu+/PDiNT93+cKFYJe6R46drs6528T+jk2oXOl6UuuXXpmoFn4WhG98QFOlcdYpSrwdgICOthiMtU9IJAj4fETforGIlTMFHpWSHaj54XxfA3/FRbpv3t1Cx+9Ax/MlND+CEVSO49eqXJvk6zGTMxlh74sjDXp2YC0q3JKF26xKd7o3z/975KD5x824sNJp414XPQr3Zwtu/cD9aLRcvPXmNEJFGIZB2YZ/D7Z+1jeVyqHaRu9rqq114UETj7pRudl0Xb//8fZitN/GSZ63BitFKR+/TDfDrk4MzHxaC1S6qQR1zDReQSm3b992O//dz3LLrSRy/agQXnbo+my+xSAh79RLTfORZ7dJR2sUbD21gePARtsFaDIzmwyBXqBFzvM+H/HwenW3TaD5U5oPSGWXHYpOIvtrF13z4wUbcTuRoO7h5cnoh8nUcPKdeceLZiE5RZ58DILDY6tDUGMxR6urITA0AMLvQFK6kSSc10rmMVIIVR3O6Utu87NWZw6laYaDubGm3aFt+59FO6ebZWhMztSZcNx+WK0vUQqpdyOej2VRLbb0qN+6DEcp8aKpdDrXvnSOztQxGnw3qLHDPz+GUaT4SpERV0LVIqVtdbyJCFimulgk+DPKEqraOuxnUSSbLCgmC+pZRlJ9KL07NUbWLX84WxnzQwsjp5rgJh3bCM7VmYnfCOnM4dTqo708KnzpWNB8R49RVuxAbIroFs2OcdEKm15HJmOTzEaP5yDIu49Uu3DQLCE6o83W/WqgakrJLCh5wFD1fTjv8cki1i66lerPlBpgPHWqaahc6NkUSoHJ7dUpbZq0B85kPm6VdUjAfdUq7BDUfeQQfTclkrDjnqlOY4KNgoF0gKahbbrTuQ2fMlDXUtEuU06C6E+dpF9rBqN0peUdbwBdoAvG5zVrT/7xjC8l2tPQ3lZLNLKuzP24NtdolbaktMQLUHbNOP5mwLeEOiF43qkm7zGuYD36KsuztwqtdyswuHAhey/PM/4WCj07TLlxQXPRdo8qYEZwQkzHAO2/8+CVhPuhepWOTVev3LOC3JrByq37TVrukYT6alHZpaz7Y8VPHmrngtEDnqlOY4KNgoAmkynY96uLPEWQ+8ki7yBd6VO5VvckmebVLSO5WTbvwvh9xOxF+Eyal0znz4X9O9jczTWQ0sYlS26QmY4rhF2kzuK4mLfMxorG4l6td2hUTeaVdWn7wETAZCwlKveBjcT4f030UfIQ5nIY1lgO8Y8cXvLBrjO+Y5+tNuK7LmI/ipKPou3gGYPmmXRzuQdRIfq0HmY9wzUcWwYckOF0CbQZM8FEw0EJDLAAQvStXmY480i7qdZ5G8zE971e7xAlOaWGk18d9FiDf8JMJvTq4oC9JBUqn8J0qFeYjpb262pp7XmI+ko1bTbvw4yrZq2s6o2Y5z4mutkzkF2avLoIPlnbplG6m9N9i3qNbiOtq22y1NDqseObDdV2F+WhgttYUry1S6S1d+yWuFcuY1RVpF1Z5lcpkLKD54GkXva5tMWgY5sMgT9DOd5gFH0lpeu/veyw4VSJ8+tNyiQvHXO3fDEnBR7I8L19IkjIfXHDq0605aj4cWfORtNSWxKd0TilImGNeKkl3g4G0CxecajQffIh5VbuovidqIEXpoJJtoVpeHPXeT2mXMMGpf/1oNh0q86GZBzxhqv/7XL0l3TOFCj7YBiE/wan3fk7HJmPEfGhKbY3PRyxSBx+33347Lr30UmzcuBGWZeGmm24Sz9XrdVxzzTU4/fTTMTo6io0bN+KNb3wjnnjiiSzHvKRBC6PEfETulIPCs6yhLj5Rk3fYBFZhO5gwJ0secFVK+g64KviEm9QorMYEfUna3HcK32RMdjitR5wjHpj5aZc289GewDpLu7SrXTQ+H1JXW5c0H/448nA4dTRdbdXrYl5Q74tPu3D7/KJ7JIR3tdX7fADeNVWPqXYJHN96U7pnsmqAlgV0JmN5CU4X6/PBS23pXgloPrIQnLK3LHoAnQSpg4+ZmRmcccYZuP766wPPzc7O4r777sN73/te3HffffjSl76EXbt24ZWvfGUmgx0E0IKVVPPRnbRLkOINA01gy0fK0uNR3Sl1aRcqgY1bKPhNmFjzwXZV5QSW552CKFxiPoQ9dsQEx/U1/qLs/ZzXVLskFpxG+HzwRUdnrx51/aUFr3YJlNqGXBcOC1w7Dj7m+of58K9PWXAqVbsEGM+WnHbRnLMFZQGcrTWk45KFEVZWaDADsHLCuSAtaFPnOBbTY6VnPkhwCvj3WVSrgE7Rkqpdin0NJ0Fqk7Ht27dj+/bt2ucmJibwrW99S3rsb/7mb/CCF7wAjz32GLZs2dLZKAcIXKRoWx79HSlQVEtzu1DtErU7oAls5WgFR2f9ic0zGUvW2wXwywzTaD6S9meh4KkiMR/5VbsIzUeCz5KYD5F28X5SkCBpPhLs1HgjMjrGYb1d6PFWTqW2cldbWYAbVu1Stpnmo8NJXCq1LdAiq0Oowykz3wPcwN/InYg1wYcmuOPHpUjMR0OTesq8sRxjPirUzDLFou5rPvxltNZooVpyQgPpxYCf09oSSLvk7nA6OTkJy7KwfPly7fMLCwtYWPANoqampvIeUqHBm5GVbDvQqE2FruQua6SyV2/fZKtGK3j4yRnxeDkidyvs1ZlTp8+SxFW78A66CdMujNYu51pq6yv2+c9IkzGN4JQmYgrS+CKRRITHj7eodml5FLFlWXLaRcN8ZFlqS+9lW8zYSRGclh0L9abfHdlhaZdOqff+0nzo0y5RweuMsrjpNiE6HxV+XIrk80HHoORYsK287NWJhbMTpURVkOiTersA3jEeQ7iubTFoLjHmI1fB6fz8PK655hq8/vWvx/j4uPY1O3bswMTEhPi3efPmPIdUePBmZI4dXx2h6kHyKbUN7rLCQIZVK0Zk++oyL7UNUYJLmo+k1S7s+bRplzKrdsmj1Fa0BVeZj0iTsaBokNI3urRLknHz11BvF9f1z+usxudDZj4yDD7ab+Vo7NVpQqXrYF5T7VJvuh0FitN9pfnQC04ln49AAC9f+1rNR8MXWALeAk+uuUDB0i7ETvIquZzs1bnmI6lRIeBfr9WSE0gLBjZYWTucmmqXcNTrdbz2ta+F67r45Cc/Gfq6a6+9FpOTk+Lf3r178xpSX0AsjCUrUXWEGqmnuXmSQl18onafVKGwapkcfFQcy+9WG9rV1r8cKVCJ1XywmzBp2sXvauvnenMptVX8GhKZjOkEp8x+vN5sSaZgSYIPfgyHK8EqKp3Ph8R8ZJl2IeaDVRjQY74XiRcgCYdT25JSEJ0ED32l+UjicKqcFHVnrUvVUppg+bCvUTjI2hIUKu0i9FKWOA6qOeFioa12SXGxU+qjWg6mBfMwGZN7uxTnXHWKXNIuFHg8+uijuPnmm0NZDwCoVquoVqt5DKMvwS25nQSLlWoAlg/zIf+exOdj5aiG+QhRrftdbf3LsZJQfb4owSlzOM1DK9MIZT6SpdF0zp9z9aa0SCRZSP0+GZZkXFVvtjBUdrS9XXJLu7BqlzabzhqjUUWOFyD5Ph+WJMBeaDSlICoJZJOxYk/cYYJTXu2ixhZq4BCl+RgbKuHIbA0tFzg05QcfRSm1dV0XvLeLCz84pVRhFqDbqiSZGnbCfNiolhxMoxEqOM28q60xGQuCAo8HH3wQ3/72t7Fq1aqsP2JJg9sKJ2E+gvX+eSyi8oUe5QJIk6CadvG6U0b3dhnWmIyl8flIqvmoM0pX9ZrIEoHeLgl2V2rDMP4+gHesOk278AAQCGpJgBDNRx4OpzYC1vY0zlHBfPg+HyWWIuuI+ZB6uxR74q6x4JiDp13UOUFNu+iuMWIJh8qOSG0dmp4Xzxcl7cK/W9mxUHW8sfJUYTafo2E+Es6f3LCtWnIC9v+qUZx6fjob79JKu6RmPo4dO4bdu3eL3/fs2YOdO3di5cqV2LBhA37t134N9913H772ta+h2WziwIEDAICVK1eiUiluG+uigIsUk3hQBAWn+addkjAfatqlHJG7nddVu4QYkqnohPnw0y62CAharrfDt+1sdlVAeLWLylZx8OdosuHnOBB8JFhIuamaY1uwLG8iJ9Epfz/BfLBznmU8y30+aAerOrlSEOrbq3vnqFqyMVtrdhQ8SMxHwSdufn1ylCKDj3jmg/c0Gq44mKk1cXDKDz6Kknbh13upXfVHqDddlNKRXrGf47By3sSmfex1lRJ34JWDj4nhMp6cXsikb46cdin2NZwEqYOPe+65By996UvF71dddRUA4IorrsCf/dmf4atf/SoA4Mwzz5T+7pZbbsEFF1zQ+UgHBGq1CxDHfMgXYR7aBfV+jMq9UiAxMVwWpcIAMR/6gGJW5/ORsNS2I5MxjeAU8CajSobBh+rzkaRzpmwy5v296kY612G1Cx3TcruKqt5028ZI/mspxcLjo2wdTn3Nh23JwTVNqHQdCIfT9nGriOAj/SLJ7dV5M8IiItxkzGfO4oKPKOaj2g4+AODApB98zLV7vWSV1ugUfGEvO/51Qs8NI5vogzeWKyXc7IhxsHmnyuY2ujbp+fGhEp6cXsiEVZJ9Pop9DSdB6uDjggsuiHQ8zNINcRBBE3HFsUHNXVOV2uaQdgmU2kZVuzD9xnDZESWAUndKlrvlO+8hTbVLriZjJX/HA2QfuHGtBeAvHknt1dUSVMA7vpLJWArBKR3TsmOh1vQC16BQ0YXruhLzkeU9TV+Pd7VVv+eIwnxQgEi7y/mUu8h6syUds6IzHzwtyMGZD/U+V2l9nU6HpwmIZeTpKNf1XsPvw16Af7eybYPHQllWKvnMh42S3Q70EzLHC0rwUW0fMxofGQNOtMW9maddlgDzMZC9XT5/92N41fXfw5NM6d0Jbv7FQVz6iTvwy4PTgec+dfvDeO0Nd2Imos375+5+FK+6/nt4+pg/jjjmo95s4Q3/cDf+8j93BZ4DchKcatIuC40mLv/7u/DRb/1Seo67laq+HbJhkFxeCaiaj4SCU+7zMVdPtFD6VSiOxHykaSqVBA2FcdDpS275xSFc+ok78PP9nr8N/75qV1vAY5Z4wJBkMvYrqGTtCffS4GgpufU0QdmPHz+KV3ziu/je7qe0z/veCsFSWyE4DVS7UNolucX6zr3eOL7/0FOBoLQoE/e/3fs4Lrv+exL7AMQ3lms0g11tw5iPG7+3B6/5P9/D5Fxd7JarJVtKcXJ0UpXxie88iNf/3V2Z7cbpvrEtjyGzLCuX/i6c+Uir+aBrqFKyYVlWaNqFms6FHdfvP/QUXvGJ72Ln3qMJxuv/v+jl4kkwkMHH/73rUezcexQ/2HN4Ue/z7z/aj5/sm8TNvzgUeO4LP3wMP3jkMH4UcVF98Qd7sXPvUdz2yyfFY7wZmc59c9eBaXz3wafw+bsfa78+f82Hzl795/un8b3dT+Pzdz8qPSc8OyqOVDpbYY3lvPfwxslvyiE22SYXnMqLdZJdsfBRKFnCXh2I7qHTCbhiH9B3tf2Xe/ZK15DOZIwzTZ0ITsmorcyYD+/9W2LRkvPq8numiWe//bODeGDfFP7t3se1z/NqFwom5utNScdAze/mG77gFPCZjyQT7zd/egAP7JvCl+7bFyjBLgpl/aX7H8eP9h7F9x+SA7Ukmg+6NuiYzC6omg/vPf7lnsdx32PeXEfvWy3bodVCnVS8fOEHj+HOh5/Gz/cHN2GdwPfHkecPINvgg2s+0vZ2oU0PHX+16zLds8R8hM1L/3bvPjywbwrf/tnB2M9cavbqAxl87DsyC2DxkxDdzDoalx6LukhIo7DvyJx4jDcj01W70ORA7xsotc0j7aLx+aAJXY3oReUKU9QDspso4N/kwsmQ5V0BZq8e43CqLkRxug/XdSXNh90WYALZMx/qDlbnULnvqHfu6XtIPh9UgsrGNRvQfKSrdvHG4e/yKBetujRypEm7EN38+NE57fO82oVsqY8tNBQvEt8IDfCDNupsm+S+pWO078hcgPkoyq5RzB/KeLhAmIML0Ok6oRSJamKlinin5ur+bt2JYD46CD5ovFFC6jSg677MIuK0gtAkaHIvkZQ+H/SdA8GHUu1CwUet2dJ6MO07Oiu9Pnq8MhuZh6dTNzFwwcf0fF3kORcbPdIFqJsMFxrhz/lj8caxj03UXKSoYz5oUhURdheqXeiiH2JtzWnss22RGgBJvzGspF0q7coSmk/EsavrKWah+YgRB6rHN85ojDNF/mKcj8V6XVlEdPbqFHjSayWHU8VkDPBEmDLzkV5wynd59F5ScyzlvkhzXGhC5AE1h2A+bEu0Indd4Mis77Q5ouzK6fzQNZHkvqUc+76jc4GAtCi7RgrU1F4z8V1tg716Zhf0Dqd0DU3P12XNh3KM6d7uJO2iC5wXA87+EpK2W0gDGm8n1S6+eNeRfqo+H+PsvtIFdjT3J7mP03QX7wcMXPDBF/rFNpgK27l4jzVDnwO8hZoWSj4m3lBJV5pJNDnZTHfTXp0munrT7wlBIjVAphY95iM4eaidbXkemiOsMkaFenynYkSnfHKpaJiALKEKPX1fCz/l9HTb3rommCx5d+O6spvlbK0hLRBJJiB/HN7n8zJmup6oLTgQTHWluaRorAem5rU7M8F8tPPkdGyePhYRfDjpNR9U2rh/cg6TgbRLMSbtsPmDrnn1nuCbEbqOKWgIaD4UEe/UfMNPFZRtydAPANaMeUaPi2M+sgo+5DQh/3+W5lq0mHsmY+nSOtxgjP+koISCpNFqSTCr6rFttlzsP+rpfZJsGtO0uegHDF7wwXZki52E6kmYj5Bc33zd70LJx8R3y7reLlJH00ZLXLR0gWetWwA48+EHH9w3QddzZCiQdpF3r6rgtKoU7ydto01/T8cqLu0iBR8R6ZAsEJbuoO8uMV6Kyyc9FrDRrrfSaz6UcfhVJi1JIExQg/I0pbZ8ITqoEXTzahfLskTQ89SM91ou/iMIzUdZDlyjMMeC9IcOHQPgXyNF0Xz484eSdgnVfLQ9aRjzEZZ2UY3bpufrokTeK7X133u04mBZlaoy0h8bumazun9Ufxwgb82HDbXyKg50DdG41JQgZxtH2udIZZUOTc8H0mNJxuuPwQQffQWJ+cgo+FAnQ9d1/V1NyEXFF8l9R+dE6oKLFHXVLrM1NfhoT0Il6laaX7WLH3y4km8CjWmOibAc2xJVCwDzmFAmkQXWH4HD351HnyM6zqvadu5x5ba0ONqWvxh10lQqCYhWV4McOp/8WqTXBvO6SvBRa3TgcCrvJHkHz7m6d7xGKiVmMS1/Zprggx9DXeqlJSZ877OoGuBwm/nglvcEtdQ2keaj7l8HPz/gVRLRNVKUHWPY5kUEixHMR0MNPhb0Dqd0/UzNNaQUJ98YjA+X/fLmlMEHTwGpVXGdos60GASxacnw3PmVV/I9kQTcM4WPT612IUM3IMh8yJvOBGmXQPBRjCC6Uwxe8MFO+GInoZqye/cf938PS+1MKy2+n2pPvsLh1LGEz4ek+eB+BY0mE55RoJL9xEoXPa82kFpxE/PRzrPTzabz7VD9O7gIjiPpToduwNXLPNo4qeaD7yodjRYjCwSYDyWvrGO8uLi00XQDNPPRubpkCtaJ4FRmPrznhit+2bF6X6S5pHiwRGI6Du5wCngmTADwdJv5UEuy+bgrlHZJUNHEF9GfPeEFH3SNFGXHSAspP95eXxNZK0TgdvQ0TwjNR8DhVF4EpxdUzYe/MRgbKgU6CSf+Duz6y4p15Z29CeWS34k3K/iaDzv1BsQXnLY1H4rPB+/PMxRyjuR0e4K0i9F89Dcel5iPfKpd+EURdoFMzsk7FboQ5d4ubZqVXXTzUvDhp13oAs+j2oXuCwoqas2WxDDQRE8LGdGMnMovC+ZDnkTEhKgwH0lMxnh/hdXtnHUs86EJdsqOzEhkBW5mBsiCQUBenOm1cqltUCH/NGuBDiQT4IkSywifj+GyI5gPVeSbZkfLd4465oNXuwC+0JU0H2pVFKBjPpJrPgDg0cPecSZdQ1FMxnSbF0/n4/1fDch1zEfYrloVnE7NNUJ9PsaHyqELZBx0vjSLBd+AEVStWBbgPh9pfURUxla9Nuln2bEDjr2Ex/nmI8GxCzAfBbmOO8XABR/d0HzwiyLsM6YVbYJa9cCtv3lAwZ3yFhrNQO43T5MxkdphpbYAYz7IqbR9s+kaxan9XVTVuPr6OCtymqhXt3vJJNV8cErbsWVGIiuouXtV2Kpj4aRS21awdfoRNfhIxXwo3XVbLcFWjVQc0ddmMaW2UtpFU27Lq10Av9yWmL8KC7oJotQ2hc/HXE127gQ481EMuppasvP5gl/vagWYzueDGE/VzFBNu8jVLrYkBh8bKgVcZZN/BzlwygKqRon/P6n9eRLQxs1hZf6JNR9K2iXg88G+AwV6gbTLIpmPorcJiENqe/V+h1ztklXwoTIfTe3/OdSqjMfb3iN08ZekaheWdqn5nzVfbwWU8XnUfreUia7e0DMfFBjRzTaUSHCqr3ZJom7nz61ZRsxHdPChZz6C2posEJZ2oUlPJzhtKGkXNSA6rAQf6RrLKQEgK7Ud4szHIkpt+eLweBTz0U67jLWFjocp7VIKMh++yRhVuyTRfARfs3qs0v77YuwY1XsAkI99WKltvdkKbDrU70SVUpTGm5r3vVSqZUekvQBP8zFU6jTtIjN1WYDPgYRqDoJTznxQ4J3U60cVyleVlCBP74axSo9r/J2ix6uMoc+Zj4EKPubrTclSfbH5Q13OVv09bJcWYD6OKsyHxn4akCfVmmYSypX54IJTjeaDJi7aRfG0C00eqpBUTQkQktTdcz2Nr/lIVmpL6R+AT+rZHjsR6IQJTo8EBacNZTJXJyU17ZJI80EOp+Ic+N9X1nzomYU0lxQfj1ZwyqpdAJ/5oO9Vcewg82GT5iNF2kWTPqAAtWiCUz4P8f/T9eL/HgzIw8zCqPkcbZZVkzHO/I0NlcR7p+1BImk+skq7tPw5kJBHqa3kcJqy3F69t9Vrk45LtWSHskpkdgkk+15BwWkxruNOMVDBxxMKDbxozUco8xGfdqFFkjq/irQLsxZWfSEAmU5eqLcC9f55dLWli54mOu5w6o1JSbu0X6c6nAL+Taoeu4DJWAKKnU+m5CQYl3bRlTHmZzLmivEBstai3mzhAGtnToEsDx65nwNBTbukEZyq42g0WbWLpPlYRNqFXatUxUVdUvnkSQGfVvMRkm5IV+2iCT7amo9GW7BZUpiFbqLFUidy2sU/V2p3WYrJ+OkICz54agbwtFC0OaiWbSnNOT5UBr2SM6tJwK+VrDY+vL8VIR+HU1ZZmKDjNIfK2KqaDz7PUPqZs0qu62r9nSLHGxCc9nfaZaA0H2oOerG0lWqUJd6XBx8hn0HMxwmrR6WxCWthx9JWYajVLnQDVUs+K5E1BLvCmAy+A6cxzTJrdf4TCFZaqNUuquYjiQCM57BpBx0nONV1DBUTT0726jon1QOT8xKjoDNqarbcwPnspNaf3ruiMB+e5sN3pA2rdkklOGXj5VVc6vuo1S5PHWNpF3XHTyZjCX0+6s2W9j4gdgzIdgfdCaSKuIYm+CgFp2aVEQIQ2oFWDVy5SLxaciRWcmyoHKpLiEMemg/BfGgdTrMPPhzeWC512kXv88Et8snQjaddDs/UJFPGJJ9LwXsap98iY7CCjyMq87FYzYe+1HZBCRB0oB36czaMS2PTO5zy4EOetFThWR6ltqqXCH22GJOodpHTLpGCU9XnI1TzET6hcaMf2kHHl9oGJzbR6j7DwI3vbFWhZ73VCgTCvsmYrPmIm5SSNZbzJ0JvHD4DQxPiUNkRQdjiSm3lF/Pvya9jtdrFZ7GsACMR1HxED4jvMMeZc+uqtigZ6H2+vC4FH0HfFlX3AvhsEcdQWT+FNzUpOwrwqiVbClrGh/1S27kCpF0oTcjTTrl2tXWYvXrCNcGv0lM0H0rapcwM3XgqMHj/J2c+hsom+Og70Akns6HF0lZhJmNSDjcm7XLyujEAwPRCA5Nzdd9gx7ZEXlzu7eJPDtzhVOgx8ki7KBe9Ct/nw99FAzLzofp8iOCDVOOqyZhoLBd+g3G9CPVQSGoyxneWZdtnArICvwbUnirNliuCTZVtUEttwyYlagSXprdLQPjKBKcjnPlQJvhUJmPK9ccDfv4+vuajLL0+kclYTOBA16FlASeuWSYeXzFSCU0tdRsqQ6T+XxWbAkENCBDDfCjX89Pt4EM1GRsbKoeW7MYhl+BDw3wkbbeQBnSt2pYf8CadP1XhesBkrOGzFDoPFXUjnGTuoWCSzBtN8NFHoBN+4hov1bEYCk/K2QaYj3jNB6Vd1o0PYWU7GNp3ZE5aKKK62tJ7026dWIk87dXLrDEcR5jmg1O7qjCLGA0RDDiLSLuUHWHTnbjUli1wOmHvYsHHrSu1JaX75hXD4vVqH5dGM7xzJe3oU2k+KO3C+ljM63w+AoLT9GkXcU0zLxN+eH3Nhyw7Kzu2ZC7lPWZJ44/bNIiAquzguPbxBTxtQ9IAJm/UQzYoOhM8gsp8lFjnaxXNZtAdl44/F0EC3rXkp11Saj4aPFjOKO0S1dslJ58PsQFJ6/OhpF0CJmMlWxi6zWqYD7pP4rp3A/59SOdusb3Jeo2BCj7IYOzE1d5uaDGRY5SLqbyTiS61HR8u4bjl3gS57+gcKzOz4GjMr+SmYk0RqRMrkUdXW+7NoJsUVXt1ujmGpLSL0tRM9flQTcYSOBryWnvaQc/WmpETiE5wmkepra57Lm+JTosyaX6oUSCHbKMtHx/6vmns1Smgo0ofKe3Cql3U+6KTapfjV40AkHd4UtpFaD5k5qPs6JgPWdQXx1rwzsqb2vdWybYwVLYTBzB5o6ZhO4A4zUeQEVLFuXSMmm5QrOy/Ru5qOzbE7dUXk3bJZu7xu9oGq12y7e3ivRf3+Wi5waoSHdR5Sy0DlwSnGj0NbT7oPkmiNxMNPivJ0o9Fx0AFHzQRbm0zH/zkHZicj61xPzQ9L0rR5Jytwnw0mqHPEYj5GBsq+8HHkVn/xrN95qMRFnzUu1Rqy4RZqusioEm7KIJTi/VRUUvm4jQfUWkXWfPh76CjUi9q5Qd9L++5NhvTaGH/pL4l/ORcPVBxEvU5DiuZpsl0rtbEroNes7MTVvksnHruGs2WtjU34AcfdH25rovHnp7VVqaEmp21WhJLQIckqPlwYz+Dj5l/L57b1lW7kFCYUNHYq/smY0F79X1H5wILEtexEPMxPlyGZVmxupHZWgOHpue1z2WJsM1LvRG8Pgkq86FjiWhh0omVCdWyrPmYGC6JjcJiBKdRc89Coxl6T6loCEaCbRBKelYO8OZlbrLWannXaRy45oMHOkkCgaDPh8yoyYLTtuajHmQ+6D5JUu2iMh+1hueAvPew/rvO1ho4NJX/tdwpBib4aLDSxhPbu0266Z84OofzPnwz3vJ/7w39+6OzNZx/3S14/afuBqCa68i71iQ+H6T5GB8qiwly39E5SaTo23EzcaeSdhH15F2wV7ctS7sjU7va0sQ22qYbedlgRZlEwrvaxgtOueaD7zCiUi81DaVbUo7zu/75frzwQzfjoSePSX/rui4u+fh38bKP3ha7c44yM5uab+BHe48CALYK5kMTfLR86lxNT0wozMdXdj6B8z9yC/729oc131kOPngHT7naRc8s0KT3me8/gvM/cgv+9Z7HQ7833Rc0qXIjpaak+UD7e6nMh4VQkzFFaPfz/VM470M343/+fz+WXj/PhM+bKPhoHz/1PVS8/lN348UfvgVHZ+MDzMUgbPPiN5ULplMsy5ICEG/HLr9umG1CwljQYNqFVbsswl49KuX7js9799Sep2Zi35NX/BHC0rCTs3W85Lpb8Rt/d6d47OM3P4jzP3IL/t9P9kd/TsimKomuJHFXW8cWGg1+bMn2gZiPRA6ngvnwNR/v//ef4cXX3YK7H3468Prf/NTdePF1twSMCYuCgQk+pucbOGXDONaOVbF5pXfC6UZ/5KkZNFt+620dHj8yh/l6Cw+3X6PeBGE0ajzzoU+7cM1HqMlYw2c+hMNpjmkXXbtzwDcmOtZmHGih3LxyGK88YyN+98UniteG0ZNqUJOEZlUDl7XjXinlgcnwaL+u+Ty1xv+hQzNwXeDhJ+WJcr7ewuNH5nB4poajszF+IpoJdOuqUVxy+gZsXT2KratH8V9OXotfOXGVeL06AfEGYuoi7Qcf3pgfPDQNANh1YDowlnkRFJLg1F+AyXRv9bJquMNp+/zTwvHQU+H3CV1/K0eDLdqJ+bAtiGB0rFoCt7PwBKcq89Ge4B15gt/dvhfVBY2XfP/KiavwkmetwZvO2+q9R0zaZdeBKSw0Wlp31izBc/y6zYruPgNk9qOsqQyiIEKn+SBU2sH677xoK177/E1YM1btuKttUp+PXQen4breXBsHnc9HJWQzsu/oHObqTTywb0qc0/seOwrAvz50aDEDNs4yA8kCgWNtpmW0LfymjdbMgmd/QIeiUrK1nkXE1FDxQxKhK8311DtrodHEfY8dAQA8qmF6dh2YxkKjhcdCmJFeY2BMxlaMVvDv73gRAH+yIoqMJquoHBot+qqJDGGh0WS5uOhS20azhZn2Z44PM+aDCU5LzOeDdhStlivVhstdbX26NWv4zcAs7Y6MRGrEOFCKwLIsfPz126TXClV9LTrtksROWf3b45YP49GnZ7U9RQi6vhFE79L3pM9U3R7573ENuHS5e9u2cP3lZ0mvI1v9MOaDJqXhsoOyY4mJmY4xtTSn8ehKjbmoFPCre4hpK9kW1o0PxXa1pfFFieNURb60M3b96gJ+TJZVSphuT8ZeKiEZ80ELpXrNcwZupFLCZ978AvFclEvqQqMp7q+06Ye0CPf5CBecApBs0R0mlCTw9GuU5gMA/uQVp4jHOvX54CxB1NxD12USrQ03/yKUQ+YDMskDgP1H53HC6lHhHBp1j/J7jadGvc+In0N95rrU/lluj6eJGTZPlB07YKzIP0N3n4SBhjzCNB801wX6vjT8lGqc/UCvMDDMB4fqRucHFuEXK010tWYLrVaw1XmYsZhOVX+M5SfHhkqCGub5ax3zMa8xM/NLbbMvRSP4bdDlSXH5iHfDEc09LZiPMsIwIiY577WqWQ8hibpd7Yjra2fCgw+f+fAnG7XVPZ1bVQPEJ+a4HaKwNI9x0eS9bnSTN42hxFpzA7JWglet6PQus0oJNO2WH33aC8LXTwy1Lab1wQdpPNTgTAc6djRB8tcKa3VlweTltp7gVD5mfqmt3LaczocatKnCZw6dboSg61eUF1QDsJZybNX7gcB36CU7qI/xNR/BYJage+88u9q6risE9klEktxugBA2H3BHVnLUpQU5SsPHK7hKtgXL8tN9Sdjj6QVfswcAy1ha9DAz1iszDZMu1UbXaLLeLu2NZvtvjjAGVp07ePuOuArAXmGggw+66VVWQwe1p0pU2iWsVwOBomZvN2tj03IvDfTUsZpgRHizI7qw1Alxrt4UE7ootc3RXl3Nja4bGwIAzLYDCYqwVREhx7BC7/qqcVXz4QdeYepzVVdBDFIUZa43GZOPc03ZWRP4ZBa3Q9QxLDrwShvdgkif6eWOuUjQX7BrTd+pVDfRzKnMhwg+vB0iBW1hPh8UfDaU46MDTaI6Rb64jhTbcK5nqWgay5WF4FS/aVCrLFS/GY6otIsUfOTNfIR4A8VdN44jB81Rmo8wsbYu+OC76STVHmLc/PyGCJHn6r4Tc5LgoynSLv44KyH26pKIs50SFexVCuYDCHadjgLN4RPtuc6xLeG98/SM3z+Ma5jkkmrv/8OaID0MdB/SBo6nG9Vjz6/lOO+jXmEwgw+20PGJu9ZohSr55RLXVoB6Dqtw0S0oIj3RvnDHh0viwuU5X5X5UHclfEx+07fsNR/CjMeWBaeksfAXvnjmg242P9UVUu3Cfg9Tn6uaD66dCQPljCUhqGJjL9IuygLEj3/czjhMy6KCf0+aSPmOjz6n5FgBYyhCvdGKTLv4zrPeNUaTIR0/CtpU5oN+p3k6CfNBu8bRqibtwoJYDl7J403WKvPh/S5SJoqdfxjzoTPgqmry7wRdv6K8oB5DvxtqUCvEwa8NXek7T7/qdAS6njGAHKipDGsUVEdeHXizxyTBh1/tEl9qy1Ohjx+dk+599f7l4OJYtRotbg51XVeqViRQEO33KfIYFZ1Ylv5P90mSKkWh+agEgw/12PNNiEm7FAh84VlguTEg3ENA7alSa6q7Yh5wyK9VA5op5cK1LEssnISyYweqXVQakZeXdaOxnGPJk93aNvMx3y75pXTS+FAE86HklnWOowASqc/pOIu0y4r44IPbHhMcVv3BP28+ItiL2xnrGBYd+PekiZQvmnRdlRy5PHK04sjdaSPSLr7vBZXayovPJsF8yMwCTcauynyE3COu65d3+mkXpgkQmg/57yTmw3EC4ysraRca37xgPpTgQ7H554gqte0m8xEIPppBfwgdJMGpIpQEGI3f0hvUhaVzeOuENKmXmhRc6q8LngJIYozF/TcIqjkhQXUN5SnXaObDHysxcTwFGoWZms8488CZ/s87NPOx8/el8z/CSqPjGjjqql0IhvnoE3gRqff/hUYzwGrooPpr1ALMh15A1nKDUS1dDHyR5k6MQJtSFcFHewxq8FHjwUeOPh+0aNhyGeS6NvMxW2uIShcghvlQrIa5URgHn3zDaH5VL0Lpq31H52JTNZLJmBLk0YSqHu+5FGkXv9ROv4MVn82ep/esatiQsm1Ji+lwxZF2g0LzsdAIXYzpGlE1FQHmQwmc6P3o+ITtDPnnEstCglhATt9xSJqPkhV4XrVXp9J2CtbUXZ+aZuKIEpzy3WLezIe6iKrMh87nA5BFmNwci0DfuRXi86Ga+RHstgkbkO671xM4nPLjmoj5EKJbDfMR0Hz4Y338yKyUco3SfAgRveVrkJIyHxRMldgxAzjz4TdJ5GOnuUcO0rl2K3zu5vPZsOYcqvc8ZzuM5qNA8MyGiMKVmY8w2+U4zUeUsZj6O10YfJEOMB92kPlQdyQzC/7veZbaNkOYj/UTHvMxV2+KC5y7SOoQTLvIqRMCV6CHTQYLSmpj/cQQLMu7yZ9ieVcOXVBAO/56e/dBk0RUmivOCTIp88GFbjzFQt/dF5zaEjVOeiHAux75WLmgudlymbhNTrsQjmsHbX61i68zAYJpl7BgsCEFH/5Y6Vjoql0AOQintEBZ0jbIXgo0BhIbhgVbw5UgAxet+WDBR5c1H35DsnZaMOQeUktt1XM5zJmPlry7BoL3mfS3mh4kceAMcBjrOjXfWdrF4dUuijkhgadW9qlpl4h7VGdkVtJ0EddBVLq0jesIFEQ/JdIuSvCh6HoA/X2iA69mGakGr2u12sUwHwUGp1/5ohKadlGYj0jBqSomU34XzAfb8UUxH3QzqBMiv7lossqjtwu3V69IaReP+ZivtzCpCah0UNMuYZoPwF8k45kP7z0rJVuIYMMqXrSltszGPsxTRf09VvMRs4hw0FgogOC+A7QQcBM1wAsk+I6Kj43vevhCQn+vtmana08ttaX3bwnmQ05LBb+zf554oESPU1ysVruMDcnVLuoY6VjI6dKmn3ZxkzMfag8ODq5N6LrmQ2PLrUMqzUf7M1aM+N18w9IugB+cpkm7qGaLOvDrMUlvFr+XFE+76DciPDV6YHJe8rSI6lOj0x/55nvJmA81vSyYj0DaRR47P2b8PokSujZDAnuCyvQazUeBwYVnMvOhv/FmpdRMUzN5tKTn5efk36eYwRhBZT683i4y7a1OiMR8lB3Lb5Oeo8+HExCcDon/k1lVlN4D8G82mjRqSuqEI85oTBe4xOk+dDvLEmNY+Gepx5tfA1FiNiB+EeGg13Dmg8Yk0i6OJe3khyu2VAHAJ+Ew7QIdJ7UfyIY2g6WmXSgoayXUfPDJc4Qt/ESViyBWZT5YdZTqwsrHUWI6qIVGSwTfocyHhp6O1nz4k3TaktO0CNu8xDFmPHArOcHKIL/axe+IvGqZH3xEBcNDGhvwOPBgIoz5mJaYj/j35q0JCNR4Ug1e+HlqtFzsbDsHA9EMjk7UKjrbxmzgVM0egTQfh9usa1g/K546ku6TCNaaazp0wYd6S04Z5qO44A2mEmk+FFvzqNRKVJdbgGs+wpmPsqa3SyD4aE++3GY5H8EpxOeUNcwHABxsW9fHMR9048wK5kOfdvEei54MdB4hm1ZEe33UNUEB7x7Mc9jqJMwnM1WMGvichGkXwL8WebULTYQi7WLb0mI6VHaYkK0lBUM67cJw2RELFzemWjNWFbvlUOYjYbUL7Rhty5vI/aBOZk5UTQe/ZipKnpy+O0G3aVB3qr7PRzAQrrB0q4qpHpbaquaFOjM/QPX5sAIsFomKPXdc73gnZT5EGXyK757E5yOt5sPvucLTLvGltgAkK/GotAulsh2driSG+fDTLvL1Rb8/Nd1mPpRO3vWmfP+o90lS5kNXxaWyf0tS83H77bfj0ksvxcaNG2FZFm666Sbpedd18b73vQ8bNmzA8PAwLrzwQjz44INZjTczcM8ANbDQgS88tUYrsCBKFS718MAE4JoP/+LdxJgPp+3xofpP0Djp72aJ+bBtafeeNXiuni8KE8NlsVs6ONVmPoajgw+6ceZUzYdmlxpnNKbzCIkrtxXVNVLaxZ8cahHMRyfVLpWQRYSDxjLHAg2f+aBAwJIWUznt4kpj0zEfnN7lkzpn3EqOGny0rz9iPprRwUddWTR4cMTfR1kvA6W2fCyAHKxwzQYdm1CBbUqfj7B0VR4IzB8K81ENCVo76e0yWnX81u8Rmo+RcrAHSfz3YOL6JMxHRCrEf09NqW3IRiTqPoz6HjRsuZw3mcmYKLOtynPdmKh2IeYjqPlwXV+DRfdHEqErH5IuqB6ItMvMzAzOOOMMXH/99drnr7vuOnz84x/HDTfcgLvvvhujo6O4+OKLMT9frO56YZqP8LSLLJoK0KbcvS5CDwLoNR+rl1XFIkQ3BNHTKvNBzqL0mQ5Lu+Rpr+6lXbwxWZbXz4BuhIPtTqCxaZeyf9x1vWk4wkRmBF0gcVwc8yFKbYOLW7PVkoMPVWPDfo+j5dOlXSzpPfmiEuZwygWn842mFODq/Cq4/oEvWJtWyEEvHztdU6rDaajglI4tMSyshwyQ0GRMo/ngqQW6b+frLSH6VXfcdJ60mo+Snr4HZOYjatecBQLMhyg9J71DvOaDu2cSZM2HL6qkuSas2gXwg7U0wYfc1VZ/XUiajyRmWhqH00rIRiRqrPMRgY6unFdl6sIwNR/CfIi0i15wSu+tsqLkM5RYcKpLu/Sh4DR1b5ft27dj+/bt2udc18XHPvYx/Mmf/Akuu+wyAMA//dM/Yd26dbjpppvwute9bnGjzRCiT0S9KS0q4T4fsqYjzCSI3lN6LkTzwRdq27awcfkQHnl61hfdOf6i6I3Be58VIxXsPewvriXbFq/Np6stBR/+DTNWLcG2feOrQ4nTLv53nmSTki4XHUa1ElSfDyAB86ErtWVuqjwfuxjmQxcYhcHXfFB/Ez+Y5GmXiiMzALQbVHc2Ou0CZz54G3ae7qPP9DurygFtQ5Ta6q8xvyGYPOnS+RP26gHNR1BwWg5hPioaxlINuHlXWxWqSyqHlK5KsENfDMI0YzofGo4A86GksES1S9P3+Sg5FsaGSnhyeiHyetS1fo//HszHJRHzEf/eQo+RICVCYz1u+bC45+n/1KxRLUfmY+WBML0ubg4N03xQEE2HQQhOpeDDZ80ryjwfVWXDj60uqI4qtaXyezXd2WtkqvnYs2cPDhw4gAsvvFA8NjExgXPOOQd33nmn9m8WFhYwNTUl/esGKmxXPS8xHyFpl4DPR3hqJeo5QK/5AIBNK7ySR7oYw9IuE0pqo2Tzypgc0i6iJt6vdqEbL5h2iY5nOcMxOefnZ3WTYrzgNKgXidV8aIICh9kq1yOYD0nzEZd2od4uHVS78DJjCngqrA066TeImp9Sdjb8d7WpHKAwH8uDzAcdV2Iwkpbaqu6cqiU2b1DIodqre+/Bg8MQzQdzOOUGTWT3r8uNVyLSLnyRjNP0LBZhgtP4ahc5aFavr2FNtUvZtsVcE8V86Fq/xyFJV9tOfT54qa2uORsf6zPWLhOP8f+HBVKinFcKcJLNoX5TOUVwqszL/rXsfwYXtfubzATMR4joX32eoLIdvPy+KMg0+Dhw4AAAYN26ddLj69atE8+p2LFjByYmJsS/zZs3ZzmkUJBOIODzEXJzzLLuibVmK3AT6Hw+uJEZh2qvTqBdu19uqAQfIu1Skf6uxFprt9zw3Gun4KW2NNnRjSbSLlOUdolmPriZETVF4gJLjigrbEAvON3YPobTCw2JWSGou3r6fMA7zlGaD6naJWlX204Ep47PZHERKtHitLul1FEU86ErO+ULm8x8KGkXNmm6rl+GHC44lVMGaifS0GoXXamtFBwyxqfsBw/8/PBLnvw/UjMf7Djy+z0PhDWmjDOnk5kPW2KxABZ8MCOrcskSAV6U5mNIKYNPAp19voq01S6i1FajxwhjPnjAceKaUTH3hn0XXedcUTEYw3xMa6oVdb/7+iVbuPrytYPu30oCxqXJ7h0+36kbVIIqMi2i7iPT4KMTXHvttZicnBT/9u7d25XP5ZOQWkarg6oLUXu78AWSJpJllVLgOUBvMgb4CwHddI5ieiOCDw3zwSelrF1OdSZjlDKiye6pY8lKbQE/YDnSDj7CFPhxzEdNU2o7Uilh5agXnOnYDzpvsuCUl9pm4/MR16ODQwhOWVNB3+eDAgHf50NtEKdOLNyvQpt2YWMigzHAZyR0XijcqTRccCoHLfS96H5IxnyQXoQtPFK1C9N8sPPBd6s6tkf8fTlc8zHdRYfTMJ8PX6gcwnxIx8UKCHMrLFXWENoJpvmI9PlI39k2WW+XdD4fdZ29eozm45ks+Dhu+bDvJxTyXXx2pYNqF41mDwhuvHTsXb3pmxgG0y5RglN/vDyApA1rlL267vciILXmIwrr168HABw8eBAbNmwQjx88eBBnnnmm9m+q1Sqq1ar2uTzBVe9qJYsOUu8WjeBU5/MxPlzG9EJDes5rSqSn7ehCKoUxH3VZcEpQc7/Nlosv3fc4VoxW8NJnrwXgGfD8052PYK7ehGNZ+NXnbcJzNoxrv6sKbq9OOzKRdmlPWBTvxGk+AH9RODrrpV3UjrYEX3AaXWqrTtTHLR/G4ZkaHj8yi1M2et/x/7v3cfz0iUnsn5yT3htQmA+u+ah7fXnIxTBN2iWsZ40OtAMSJmOOHdB8eNUuCvPR/g4qw0Ptvuk7AEraJVTz4Y2D5jEeoLXcJIJT2rGqmo+2YFUwaPLfUdlwrdEKsH6ATI3TmKbn6xLbQfO26/q269FdbeXv0Gq5mF7g6ar4RfLA5Dy+fP8+vO7szVgxKrORD+ybxF0PP403nbdVm2sPLbWNEZxGaT7KzBm30WpJNuXjgvmI0nx04HCa2ucjieA0eAx42TfXL9D1feIaP/jYtGIYIxUHs7VmYAOxc+9R3PfoETxznfd6bbVLQpMxlelQN16cXa04thDZB9IuCYSuYWmXLStH8NjhWenYS43vqiVMLzQwNV/HfL2JT93+MA63592SbeGPLzkl8rvmiUyDj61bt2L9+vX4zne+I4KNqakp3H333Xjb296W5UctGjrhGv2ug1rtkiTtQhcn15EcW2gIZkJNu5zUjt4puBATSfuipMVJ1XyUGU0PAPsn53DVv/wIoxUHP/mzi2HbFm647SHc+P1HxGt+cWAan/2dc7TfVUVLUJSWSPlQX5cRJXCI03wA/qJAi2ZYakLQ9gkdTgkbJobwk32TONg2Pjs4NY//8a8/kl6zggVw3KCNB5Wu630G0dFp0i4dmYxJPh9KtYttY1V7gaOflZDggzMfOvHlRPu7rx2rim7KQNB/oywFH5z50E+SXOAIBM9fWLULAKwfH8Jjh2exfLjSfo9gcAj4aRf1O3u7Rge1ZksEJbrgI0zzMVNrgG8ek1S7/P13H8bf37EHlgW89SUnSc994Gs/ww/2HMYz143hJc9aE/jbYKl+O+0Sc92oAknL8gKQRsuF1IyyyapdHBvr2oaAasqWo5PeLnxjEFrtklLzUdexErzLdbMFx5aZjYnhMjavHMbew3M4cc2yQEk/4U+/8gB+9Pgkfv+CkwKfkdhkbI4KBmI0Hzx4KtnAgqz5UPVNSapdbMsb88RwGdPzdZy4ZhR37H5KYj5447vjVgzjFwemMTVXx9d+vB9/+a1f+uMr2f0VfBw7dgy7d+8Wv+/Zswc7d+7EypUrsWXLFrzrXe/C//pf/wvPfOYzsXXrVrz3ve/Fxo0b8apXvSrLcS8atGAdm5cbcYWmXRR2hBYX2/KicZo8eG8Quhj5ez5x1NNGTAyXA/XaZ2yawHW/9lyc0mYkVOZjXjAf8gTiKGZDB9r6i5laE4emF7B+Yki0X372ujHsOjiNo0zsGQfOfLx623FouS4uOsVjudQJPh3z0U67hIjgdK2oOXTVLt7v7Y6q7fNAO69qycbvvHgrtq5ehmeuGxOv51VFOkGbbiLLqqstEEy78B0tV/6ffcJK7HjN6Xje8Su8v6Nql/n4ahfueXHc8mF8/PXbcNzyIenv1MoJHtC2mOaD/ArU1uzCGdUmlb+cp6fbTNfS/a9fdyYeOzyLLatGpGOijot27mrwIe6Rmn/+9KW27eBDYTZU0W4S3QOVVB6ZCd5L9NyeJ49pgw86VjR/UI8UXcqLQ1caWnZsNFpNVEs2Yz78tEvZtnDFuSdg5WgFlz53Y+j3EYtgCtE63xjo1ux6M1lam6OppO8A+XqoNVsBfcpw2cHHX7cNe56awbPWjYWmXcj6fPehY95n8AAnoWif5hOV+aiWPMdZtZqF/99bO2RmJ0mlotqU8ZP//SxMzTXw0JPe9+BrGAVHZcfCmrEqfnFgGtPzDex5ynvtGZuX40XPWCUJenuB1MHHPffcg5e+9KXi96uuugoAcMUVV+DGG2/E//yf/xMzMzN4y1vegqNHj+JFL3oRvvGNb2BoaCjsLXsCmoTURVhX7dJquUraxS+1XVYtYWq+oW0aRDQcj/b3HfV6D6h26oA3Kb/2+b7g1lZuBrrRllVLcGxLcgJ0bK9Tr+sCR2b8iXnf0VmsnxgSZWgXnrIWuw5OJzL78b+/99OxLIxWS3jjuSeI59SKgjjBKcCCj/axD6OCKf8f5/MR6IirHDf6OTZUwtUXnxx4nxKvdlHtm+tNrGj/P53mIzgBhYF2ddxKXXWurDg2bNvC61+wxf87hwSn3mRIC5nOqVNdiF95RnARUicjmfmQJzhvpy0HEYLmV5wd6TyFOZwCwLYtK7Btywrxe7jJmPc9jszK9y0FRiQULdnBvif878OM/+gYztdbaLXcgD6Fg46tLlCh6yPU5r8hzx9qV9uwe0J3XEqOBdTbDCjz++EB8IrRinTf6t872c5f+h6S4DR4nx5Tgrokmg+6jsK8XujYua4rmehtW+VfQyMhbq20gaMeMDLzEZ/+APxgX2WgLcvC+FBZBDjcS6jM+ruoZfhpmA8a7wtPWg0AuOG2h7zn2Z/6wVFZbICn5utCA/fyU9fjbRfITF0vkDr4uOCCC6SyNhWWZeEDH/gAPvCBDyxqYHmjqlRcEHS04HygV4tPnY0NlaXJg/89sQBS8NG+AFQ7dR1U5oOLB6slmzUis8TPetMVOT0AePzIHM7a4orPPXG1l9pJYvZDiFo01IoCdTegA7ElgvkIUeBHOZzqnAIJjsIa6MRlYa8PK+UL/D+h5qMTwaljy2k0AIHfvfeWWYA1Y1UcnFqQmA+abHWVHypU5oOPnQsYAUj6DALfafPx0fkLq3bRj8XPh3OmRGwaZvXMx5xGYMsRVkFFEzYdQ8C773VukgQRfGgCUTrucU67Yv5IWGrraBZkbmbFr2XVdyUOlYSaB9338P4uuC6orFy6rrb+eadOx9yFeKHREqky9XzrUqWAf64o+JCqXRJUndQaLbER1c11Y0MlP/gIEZyK1BqlXRJ00+V2Bxx0L/G0C/eRog3w9HxDsO5J1p5uoOfVLr1CVZm4CbpFWZ1cvK623smmnDnRiRSEWJZna+w957/n48wIJw7qIsoXEr4z8oMP7zFOA+87Oocjs3UxUZ6welQaZxI0Qi58ILijjrNX538jNB+x1S7Bm7LedMXEowYv6iSia58tfw6fsOXjwsV3c8r/o4LwugiM4hd93+G0bTKmVC+FjV0NPiivL1e7hHteqAh8Jps8Xab5APS7NH+xkxdFtbdLEraXjok6pkpI2kXt/KxLuQDh9urEfKwd8xnaOHaLFjZdk0F6Ls5vRp0/4qqk5K62smCxzBoSer1dkgfAQIfMR4zgVK2ySDLvhI3bb9AmB5pA8Hzr+tS4rivOFZ0ffi3GpXkBOaW5TNPans9/YWkXtZw6jb26ej/YygYVYJqU4bJgoqfm6iIQ3mSCj96iqugOCDoHPjV6rjV9zccyJbXCO60OCYrX/3uajJJcALTgtNRdXdmRFlzR9bN9IfLmSvuOzInPXDNWZamg5KKylhvOHPAdh20Bowl22EHmIy74CN6UfPzq36t6CV0OmcMX9rYCJdSzIcwHiVHDkIb50JmMRbEQBFqIaUKkhbPWbImgiZw6wxZjDvX4cJ8Fj/nwj40uSBfMh+LsGPD5SOC0qLqkEui6DzAfzaTMhz7tQhVCvF9RnKiYjrFqSMbTAeFpl/bmZUgux68rqSsVuhbweuaj5ffaSehs2YlRIRec6oIPWggnmP4tKmj3Pl9/nahpPAokKkzrQiCmj28eOFNCkH0+2kFAxPenYGpZtaRllDgbomc+okzGwo8LnZMg8+H95Meea1JoPEdm60ILuCnBxrcbGNzgI0zzoUu7aOzSa4Gdi5x2qTg2s3Dnmo/OmQ++i+VsAe2AqCTx6KzMfHCdSVRL8TBwe3UVfFEbGyprxYSBv6HgI0bz4Xe11QUfrcDrCKotfVzahefJA2kX1jk1KiWjIs6vgYNXXnnjtwMTm26io8Wd5p01YxVhrkTUK40xSdpFPT6c4m+5/gIPhLNRgLwT9x6XNR86Bk2F73Ujv1akS+dUzYesiwplPsrysSbwTqVJS07p2AZ1Bf57P3Wspn2fsPlD9YBQITMf8s65WvLTda0Wrz5KNs2XFcYwCeK62pL+aPUyTyTfcuN9iHSltvx3+kxd3yKCLu2iu1911S5R338qpMyWMK7p0Mz/75mMyd+vzDY/YQgL3HUmY37axdd87D40jWbLRcWxsXpZ960tdDDBx0x8TlKdXLy0i8x8qPbI1bKDitM2NGIXVSrNhyNfWDSpqWkXunhpET3MdoX7jszhcfaZNPkmEX4RWlFplwoPPpJJiITgdCZO82GFjlVM0iU7EPCoLappslPdIMXrJZMxfYAxn+C64Kg39BOoDupCU0rIfKjvPVIpYazq53i9MYZ7XqhQtRgl5hvhuq7UvEpX/lxXFjs1qArr7aKDrscLEH7fptV88LQEIHcqFTbjMcGHSLuougLl73Tshzp/BBxOEzEfduBnmM9HEiSh/8O+BxDCfLSPK1/w4uYees8A86EEH1F6JiE4jdFppfX5CLNWJ4QzH0xwqmjVxHGP1HwExwuwtIsbzXzsOjgNANi4fChSRN1NDHDw4V2c04rnvS4doU4uXHBKLqZC88Esv1XmY6Hhlb4C6ZkPvvMeLjtSeanYAbV/qpoPCj42LR8Wk29DmXyjoCqtOfiNn6TShcYP+Mc+TvOho/jFcdYs7mIH05KDj3Dmww/yAg6K7cWb+z5Q6iqKlu+ksZw//qDdvC6I4Wp6wDuuYyzHC7D28h1oPmzLErbQTTdB2kWp8Ak0los5DxxqfyOCSDUp9y1do3MxAlse6PLvwDuVpk67RDjhAnrdh0jbKvNHXKmtlvlgAl9fgBj/XsH3jtc8hH0PQJ+uoYVw9ZgffMSxrs2QzYK6GZmNYD507JUu+JBLl9vfPyIICDMYI8itAoKBoi7t4jNO4cclzB1YnG+d5mPI13zQxrUoYlNggIOPsAVPF5WrFy33+QhoPsh7omQHxG3722rjobItLMCjwBdFPgav2iXYq4MmbK75mK018bMnpgB4Fx7/3kkrXqKqXfiilsRgjMbPsRjNh84jpKTQmHHCO55zDTIf7V1WzQ/8aGccRcvHdSflCAQfGuZDl7dXA5vhisNK64j58NmyOKiaD8f2WQq11FZ3n/jMhyo4badd3HAGTYXv/qjXfKhoqJqPkGCLX/88HTrNOpWmZT4CNvyKQVki5kMptQ27Vm1psVQ0HyVbOl7CoC5ptUtJTvPGoaXogKI0H8uHy+I7xenNaPF3VA2Sshmh464LrIcTpl0ku3oqh40Ijvy+XPqNliQ4VRxOAb3gNEm6K6xSTMd8TLFS20ALj4LoPYABDj7CFjxt2iXAfDRF3k51MfXLP52AvsJXG48k0kbQJN1o+S6sluWNXe7KGi44BTxLYcC78PjfJa14iRScKpqPJFAXhlCTMeGQGbwpaey6xShQapuG+VAmANXLYaTiJOqB4ZdMJlhoS+qib2vSLhrNh6ajqV9aR8xHQzwXB9Xnw7EsP/hoxVe7qFVF4vwp1S5J1kJRwRWSdlGhtiAIY3q4mJff6z6dzjQfEeeXi0qD5ZzysdH2GFLmD1pQ4/xhSprgg/fS4Qs27XbLCZgm7/3ihY/Sd1CYjqhql7Ghsj8fxsw7usZyQPB6itIzDWsCSD3zwdPXMmOqQ5jBGEHqU6QRnNZYqXDAXj1C6BrGfKh2DIDcuDTYvHQERcHgBh/KgifaiWtuDO48CbTTLswkCPAnjxpLuwiRUfuxx4+EG4zpwDUffOdtWZY0flHtQn4RKlPT9Ck3r2+IJT0eB95YTkVHaZcA8xGyS41Iu4QZjAHBnYQwLQqb0CNKbWnx5mLfJN0/U3W1DaRYrMCiG+XzQRiu8LQLMR/J0y66fDI9pJ4D3QKlMkxqM7BOql0CgtOQ4MMXZccLbHVeH3xHO5QguOSBixqkJNF8BASn9ZbUvC9c88E2HUKwSMGezJilZT5KCTQPHOo1oBec+guhOO4R789LusPs/mnujdIzDZeDc6GW+dCajEVpPvTW6gRdh2aAb6R0mo/wTRYhrC8SHaOWVvOhYT5M2qX3UBe85RordIJo6Dbsm4YF6vTrGs2HknZJIzYF5B08OTfSpKr3+ZBvVlXVTEFPmMW0Dq7r+kLBmLRLUsGpujCEp13CgyQau26SDjIf7XRADPPRaLUClKvKfAxXHN9DILLaJYXgVGOSpqYbonw+CCMVR+x0iPlIshjzz5V+tyxxztUJOY3Ph+pwmoT1E5S06vQaw3xEdbQlUJk9v9c5VT2SILicjRAyqn1h9MyHWu3SlI5pEs2HMHMr+cebn0MyRwwrMVchgvaEaRc19aZnPvx0VpJ5h3+2zuUXYGmX9oZMm3bR3KO6YDJ9tUty5oOnXKM1H/78E4awvkjETGp9PpjJGMGkXQoAdRKjZm5RaRd6TY01lgv1+Sg7LPhoMx8pymwB/+ZzXWBmQd7B8uBJlNoqi8dzNoyJ/08M+1FwWHMtHfhFrWM++K4jicEYEJwsQgWnEY3luJ+KCtWvIHGpbTNYaivy+mwR962bw5uPpepqqxGXhin95dfJrxkqO76pUHvSn2dBUxz0zIcs8iNEaT58DYKcQ6dLKZHDaSjzEaL5aMkixKGI70vHkt/r02zCThJc8oCjoQiV6ZjT52iZD41mrJYg+FC72gL+9csFp944krNv3vvoz3UY1ABUy3ywdJYu6FPBF/6A70xJDoQpyItMu7BzqJ4XQL4Wk/R2SaX54L1p2NiJ4Qg2louqdgkRnBLzwYY8xQK+0UoJ/E+KYjAGDHDwoS5a1KwtSnBKr1loNANpl0abMpV9PuQcZxqDMUCeaI4tyLn7ihRVy2kXAjWoA+SAJ43XBxcy6ZgPOe3SKfMRba8e5fOh+9ugyVg0C0HHud4KdpycV5gPKe1SCz9+aRrLqa9xbCsQWOh2rwHBqaT5aLR3Wd53HynHnxudh4ATwnzoTcbk4xwwGeug2iVQahuiD1I1H1Hf1/f60DMfSdJqamCi0xZsbbsJ75+cC2WORNq2IbNuSRxO1Z1z2bGlVJnfETkt85Es+EjEfCz4aQpd0KeCf3ZY2oU+N4rlGtacQ/W8ALKoNYnZVxrNh85kjAtO/Xk7Pt0VlvrmukB1jOPDJdi2Ja4x2wLWTxSnx9oABx9haZeI4INeU28xwakf6fIqmGrZDuQ40xiMAfKkQQ2adGkXVXBKeA4PPljAo5t8w8DnoTjBadpSWzGeWJOx4GTAj7MKmkSais9HKPPBtDXUcZIcGecU5mO47GgntrDxJdJ8aBxaVfGnNvhQ/m6kIpfa8vENVeLHoU27kOZDyUfr0y5yeitgr56m2iWEzYvTfJD+Yjji++rof65NCGtKxhEIPjT0/uaVnsC75QIHJufF867r913h/Z+42DQsNcUXS5X5oO9Fv9P3y8tkTL0Gmi034F7KzduSeAzxAEYNyivK9ZSk2kV3Xk5cMyrM+HQ+H1lpPrTVLhrBaaLeLm4088FPmTpGYmPWjQ8lLrvuBoozki5DncQmRiI0H+2LdmIkXPNBf8vTATy90Wy5YgJKq/kAgGPtHYQu7aKqpgGvKuZZrG28zHzE70AInPnQ0eWdaD7UySJsNxvVWC5V2qUl7zSCr/cnNZoYVC8PXbWLWlLJ4ZfaJtc38PEHql0SaD6Gylzz0RALsW0lC4J0zActgkk0H6qwVzUZS1Xt4sgLKyGMJaNA02++GMF8EPPHzKroGhsbKoe2Y+cIlNdqhI0jlRI2Lvd2mjz1woNpUS3XaCaqkNItlipLROcxjcU/f5+kPh++rsl/f5X90Go+IjY9/NioewWRhhVpl6hql2AASUzJ+FAZ69qtCHSmbVHBVxzzESY45WMPMxmLEuKKDuaBe9T7SayitwbRHFZuj9X7WSS9BzDAwUdA8zHcTqlEVLvQa3hvl+GyI1XB8BJQvsM6ODWPRstFybak5lVR4BcaXfR0U2lNxtgksKxSwuaV/sXGUz3qohAFPpnoDEKrJVtMEkk1H+pkEbYwJjEZSyQ4FZqPeBGfmKCI+agHmY84Wp7vbDsxGXOcdF1tCVK1y3ydBUylRCJPdaF3bEsEnIG0i+baCetq21naRZ6YCaGltorJWJTgtKIwH3RvWRYwVk2v+VBfy/VBtNHgolN+PY+2Ny/1pisEolHeMJw1cpjWg/9M0pRQhyQ7cA66BoZYQMj/1nVd37yNl9omYD7KjhW4ZtXqqbRpF9KIDLPzoitdjip5jdN8LItJu3RqMhZWKaYKTnkjPxoLbaSKVOkCAMm2qksQ6iS2gliN9gXw1R89gU/d/jD+z+VniQuYXgP4F3W5ZIn29gv1llLt4t9stPPZsHwo0eQLyBfatJJ2kWrIFfoV8G6OsaEyxodKmJpv6DUfCapduHOebhKzLAvDZQcztWZye3VV8xGyUNCO6oF9k3jBB78tPUe7Ht1OOFBqqyyKKvgCJ1iuYXIGjKp2aeGBfZP4gy/ej+n5BiwL+O/nHI/fe8lJ/lg6EZzqmA+tz4f8mpGKLzidnm/44ssEZbaAvmOmn3ZRNR/esb36X3+ERsvFR197RqCFu0pj06WUptoladpF1XxEVrsoO3DanS+rejnyJGk1lfXi4mOeDqD7TmI+2LHkzCnpuqKocd1iqTaYC2ol0jEfSdMuFEQNVRzhOMtLPmdrTXFexoZKUtA3OVvHFZ/+AZ5oH5dfOXEV/vp1Z4Zaq/Pv4Ve7hIupdQEkabSGK955uffRI7LPRwrmIyzt4rQ1FscWGkpXWyY4VTYmajsIHSguCTSWU0pteeM7es4wHwWDuuBNsEoW13Xx/937OH6ybxLf/OkBMYlPjAQvuLIjl9TydAD3ExBltikuAIvl3J885tmy00UvMx/BtAsFAmefsBIVx8ZzNy/3v3uaahc3nAYlnLJxHMuqJRy/alT/AgVJNR8nrVmGkm2h0XJxaHpB+kcT9cnrxwJ/x/tbeD+TVbsA/sJBwYda7TJcdlgpZgNf+/F+PPTkDA5NL+Dg1AL+712PSixBR8yHndBeXSM4XTHqjfupYwssYEp2mwcoXVZqG/D5aLQws9DAv977OL58/z5MzTUCQjpVcNoMcWnU4ZnrxmBZwLPXyedXDTZpyHSOucNwGFTmj87xaDtVQwtXlM9HkPloBZ4bqTii3J0b//EFlrOAT7ZbL+hatRMcds4pWHj2ek/bRfdCksBVB07/x3WeBfzvwe9nznzMLPiMEu9HtdBs4e49T2Pn3qPifv7qj57A0dk6Sy+EX+9q2kUXfHDdjqthxc7euhIA8My1ywLfPyrtRN9ptBoe3J523DhGKo7EPNPYeVWTynxE2bqHsYaOwnxwdodw+nETALy1oEgwzEcbE4xGW2i0hGhn39E5KVdoWZDaMlcEw1H3LqwQnw9fbJrOYa5k26g1W3jsadmgjE/Cuj4YFKTc8IbnYXq+Idm560yWwuA3lQvfsX72d87BfK0lHcMoJLVX37xyBHf90ctwcGpe+/xQ2cGJq4MBT1nZwflahPTMR5zPx7EF77xeduZGfGXnE5ieb0jHtROfj7JjB/Q7usAp4HBa8XfaTx2rie7GSSpdAJ3mw99pqaLferMV8LrwG5nJkyqxJGnSLmdtWYF7/vjCQBsCVR+0rOoxe9TBOK4lPeAHRTRetSxa145dRVQzOR6o0oIiWdOzIK3UZpdaLvDwkzMAIHQiOuh6u7z5vBNw2ZkbRaATSLskZD54oNxsubF/R4s0D6B452O/8qhtjCiYj6ZIx5y1ZTl27j2Kluu9n/DkiRBYi662ESwXsX3NlpcCrZQswVaNVBz893O24OWnrsca1nMmrrdNk9nJD4VojwDgn958DuZqTWmzyt1ZVW1PkoZ2YWJtX3CqVPaxa+CdL3sGfvOcLdJ3LQIGNvgo2ZYUSKwY8Se5hUZLULH7jsxJ0WS1ZEstsyuOLe2kRNql7Nurt1zgkae8iSVt3s2xLaAJPHpY/nudyRhf6Eh4WHaCfWQ6KbWNWjCqJUeb/ghDxbHFhAtEe2GsXlZN3QLaUXLXqu134PXshp5jgSbgV09wipe3636qzUids3UVvrLzCczVm5it+0LPJAutyo5wC3BALzYF5PNNotLKsI3RipcGe+iQd81EeV5wqBO+bYWnXerNllJJ4DMfwu5bCXLTVLsAwCrNeVeP1dhQGVPzjcQpNiAoXKwri0EnpbbcWIwHqm77dZwR4AZ0lmWh0p5THn7yGIBodlQnkLQsS7pHOmc+/Nc1Wi7ibmk6ftWSLeZS/j1VZoLPOzS/blg+jJ/tn8J83WME/HtVE3wo1S5JutoC3rmqlGwpHWZZVmAxjuttw++BqDmrwooNCNydVS3nT1LiGybW9n0+5LnOljYvwe9aBAxs2oVH4oCXprDYREuR+b6jc6I513A5uMgG0y7c58N//4fbwcemlHk3ugmfaDelo4mJX9x0AfKJKarPSieC06QLRhKQToSQJnBJAl466/0MzyMDsraBFhEK3iiQmGW7LE7pEqN1MjN0O3zMYxySGIwBwYqYsmNp6XUVfCEm233LskSA+uCh6fZzHaZd7HCH01qjJe/2603f50MRQgYFp4mGo4XKfFB6kc51nJU+EBQuqjS4rimZCpUVmdcxHxVH6+GglmHT9f+QCD7C2VEd86FCbciW1OeDvy5JxYu/g/eZOs7w8CAMkOcdbj7Gq9rE+YtIu6hdbXWaJj4mn70Mpok46DPDtBc8TR2V1tOBpyDV1gulkHuMI1RwGsJ8JD3nvcTABh+AvOiNVErMBKfpMx8s7TJccaQFhXa2vm9GS+q2yhcHsatJy3woC6mO+VC72gLRhl+pNB8pqPI04KWQaW/kOKg3c0NTEhj4m/YxnFXTLu3f5xmVTpPX1HwDh9p5+i0rRzDanmSfnllof17C4CPAfNjSzj1sIuF/x48nBagPHvKuuZGIslP1c+XfLZZ2CQpO1TLGIPMh/22YS2MaqMwHN/nzxhVO2xNU4aK6E+0o7aKxWx8uO9pFWa12oOt/TwJ2VGI+Qqu35MfT+nwAyUSnNcbgqDorQL5nADndS/MrNx+rN91IfVZYV9uwYEIVDs9FOKIC8ZoP2qzpNFlxoA1GjQlOiYFLYu4WtgkUmg8lxZz1fJ0HBjz48L8+F0QdW2iI1MrR2bqg1oeZZTrgT1YUxNQUzYdtW+LGOjLr3Wxp7W3Vnc768SHpM+lx9bVRzEcSsx9CVFO5xYCLIIcS7syTwlEmfH9CC/8cOna04Eww07lmy5UoZEpjPPzkMbiuN/5VoxVxzJ8m5iPhBKW+zjMZC9Lrgb8r8eDD//+mFd7OeXc7+EjS0RbQuyeKtIvG54OnGmZrzcCiqjYCEz2CFnEt8caIgF9OqDIfUcde1Q6QgRqN10+rhfu4BPq5hGg+hI5Ao/kQ80c5+RzBA4tQ5kN5POl16LRT0UAy5kOkq0q236JAl3ah4IOZG/oW4CWJIWtGePLw5myA7Keigy8cVposhgQfcb1tfBuF9PMVZ204Y8R/Jku7RGs+iCFJWl7dSxR/hDmCU7hDZUdUwDw1Lbek5x4bOsaB2wartt98gbAsYMNEB5qPNtaPD4mIm49dZ6+utlLmSKP5aIU46y0WfEGsONmmXdRJRO22qoPPlnh/w0vp5utNaZdF1S50XWxcPgzLssQxT8t8BBxOla62Ye/Dvw8/nrRzpvElLrXV0PWC+dA4nKqpBpVhEpqPpjwxLjaQ5cdLZT6iBIsENR2k0uBJfD4CaRcd88HSLk22q1U1JmpwkFzzESKg7lBw6r1nMFgKAz9uatUREEy7yJoPSm+WtaxAVKltQHAaUs01rDBYajCkIi79UWt6f580ncrB0y41Ne2Sxl491OfD+z2usq9IGOjgg9/0nPkgpkOF9xq+aMqBwEK9Gei2yoOVtWPV1Bcuj2Alrw42dn2pbQLNRwKfD7qoc0275MR8JC21BYLUND9+c/UmE7eVAtU6dF4CzEdSzYdWcBqv+YhLuxCSdLQFYhrLNeXF1hOcyuWl9Za86/J3e97fZpF2Afx7qlryU5ukJ6lHaAYIqubDd6NV0y7h9wctZKquANAzHzyNoXY85nOKbUX339A1llOhMktp8v+iuVoSzYdgcPw0hFbzofSjWqi3JOZDLMxtlhEI87VR0i4xPjaqdmdeMCXpe0kB/vXQEfPBql3q7Lh5nxstdAXCy9RVn49mguC7KBjo4IPf9ENlX88RFnwMl2XNh5qzlTQfmuCjE5MXPofq+rMA/uSiK7XVoRCaDzb+rDUfZWXCV0tAdVAn6GrZFumguVqTpV3swM6JaHLS2TzVDj6Smjupr1NLbcOZDxZ8sOOpagaSdLQF9B4CjsIIERYactrFYz4UzYdCJ6fx+YgC3bfDFUcEMmlYLpXm9gWg3t/Q+a01W6GLMC18VEmmlh3T+NQmh977yjtofi+vj+m/IZuMhWg+eLM0O+gUGoUklRcEnj5QU51A0ASMzzvcrItrOaJNxiholJt4xqVdRH+mGI1InMlYVDPLOEiCUyXtQucxKg0e6vPRvgTUtKNhPgoOuukrJe/moYuKzH5UDCmaD6ILueZDvUCrEh2ezuMDiGA+ND4ffNKKchvl441DVlS5ijyrXQL26kmYD015Ihes8TI9dTEnjQUxH4cXLTiVBW1hO1fedZYfT7WiKmnaRVvtQpqPQKmtK6ddInw+sqx2Afz7dkQSdLZZDGJfIj5EFS6qWhV+vMLKbelxCj5kG29/h13S7GpVjYm0QYnRhPFrOGx3m+Q1YfB34Qk0H+x8R1a7tH1m+LxDPkpjQ2VJgxNVrcGvJ37tJRWcxjn+8nOlM1mL6icVBznAks+/7hpRIRxOQ9IudG+Zapc+QVWhWel3XfBhW23jMEmrEGQ+1G6rPLXTCfPBJxKJ+dD4fEjMR4ThV6rGcjkxH3y30kkONQplR54IBRWZIu1SKdlijHO1JqNsS4HJjs6rr/lIl3ZRc/5lW2Y+kpSN8uO5elk1kFJMAl0ZnyXSLkrwoZTaztaaoieGavvdaLlotVxxPtLsxHWg63eo4gQCTdVlVQdVuFgLpEF8DUNo8KEwH2ogBniLnBgfO36qxoQH33FzhM5ePeo1YRUx4e8fvfvn4FVC6nkAOPMRnCenWNt3zmioFv0cPEjh5yUsGOANAlsSUxLCfLBjpQsE1IZwacBTTmEOp0lMxsLSLvS80Xz0CSpE3yqlYGRlzs8f+ShoBachPh+ATKl20tiHTyR8YqpIwUf7IpbSLuHMRyVN2kUIThMOOCFo96FWdmQBP1Wg7IZTMR+WSLvM1pqSz0dA8yHSLp1Vu9i2bCrmMR/+72rXW3WcgLybs21LcslMWu0SaCzH0y4akzGeauCltpTf5tdordkS1S6LPd/0vmopq9fS3XtN1KKrChfVUlvuQxMmOlWZDzoWzZbvYDlSKfmLua7UVnOc0jEf+u8oiVLTaswSdFgl8CBKZaCAcM3HfL0ZUmrbitzs8P4oXFcTpiHinW3n2VwXlobk95wu+OJ9u9KCrjkeNNHxSFLtEp52UTdaJvjoC1TZJAaAaT68xeMEZt2tGuXw/3MVN/f54J8BpDcYA6KYD1ZqK+zVedolG+ZDXPQZp11UtilLqGV/VAPvRAQDuvJEYhOm5v2eE8NlJ2CtrApOSTOUNO2ivrbkWIkWGSDoTSHGxK6VTjUfto3QUtuasvuUql0UwSngLRhZpfDo2h+pOJKbLRcKRqUbVOGiWvoI+ALeuLTLKkq7KLoCoB0cRZqMUdqWs6PRqVn+vZL0KkpLv6vW81HgNuE+w6NjPijt4r331HxDLLRjQyURINUavr26jrni5apqJY0OPO3CA+Uwa3R+bKM6aS9G80G9Yfhjvi4onvmIayyXxFagKCj+CHOECD6UUjBaPJ6zYVy8VhVNAYymZb4ZAc0Hp1QzZD6kcVC1C7t5IjUf7ZsySbWLzq43C4jjmXBXngZqd84kltu6Rm40eR1hTcFI5EisSMm2sK7tvUJpF7oG0uw6y4pIUApGIsYtXDlDKnCANMxHUHAaajLWaEnlpbP1JqPMgxqketPNvNplqMxLWV2JXYgK/DjN741NDgYAP1UQyny0H1+hpF3466slvRYiaDKWfI6Qu7DGaz7SBMBAsrJPAk8fJPP5kOdX2/Ka+XFGwxdMBsfNewXFlc0CsuDUr4yxQ68/Ke2iCz7q8sYyDXhjOf8x+T6JCvjC9FJqY7lWApa3KBjw4ENJu7QvqqfbN8cJq0bEIuOnZvyLvazsXHjaJatqF5pIVi+rSNS63NXWew1dcJWSHSkyrCo7vyjkxXwMlfNkPuSdRCeC00rJFmZEpOFwbEucc7oe1k8MBVpXi/dIIfZT02hJFxCdSBKQd9BJgw91UpYdToM+H1LapdYM7Fq5ILbebLG8daLhhIIzlnzHzReMJAGbMBlrapiPhGmXVUraZb4upwN01SMBjUk5+RyRxF5d1gulO9g6U7Qw8CBKp/nwj4U8F9L8uqxags0CbZ520W0U+OvUShodePAxX48PVmx2vWo1H015bk8DdSPCm0UmSXWFbQLp95YLuG60Q2zRkPnM32w28d73vhdbt27F8PAwTjrpJPz5n/95ohbN3UYlwHx4v9N1Nz5Uxsb2ZKBSh97fq7nMVkCURD+Xj5QxGtEqOww0GaiTEtcTqCZjUWW2/Duk0XxkLzgNprGyAh2HlusFT4lKbTUGW2QmRu3QqTsn4As8+XlRdTZpdp38fJYcK/ECkiTtklRwCgQXN9oM6qpdAr1dNB4b3FMjTVfbKPDvzLUGfIGP+gzV4ZQM1GTH2Oi0y6wQnFal16nN1KKYDzFHpBClJ7FX5wtU2h1wkg6rBH7ctKW2zBsH0MyvbVE8ZzTqEX2Y+HlLEkzo0i5xrQaijMZ8D6fO0y78d5pLVGsAHcKqWPim0NM9xYvri4LMu9p++MMfxic/+Ul85jOfwamnnop77rkHb3rTmzAxMYF3vvOdWX/coqBqPtSIdny4jOOWD+PhJ2cC0TvAc7bkeFkPvDf97IT1AHyhp0rHltq7jWbLDTAfUWJTIK3JmD7XuFiEHfMswCeuRssVO/KkzAdNDLSAUPDBbZmJEePnJcB8pEm7KNVLct4+nvkIq8BRxx0Hx7ak3ZOadqmWbCy0O3PKXW2DglNvfBbm6iQ4zaraxff54Gp/LoCM+gy6bwMmYxrfFF1zOS4qXTHa7n4smpfJi6Iun6/6PBDzsWq0EqvPoe9rWeHpqyQeMWEoKaxQFPjx1gUf5AMzFLLRoPuFBxVqKoKDm5GpQZ4OIzztUvfTLlEoO971nbXgVBd8iM8sBa8RFWF6KX4NNPuM+cg8+Pj+97+Pyy67DJdccgkA4IQTTsAXvvAF/OAHP8j6oxYNuulVzQdhbKgkDKR0i6Vap0+dZ/l70c9Og48w5oM+d7bWFK8R9H9EmS0fU5TgdP/kHFaOVvxeARk75unSWFmB58KpCgKIq3YJMkmUynjkaa/hF1/g6ZrhIuKJ4c6ZD1lwasvVLqX4hTTM+Ez3XBRKtgUqNLeZ5oMW2+GKI0rKVeZDLOI8kJM8HLzHFjsxcs0Hz3k3msmu1UDaRVNCScfsFwemsGXlCE47bkKMm5fVrmozH7QYqukArc+HojERc0QCTZiuj1PYa/h3TQq1zcDMQgOztabUkn3v4VlsXD6MBVbWrDNToy6yIyH3Om2SuJCU/q81GWM27HGGYfy5uXozUZoG4OdLJzhdhM+H2rlaU61Yb3r+IpNtD5TlIxXxmjC9FD9OrdaA+3y88IUvxHe+8x388pe/BAD86Ec/wh133IHt27dn/VGLxhBTzQMa5mOoLAykBHXILnY13/6TfZMAPCGVv4AFd8hpQDeDLvigz6ULm6LpOOaDd5fUYe/hWZz3oZvx+5+9zze3ybrapdod5qPO6PioqhGpl0p7TNSl9v7HjgKQ0xci7RLBfHQafDhK6W2kVbiSOiSsnxgSlSpp0i6qfbdatszdP2Wfj4ag0/lx9pvLuZlVu9B1P1JxRKVXg1H2cRMvp/kBvTfISDtFev0tD+Gy67+HP//az8RznA1ZMdLuflxvwnVdzNXbfaDaY3Q0lLqqMRFzRIINiq6SSMViNB90PdHi+9q/vRMv+cgtwg79tl8+iRdfdws+9PWfS43ldMzHvLLgq/e6YD6Y4DQqbSBVu9Tk46wDXSczjPkYKcelXegzwn0+OtkwqeeLX2v8/wuNFi7+2O246K9ul1JfYfeOlHaRmI/s59WskTnz8Yd/+IeYmprCySefDMdx0Gw28cEPfhCXX3659vULCwtYWPBNvaamprIeUii2n74edz38NF69bRMA3c1RwiWnb8Btv3wSv/b84GvoRj3/matx9gkrRInuxaeuF7TvK8/ciJ8fmMavnrWpozG+7uzNmKs18fLTNgSe++0XbcWPHz+KZ6xZBgB48bNW49wTV+Hyc7ZEvidNdmGajz1PzaDlArufPJZb3fh5J63Gec9YhV97XmfHJQo8F95sJmU+5LQLAFx6xkbctedpzCw0YVnAFS88Qbzm8nO2wLEsXPicdeIxVWvTqeDU20nKGpAwXH7O8aiUbJz3jNXS42XHxu9f8Aw8engWW1Ymd9YtKUGQX2rrlxoDCKRdyC5bHS93dqQyw6Slv2G47MyN2HVwGpecvhF37H4SgMx8xAV9ga62mrTLrz9vE3YfPIbDszU8Ob2Ah548Jp7jegP6Lq7rLRzU70bVfMhpF1ljctEp63Hrridx+TnHx373zSuHcekZG7F1Vfg5lSpiUpuMyczH7kPHsNBo4dDUPMaHyni4fRzuf+yoqKgrM6aOf8/ZutzYUK0Soeownfun7prndv0Hp7w1Y/VYJfA6wuo2W3Noat6vdom59iqRzEfnJmOezT18HxqF6SQ8Ob0gvtvRuTpWL/O+QxjzwU8vZ3kX6yLcDWQefPzLv/wLPve5z+Hzn/88Tj31VOzcuRPvete7sHHjRlxxxRWB1+/YsQPvf//7sx5GIpy8fhz//Hvnit/Vi2p8uIwTVo/iX0JeQxfQ2vEh/OtbX6j9jOcdv1L6+7R4+WkbtIEHAFz50mdIv2+YGMYX3vIrse9JXWTD0i70+GytmZu9+orRCj73O/Fj7QQ2u9E95qO9m4pYxOUSRu//Z2xejq+948Xa11925nG47MzjpMeGyl5pJe0+0kxSPFBRTcaiFpBXbTsOr9p2nPa5/3HxsxN/Pv9sgm0xh9OGbE2tCk7JLlsdb4WxbFOsk+li8PwT/HvqzoefBiD7fKRNu6gCUAC44NlrccGz1+IbD+zHWz97X2jvFr7z9noAyTtyXgpMUDUmz1i7LPEcYVkWPvH6bZGvWVS1Cyv7dF3fFVQtS953dA4ntTc91ZIt7h+5t4vsKFp11LRLW3AqHGf54qnRfLCgcd/ROQDRviiUEt13dI6ZBEbfk1G9bRaTdrEsr6pHl+Lj5+vIrF/WPyUFH95j6iaQb1K4uL4fmI/MR3j11VfjD//wD/G6170Op59+Ot7whjfg3e9+N3bs2KF9/bXXXovJyUnxb+/evVkPKTF0mo/ga4KC036D6MIbGnz4XSD9iLs7Y8sKqvMlkEJw2mEqyLIsaWHtWPMRsFfv3nWmVrs4Sqkt7ejrjXTMR73ZEoLsKA+aTsfbZMFHLPPB6HtvbOGMCQVbqrgWIBMxv7Mu737sC06Di5ku2MkSjsOvnXSfwXu78NJPP1DzvsfBqXnMtAMt3ttFX2obwny0rwPucEp/H2Uy1mi52Ht4FkB0Opuem55v4MkpT48XW+0SUe1DAv1Ou3Bzkalcrej//2nmKTTF7qlQwSn7tem6ojqxHzQfmTMfs7OzsFWbZsdBK0TJW61WUa1Wtc91G8GbI7hDk30++mxFboMCKI+qbgUmKJqU5+rN3NIueaNk26g3vfJPf0JLqPlYxGI/PlQS1TGdBB9U/6/TTXQDkubD8kttVc3HQrMF+POktOjIKSw/n0/sSFwpeCfjbbRaic4z4GukAoJTzd/RYiX1blG0DMMVB7W5ltSAcCSi1JY7g+YB3fFP/rd+YMY1YRSI0Ial5QKPPe0FALqutq7r+iwQVbsox5cCdc6O0aKv72rrP7bnKU8EHqWTGamUsGKkjCOzdexup4vimiyKstdIn4/O0oZlTVAO+OnNlisbGvLqybC0i2X5f9tipbb9MF9nHnxceuml+OAHP4gtW7bg1FNPxf3334+PfvSjePOb35z1R2UOmdXQG3XJXW37Nfjwv1dNE3zQBNNouYIFyVpwmjf4Tixtqe1iFnsuOk1VaqtYLcsVC9079lLaxUag1JbuCe7bwVF25Bbu3Nnx2AK1Uc+X+UgsOBWN5cIZEwq21D42/LnhsoPJuXo77SJrC0qOfPziPi8LSNb8KSlLzi5wZrQuWCL/sadFkB2sduG9fCj4sG0LFccW39/XjHDBaXgAqWMINsUI+Y9bMewFH4e84COu8ivK8Mv3+ejsvJWlDYWSPmmnZA5z5mPOZz7EJlBzaTu2hVZ7k0XHfyCZj0984hN473vfi9///d/HoUOHsHHjRvze7/0e3ve+92X9UZmDX1Tjw/pDU1EClH4E/w4L9RZGFM3WQj1Ip/dDJM3B6VPf/Coi+OCU6CKCSn7dpAkaKKilxSJpV9usoS5caqktr5zR7Q7VxY4m3KOz9YC5VJbjbUiltsnSLnWl2kV33oXNel2TdmHMB70m6PMR1ELknnax+LWT7r7lJmMLGuZDbTAIeN+DduTN9uvma/7r+IJfKfnBh9B8aASn+sZyduD3NcuiWfPjlg/jgX1TgimJq/yKsjpfjOYD0OsFxe+2hRrktIuO+dD1p/LuUS+97PexKv58nXnwMTY2ho997GP42Mc+lvVb5w7OCIQ1ZuOvyWvyyBtUyqnubgj8sZkF74brh0iagzcc83cDEWmXrJiPKmM+UqVdLGkcsuC0N5oPXWO5pDtHAt0jZKldcexMy6vl3i7J0hlqYzldqS1B53SqBhicHZmvKWkX5vPhui4sy4rUmGQBJ4TeTwKfqXGlTYgaqHFIXW3bazZVuqh9iqolG+1LQWsyFlVqa7N5CwA2LB+K7RNEVgmqZikMUQ6vizEZAxTNh/IeXsDcxOFjXPPBgo8I4T9vLtdPzEd/rp45gV9UYdQw14V0kw7PGlEW61Lw0c7b9lvapcwWJVFqG3G+5Bb2GTEfnaRdRBDCBKhdZT5YLtqyxOQeNnnbVsyOrv077ejGhkqLdjiVP5+nXZJNvDQmujZE6WtE2qXW8FMCgeCDOWmKtIvicEqfR+8V9nlZQPaI6Uzz0WjJzIdflqxLtXHNR1svFmLqVdWwyzwNVo/ZKPDrK4kvivqaOM1HVG+bxfh8APLY1XNP89XhWc58MMFpRAktN9qLqhYqGoo/wi4iGfPRGyFg1qiySVUFf6xf0y7cHCuJFkDncNoJ+HWTSnDavq5o0nDa5cJAb6td+OIOBHd9I5WSRGWrx47cWSn4yDLl4o3XZ7iSVrvwMdabflWHLljk342CDjK4oucoCJnXpF1Uq3+gG5qPznVpZcZ8SIJTUXIbnC901S5hXWe5SaNvMuanwZoRPh98fEDC4EPRhMSlXSKrXSj46LDahbuchgXpsuYjyHzoNoG2YT76H/yiCtN8LIVqF8C/4fVpF58NIWOoxbZB7zZ0pbZRaZfFWFJz8EqONDtbeq1u19pNbZEsOLWgnnanLRokDJVlr4swzQelXbIss+XjTWMyxp+vN1us+iT4dzzYmhMW6m3xraL5mGXdU2mR4+9JC0NUmicLSCnEtMwHK3vVaj50aZeS5ft8tM/BfF3PfPBrJ2Cv3mzFutRyli2Ja7QaoMSlDRNpPjq8HyXBaSDt4n1fudpFIzjVHBf/HkBfVbv07+qZA/iNwXP30ms0Dqf9iGqEy6ms+WgzH32WduFmQUl6fsi9VBah+WCLayqTMRKcco8Gjfg0b0jMh2UFJrGSbUnfa0Qx2gowHyL4aDMfGZbZ8vGmMRnj93mt4TNjuiDPsiy/R0g7+JhVLNR13VNp0eXHr5lA4JoFJNFwap8Pf/Hlc4NqyMZRcZwA8xHWe4Vv8MaE4DRY7RK2eKbpAAwEq2Hi0y4R1S6LZD7CfD4Av8RX9vnwmY9WRHdxW0q7IPR1RUP/rp45IBnzEX4B9ROE5kPT2ZY/Nr3Qn2kXznw0EvT80Nmrd4LOTcZkwSn/f6+qXbzUj6U8b0sBBrcYB4JjpR3e0zM5MR9C29NKJCwGfOEi4AWnfjCgvz5GWDULgIColH7q0i78fNKuPkpjkgUWY1BXFkFES5oHdKW24m9KlsRAAcGKIILfFNAWwRcXnMZ5tZRTMh8Tw2XRowlIUO1CvW0033Oxmg9546oE9e3zNMlSLVMa5kOXdqHz3XLdSMFu0dC/q2cO4BdV2A5tyWg+qLOt7iZrBpmPfhOc+vX6TW3Ds8DrNfbqnYAvrmlodV9wyoWmVur3WSz4YmVbVoDxKjly9cJQRU276JkPymXnxnw0XbFgJDle3Hk1rvpkqCwHH357dkf6OVtrBISWlhVcmKM0JllASiGm7e3CGEM+D6gmYxw6zYeafiLQvDOmSU/GmYzRZxE2r4jvWWRZlhSkxFa7aJxaCYutdpF9PpS0i+Y8cc1HK4LRkFKPfWQK2b+rZw7gF1XYDq0aQTH3EyKZD0a3HhPMR3fGlRUoB82/X2KTsYgW9nHoVPOhmowB/ndIaxS1GPAgkzeW44/xiXNEYT7CunfSXJ6n5iNNCWtZBKfRmg+Aazoa7Z9h1S76Vu8BA66Yz1ssFsV8SD4fyUptI6td1LRLe97h1YSitwtrAhk2t9Ixsy2vc3MS8PRMfKm4PxYVVHrcuclYlOA0+H0lzUek4NT72Wgla6JZFPTZkpIvZJOxEM1HRmZUvQaNXav5YAv2sT6tdqEdDN+pJTYZczqjVQGF+UhxfVQ1mg+RiulRtYttIZB2UTUfanM1dRJVJ9m8ql2aKTQfAFAp+dVecdUnPK3Cf4q0C2NGdCWmPjsjpy7ySrssRjzN01F8HlD74HBGw2ss54seAQRKjgl07eiqwjz9TXSpKP39uvGhxN8tFfORyOej07RLVJCuYT6Y5iOK0SB2kle7mFLbPoPMfOgnSc8+2vv/ktB8xJiMHetTzQeNl/fkiBScZsR8TAwvjvmQfDZ6Uu1C47CklAEfEx9PnOZDDdBzYz7YxJsk1UA9T7htethmwm8u5/c8AjQOpzztUg4eE7XaJUxjslg4iygbLzP9hc7ng36esGqUfQYzGWvJxyiYdmkzH5r7hAtOQ6td2t8nidiUsImlZ2KZjxCfD57S6DztEi5q181NxxYawt+jFXFcbMb+GeajTyFrPvSTpGVZ4uLr194ugP9d43w+aALqv2oXTfAR5XCalclYpz4fEaW23RScit4y7fOtzmEl25KCs9TMR8aaD2Gv3kzHfNC9S6kUIPy8D5f1aRdV8yHZq2uZDwo+8nU4la+hlNUuzDelpgk+6LGtq73gw7ba3Y+Vhmxq/xsCzTvjUlWYX+0Sdw7pmCURmxLSpV38sXDwY5FNtUv0fQIArgsca19zYY3lAMZ8GM1H/4KzGmHMB+DfQH0tOBWlttGaD0L/+Xx432++/f2oW2z46zunqjmWaSbVJNBWuyiup90AVY/QmqWed6/aJYL5UBY7dUHPmvmQqppSaT6811D7AO+x6GqXeWEypq92eWDflJj8R8r+9+Sdd4H8NR+LaUrIF18+D6hN+E5YPdJ+f/kaVatdhlTmoxyddonbuYvgIwXzkSbtQtermnbhx6LTzUm04FTe/BAzQrqPVgJ79abr+gxJH+gR+3f1zAGWZWHlSAWWBawZC29YtHLU68S2POP8dTfhm4xF+3wQ+o75UNIucTSkk1G1i2Nb4tpJo29Y0e7ux9M2dH118zoLMh9q8CEfnzifD/X3rDUfvLFcnEGVPC4KPrzJPSo4HQ6pdqHHV7Wbm+07OgfAKyPViXAbTa+/S94Op5JXTFrNh+Tzwatd5JTRs9ePAwCWj3jnk58HgKVdynKwSdf5unF/fvUrj+L7MK1of96Ja5Yl/k4nrBqFY1tYVi3Fpkx4bxsOwQDbVsdMZGTwwc3XhkuCIaSKF5/5CL4v9/mgALcfqhMzbyzX7/g/l5+FwzO1yODjr37jTDzy1AxOWD0a+pqiQzAf2moXTfDRb8yHSLvQgpRs0gEWLyT+P5efhUNTC1g7lkyNDwAvefYafPDVp+G8k1aLx/7Xq0/Dj/YexZmbly9qPGlA55kYj2C1i9wYbqjsRLJGFUWclx/z4XcvTpIOpXNMvYsqjh3ac4Y7mAL+bpR27+edtAofuOxUHJyaBwC8YOsq6RqSOu8yLUE3TMbSBjgk1A7VfLQ9Sk5cPYq/+c1t4hrnDBTge6FQV2DCFS88AauWVXDpczcGxlhrtsTiGdaV9T0XPRtnHb8Cl56xIfF3WjlawScvPwuj1fi+Qry3DQfNk4tpihhlUCkZXA6VYQF46tiCH3wkbCzXT5oPE3woOOfEVbGvOXPz8q4uCHlAaD4izHQ4+jbtkpD5kGnPxX3Xs09Ymfpvyo6Ny885Xnrs5PXjOLm9w+wWBPOhMCD8eSntUnG0qSJCgPnIS/PBe7skuFbpHFPaJYpK58yH67piQSAjwpJj443nnhD697xfCNcSdMNkLH3axRdc6jQfvH/OK1gAoTIfYb1dVo5WAseKL8S0WQgTDW9eORJ5rMNw0anrE73Or3aRmY9as22tvpjgI0JXxjc/40MlUP5fpF0S2qv3k+bDBB8DiqQ+H4S+S7u0b2ZBl8ZMwqUISnSQIKpd2uc76HBqSQvaSMVRTK3k16s7vOxNxnipLeW7k2s+SEQaxZYQ8zFf8wSlNMFH6cLkMfqsAF/Q8/IJ4inE1ILTUJ8PWfOhjj2s2mW4Er/E8IWY9DS9WjxLjIXhmBfMR+dl+HJvF/X4KcxH+2kqtxU+HzEmY0k6eBcFJvgYUCT1+SD0G/NBN+SCYD5i0i4ZCU77HfTVbYUBIajMh5p2USc99Vguy8levdHyHU4TVbsogtOoQICnXWgnaluQbLujwDvv0qIWJ4BeDPghT28yxjQfGp+PMLEsL/cEwk3G9J/pj5GCwV4tnmGN5WgTs5hUGQ9wo0zGxodLsKAyH95z2rQL9/mI8UkpEkzwMaAQ9uoxPh+EvmM+SHDaSJ926ecS6sVCbWanczhVfT7KEQJHPskuq5YyX3DlHj7JfT5UwWlUwMnTLn7KpRyrHxBjFAGSbOWe9O/TYjE+H8JkrKV2tY1uiqdqPnzmI/5ceJ4yXmkppWt6pVkos3PFITraLib4iBSc+t93rMqYj/b11ojoVtuvDqcm+BhQhJmMtVquVgfSDzQeBy2CQnAam3YJz8cOEoTgNCTtUnKCXW2Tpl3CvHOyGG9ah1O6/slHIWpHS8HHfL0pmn2lEc5KXiTkkpnjNbYYnw+52oWlXdplsKSXVe8R1efDrwiKP06W5bFptYYf8HSzpQCHMBlTNR+L7GgLRAtO+fcdH/aFsdTYM6pbrRCcsmoXo/kwKCzoJqopaRdd4AH0R+kWx2JKbfNynuwHBASnCXw+ovQyMp2cfckwZ+QWUvhn0LhmF/xqlzDwtAvl4NNoV7hxlxBs5siuLaraRfL5kAWnXCyrjj/AfIR0tQ1DtR18iPfr0WaHi4M5FmutDkQLTnkwQtUugM98CJ8PHfPBSm1FE00TfBgUFb7Ph/4mU9FvZECg2iXmC5QXMWEvJahBRyDtYgW72vI0R8BeXSohzIH5YBM6nes0XW1nak3pdx142mV6McxHy2UBUn6Lw2KqXbjnhhp88I2J+r6c3QHC7dVDP7dkAwv+771Pu4RoPhYxNyQ1GRsfYszHvOJwGmMyJnw+TPBhUFRQd15VXKoToAJ9yHwEfD7imA8TfABBrUfQZEy2Vx+pqD4f4YLTrCtdAPm8zicUFwNBe/UkgtO5GtN8pPguulLbPK8xfi2nNcTimgcefCw0WnKljp2Q+UggOOWf2+m4swJdO6rdAAnXF5N2kYOP8O+rq3aJLLVl9urNptF8GBQc1ZBqF12lC9AfOUQOuvno+8WNX+pqO8CCU95YDggGHyXHkvQKatpFXfjLeTMfUvCRoqttoNol/JzT7n2u7qddkpbZAqy3CysHzvMaK0mltmkFp7zaRS61FZoa29LY7vtBS6vlCuZD7WobhigmoJsQ1S4t1ecjW5OxQHqSMx/DLO1CzEeEyZgtMR/G58Og4KCbSNV40O+ObYldDP3eT/A1H7QgJS+1HWTBKS3cFHToql2CJmN24O8JkuA0B80H/2w/7RJ//mhc1LU5Khjwu9r6aRcyGEs0RibiFNUiXWI+0jIsvLcLnxvqTVe4m+qOFe/twhmTpGmXJF1eu4FymOYjA58Pfs7VIKakBOn07acT2KtLzEeMPX2RUPwRGuQCUWqrpl3av6v9RPot7UI7+IWkpbZO5xP2UoKq+dD6fLCJc7gs93YJCOlyZj748KisOmvB6UjbKIuX2nbCfDRbrdz7ugDqtdyp5qMlzQ08GNGNnVe7zDHGJCnzEaye6ZXgVF/tkonPR1Jh9lBZBOpTamM5XdqFBX6G+TAoPCohpba0WA9XHFQWfAV6P1zMHGk1H6VFeCMsJdAuis633uFUDj5kjYGi+SjJk2rWsCwLJdtCo+WmSrt0JDjlzEeKQKrEqPxaFwSnfKOQmvkQfUJ8JgmQ0y7a4INVXMyy8uWk80Yw7dKbDUCZpY84svH5YOelpAYf+lJb4XDaCk+7iGPvoq98PgZ3izfgCNV8NPzcJt/R9q3JmKh2McxHEgSrXVTmwxYlgxXHRqltlkXXSpTJWBq2oJMxi7RLCpMx8XsCn49Gy8XhmRqAdCkkoflgaZdcmY+IYDAO/DhQ0z1AFpzqeh9xv5X5lJUugE6AWSzmo5ZBqa3scBr+fceGyoIlrDVamK83RQlttL16q698PgZ3lh1wDAmfD0XzIehFmU7vh4uZg+82gXT26ovZ3fQ7aBL0GRD5ecf2TcaGmPKfKkIiTcZS6CTSwLfST28yRkji8wEAh6a9zrVpmA9d87s8BacSE5W2t4ukodH7fMRpPuZq3uuSVroAxRGccs0Lx0IWJmNc8+HIx4aOu2UBY9USllVKouLl6GzdH1+kz4dvw94PppCDO8sOOMLs1TnzwXcufRd8aLQKUTClth4E4xGSduG9XfiiHMZ8qK3C8wCNOazpmQ7qOY4ylis7lviMA5MUfKQwGeOltiTaLKjmI2zRqjfdGM2HH2BR2iVN8BHl+NlN0HkJ9nbJoKstZz7UxnLt476sUoLdriZaVvUC3KNzNfE6PfPh/Wy5/eVwOriz7IAjTvNRLdmSWKwfTGs41Ek0bicgd5wc3NtCOJxa8k8C13yMsI6lgvmI9PnIh/kIBpodpF0iggGeVvLt1ZMHH5LJWMF9PsKC9GbLbzSnGzv3+fD7uqQIPgrGfAQ0H/V8Bad0nng6jwLcIzM+86HVfLC0HqVn+iFNPriz7ICDIvhmy8XZH/w2LvubO3BkpuaXlJUdafLoh4uZI+2CJDMf/fVds0TA50OTdqGJkwentDirk6pjW6IiJT/mI3kg4b8mPEjSQV1IU5XaikqQlujtkmeAuxjxNAl4daCmb7qxc5+PtAZj3jj997St3m12Qnu7NDPQfPAGjGp6sv0crwij/08y5iPKXr3W9PV7/VBqa6pdBhRjQ2Uct3wY+47O4cnpBTw5vYA7H35aMtNxXZ526dVIO4N688XRkBPDZawbr2K0Uhpon49nrF0GywKeuW4ZAJ3g1MIz1i6DY1s4ZcO4ePzUjeP42f4pnLRmWeA9T14/jv2Tczhu+XAuY1Yn8iQLrrqDjQ0+lIW0c5Ox/KtdxoZKWD8+5FWsdXAtlxwrYLIF+B2AdYJTut+aLVdUEI1Uky8vPKDp5cIZ7/PR+dhWL6ti1WgFa8aqgXQm3VOnHTchHiMW5AjTfETZq3P9ntMHG6hcgo99+/bhmmuuwde//nXMzs7iGc94Bj796U/j+c9/fh4fZ9ABHNvCf777fDzy9Aze/+8/ww/2HMb0fF24GqqTc7/5fHSSdvnOey6AY1m5tTrvB5y5eTnu+eMLsXK0AkBvr/6Mtcvwwz++EBOMIv6LV5+Oqy9+NlYtqwbe80u//0LUmq1UNHwaBLxIkpiMRTT20iEYfCzOZCxPUXPZsfHt97yk42u57NhCbFpxbLEhiTJk46kl34I++THi56OXeoVwn4/Faz6Gyg5uvfoCbaD7jLVj+MEfvQwrRiriMTp+XHAayXzwxnx9kCbPPPg4cuQIzjvvPLz0pS/F17/+daxZswYPPvggVqxYkfVHGSwSo9USTt04gY0TQwC8JkZUJ14t2VKqpR8ETBw6c6w4LEuxU1vK4AGErtQWgAhOxOtsSxt4AN6km9RsqhMEAs0E5zogOI0JTnngNFJxUmk2uB6i1l7U8hY1L+Za5mOrlu22kNFlfXCiNR/THehiuOC3l5UaoqtvwOcjmyqlqGOi3j+k+Tg6ywSnmkNDx5470vbDfJ35bPvhD38Ymzdvxqc//Wnx2NatW7P+GIMMQTfE1FxdRP7VkoOK40f/fSc4VRtfDXAqZTEIlNoWkM5VJ9pEmo9FpF3SOrVyEaNvMlbc61EuO3fQaLpotJqRhmzc54OMsdLoYvh79nLXTiWvbtuwS01pLEbzkRZjCvNhW8HqM4CVmvO0Sx+wt5nfAV/96lfx/Oc/H7/+67+OtWvXYtu2bfjUpz4V+vqFhQVMTU1J/wy6C5okpuYb7CaTq1364WLmSFtqa6CHrtS2aOhE85FWcMrLztM6tXbbZGyxkJiPkp3Iip6nXabn03f+lYKPHh4bzrpwr48sfD7Swtd8eMxHGJthKwFSLwW7aZD5kXz44YfxyU9+Es985jPxzW9+E29729vwzne+E5/5zGe0r9+xYwcmJibEv82bN2c9JIMYCOZjvi7lNjnVXMRFJwpBKr64k32RodN8FA3Bzrvx51rN3cdVnwxVOmc+eN+TbpiMLRb83qmWbVTau/1jogOwTnDKmI+59Bb0hWE+2Di46DYLzUdaqMxH2L3nKJqPfpnrMh9lq9XCWWedhb/4i7/Atm3b8Ja3vAW/+7u/ixtuuEH7+muvvRaTk5Pi3969e7MekkEMaIcyPd+QTcb62ecjkHbpr/EXBYG0SwEZsEA/mQ5Mxqop0i5pu/NKJmOiq23xjiOBH5uK49vpzyQQnPK0SzrNB2c+eig4ZfNcvaFhProYfAifD2I+Qu49W9F8FHGDoEPmR3LDhg045ZRTpMee85zn4LHHHtO+vlqtYnx8XPpn0F1QhD01Vw/3+eiTC5qgTmD9Nv6igKddrILSuarPR0cmYxEOp4CcdknrV8JTErVGdwSni4Gk+Sg7ghWaiRSc+o9RaWgazUdF8sDo3bHh8wQXnfZC80FB7tF29VDYvacyH/0y12V+ls877zzs2rVLeuyXv/wljj/++Kw/yiAj0EXuMR8hDqcF3PFGIaAD6JMbsmjg572oqbfONB+dC07TOrXyUtsoi/KiIKj58H6fjRKcsmN+pN18L02QVpS0i2VZWov1XjAfftolWvNBh27gg493v/vduOuuu/AXf/EX2L17Nz7/+c/j7/7u73DllVdm/VEGGUEwH/N1yWSsn3u7qONVd8cGydAP5dZ8XI6dzNtCFU3GBQND5c6ZD8lkrAsOp4uFpPlgwUdU2oUHDJQm6FRw2uvrTFQn8eCjTpuyLjIf7eNHniNJ0y5F3SSoyPwOOPvss/HlL38ZX/jCF3Daaafhz//8z/Gxj30Ml19+edYfZZARxlmpLe9hMNzH1S7B3gn9Nf6igM9jRRWy8ck2qXOouoDGCUClapeU3Xl9Maav+YjTmPQSvLNttWSLY0Npl6hqF8BnCVKV2hZE8wH454unXXpR7aIKm5da2iUXV6VXvOIVeMUrXpHHWxvkAKKRjy00RFOoasmRFP4FXXdC0YnJmEEQtt1fzEc54YWqBilxNuTDiym1dXzmA2hrPmI0Jr2EzHw4THAakXbRbE7SMERVKe3S28mmrKRdmi1XVL50s/WCKmwO2wCqXZ37Za4zlo4G4iJvub5YTK12KerCEwZ1cTEmY52h3zQfSXfNaU3GhhZjMmb7i1nLLb7gNEzzQWkXXeBk2xYsyzPnAjzGbDSFnT5/z15fZ3QNEUvFbct7yXyEaz4U5qNPWN7i3gEGXQM3Enrq2IL3WNnu6662wQqI/hp/UcAPW1EDUH6ukwaZQc1H8mqXtKW2vuaj1ScmY7LPB41VWIyHjJ3fY2ND5VR9ZWSTsV6nXai/i/d9SYQPdJf5qJYcSeAaRgipwUevmaOk6I9RGuQKy7IElfx0O/ioOI6s+SjowhMGNdjot/EXBTztUtQAjq8HSauaulntwkttSTxY5M7JJUnzEexjE3as+D2WVhdTLlDahTQulGpZaPjpjG4zqDx1FXZciJ1c6DPNR3HvAIOugig+MvULMB99ckETOjGeMgiCp12K6PEByJNy0sXBsS3pmo4roVyM5oNrCPrN4bRSsgPHJmzs/DyMVdMdo6KYjAFMcErMR71354wHcWG3XyDt0icsdXHvAIOuQqWSq0q1S7/5fJhS22zg9IHmQxKcpli4+GvTNZZbhMlYX6Rd9L1ddM9zLIb5qEjMR681H7LgtNbsvrU6gV9rsfbqg+5watCfUMVN1VJ/O5yqVQ+G+egMPOYs6jUgl9omn9L4a+N8N4YXU2rL7NX9rrbFPJaAovlgglPd8xz8PHTKDnnv0+tqF1+jAwDz9e67mxJ4ii9sA0iMZLNNW/eaOUoKE3wYAAhOFtWSjaGSIxafXu9G0kJVfBd14Sw65GqXYk4X/NymmXj5bjsuGBiteItAybYkFiQJ6Lg1W/3R1bYkMR9OIDAL06vw85CWHeLHv9fVGnRuKFAkwWlP0i5JmA9b/b0/5jpTamsAIMh8VEo2bNvC751/Eg5Nz2PNWLVHI+sMKvNR1IWz6FDdQ4sIHnCkOc98MYkTgG5aMYzLztyITSuGU1Vx8PFxwWkvKPyk4KLdSslO7AZbWkTapSj26gCwcrQCAHhy2hPfH5ryfq5aVun6WPhxDLv/Al2dC3qfqjDBhwEAPfMBAH+4/eReDGfRMCZj2UByOC0ondu55oMFHzHBgGVZ+OvXbUs/OLBS22bLt1fvG+bDTuwGay+C+eDBWK83CsctHwYAPH50DgCwr/2THu8m+LwclnYJ6tuKeZ+qKO4dYNBVqJNFNSW1XDSowUZRF86iox8cTvlilU7z0ZlWJC20gtMCMx+lgM9HMsGprPnoX+Zj0wovyNh3xAs6Hm//PG5F94MPzkiH3X+Bua5PWN7+GKVB7lBp0iLTwklg21Zf9CUpOvrB4VTWfHQmOM3zu4lSW6napZjHElB7uwR9Pioh1vBStUtazUeBSm2J4dinMB+besF8sCrE0MZylmE+DPoYnPmwrOIuNGnAA45+uSGLhv5wOGUMRooxUvqg4tipdRxpQONbqDeF/XiRTcbC7NV1z3Pw+y295qM4Qe5xCvOxr+DMR7+mmIt7Bxh0FZwmrZbynYy7hZJEq/f/9+kF+K6qH4KPTqpd8q5iICZhts5sugvMLHZqMraYapeq46d5e92HiZiPQ9MLWGg0meZjpOtjSVLtopr/FdUMUEVx7wCDroJPFr2oZ88D/VCpUXTImo9iThelRaZd8g5MqXSUWA/+2UWE7POR3F6dBy3p0y7FYT5WjlYw1G4g9+DBY5ic85pt9ob5YILTGJMxQq+PX1IU9w4w6Co4Tdrveg+CZCJV4Mm+yJB1M8Wc1DpNu5DOIO9rQzemoh5LQO3tEky7JPH5WEypba83CpZlCfbjB3sOAwAmhstYVu1+cahUahtyWEy1i0Ffg+9Uutk2Ok8Y5mPxcPog7dKpw2mlPZvnHXyoxy1vjcliEexqm77aJW3apVP2Ki8ct8JLsdy952kAfgVMt5HEXr1ffT56f5YNCgEefBRZDJcGZWlR6o8bsmiw+qLaJX1jOcBfRPPWX6hjKvq1yMdbcYI+H2HjlzUf6VgCy7LEvFOE64yYjx8+ckT6vdtIYq/er32s+mOUBrljmSQ4XSKaD27Z3Cc3ZNHQD+xRqcMgk1e75Al1MS2y2BRQql3KTuD4xAlOh8tBnUgS0Pv2utQW8JmOwzM1AL3RewCerT/FHEnt1YsQvCVBse8Cg67BsS2R01wqaRfuV9AvN2TR0G+ajzR+LkJwGuJbkRXURaPo+qP4xnJhwYf3eFq9h/q5RbjOVKajV8yHbVsYa8/LYYLTgM9HAYK3JCj2XWDQVRDFt1QEp52WYBr4sKzis0edllT71S45C04TLt5FQUBwGki7RGs+0uo91PctgiGgynT0SvMB+MczzGRMPV5FCN6SoPdn2aAwoIu8slTSLn2QMig6ZFahmMeQ7/yKKDhVD1vR0y6qz4fUcda2Ys2u0lqrE0TwUYCNghps9MLjg0Aup2H3nxqr9ctcV+y7wKCrILp0qTAfUqltAXZT/Qg+jxXVvKjUIcNFQUDe17tlWdICXnRBtzpWfnyixr5Y5kNoPgpwr64dG5Kuq15pPgA/mAv1+VAFpwWupOLo/Vk2KAxo0lgqwYfEfBRgN9WP6LfeLukay3Un7QIoY8xZY7JY0PEgp2PZLyd87IL5GO4w+ChQtYtjW9iwfAgAMFJxsGKks++UBeLSLurj/TLXLY1VxiAT+JqPpZF2kbqWFmA31Y/oB3t1znakWbi65XAKyNdfv2g+qhoTtqiUUWmxaZd2UFaU64xEpsctH+6pLwsx0qGCU9PbxaDfIZiPJVLtYjQfi0d/VLt05vNR6ZLDKSDvRosefFAwVi077d+TBU50HhYtOC3Izp10Hr1MuQC+B1PYoQ8wH32y0eqPURp0BesnPJqxlxRjluhWy/SljH5IXXXq87G8fZ2vGKlkPiYVXMdQdM3H8vbxWNn+WUkYfEy00y3rxqsdfS6dh4kO0zZZ48Q1o97P1ct6Oo514968HNYvp1+72nbfrN6gsPjv5xyPsaESLjl9Q6+HkgnoprSt4ooli47+cDjtjFV41ZnHodVy8V9PWZ/HsCTwY1f0apdnrF2Gj772DDxjrbfo8vFGjf2tLzkRJ6wewau3HdfR5/7JJc/By56zFi96xuqO/j5r/PdfOR6jFQeXPHdjT8fxm+dswUjFwSXP1c/L6tzWLyyvCT4MBCZGynjjuSf0ehiZgSb8Iqjn+xmObaHZcgtL50rVLikm3tFqCW/o0vXudMjO9AqvOWuT+H85Ycpo7fjQouaPE9csw4lressycEwMl/Fb523t9TAwMVzGFS88IfR509XWwKBgoKCjKDnkfgXNZUWd1DplPrqJpAt4EVGWSm2LeQ0MMkxXWwODgoE0Cv1yMxYVlHop6nHsBydbPsaiaz5UJNV8GPQGJvgwMCgYqKutmTAXB6efgo+CpoaSVowUEf089kGASbuE4EMf+hAsy8K73vWuvD/KwEACaRSKumj2C4qedpEqSQpq4OX0keBUBbdU77exDwKC9ur9cY5yHeUPf/hD/O3f/i2e+9zn5vkxBgZaUJ69XNBFs19gG+Zj0Sj1OXtQ7lIfHIP06NdS29yupGPHjuHyyy/Hpz71KaxYsSKvjzEwCAXdlEX1p+gXUClfUSe1Tnu7dBOSF0lB2ZkoUNBRVGZpkGEHTMb64xzlFnxceeWVuOSSS3DhhRdGvm5hYQFTU1PSPwODLGBKbbMBzWVFpXP7odqlnwWngD/moh7fQUaA+ShoAK4iF5+PL37xi7jvvvvwwx/+MPa1O3bswPvf//48hmEw4CCqu6g79n6BU3Tmo8PeLt1EP3W11YG0Hv049qWOoL16Me8BFZlfSXv37sUf/MEf4HOf+xyGhoZiX3/ttddicnJS/Nu7d2/WQzIYUNBC1C83Y1FR9FLbUl8wH0zz0YeiTdGErw/HvtTRr43lMmc+7r33Xhw6dAhnnXWWeKzZbOL222/H3/zN32BhYQGO43dNrVarqFY76wVgYBCFkhHJZQJR7VJQOtfpg46x5T4IkKJAzI1hPooJciH2/t8f5yjz4ONlL3sZfvKTn0iPvelNb8LJJ5+Ma665Rgo8DAzyhCm1zQZE66rCtqKA087FDZB42qWYY4yCYD76cOyDADn46PFgEiLz4GNsbAynnXaa9Njo6ChWrVoVeNzAIE/4JmNmwlwMKO1SVDpXaldf0F1fvxt1keajH8c+COABeL8wH/0xSgODDmDs1bOBU3DtTD+U2vazyRjgp1v6ceyDANnrppj3gIqudLW99dZbu/ExBgYSTKltNii+5qP4wUepjxvLATzt0n9jHwTweKOomwQV5koyWLIwXW2zge9wWszpQqp26Ycx9uECXjaltoVGPzIf5koyWLKgoKNfbsaiougOp5LJWEHTAk4f9J+JQkVUjvXf2AcB/B4wzIeBQY/xrHVj0k+DzvCsdctQdiycsHq010PRYqRSwqYVw9i0YhjD5WJW05X7PO1y8vpxAMCz1pt7qYjglWj9kmbuiubDwKAX+JUTV+GeP7kQq0YrvR5KX+Pjr9uG6fkGVhT0ODq2hW++63xYVnF3ff1ur/6ei56F3zrvBKxeZjyZioh+ZD5M8GGwpGEmy8Wj5NiFDTwIo9ViT2VSqW1BU0NRsCzL3EsFht0HXjcq+u8uMDAwMOgz9DvzYVBs8ICjqGaAKsxdYGBgYJAz+t1e3aDYkFx++yTtYu4CAwMDg5whV7uYadcgW9h9qPkwd4GBgYFBzpBNxvpjcTDoH/RDfyMVJvgwMDAwyBklo/kwyBGG+TAwMDAwCMAxmg+DHMEvqX7x+eiPURoYGBj0Mfq91Nag2JC72hrmw8DAwMAAptTWIF/YpreLgYGBgYGKshGcGuQIw3wYGBgYGARApbZlx4LVJyZQBv0DIzg1MDAwMAigLLrCminXIHvwVIvTJ8GtuRMMDAwMcgbtRk3wYZAH6PqyLZkFKTLMnWBgYGCQM6j80bibGuQB6ufSL2W2gAk+DAwMDHIH0eKm0sUgDxDz0S96D8AEHwYGBga5wxGaj/5ZHAz6Bz7z0T/Xlwk+DAwMDHIGMR4m7WKQB4hQc/oouC31egAGBgYGSx3btizH+c9ag4tOWdfroRgsQVC6pZ+YDxN8GBgYGOSMkUoJ//TmF/R6GAZLFJR2sfukzBYwaRcDAwMDA4O+Rj8yHyb4MDAwMDAw6GOIapc+0nyY4MPAwMDAwKCP4RifDwMDAwMDA4Nuwvh8GBgYGBgYGHQVttF8GBgYGBgYGHQTlHYxzIeBgYGBgYFBV2CqXQwMDAwMDAy6CtswH8COHTtw9tlnY2xsDGvXrsWrXvUq7Nq1K+uPMTAwMDAwMACzVx/k4OO2227DlVdeibvuugvf+ta3UK/XcdFFF2FmZibrjzIwMDAwMBh42H1Y7ZK5vfo3vvEN6fcbb7wRa9euxb333ovzzz8/648zMDAwMDAYaPSjz0fuvV0mJycBACtXrtQ+v7CwgIWFBfH71NRU3kMyMDAwMDBYMij1IfORa5jUarXwrne9C+eddx5OO+007Wt27NiBiYkJ8W/z5s15DsnAwMDAwGBJwfh8KLjyyivxwAMP4Itf/GLoa6699lpMTk6Kf3v37s1zSAYGBgYGBksK/ejzkVva5e1vfzu+9rWv4fbbb8emTZtCX1etVlGtVvMahoGBgYGBwZKGYD76qLFc5sGH67p4xzvegS9/+cu49dZbsXXr1qw/wsDAwMDAwKANv7fLAAtOr7zySnz+85/HV77yFYyNjeHAgQMAgImJCQwPD2f9cQYGBgYGBgONieEyAGB8KPcaksxgua7rZvqGlp72+fSnP43f+q3fiv37qakpTExMYHJyEuPj41kOzcDAwMDAYMlhZqGBL933OP7rKeuxfmKoZ+NIs37nknYxMDAwMDAw6A5GqyW84dwTej2MVOifBJGBgYGBgYHBkoAJPgwMDAwMDAy6ChN8GBgYGBgYGHQVJvgwMDAwMDAw6CpM8GFgYGBgYGDQVZjgw8DAwMDAwKCrMMGHgYGBgYGBQVdhgg8DAwMDAwODrsIEHwYGBgYGBgZdhQk+DAwMDAwMDLoKE3wYGBgYGBgYdBUm+DAwMDAwMDDoKkzwYWBgYGBgYNBVZN7VdrGgrrhTU1M9HomBgYGBgYFBUtC6naS7feGCj+npaQDA5s2bezwSAwMDAwMDg7SYnp7GxMRE5GssN0mI0kW0Wi088cQTGBsbg2VZmb731NQUNm/ejL1792J8fDzT9y4Klvp3XOrfDzDfcSlgqX8/wHzHpYCsv5/rupiensbGjRth29GqjsIxH7ZtY9OmTbl+xvj4+JK8kDiW+ndc6t8PMN9xKWCpfz/AfMelgCy/XxzjQTCCUwMDAwMDA4OuwgQfBgYGBgYGBl3FQAUf1WoVf/qnf4pqtdrroeSGpf4dl/r3A8x3XApY6t8PMN9xKaCX369wglMDAwMDAwODpY2BYj4MDAwMDAwMeg8TfBgYGBgYGBh0FSb4MDAwMDAwMOgqTPBhYGBgYGBg0FUMVPBx/fXX44QTTsDQ0BDOOecc/OAHP+j1kDrCjh07cPbZZ2NsbAxr167Fq171KuzatUt6zQUXXADLsqR/b33rW3s04vT4sz/7s8D4Tz75ZPH8/Pw8rrzySqxatQrLli3Dr/7qr+LgwYM9HHE6nHDCCYHvZ1kWrrzySgD9ef5uv/12XHrppdi4cSMsy8JNN90kPe+6Lt73vvdhw4YNGB4exoUXXogHH3xQes3hw4dx+eWXY3x8HMuXL8dv//Zv49ixY138FtGI+o71eh3XXHMNTj/9dIyOjmLjxo144xvfiCeeeEJ6D925/9CHPtTlb6JH3Dn8rd/6rcDYX/7yl0uv6edzCEB7X1qWhY985CPiNUU+h0nWhyTz52OPPYZLLrkEIyMjWLt2La6++mo0Go3Mxjkwwcc///M/46qrrsKf/umf4r777sMZZ5yBiy++GIcOHer10FLjtttuw5VXXom77roL3/rWt1Cv13HRRRdhZmZGet3v/u7vYv/+/eLfdddd16MRd4ZTTz1VGv8dd9whnnv3u9+Nf//3f8e//uu/4rbbbsMTTzyB17zmNT0cbTr88Ic/lL7bt771LQDAr//6r4vX9Nv5m5mZwRlnnIHrr79e+/x1112Hj3/847jhhhtw9913Y3R0FBdffDHm5+fFay6//HL89Kc/xbe+9S187Wtfw+233463vOUt3foKsYj6jrOzs7jvvvvw3ve+F/fddx++9KUvYdeuXXjlK18ZeO0HPvAB6dy+4x3v6MbwYxF3DgHg5S9/uTT2L3zhC9Lz/XwOAUjfbf/+/fjHf/xHWJaFX/3VX5VeV9RzmGR9iJs/m80mLrnkEtRqNXz/+9/HZz7zGdx444143/vel91A3QHBC17wAvfKK68UvzebTXfjxo3ujh07ejiqbHDo0CEXgHvbbbeJx17ykpe4f/AHf9C7QS0Sf/qnf+qeccYZ2ueOHj3qlstl91//9V/FYz//+c9dAO6dd97ZpRFmiz/4gz9wTzrpJLfVarmu2//nD4D75S9/WfzearXc9evXux/5yEfEY0ePHnWr1ar7hS98wXVd1/3Zz37mAnB/+MMfitd8/etfdy3Lcvft29e1sSeF+h11+MEPfuACcB999FHx2PHHH+/+1V/9Vb6DywC673fFFVe4l112WejfLMVzeNlll7n/5b/8F+mxfjmHrhtcH5LMn//v//0/17Zt98CBA+I1n/zkJ93x8XF3YWEhk3ENBPNRq9Vw77334sILLxSP2baNCy+8EHfeeWcPR5YNJicnAQArV66UHv/c5z6H1atX47TTTsO1116L2dnZXgyvYzz44IPYuHEjTjzxRFx++eV47LHHAAD33nsv6vW6dD5PPvlkbNmypS/PZ61Ww2c/+1m8+c1vlpop9vv549izZw8OHDggnbOJiQmcc8454pzdeeedWL58OZ7//OeL11x44YWwbRt3331318ecBSYnJ2FZFpYvXy49/qEPfQirVq3Ctm3b8JGPfCRTOjtv3HrrrVi7di2e/exn421vexuefvpp8dxSO4cHDx7Ef/zHf+C3f/u3A8/1yzlU14ck8+edd96J008/HevWrROvufjiizE1NYWf/vSnmYyrcI3l8sBTTz2FZrMpHUgAWLduHX7xi1/0aFTZoNVq4V3vehfOO+88nHbaaeLx3/zN38Txxx+PjRs34sc//jGuueYa7Nq1C1/60pd6ONrkOOecc3DjjTfi2c9+Nvbv34/3v//9ePGLX4wHHngABw4cQKVSCUzo69atw4EDB3oz4EXgpptuwtGjR/Fbv/Vb4rF+P38q6Lzo7kF67sCBA1i7dq30fKlUwsqVK/vyvM7Pz+Oaa67B61//eqlp1zvf+U6cddZZWLlyJb7//e/j2muvxf79+/HRj360h6NNhpe//OV4zWteg61bt+Khhx7CH/3RH2H79u2488474TjOkjuHn/nMZzA2NhZI6fbLOdStD0nmzwMHDmjvVXouCwxE8LGUceWVV+KBBx6Q9BAApBzr6aefjg0bNuBlL3sZHnroIZx00kndHmZqbN++Xfz/uc99Ls455xwcf/zx+Jd/+RcMDw/3cGTZ4x/+4R+wfft2bNy4UTzW7+dv0FGv1/Ha174Wruvik5/8pPTcVVddJf7/3Oc+F5VKBb/3e7+HHTt2FN7G+3Wve534/+mnn47nPve5OOmkk3DrrbfiZS97WQ9Hlg/+8R//EZdffjmGhoakx/vlHIatD0XAQKRdVq9eDcdxAmregwcPYv369T0a1eLx9re/HV/72tdwyy23YNOmTZGvPeeccwAAu3fv7sbQMsfy5cvxrGc9C7t378b69etRq9Vw9OhR6TX9eD4fffRRfPvb38bv/M7vRL6u388fnZeoe3D9+vUBAXij0cDhw4f76rxS4PHoo4/iW9/6Vmyr8nPOOQeNRgOPPPJIdwaYIU488USsXr1aXJdL5RwCwHe/+13s2rUr9t4EinkOw9aHJPPn+vXrtfcqPZcFBiL4qFQqeN7znofvfOc74rFWq4XvfOc7OPfcc3s4ss7gui7e/va348tf/jJuvvlmbN26NfZvdu7cCQDYsGFDzqPLB8eOHcNDDz2EDRs24HnPex7K5bJ0Pnft2oXHHnus787npz/9aaxduxaXXHJJ5Ov6/fxt3boV69evl87Z1NQU7r77bnHOzj33XBw9ehT33nuveM3NN9+MVqslgq+igwKPBx98EN/+9rexatWq2L/ZuXMnbNsOpCv6AY8//jiefvppcV0uhXNI+Id/+Ac873nPwxlnnBH72iKdw7j1Icn8ee655+InP/mJFEhSIH3KKadkNtCBwBe/+EW3Wq26N954o/uzn/3Mfctb3uIuX75cUvP2C972tre5ExMT7q233uru379f/JudnXVd13V3797tfuADH3Dvueced8+ePe5XvvIV98QTT3TPP//8Ho88Od7znve4t956q7tnzx73e9/7nnvhhRe6q1evdg8dOuS6ruu+9a1vdbds2eLefPPN7j333OOee+657rnnntvjUadDs9l0t2zZ4l5zzTXS4/16/qanp93777/fvf/++10A7kc/+lH3/vvvF5UeH/rQh9zly5e7X/nKV9wf//jH7mWXXeZu3brVnZubE+/x8pe/3N22bZt79913u3fccYf7zGc+033961/fq68UQNR3rNVq7itf+Up306ZN7s6dO6V7kyoEvv/977t/9Vd/5e7cudN96KGH3M9+9rPumjVr3De+8Y09/mYeor7f9PS0+z/+x/9w77zzTnfPnj3ut7/9bfess85yn/nMZ7rz8/PiPfr5HBImJyfdkZER95Of/GTg74t+DuPWB9eNnz8bjYZ72mmnuRdddJG7c+dO9xvf+Ia7Zs0a99prr81snAMTfLiu637iE59wt2zZ4lYqFfcFL3iBe9ddd/V6SB0BgPbfpz/9add1Xfexxx5zzz//fHflypVutVp1n/GMZ7hXX321Ozk52duBp8Bv/MZvuBs2bHArlYp73HHHub/xG7/h7t69Wzw/Nzfn/v7v/767YsUKd2RkxH31q1/t7t+/v4cjTo9vfvObLgB3165d0uP9ev5uueUW7XV5xRVXuK7rldu+973vddetW+dWq1X3ZS97WeC7P/300+7rX/96d9myZe74+Lj7pje9yZ2enu7Bt9Ej6jvu2bMn9N685ZZbXNd13Xvvvdc955xz3ImJCXdoaMh9znOe4/7FX/yFtHj3ElHfb3Z21r3ooovcNWvWuOVy2T3++OPd3/3d3w1s4Pr5HBL+9m//1h0eHnaPHj0a+Puin8O49cF1k82fjzzyiLt9+3Z3eHjYXb16tfue97zHrdfrmY3Tag/WwMDAwMDAwKArGAjNh4GBgYGBgUFxYIIPAwMDAwMDg67CBB8GBgYGBgYGXYUJPgwMDAwMDAy6ChN8GBgYGBgYGHQVJvgwMDAwMDAw6CpM8GFgYGBgYGDQVZjgw8DAwMDAwKCrMMGHgYGBgYGBQVdhgg8DAwMDAwODrsIEHwYGBgYGBgZdhQk+DAwMDAwMDLqK/x+WEZFvIK0D2AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3033738136291504, 2.3022608757019043, 2.302619218826294, 2.3026416301727295, 2.302729845046997, 2.3026928901672363, 2.3024868965148926, 2.302499294281006, 2.3026123046875, 2.302568197250366, 2.302534580230713, 2.3025219440460205, 2.302642583847046, 2.302581310272217, 2.302583932876587, 2.3025918006896973, 2.302581787109375, 2.3025848865509033, 2.302588701248169, 2.302583932876587, 2.30259108543396, 2.302612543106079, 2.302583694458008, 2.302603006362915, 2.302560329437256, 2.3025856018066406, 2.3025832176208496, 2.3025894165039062, 2.3025553226470947, 2.30234956741333, 2.302642822265625, 2.3026068210601807, 2.302809238433838, 2.302457332611084, 2.3026583194732666, 2.302539825439453, 2.302593469619751, 2.3025801181793213, 2.302556276321411, 2.3025686740875244, 2.3025600910186768, 2.302588701248169, 2.3025848865509033, 2.302581548690796, 2.3025851249694824, 2.3025879859924316, 2.302583694458008, 2.302579641342163, 2.302602529525757, 2.304403066635132, 2.3026576042175293, 2.3026816844940186, 2.3025753498077393, 2.302589178085327, 2.3025805950164795, 2.3025834560394287, 2.3025906085968018, 2.302471160888672, 2.302581548690796, 2.302581310272217, 2.3025858402252197, 2.3025851249694824, 2.3025896549224854, 2.3025858402252197, 2.302586078643799, 2.3025875091552734, 2.3025856018066406, 2.302586078643799, 2.302586317062378, 2.302584171295166, 2.302584409713745, 2.3025991916656494, 2.302579402923584, 2.302579402923584, 2.3025856018066406, 2.302586793899536, 2.3025856018066406, 2.302583932876587, 2.3025858402252197, 2.3025853633880615, 2.3025858402252197, 2.302584171295166, 2.3025853633880615, 2.3025858402252197, 2.3025851249694824, 2.302574396133423, 2.3025848865509033, 2.3025689125061035, 2.3025858402252197, 2.302586078643799, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.302586793899536, 2.3025856018066406, 2.3025858402252197, 2.302584409713745, 2.3025856018066406, 2.3025848865509033, 2.302586078643799, 2.3025858402252197, 2.3025858402252197, 2.3025848865509033, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025951385498047, 2.3025858402252197, 2.3025856018066406, 2.3025858402252197, 2.302586317062378, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025856018066406, 2.3025858402252197, 2.3025858402252197, 2.3025829792022705, 2.3025856018066406, 2.3025856018066406, 2.3025851249694824, 2.3025851249694824, 2.3025853633880615, 2.3025853633880615, 2.3025784492492676, 2.302584409713745, 2.302586078643799, 2.3025851249694824, 2.3025858402252197, 2.3025853633880615, 2.3025853633880615, 2.3025858402252197, 2.3025858402252197, 2.302579164505005, 2.302584171295166, 2.302584409713745, 2.3025848865509033, 2.3025858402252197, 2.3025858402252197, 2.3025851249694824, 2.3025853633880615, 2.302586078643799, 2.3025858402252197, 2.3025896549224854, 2.3025851249694824, 2.3025851249694824, 2.3025853633880615, 2.302586793899536, 2.3025856018066406, 2.3025848865509033, 2.3025858402252197, 2.3025856018066406, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025853633880615, 2.3025853633880615, 2.302582025527954, 2.3025858402252197, 2.3025877475738525, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025856018066406, 2.302586793899536, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025856018066406, 2.3025858402252197, 2.3025856018066406, 2.3025858402252197, 2.3025858402252197, 2.3025851249694824, 2.3025858402252197, 2.3025851249694824, 2.302584171295166, 2.3025858402252197, 2.3025851249694824, 2.3025856018066406, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197]\n",
      "[10.714285714285714, 11.607142857142858, 8.035714285714286, 10.714285714285714, 7.142857142857143, 8.928571428571429, 8.035714285714286, 10.714285714285714, 7.142857142857143, 11.607142857142858, 8.035714285714286, 8.035714285714286, 11.607142857142858, 8.035714285714286, 8.928571428571429, 9.821428571428571, 11.607142857142858, 10.714285714285714, 9.821428571428571, 15.178571428571429, 8.035714285714286, 8.928571428571429, 11.607142857142858, 8.035714285714286, 14.285714285714286, 8.035714285714286, 9.821428571428571, 8.928571428571429, 9.821428571428571, 9.821428571428571, 6.25, 6.25, 4.464285714285714, 8.035714285714286, 5.357142857142857, 14.285714285714286, 9.821428571428571, 11.607142857142858, 8.928571428571429, 10.714285714285714, 13.392857142857142, 10.714285714285714, 15.178571428571429, 10.714285714285714, 8.035714285714286, 11.607142857142858, 14.285714285714286, 13.392857142857142, 8.928571428571429, 8.928571428571429, 8.928571428571429, 8.928571428571429, 12.5, 10.714285714285714, 9.821428571428571, 3.5714285714285716, 9.821428571428571, 9.821428571428571, 14.285714285714286, 12.5, 6.25, 10.714285714285714, 8.035714285714286, 8.035714285714286, 10.714285714285714, 8.035714285714286, 8.928571428571429, 8.928571428571429, 7.142857142857143, 11.607142857142858, 16.964285714285715, 10.714285714285714, 10.714285714285714, 11.607142857142858, 7.142857142857143, 13.392857142857142, 7.142857142857143, 12.5, 9.821428571428571, 12.5, 8.035714285714286, 10.714285714285714, 8.928571428571429, 8.035714285714286, 10.714285714285714, 15.178571428571429, 9.821428571428571, 10.714285714285714, 13.392857142857142, 6.25, 15.178571428571429, 3.5714285714285716, 10.714285714285714, 6.25, 8.928571428571429, 6.25, 11.607142857142858, 10.714285714285714, 6.25, 8.035714285714286, 17.857142857142858, 11.607142857142858, 9.821428571428571, 14.285714285714286, 8.928571428571429, 15.178571428571429, 11.607142857142858, 8.035714285714286, 10.714285714285714, 3.5714285714285716, 8.928571428571429, 11.607142857142858, 10.714285714285714, 12.5, 8.928571428571429, 4.464285714285714, 8.928571428571429, 10.714285714285714, 8.035714285714286, 8.035714285714286, 5.357142857142857, 7.142857142857143, 9.821428571428571, 7.142857142857143, 7.142857142857143, 9.821428571428571, 8.928571428571429, 2.6785714285714284, 7.142857142857143, 11.607142857142858, 8.035714285714286, 8.928571428571429, 13.392857142857142, 16.964285714285715, 15.178571428571429, 8.035714285714286, 14.285714285714286, 8.928571428571429, 13.392857142857142, 6.25, 11.607142857142858, 9.821428571428571, 13.392857142857142, 10.714285714285714, 12.5, 9.821428571428571, 4.464285714285714, 8.035714285714286, 3.5714285714285716, 8.035714285714286, 7.142857142857143, 11.607142857142858, 4.464285714285714, 6.25, 8.928571428571429, 10.714285714285714, 7.142857142857143, 8.928571428571429, 8.928571428571429, 4.464285714285714, 10.714285714285714, 16.071428571428573, 11.607142857142858, 7.142857142857143, 8.035714285714286, 10.714285714285714, 9.821428571428571, 10.714285714285714, 8.035714285714286, 7.142857142857143, 9.821428571428571, 8.928571428571429, 16.071428571428573, 10.714285714285714, 5.357142857142857, 4.464285714285714, 5.357142857142857, 8.928571428571429, 10.714285714285714, 14.285714285714286, 10.714285714285714, 8.928571428571429, 13.392857142857142, 10.714285714285714, 6.25, 10.714285714285714, 11.607142857142858, 6.25, 8.035714285714286, 6.25, 4.464285714285714, 13.392857142857142, 9.821428571428571, 10.714285714285714, 1.7857142857142858, 8.928571428571429, 10.714285714285714, 8.928571428571429, 9.821428571428571, 9.821428571428571]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [0.841748058795929, 0.5383376479148865, 0.37141960859298706, 0.2189747840166092, 0.2170722633600235, 0.2683789134025574, 0.1937561184167862, 0.2995546758174896, 0.13230514526367188, 0.12556131184101105, 0.08791607618331909, 0.13517722487449646, 0.1180429607629776, 0.2700677216053009, 0.23012836277484894, 0.11778731644153595, 0.08971132338047028, 0.0745047926902771, 0.044976893812417984, 0.030214795842766762, 0.14274518191814423, 0.16257527470588684, 0.13489486277103424, 0.22497442364692688, 0.04410076141357422, 0.0439407117664814, 0.0999048724770546, 0.09295899420976639, 0.05333646386861801, 0.042801376432180405, 0.0852958932518959, 0.035196453332901, 0.09896297752857208, 0.09667126089334488, 0.11132311820983887, 0.07094293087720871, 0.11317868530750275, 0.17386971414089203, 0.04825839400291443, 0.1526862233877182, 0.12213451415300369, 0.0335562527179718, 0.14572270214557648, 0.14732243120670319, 0.08901072293519974, 0.10628568381071091, 0.1219853013753891, 0.04227989539504051, 0.1546023041009903, 0.07231778651475906, 0.08872615545988083, 0.06031284108757973, 0.11893129348754883, 0.07610543072223663, 0.05435555428266525, 0.03299633413553238, 0.06796611100435257, 0.09908641129732132, 0.1245361715555191, 0.13339823484420776, 0.044910043478012085, 0.039106521755456924, 0.08405368030071259, 0.03416334092617035, 0.18436889350414276, 0.06167331337928772, 0.05363277718424797, 0.03776988759636879, 0.010305949486792088, 0.08863425254821777, 0.11051689833402634, 0.03690870478749275, 0.021718373522162437, 0.08610344678163528, 0.08286675065755844, 0.05776119977235794, 0.09465332329273224, 0.032651614397764206, 0.07205092906951904, 0.0745658427476883, 0.08170061558485031, 0.10555801540613174, 0.016445361077785492, 0.12694816291332245, 0.11931197345256805, 0.08286337554454803, 0.07604096084833145, 0.04736681655049324, 0.07517056912183762, 0.13407494127750397, 0.02461135759949684, 0.026882896199822426, 0.050736844539642334, 0.03605273738503456, 0.056351643055677414, 0.09767205268144608, 0.07290007919073105, 0.08676333725452423, 0.0794496163725853, 0.04368472844362259, 0.050167299807071686, 0.04737326130270958, 0.05501176789402962, 0.08879045397043228, 0.01769072189927101, 0.11385718733072281, 0.045953329652547836, 0.057710688561201096, 0.03719104081392288, 0.07977698743343353, 0.02595260553061962, 0.1046842560172081, 0.06301649659872055, 0.02800893224775791, 0.024529291316866875, 0.020508909597992897, 0.14025148749351501, 0.05224132165312767, 0.02634393982589245, 0.03067580796778202, 0.010352589190006256, 0.030206164345145226, 0.09297139197587967, 0.1973668485879898, 0.11294060945510864, 0.10930002480745316, 0.0792819932103157, 0.11282505095005035, 0.06902279704809189, 0.034222979098558426, 0.01758032664656639, 0.20883719623088837, 0.0871180072426796, 0.021445829421281815, 0.058817390352487564, 0.11408091336488724, 0.04319537431001663, 0.028295835480093956, 0.009734376333653927, 0.0865861177444458, 0.013264675624668598, 0.03975219279527664, 0.03132316842675209, 0.07329122722148895, 0.031415101140737534, 0.057007454335689545, 0.07466187328100204, 0.03515228256583214, 0.01828647591173649, 0.034930113703012466, 0.04921986907720566, 0.05617351084947586, 0.025701504200696945, 0.07073844969272614, 0.0677885115146637, 0.0442965142428875, 0.08668070286512375, 0.01085565984249115, 0.10640285909175873, 0.042185988277196884, 0.045891039073467255, 0.010602300986647606, 0.07824820280075073, 0.029184645041823387, 0.1528889238834381, 0.0852082297205925, 0.01046351995319128, 0.26733046770095825, 0.008088228292763233, 0.1218838021159172, 0.06059052422642708, 0.17010393738746643, 0.09900021553039551, 0.027551589533686638, 0.009467942640185356, 0.0559978224337101, 0.015254249796271324, 0.06907999515533447, 0.026691734790802002, 0.09885875135660172, 0.01129892561584711, 0.03152812644839287, 0.08123517781496048, 0.04274165257811546, 0.03844240680336952, 0.06572488695383072, 0.10163140296936035, 0.020722707733511925, 0.016591958701610565, 0.10138952732086182, 0.10918857157230377, 0.028943251818418503, 0.04512939602136612, 0.040990330278873444, 0.04000023752450943, 0.045494887977838516, 0.011356256902217865, 0.05481533333659172, 0.013076278381049633, 0.04331720620393753]\n",
    "# acc_list_epoch_ = [71.42857142857143, 83.03571428571429, 84.82142857142857, 95.53571428571429, 91.07142857142857, 91.96428571428571, 93.75, 91.96428571428571, 96.42857142857143, 94.64285714285714, 98.21428571428571, 93.75, 96.42857142857143, 92.85714285714286, 94.64285714285714, 96.42857142857143, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 95.53571428571429, 95.53571428571429, 97.32142857142857, 91.96428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 97.32142857142857, 98.21428571428571, 95.53571428571429, 98.21428571428571, 96.42857142857143, 96.42857142857143, 95.53571428571429, 98.21428571428571, 95.53571428571429, 97.32142857142857, 99.10714285714286, 93.75, 95.53571428571429, 98.21428571428571, 94.64285714285714, 95.53571428571429, 97.32142857142857, 95.53571428571429, 94.64285714285714, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 98.21428571428571, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 96.42857142857143, 98.21428571428571, 98.21428571428571, 95.53571428571429, 99.10714285714286, 94.64285714285714, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 97.32142857142857, 95.53571428571429, 98.21428571428571, 100.0, 97.32142857142857, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 96.42857142857143, 99.10714285714286, 98.21428571428571, 94.64285714285714, 97.32142857142857, 96.42857142857143, 98.21428571428571, 95.53571428571429, 93.75, 100.0, 99.10714285714286, 98.21428571428571, 99.10714285714286, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 99.10714285714286, 95.53571428571429, 98.21428571428571, 96.42857142857143, 98.21428571428571, 98.21428571428571, 99.10714285714286, 97.32142857142857, 97.32142857142857, 98.21428571428571, 99.10714285714286, 99.10714285714286, 93.75, 97.32142857142857, 99.10714285714286, 98.21428571428571, 100.0, 99.10714285714286, 95.53571428571429, 91.07142857142857, 95.53571428571429, 95.53571428571429, 95.53571428571429, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 94.64285714285714, 98.21428571428571, 100.0, 98.21428571428571, 97.32142857142857, 98.21428571428571, 98.21428571428571, 100.0, 96.42857142857143, 100.0, 98.21428571428571, 98.21428571428571, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 99.10714285714286, 95.53571428571429, 98.21428571428571, 99.10714285714286, 98.21428571428571, 100.0, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 96.42857142857143, 99.10714285714286, 96.42857142857143, 97.32142857142857, 100.0, 91.96428571428571, 100.0, 96.42857142857143, 97.32142857142857, 91.96428571428571, 97.32142857142857, 99.10714285714286, 100.0, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 96.42857142857143, 100.0, 99.10714285714286, 99.10714285714286, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 100.0, 100.0, 95.53571428571429, 94.64285714285714, 99.10714285714286, 97.32142857142857, 98.21428571428571, 98.21428571428571, 98.21428571428571, 100.0, 98.21428571428571, 100.0, 99.10714285714286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 10.95%\n",
      "Loss on the train set: 2.30\n",
      "Accuracy on the test set: 10.83%\n",
      "Loss on the test set: 2.30\n",
      "Generalization error: 2.3841858e-07\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
