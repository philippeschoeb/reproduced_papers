{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 74.83%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "def generate_random_qubit_state_torch(n_qubit):\n",
    "    # Generate a single random state of size (n_qubit,)\n",
    "    random_state = torch.randint(0, 2, (n_qubit,)) * 2 - 1  # Converts {0,1} â†’ {-1,1}\n",
    "\n",
    "    # Repeat this state 2^N times\n",
    "    repeated_states = random_state.repeat((2**n_qubit, 1))\n",
    "\n",
    "    return repeated_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "def generate_random_tensor():\n",
    "    return torch.randn(\n",
    "        126 * 70, 1\n",
    "    ).cuda()  # Generates a tensor with standard normal distribution\n",
    "\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit + 1, output_dim=1, bond_dim=8)\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "\n",
    "        probs_ = generate_random_tensor()\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_random_qubit_state_torch(n_qubit)[\n",
    "            : len(nw_list_normal)\n",
    "        ]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  1984\n",
      "# of trainable parameter in full model:  1984\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108 + 84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "# print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.2999, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.3022, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 2.3036, batch time: 0.07, accuracy:  2.34%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 2.3036, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 2.3021, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 2.3020, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 2.3042, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 2.3032, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 2.3022, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 2.3030, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.10, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 2.3013, batch time: 0.11, accuracy:  14.84%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 2.3030, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 2.3034, batch time: 0.09, accuracy:  5.47%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 2.3038, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 2.3022, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 2.3047, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 2.3035, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 2.3035, batch time: 0.09, accuracy:  4.69%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 2.3017, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 2.3032, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  17.97%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 2.3010, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.09, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.10, accuracy:  12.50%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 2.3029, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 2.3022, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 2.3016, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  3.91%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 2.3023, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.11, accuracy:  13.28%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  18.75%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 2.3035, batch time: 0.08, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 2.3036, batch time: 0.10, accuracy:  7.03%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  16.41%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.10, accuracy:  12.50%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 2.3018, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  4.69%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 2.3020, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 2.3022, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 2.3030, batch time: 0.10, accuracy:  5.47%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  3.12%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 2.3030, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 2.3020, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 2.3022, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 2.3029, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 2.3030, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 2.3031, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 2.3023, batch time: 0.06, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 2.3053, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 2.3023, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 2.3030, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 2.3029, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  14.84%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  18.75%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  16.41%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  16.41%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  6.25%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  9.38%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  17.19%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.10, accuracy:  13.28%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  4.69%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  9.38%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 2.3023, batch time: 0.05, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 2.3035, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.11, accuracy:  9.38%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 2.3029, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  3.91%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.08, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 2.3018, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 2.3029, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 2.3031, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  17.19%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.10, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  17.97%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.03%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.10, accuracy:  7.03%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  17.97%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  17.19%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  16.41%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 3.3851, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 2.3006, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 2.3034, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  16.41%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 2.3023, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 2.3031, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 2.3020, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  16.41%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 2.3016, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 2.3020, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 2.3012, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  18.75%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  17.97%\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 2.3020, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  1.56%\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 2.3017, batch time: 0.01, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  15.62%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 2.3022, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  3.91%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 2.3038, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 2.3021, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 2.3034, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 2.3042, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  4.69%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  18.75%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  17.19%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  15.62%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  16.41%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 2.3017, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  15.62%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  15.62%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 2.3005, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  2.34%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  4.69%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.12%\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  17.97%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  3.12%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  17.19%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  3.12%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 2.3039, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 2.3014, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  15.62%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  15.62%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  15.62%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  21.88%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  17.19%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 2.3032, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 2.3033, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  17.97%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.12%\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  4.69%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  4.69%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  17.19%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  3.91%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "loss_list_epoch = []\n",
    "acc_list_epoch = []\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.302335023880005, 2.3025476932525635, 2.3025834560394287, 2.3025894165039062, 2.3026654720306396, 2.3025314807891846, 2.3026485443115234, 2.3021392822265625, 2.300436496734619, 2.302583932876587, 2.3025853633880615, 2.302593231201172, 2.3025646209716797, 2.302544116973877, 2.3025588989257812, 2.302593469619751, 2.3025872707366943, 2.302563428878784, 2.302600383758545, 2.302434206008911, 2.3026487827301025, 2.302590847015381, 2.3026649951934814, 2.3026773929595947, 2.3025596141815186, 2.3024890422821045, 2.303035020828247, 2.3027145862579346, 2.302631378173828, 2.3025519847869873, 2.30259370803833, 2.302638530731201, 2.3025262355804443, 2.3025753498077393, 2.302602767944336, 2.3026301860809326, 2.302544355392456, 2.302555799484253, 2.302586793899536, 2.3025665283203125, 2.3025996685028076, 2.3025851249694824, 2.3025858402252197, 2.302558183670044, 2.302347183227539, 2.3026046752929688, 2.302504301071167, 2.302583932876587, 2.302781820297241, 2.3025624752044678, 2.3023219108581543, 2.302563428878784, 2.3025214672088623, 2.3026421070098877, 2.3025870323181152, 2.303457498550415, 2.302656412124634, 2.3025155067443848, 2.3025975227355957, 2.3025705814361572, 2.3025877475738525, 2.30260968208313, 2.302582025527954, 2.302586078643799, 2.302589178085327, 2.3026013374328613, 2.3025572299957275, 2.3025848865509033, 2.302583694458008, 2.3025853633880615, 2.3025856018066406, 2.302582025527954, 2.302584171295166, 2.302558660507202, 2.3025875091552734, 2.302581310272217, 2.3026106357574463, 2.302582025527954, 2.302602529525757, 2.3025739192962646, 2.3025825023651123, 2.3026516437530518, 2.3025684356689453, 2.3025593757629395, 2.302553415298462, 2.3027894496917725, 2.30256724357605, 2.3025834560394287, 2.3022751808166504, 2.302604913711548, 2.3024895191192627, 2.302582263946533, 2.302565813064575, 2.302598714828491, 2.302588939666748, 2.302579164505005, 2.302562713623047, 2.302579641342163, 2.302568197250366, 2.3025856018066406, 2.3026278018951416, 2.3026301860809326, 2.302579402923584, 2.302584171295166, 2.302628755569458, 2.302520275115967, 2.3026187419891357, 2.302536725997925, 2.302586317062378, 2.3025848865509033, 2.302338123321533, 2.3024466037750244, 2.302609920501709, 2.3025829792022705, 2.302558422088623, 2.3026883602142334, 2.3025898933410645, 2.3025894165039062, 2.3025927543640137, 2.302523136138916, 2.3025825023651123, 2.3025858402252197, 2.3025670051574707, 2.302581787109375, 2.30277943611145, 2.3026087284088135, 2.302783966064453, 2.302574396133423, 2.302591323852539, 2.302577257156372, 2.3025834560394287, 2.3025879859924316, 2.3025825023651123, 2.3025870323181152, 2.3025810718536377, 2.302584409713745, 2.3025896549224854, 2.3025665283203125, 2.3025870323181152, 2.3025810718536377, 2.3025825023651123, 2.302593231201172, 2.3025834560394287, 2.3025944232940674, 2.3025872707366943, 2.302583694458008, 2.3025872707366943, 2.3026297092437744, 2.302583932876587, 2.3018782138824463, 2.3025505542755127, 2.3025875091552734, 2.3026154041290283, 2.3025856018066406, 2.3025803565979004, 2.302583694458008, 2.3026459217071533, 2.3025832176208496, 2.302581787109375, 2.3026123046875, 2.3026068210601807, 2.302586317062378, 2.3025588989257812, 2.3025929927825928, 2.302579879760742, 2.3025856018066406, 2.3025882244110107, 2.302577257156372, 2.3025853633880615, 2.302555561065674, 2.3025872707366943, 2.302560806274414, 2.3025872707366943, 2.302600383758545, 2.302588939666748, 2.302574634552002, 2.302583694458008, 2.302586793899536, 2.3025856018066406, 2.3025851249694824, 2.302560567855835, 2.302584171295166, 2.3025848865509033, 2.3025877475738525, 2.302586793899536, 2.302586078643799, 2.302583932876587, 2.302584409713745, 2.302586793899536, 2.3025856018066406, 2.3025763034820557, 2.3025856018066406, 2.3025856018066406, 2.3025882244110107, 2.302583932876587, 2.302583932876587, 2.3025851249694824, 2.3025906085968018, 2.3025851249694824, 2.3025856018066406]\n",
      "[8.928571428571429, 8.928571428571429, 9.821428571428571, 10.714285714285714, 11.607142857142858, 14.285714285714286, 7.142857142857143, 2.6785714285714284, 16.071428571428573, 15.178571428571429, 9.821428571428571, 7.142857142857143, 11.607142857142858, 10.714285714285714, 12.5, 10.714285714285714, 10.714285714285714, 8.928571428571429, 9.821428571428571, 11.607142857142858, 8.928571428571429, 8.035714285714286, 16.964285714285715, 7.142857142857143, 7.142857142857143, 9.821428571428571, 12.5, 8.928571428571429, 5.357142857142857, 7.142857142857143, 10.714285714285714, 8.928571428571429, 13.392857142857142, 8.928571428571429, 6.25, 6.25, 11.607142857142858, 21.428571428571427, 9.821428571428571, 11.607142857142858, 7.142857142857143, 8.035714285714286, 5.357142857142857, 10.714285714285714, 11.607142857142858, 8.035714285714286, 11.607142857142858, 10.714285714285714, 6.25, 9.821428571428571, 8.928571428571429, 8.035714285714286, 13.392857142857142, 7.142857142857143, 8.035714285714286, 3.5714285714285716, 4.464285714285714, 13.392857142857142, 8.928571428571429, 12.5, 8.928571428571429, 6.25, 13.392857142857142, 8.928571428571429, 6.25, 9.821428571428571, 11.607142857142858, 9.821428571428571, 14.285714285714286, 8.928571428571429, 8.035714285714286, 5.357142857142857, 16.071428571428573, 8.035714285714286, 8.928571428571429, 15.178571428571429, 11.607142857142858, 11.607142857142858, 6.25, 9.821428571428571, 10.714285714285714, 6.25, 9.821428571428571, 16.071428571428573, 8.035714285714286, 10.714285714285714, 7.142857142857143, 9.821428571428571, 12.5, 5.357142857142857, 9.821428571428571, 16.071428571428573, 14.285714285714286, 10.714285714285714, 10.714285714285714, 16.071428571428573, 12.5, 11.607142857142858, 13.392857142857142, 6.25, 8.035714285714286, 5.357142857142857, 11.607142857142858, 13.392857142857142, 8.928571428571429, 13.392857142857142, 6.25, 9.821428571428571, 6.25, 10.714285714285714, 9.821428571428571, 13.392857142857142, 8.035714285714286, 10.714285714285714, 11.607142857142858, 8.928571428571429, 11.607142857142858, 9.821428571428571, 3.5714285714285716, 11.607142857142858, 14.285714285714286, 13.392857142857142, 8.928571428571429, 9.821428571428571, 8.035714285714286, 7.142857142857143, 5.357142857142857, 13.392857142857142, 5.357142857142857, 12.5, 9.821428571428571, 7.142857142857143, 9.821428571428571, 7.142857142857143, 9.821428571428571, 7.142857142857143, 8.928571428571429, 13.392857142857142, 11.607142857142858, 10.714285714285714, 8.035714285714286, 15.178571428571429, 16.071428571428573, 3.5714285714285716, 8.035714285714286, 10.714285714285714, 8.035714285714286, 5.357142857142857, 14.285714285714286, 9.821428571428571, 7.142857142857143, 7.142857142857143, 15.178571428571429, 9.821428571428571, 8.928571428571429, 12.5, 6.25, 11.607142857142858, 8.928571428571429, 7.142857142857143, 9.821428571428571, 7.142857142857143, 17.857142857142858, 5.357142857142857, 16.964285714285715, 11.607142857142858, 9.821428571428571, 13.392857142857142, 10.714285714285714, 11.607142857142858, 3.5714285714285716, 13.392857142857142, 10.714285714285714, 8.928571428571429, 10.714285714285714, 10.714285714285714, 10.714285714285714, 6.25, 14.285714285714286, 9.821428571428571, 16.964285714285715, 13.392857142857142, 12.5, 11.607142857142858, 8.928571428571429, 4.464285714285714, 12.5, 15.178571428571429, 10.714285714285714, 12.5, 8.928571428571429, 10.714285714285714, 8.928571428571429, 9.821428571428571, 14.285714285714286, 11.607142857142858, 10.714285714285714, 8.035714285714286, 10.714285714285714, 10.714285714285714]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [0.841748058795929, 0.5383376479148865, 0.37141960859298706, 0.2189747840166092, 0.2170722633600235, 0.2683789134025574, 0.1937561184167862, 0.2995546758174896, 0.13230514526367188, 0.12556131184101105, 0.08791607618331909, 0.13517722487449646, 0.1180429607629776, 0.2700677216053009, 0.23012836277484894, 0.11778731644153595, 0.08971132338047028, 0.0745047926902771, 0.044976893812417984, 0.030214795842766762, 0.14274518191814423, 0.16257527470588684, 0.13489486277103424, 0.22497442364692688, 0.04410076141357422, 0.0439407117664814, 0.0999048724770546, 0.09295899420976639, 0.05333646386861801, 0.042801376432180405, 0.0852958932518959, 0.035196453332901, 0.09896297752857208, 0.09667126089334488, 0.11132311820983887, 0.07094293087720871, 0.11317868530750275, 0.17386971414089203, 0.04825839400291443, 0.1526862233877182, 0.12213451415300369, 0.0335562527179718, 0.14572270214557648, 0.14732243120670319, 0.08901072293519974, 0.10628568381071091, 0.1219853013753891, 0.04227989539504051, 0.1546023041009903, 0.07231778651475906, 0.08872615545988083, 0.06031284108757973, 0.11893129348754883, 0.07610543072223663, 0.05435555428266525, 0.03299633413553238, 0.06796611100435257, 0.09908641129732132, 0.1245361715555191, 0.13339823484420776, 0.044910043478012085, 0.039106521755456924, 0.08405368030071259, 0.03416334092617035, 0.18436889350414276, 0.06167331337928772, 0.05363277718424797, 0.03776988759636879, 0.010305949486792088, 0.08863425254821777, 0.11051689833402634, 0.03690870478749275, 0.021718373522162437, 0.08610344678163528, 0.08286675065755844, 0.05776119977235794, 0.09465332329273224, 0.032651614397764206, 0.07205092906951904, 0.0745658427476883, 0.08170061558485031, 0.10555801540613174, 0.016445361077785492, 0.12694816291332245, 0.11931197345256805, 0.08286337554454803, 0.07604096084833145, 0.04736681655049324, 0.07517056912183762, 0.13407494127750397, 0.02461135759949684, 0.026882896199822426, 0.050736844539642334, 0.03605273738503456, 0.056351643055677414, 0.09767205268144608, 0.07290007919073105, 0.08676333725452423, 0.0794496163725853, 0.04368472844362259, 0.050167299807071686, 0.04737326130270958, 0.05501176789402962, 0.08879045397043228, 0.01769072189927101, 0.11385718733072281, 0.045953329652547836, 0.057710688561201096, 0.03719104081392288, 0.07977698743343353, 0.02595260553061962, 0.1046842560172081, 0.06301649659872055, 0.02800893224775791, 0.024529291316866875, 0.020508909597992897, 0.14025148749351501, 0.05224132165312767, 0.02634393982589245, 0.03067580796778202, 0.010352589190006256, 0.030206164345145226, 0.09297139197587967, 0.1973668485879898, 0.11294060945510864, 0.10930002480745316, 0.0792819932103157, 0.11282505095005035, 0.06902279704809189, 0.034222979098558426, 0.01758032664656639, 0.20883719623088837, 0.0871180072426796, 0.021445829421281815, 0.058817390352487564, 0.11408091336488724, 0.04319537431001663, 0.028295835480093956, 0.009734376333653927, 0.0865861177444458, 0.013264675624668598, 0.03975219279527664, 0.03132316842675209, 0.07329122722148895, 0.031415101140737534, 0.057007454335689545, 0.07466187328100204, 0.03515228256583214, 0.01828647591173649, 0.034930113703012466, 0.04921986907720566, 0.05617351084947586, 0.025701504200696945, 0.07073844969272614, 0.0677885115146637, 0.0442965142428875, 0.08668070286512375, 0.01085565984249115, 0.10640285909175873, 0.042185988277196884, 0.045891039073467255, 0.010602300986647606, 0.07824820280075073, 0.029184645041823387, 0.1528889238834381, 0.0852082297205925, 0.01046351995319128, 0.26733046770095825, 0.008088228292763233, 0.1218838021159172, 0.06059052422642708, 0.17010393738746643, 0.09900021553039551, 0.027551589533686638, 0.009467942640185356, 0.0559978224337101, 0.015254249796271324, 0.06907999515533447, 0.026691734790802002, 0.09885875135660172, 0.01129892561584711, 0.03152812644839287, 0.08123517781496048, 0.04274165257811546, 0.03844240680336952, 0.06572488695383072, 0.10163140296936035, 0.020722707733511925, 0.016591958701610565, 0.10138952732086182, 0.10918857157230377, 0.028943251818418503, 0.04512939602136612, 0.040990330278873444, 0.04000023752450943, 0.045494887977838516, 0.011356256902217865, 0.05481533333659172, 0.013076278381049633, 0.04331720620393753]\n",
    "# acc_list_epoch_ = [71.42857142857143, 83.03571428571429, 84.82142857142857, 95.53571428571429, 91.07142857142857, 91.96428571428571, 93.75, 91.96428571428571, 96.42857142857143, 94.64285714285714, 98.21428571428571, 93.75, 96.42857142857143, 92.85714285714286, 94.64285714285714, 96.42857142857143, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 95.53571428571429, 95.53571428571429, 97.32142857142857, 91.96428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 97.32142857142857, 98.21428571428571, 95.53571428571429, 98.21428571428571, 96.42857142857143, 96.42857142857143, 95.53571428571429, 98.21428571428571, 95.53571428571429, 97.32142857142857, 99.10714285714286, 93.75, 95.53571428571429, 98.21428571428571, 94.64285714285714, 95.53571428571429, 97.32142857142857, 95.53571428571429, 94.64285714285714, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 98.21428571428571, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 96.42857142857143, 98.21428571428571, 98.21428571428571, 95.53571428571429, 99.10714285714286, 94.64285714285714, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 97.32142857142857, 95.53571428571429, 98.21428571428571, 100.0, 97.32142857142857, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 96.42857142857143, 99.10714285714286, 98.21428571428571, 94.64285714285714, 97.32142857142857, 96.42857142857143, 98.21428571428571, 95.53571428571429, 93.75, 100.0, 99.10714285714286, 98.21428571428571, 99.10714285714286, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 99.10714285714286, 95.53571428571429, 98.21428571428571, 96.42857142857143, 98.21428571428571, 98.21428571428571, 99.10714285714286, 97.32142857142857, 97.32142857142857, 98.21428571428571, 99.10714285714286, 99.10714285714286, 93.75, 97.32142857142857, 99.10714285714286, 98.21428571428571, 100.0, 99.10714285714286, 95.53571428571429, 91.07142857142857, 95.53571428571429, 95.53571428571429, 95.53571428571429, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 94.64285714285714, 98.21428571428571, 100.0, 98.21428571428571, 97.32142857142857, 98.21428571428571, 98.21428571428571, 100.0, 96.42857142857143, 100.0, 98.21428571428571, 98.21428571428571, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 99.10714285714286, 95.53571428571429, 98.21428571428571, 99.10714285714286, 98.21428571428571, 100.0, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 96.42857142857143, 99.10714285714286, 96.42857142857143, 97.32142857142857, 100.0, 91.96428571428571, 100.0, 96.42857142857143, 97.32142857142857, 91.96428571428571, 97.32142857142857, 99.10714285714286, 100.0, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 96.42857142857143, 100.0, 99.10714285714286, 99.10714285714286, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 100.0, 100.0, 95.53571428571429, 94.64285714285714, 99.10714285714286, 97.32142857142857, 98.21428571428571, 98.21428571428571, 98.21428571428571, 100.0, 98.21428571428571, 100.0, 99.10714285714286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 10.85%\n",
      "Loss on the train set: 2.30\n",
      "Accuracy on the test set: 12.00%\n",
      "Loss on the test set: 2.30\n",
      "Generalization error: -7.1525574e-07\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
