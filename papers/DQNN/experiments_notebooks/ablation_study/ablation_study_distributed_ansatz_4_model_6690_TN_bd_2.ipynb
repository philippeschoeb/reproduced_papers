{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 73.50%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "def generate_random_qubit_state_torch(n_qubit):\n",
    "    # Generate a single random state of size (n_qubit,)\n",
    "    random_state = torch.randint(0, 2, (n_qubit,)) * 2 - 1  # Converts {0,1} â†’ {-1,1}\n",
    "\n",
    "    # Repeat this state 2^N times\n",
    "    repeated_states = random_state.repeat((2**n_qubit, 1))\n",
    "\n",
    "    return repeated_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "def generate_random_tensor():\n",
    "    return torch.randn(\n",
    "        126 * 70, 1\n",
    "    ).cuda()  # Generates a tensor with standard normal distribution\n",
    "\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit + 1, output_dim=1, bond_dim=2)\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "\n",
    "        probs_ = generate_random_tensor()\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_random_qubit_state_torch(n_qubit)[\n",
    "            : len(nw_list_normal)\n",
    "        ]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  124\n",
      "# of trainable parameter in full model:  124\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108 + 84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "# print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.3058, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.3018, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 2.3021, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 2.3032, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 2.3035, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 2.3029, batch time: 0.03, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 2.3008, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 2.3019, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 2.3034, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 2.3022, batch time: 0.03, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 2.3022, batch time: 0.02, accuracy:  18.75%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 2.3039, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 2.3034, batch time: 0.02, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 2.3013, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 2.3032, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 2.3041, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 2.3047, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 2.3029, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 2.3020, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 2.3033, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 2.3030, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 2.3033, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 2.3042, batch time: 0.02, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 2.3032, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 2.3031, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 2.3030, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 2.3016, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 2.2998, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 2.3034, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 2.3032, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 2.3031, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 2.3031, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 2.3018, batch time: 0.02, accuracy:  17.97%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 2.3023, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 2.3030, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 2.3029, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 2.3023, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 2.3031, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 2.3020, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.02, accuracy:  18.75%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  3.91%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  17.19%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 2.3032, batch time: 0.03, accuracy:  3.12%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 2.3031, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 2.3022, batch time: 0.02, accuracy:  18.75%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 2.3022, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 2.3022, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.02, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 2.3029, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 2.3034, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 2.3023, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 2.3021, batch time: 0.02, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 2.3029, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  19.53%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  16.41%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 2.3030, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  6.25%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 2.3020, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  3.91%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 2.3022, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  3.91%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  19.53%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  4.69%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  3.91%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  3.91%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 2.3031, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 2.3021, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 2.3018, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 2.2953, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 2.3014, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 2.3016, batch time: 0.06, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 2.3037, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 2.3049, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 2.3010, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 2.3021, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 2.3020, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  1.56%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 2.3015, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 2.3047, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  17.97%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 2.3029, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 2.3031, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  3.12%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  3.12%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  4.69%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  3.91%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  17.19%\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  3.91%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.03, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  3.12%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 2.3030, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 2.3033, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 2.3023, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 2.3017, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 2.3029, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  16.41%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 2.3021, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 2.3030, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  4.69%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 2.3029, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.03%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.12, accuracy:  13.28%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  8.59%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  7.81%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.12, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  6.25%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  10.94%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.84%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  15.62%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.12, accuracy:  7.81%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  4.69%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  14.06%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.13, accuracy:  13.28%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.84%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  14.06%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.12, accuracy:  8.59%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.12, accuracy:  13.28%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  17.19%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  12.50%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  17.97%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  5.47%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  12.50%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  15.62%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  18.75%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 2.3033, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.03%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  13.28%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.10, accuracy:  14.84%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  9.38%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.12%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.14, accuracy:  12.50%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.12, accuracy:  7.81%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.12, accuracy:  7.81%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  20.31%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  3.12%\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.12, accuracy:  14.06%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  7.81%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  12.50%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  3.91%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  8.59%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  13.28%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "loss_list_epoch = []\n",
    "acc_list_epoch = []\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.302589178085327, 2.3022067546844482, 2.302539348602295, 2.3023946285247803, 2.3023383617401123, 2.3023147583007812, 2.3027117252349854, 2.3024463653564453, 2.3025882244110107, 2.302499294281006, 2.3027119636535645, 2.302595853805542, 2.3024420738220215, 2.3025412559509277, 2.3027865886688232, 2.302766799926758, 2.3024463653564453, 2.302701950073242, 2.3025963306427, 2.302607297897339, 2.3025779724121094, 2.302607297897339, 2.302579164505005, 2.3025870323181152, 2.302582263946533, 2.302633285522461, 2.3023343086242676, 2.302593469619751, 2.3025994300842285, 2.3023555278778076, 2.3026270866394043, 2.3025810718536377, 2.3026084899902344, 2.302586078643799, 2.3025856018066406, 2.30257248878479, 2.302546977996826, 2.3025896549224854, 2.302626371383667, 2.3025715351104736, 2.3026413917541504, 2.3026092052459717, 2.302588939666748, 2.3025853633880615, 2.3025848865509033, 2.302584171295166, 2.302623987197876, 2.3025965690612793, 2.3026022911071777, 2.302593469619751, 2.3025853633880615, 2.3026154041290283, 2.3025858402252197, 2.3025853633880615, 2.302584409713745, 2.3025856018066406, 2.3025858402252197, 2.302586317062378, 2.302583932876587, 2.3025853633880615, 2.3025848865509033, 2.3025856018066406, 2.3025858402252197, 2.3025858402252197, 2.3025851249694824, 2.302595853805542, 2.3025851249694824, 2.3025851249694824, 2.3025856018066406, 2.302586317062378, 2.302584171295166, 2.302687406539917, 2.3025710582733154, 2.3025474548339844, 2.302577495574951, 2.302574872970581, 2.302614688873291, 2.3026046752929688, 2.3025858402252197, 2.3025856018066406, 2.3025832176208496, 2.3026676177978516, 2.3025851249694824, 2.302586317062378, 2.302598237991333, 2.3025949001312256, 2.3025810718536377, 2.30230712890625, 2.3021950721740723, 2.3026137351989746, 2.3026559352874756, 2.302581787109375, 2.3026421070098877, 2.3025753498077393, 2.3025920391082764, 2.302604913711548, 2.302607297897339, 2.3025271892547607, 2.3025853633880615, 2.302588701248169, 2.3025870323181152, 2.3025875091552734, 2.30255126953125, 2.3025829792022705, 2.303218364715576, 2.302582025527954, 2.3025779724121094, 2.3025689125061035, 2.302583694458008, 2.3027455806732178, 2.302584171295166, 2.302582263946533, 2.302558183670044, 2.3025784492492676, 2.302608013153076, 2.3026115894317627, 2.302589178085327, 2.3025662899017334, 2.3026020526885986, 2.302584409713745, 2.302614450454712, 2.3025546073913574, 2.302567720413208, 2.302586078643799, 2.3025858402252197, 2.3026154041290283, 2.302584409713745, 2.3025858402252197, 2.3025870323181152, 2.3025851249694824, 2.3025858402252197, 2.3025810718536377, 2.3025856018066406, 2.302581548690796, 2.3025858402252197, 2.3025856018066406, 2.302581787109375, 2.3025856018066406, 2.3025858402252197, 2.3025848865509033, 2.3025858402252197, 2.3025858402252197, 2.3025851249694824, 2.302586317062378, 2.3025858402252197, 2.3025951385498047, 2.3025856018066406, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025858402252197, 2.3025848865509033, 2.3025858402252197, 2.302584409713745, 2.3025853633880615, 2.302574872970581, 2.3025870323181152, 2.3025929927825928, 2.3025906085968018, 2.302584409713745, 2.3025858402252197, 2.302584409713745, 2.302536725997925, 2.3025882244110107, 2.302584171295166, 2.3025851249694824, 2.302581787109375, 2.3025858402252197, 2.3025877475738525, 2.3025853633880615, 2.3025870323181152, 2.302591323852539, 2.302586078643799, 2.3025853633880615, 2.3025858402252197, 2.3025853633880615, 2.302586317062378, 2.3025848865509033, 2.3025875091552734, 2.302588939666748, 2.3025856018066406, 2.3025851249694824, 2.3025963306427, 2.3025853633880615, 2.3025851249694824, 2.3025851249694824, 2.3025858402252197, 2.3025856018066406, 2.3025858402252197, 2.302583694458008, 2.3025858402252197, 2.3025851249694824, 2.302586078643799, 2.302584409713745, 2.3025848865509033, 2.3025851249694824, 2.3025848865509033, 2.3025825023651123, 2.3025858402252197, 2.3025856018066406]\n",
      "[7.142857142857143, 13.392857142857142, 11.607142857142858, 11.607142857142858, 9.821428571428571, 10.714285714285714, 8.035714285714286, 8.928571428571429, 8.035714285714286, 16.071428571428573, 9.821428571428571, 10.714285714285714, 8.928571428571429, 16.071428571428573, 11.607142857142858, 8.035714285714286, 11.607142857142858, 8.035714285714286, 7.142857142857143, 9.821428571428571, 6.25, 11.607142857142858, 8.928571428571429, 8.035714285714286, 5.357142857142857, 10.714285714285714, 16.071428571428573, 10.714285714285714, 11.607142857142858, 18.75, 8.035714285714286, 8.928571428571429, 7.142857142857143, 9.821428571428571, 10.714285714285714, 7.142857142857143, 11.607142857142858, 8.928571428571429, 5.357142857142857, 12.5, 8.928571428571429, 9.821428571428571, 10.714285714285714, 7.142857142857143, 12.5, 8.035714285714286, 3.5714285714285716, 6.25, 9.821428571428571, 4.464285714285714, 8.928571428571429, 12.5, 14.285714285714286, 7.142857142857143, 11.607142857142858, 11.607142857142858, 5.357142857142857, 8.928571428571429, 10.714285714285714, 10.714285714285714, 11.607142857142858, 7.142857142857143, 7.142857142857143, 13.392857142857142, 8.035714285714286, 7.142857142857143, 9.821428571428571, 13.392857142857142, 8.035714285714286, 6.25, 8.035714285714286, 7.142857142857143, 11.607142857142858, 16.071428571428573, 11.607142857142858, 9.821428571428571, 7.142857142857143, 14.285714285714286, 11.607142857142858, 10.714285714285714, 13.392857142857142, 7.142857142857143, 13.392857142857142, 6.25, 5.357142857142857, 7.142857142857143, 9.821428571428571, 10.714285714285714, 10.714285714285714, 11.607142857142858, 7.142857142857143, 16.071428571428573, 6.25, 10.714285714285714, 10.714285714285714, 13.392857142857142, 5.357142857142857, 10.714285714285714, 9.821428571428571, 10.714285714285714, 8.035714285714286, 10.714285714285714, 11.607142857142858, 10.714285714285714, 6.25, 13.392857142857142, 13.392857142857142, 8.928571428571429, 7.142857142857143, 12.5, 8.035714285714286, 11.607142857142858, 13.392857142857142, 12.5, 8.035714285714286, 8.928571428571429, 8.035714285714286, 13.392857142857142, 8.928571428571429, 8.035714285714286, 4.464285714285714, 11.607142857142858, 9.821428571428571, 10.714285714285714, 8.035714285714286, 6.25, 8.035714285714286, 10.714285714285714, 12.5, 8.928571428571429, 8.928571428571429, 9.821428571428571, 10.714285714285714, 10.714285714285714, 9.821428571428571, 9.821428571428571, 9.821428571428571, 12.5, 5.357142857142857, 12.5, 8.928571428571429, 10.714285714285714, 10.714285714285714, 11.607142857142858, 10.714285714285714, 8.035714285714286, 6.25, 14.285714285714286, 6.25, 8.928571428571429, 5.357142857142857, 13.392857142857142, 5.357142857142857, 12.5, 9.821428571428571, 9.821428571428571, 10.714285714285714, 15.178571428571429, 9.821428571428571, 13.392857142857142, 8.928571428571429, 14.285714285714286, 10.714285714285714, 9.821428571428571, 12.5, 8.035714285714286, 8.928571428571429, 10.714285714285714, 9.821428571428571, 10.714285714285714, 8.928571428571429, 8.035714285714286, 8.035714285714286, 9.821428571428571, 8.928571428571429, 10.714285714285714, 8.035714285714286, 9.821428571428571, 7.142857142857143, 8.035714285714286, 12.5, 14.285714285714286, 8.928571428571429, 12.5, 7.142857142857143, 5.357142857142857, 7.142857142857143, 7.142857142857143, 6.25, 9.821428571428571, 8.928571428571429, 9.821428571428571, 7.142857142857143, 7.142857142857143, 12.5, 8.035714285714286, 8.035714285714286, 12.5, 8.035714285714286, 7.142857142857143]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [0.841748058795929, 0.5383376479148865, 0.37141960859298706, 0.2189747840166092, 0.2170722633600235, 0.2683789134025574, 0.1937561184167862, 0.2995546758174896, 0.13230514526367188, 0.12556131184101105, 0.08791607618331909, 0.13517722487449646, 0.1180429607629776, 0.2700677216053009, 0.23012836277484894, 0.11778731644153595, 0.08971132338047028, 0.0745047926902771, 0.044976893812417984, 0.030214795842766762, 0.14274518191814423, 0.16257527470588684, 0.13489486277103424, 0.22497442364692688, 0.04410076141357422, 0.0439407117664814, 0.0999048724770546, 0.09295899420976639, 0.05333646386861801, 0.042801376432180405, 0.0852958932518959, 0.035196453332901, 0.09896297752857208, 0.09667126089334488, 0.11132311820983887, 0.07094293087720871, 0.11317868530750275, 0.17386971414089203, 0.04825839400291443, 0.1526862233877182, 0.12213451415300369, 0.0335562527179718, 0.14572270214557648, 0.14732243120670319, 0.08901072293519974, 0.10628568381071091, 0.1219853013753891, 0.04227989539504051, 0.1546023041009903, 0.07231778651475906, 0.08872615545988083, 0.06031284108757973, 0.11893129348754883, 0.07610543072223663, 0.05435555428266525, 0.03299633413553238, 0.06796611100435257, 0.09908641129732132, 0.1245361715555191, 0.13339823484420776, 0.044910043478012085, 0.039106521755456924, 0.08405368030071259, 0.03416334092617035, 0.18436889350414276, 0.06167331337928772, 0.05363277718424797, 0.03776988759636879, 0.010305949486792088, 0.08863425254821777, 0.11051689833402634, 0.03690870478749275, 0.021718373522162437, 0.08610344678163528, 0.08286675065755844, 0.05776119977235794, 0.09465332329273224, 0.032651614397764206, 0.07205092906951904, 0.0745658427476883, 0.08170061558485031, 0.10555801540613174, 0.016445361077785492, 0.12694816291332245, 0.11931197345256805, 0.08286337554454803, 0.07604096084833145, 0.04736681655049324, 0.07517056912183762, 0.13407494127750397, 0.02461135759949684, 0.026882896199822426, 0.050736844539642334, 0.03605273738503456, 0.056351643055677414, 0.09767205268144608, 0.07290007919073105, 0.08676333725452423, 0.0794496163725853, 0.04368472844362259, 0.050167299807071686, 0.04737326130270958, 0.05501176789402962, 0.08879045397043228, 0.01769072189927101, 0.11385718733072281, 0.045953329652547836, 0.057710688561201096, 0.03719104081392288, 0.07977698743343353, 0.02595260553061962, 0.1046842560172081, 0.06301649659872055, 0.02800893224775791, 0.024529291316866875, 0.020508909597992897, 0.14025148749351501, 0.05224132165312767, 0.02634393982589245, 0.03067580796778202, 0.010352589190006256, 0.030206164345145226, 0.09297139197587967, 0.1973668485879898, 0.11294060945510864, 0.10930002480745316, 0.0792819932103157, 0.11282505095005035, 0.06902279704809189, 0.034222979098558426, 0.01758032664656639, 0.20883719623088837, 0.0871180072426796, 0.021445829421281815, 0.058817390352487564, 0.11408091336488724, 0.04319537431001663, 0.028295835480093956, 0.009734376333653927, 0.0865861177444458, 0.013264675624668598, 0.03975219279527664, 0.03132316842675209, 0.07329122722148895, 0.031415101140737534, 0.057007454335689545, 0.07466187328100204, 0.03515228256583214, 0.01828647591173649, 0.034930113703012466, 0.04921986907720566, 0.05617351084947586, 0.025701504200696945, 0.07073844969272614, 0.0677885115146637, 0.0442965142428875, 0.08668070286512375, 0.01085565984249115, 0.10640285909175873, 0.042185988277196884, 0.045891039073467255, 0.010602300986647606, 0.07824820280075073, 0.029184645041823387, 0.1528889238834381, 0.0852082297205925, 0.01046351995319128, 0.26733046770095825, 0.008088228292763233, 0.1218838021159172, 0.06059052422642708, 0.17010393738746643, 0.09900021553039551, 0.027551589533686638, 0.009467942640185356, 0.0559978224337101, 0.015254249796271324, 0.06907999515533447, 0.026691734790802002, 0.09885875135660172, 0.01129892561584711, 0.03152812644839287, 0.08123517781496048, 0.04274165257811546, 0.03844240680336952, 0.06572488695383072, 0.10163140296936035, 0.020722707733511925, 0.016591958701610565, 0.10138952732086182, 0.10918857157230377, 0.028943251818418503, 0.04512939602136612, 0.040990330278873444, 0.04000023752450943, 0.045494887977838516, 0.011356256902217865, 0.05481533333659172, 0.013076278381049633, 0.04331720620393753]\n",
    "# acc_list_epoch_ = [71.42857142857143, 83.03571428571429, 84.82142857142857, 95.53571428571429, 91.07142857142857, 91.96428571428571, 93.75, 91.96428571428571, 96.42857142857143, 94.64285714285714, 98.21428571428571, 93.75, 96.42857142857143, 92.85714285714286, 94.64285714285714, 96.42857142857143, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 95.53571428571429, 95.53571428571429, 97.32142857142857, 91.96428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 97.32142857142857, 98.21428571428571, 95.53571428571429, 98.21428571428571, 96.42857142857143, 96.42857142857143, 95.53571428571429, 98.21428571428571, 95.53571428571429, 97.32142857142857, 99.10714285714286, 93.75, 95.53571428571429, 98.21428571428571, 94.64285714285714, 95.53571428571429, 97.32142857142857, 95.53571428571429, 94.64285714285714, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 98.21428571428571, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 96.42857142857143, 98.21428571428571, 98.21428571428571, 95.53571428571429, 99.10714285714286, 94.64285714285714, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 97.32142857142857, 95.53571428571429, 98.21428571428571, 100.0, 97.32142857142857, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 96.42857142857143, 99.10714285714286, 98.21428571428571, 94.64285714285714, 97.32142857142857, 96.42857142857143, 98.21428571428571, 95.53571428571429, 93.75, 100.0, 99.10714285714286, 98.21428571428571, 99.10714285714286, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 99.10714285714286, 95.53571428571429, 98.21428571428571, 96.42857142857143, 98.21428571428571, 98.21428571428571, 99.10714285714286, 97.32142857142857, 97.32142857142857, 98.21428571428571, 99.10714285714286, 99.10714285714286, 93.75, 97.32142857142857, 99.10714285714286, 98.21428571428571, 100.0, 99.10714285714286, 95.53571428571429, 91.07142857142857, 95.53571428571429, 95.53571428571429, 95.53571428571429, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 94.64285714285714, 98.21428571428571, 100.0, 98.21428571428571, 97.32142857142857, 98.21428571428571, 98.21428571428571, 100.0, 96.42857142857143, 100.0, 98.21428571428571, 98.21428571428571, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 99.10714285714286, 95.53571428571429, 98.21428571428571, 99.10714285714286, 98.21428571428571, 100.0, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 96.42857142857143, 99.10714285714286, 96.42857142857143, 97.32142857142857, 100.0, 91.96428571428571, 100.0, 96.42857142857143, 97.32142857142857, 91.96428571428571, 97.32142857142857, 99.10714285714286, 100.0, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 96.42857142857143, 100.0, 99.10714285714286, 99.10714285714286, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 100.0, 100.0, 95.53571428571429, 94.64285714285714, 99.10714285714286, 97.32142857142857, 98.21428571428571, 98.21428571428571, 98.21428571428571, 100.0, 98.21428571428571, 100.0, 99.10714285714286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 11.05%\n",
      "Loss on the train set: 2.30\n",
      "Accuracy on the test set: 10.50%\n",
      "Loss on the test set: 2.30\n",
      "Generalization error: -7.1525574e-07\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
