{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split=\"train\")\n",
    "val_dataset = MNIST_partial(split=\"val\")\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 71.83%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = []\n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "\n",
    "def generate_random_qubit_state_torch(n_qubit):\n",
    "    # Generate a single random state of size (n_qubit,)\n",
    "    random_state = torch.randint(0, 2, (n_qubit,)) * 2 - 1  # Converts {0,1} â†’ {-1,1}\n",
    "\n",
    "    # Repeat this state 2^N times\n",
    "    repeated_states = random_state.repeat((2**n_qubit, 1))\n",
    "\n",
    "    return repeated_states\n",
    "\n",
    "\n",
    "#############################################\n",
    "def generate_random_tensor():\n",
    "    return torch.randn(\n",
    "        126 * 70, 1\n",
    "    ).cuda()  # Generates a tensor with standard normal distribution\n",
    "\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit + 1, output_dim=1, bond_dim=6)\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\" \"\"\"\n",
    "\n",
    "        probs_ = generate_random_tensor()\n",
    "\n",
    "        # probs_ = trans_res.to(device)\n",
    "        probs_ = probs_[: len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal), 1)\n",
    "\n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_random_qubit_state_torch(n_qubit)[\n",
    "            : len(nw_list_normal)\n",
    "        ]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(\n",
    "            len(nw_list_normal), n_qubit + 1\n",
    "        )\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = (\n",
    "            prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        )\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ########\n",
    "\n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "\n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict[\"conv1.weight\"].to(device).type(dtype)\n",
    "        conv1_bias = state_dict[\"conv1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict[\"conv2.weight\"].to(device).type(dtype)\n",
    "        conv2_bias = state_dict[\"conv2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict[\"fc1.weight\"].to(device).type(dtype)\n",
    "        fc1_bias = state_dict[\"fc1.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict[\"fc2.weight\"].to(device).type(dtype)\n",
    "        fc2_bias = state_dict[\"fc2.bias\"].to(device).type(dtype)\n",
    "\n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  1116\n",
      "# of trainable parameter in full model:  1116\n"
     ]
    }
   ],
   "source": [
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3  # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1  # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = (\n",
    "    2 * np.pi\n",
    ")  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108 + 84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step)  # , weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "# print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter)\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.03, accuracy:  4.69%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.3012, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.3021, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 2.3034, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 2.3022, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 2.3038, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 2.3038, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 2.3022, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 2.3035, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 2.3035, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 2.3014, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 2.3032, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 2.3021, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 2.3029, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 2.3031, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 2.3023, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.04, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 2.3032, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 2.3013, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 2.3019, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 2.3032, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 2.3022, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 2.3029, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 2.3023, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 2.3031, batch time: 0.03, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  3.91%\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 2.3023, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.91%\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 2.3021, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 2.3057, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 2.3023, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 2.3020, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 2.3034, batch time: 0.05, accuracy:  3.91%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 2.3023, batch time: 0.03, accuracy:  18.75%\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 2.3019, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 2.3022, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 2.3018, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 2.3029, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 2.3030, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 2.3022, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 2.3022, batch time: 0.05, accuracy:  17.97%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 2.3022, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 2.3030, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 2.3033, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  4.69%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  17.97%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 2.3036, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 2.3022, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 2.3023, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.06, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 2.3022, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 2.3032, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 2.3030, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 2.3022, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 2.3029, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 2.3018, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.19%\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  17.19%\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.12%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 2.3023, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 2.3031, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 2.3029, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 2.3023, batch time: 0.08, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  12.50%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  3.12%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 2.3021, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.03, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  17.97%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  4.69%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 2.3029, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  4.69%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.09, accuracy:  4.69%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  17.97%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.91%\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 2.3030, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 2.3030, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  17.97%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  16.41%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 2.3021, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 2.3030, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 2.3021, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 2.3023, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 2.3022, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 2.3023, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 2.3037, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 2.3022, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.07, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 2.3022, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 2.3030, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 2.3033, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  16.41%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 2.3029, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 2.3022, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.04, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  4.69%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  17.97%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  3.12%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  14.06%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  14.84%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  9.38%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  6.25%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.12, accuracy:  13.28%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 2.3022, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  13.28%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  13.28%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 2.3013, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  5.47%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  10.94%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  19.53%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 2.3032, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  11.72%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  14.06%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.11, accuracy:  8.59%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  4.69%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  4.69%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  16.41%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.09, accuracy:  5.47%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  15.62%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  19.53%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  16.41%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  10.94%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.91%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  6.25%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.13, accuracy:  9.38%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.12, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  3.12%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  3.12%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 2.3029, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 2.3035, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.91%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  3.91%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.09, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  14.06%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 2.3030, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  17.19%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.14, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 2.3041, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 2.3032, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 2.3031, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  3.91%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.09, accuracy:  14.84%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 2.3018, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 2.3037, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 2.2971, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  13.28%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  3.91%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.09, accuracy:  16.41%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  3.91%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  16.41%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  15.62%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 2.3022, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 2.3031, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = []\n",
    "loss_list_epoch = []\n",
    "acc_list_epoch = []\n",
    "for round_ in range(num_training_rounds):\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    acc_list = []\n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters=qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(\n",
    "                    f\"Training round [{round_ + 1}/{num_training_rounds}], Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\"\n",
    "                )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAADM30lEQVR4nO39ebwlVXU2jj91xntvd9/bEz3RzSiCMomoiANC5Ad0FHEgUUOUmMFocMTXLyGJJpqYVnxjTAwRkzcRfR3j5xWcEgwqg4ZBGVrBARkauukReri373im+v1RZ+1ae9euOlV16ox3PZ9Pf/rec8+pU+Peaz/rWc9yXNd1IRAIBAKBQNAl5Hq9AwKBQCAQCBYXJPgQCAQCgUDQVUjwIRAIBAKBoKuQ4EMgEAgEAkFXIcGHQCAQCASCrkKCD4FAIBAIBF2FBB8CgUAgEAi6Cgk+BAKBQCAQdBWFXu+AiUajgV27dmHZsmVwHKfXuyMQCAQCgSAGXNfF4cOHsWHDBuRy0dxG3wUfu3btwqZNm3q9GwKBQCAQCFJgx44d2LhxY+R7+i74WLZsGQBv58fHx3u8NwKBQCAQCOJgamoKmzZtUvN4FPou+KBUy/j4uAQfAoFAIBAMGOJIJkRwKhAIBAKBoKuQ4EMgEAgEAkFXkSj42LJlC57//Odj2bJlWLNmDV796lfjoYce0t4zPz+PK664AqtWrcLSpUvxute9Dnv37s10pwUCgUAgEAwuEgUft912G6644grcdddduPnmm1GtVnHBBRdgZmZGvee9730vvvWtb+FrX/sabrvtNuzatQuvfe1rM99xgUAgEAgEgwnHdV037YefeuoprFmzBrfddhvOOeccTE5O4ogjjsCXvvQlXHrppQCAX/3qV3jWs56FO++8Ey984QtbbnNqagoTExOYnJwUwalAIBAIBAOCJPN3W5qPyclJAMDKlSsBAPfeey+q1SrOP/989Z6TTjoJRx11FO68807rNhYWFjA1NaX9EwgEAoFAMLxIHXw0Gg285z3vwYtf/GKccsopAIA9e/agVCph+fLl2nvXrl2LPXv2WLezZcsWTExMqH9iMCYQCAQCwXAjdfBxxRVX4MEHH8RXvvKVtnbg6quvxuTkpPq3Y8eOtrYnEAgEAoGgv5HKZOwd73gHvv3tb+P222/XLFTXrVuHSqWCQ4cOaezH3r17sW7dOuu2yuUyyuVymt0QCAQCgUAwgEjEfLiui3e84x244YYb8IMf/ADHHnus9vczzzwTxWIR3//+99VrDz30ELZv346zzz47mz0WCAQCgUAw0EjEfFxxxRX40pe+hG984xtYtmyZ0nFMTExgdHQUExMT+IM/+ANceeWVWLlyJcbHx/HOd74TZ599dqxKF4FAIBAIBMOPRKW2YX7tn/3sZ/F7v/d7ADyTsfe973348pe/jIWFBVx44YX453/+59C0iwkptRUIBAKBYPCQZP5uy+ejE5DgQyAYHNz04B64rovNp67v9a4IBIIeI8n83XddbQUCwWCgUmvgXV+5H67r4oGT1mCkmO/1LgkEggGBNJYTCASpUGs0UKk1UK27WKg2er07AoFggCDBh0AgSIV6w8/Y1vsreysQCPocEnwIBIJUYLEHag1hPgQCQXxI8CEQCFKBa9U5CyIQCAStIMGHQCBIBR5w1OoSfAgEgviQ4EMgEKQCJzuE+RAIBEkgwYdAIEiFBku71CT4EAgECSDBh0AgSIWGaD4EAkFKSPAhEAhSQapdBAJBWkjwIRAIUqHREOZDIBCkgwQfAoEgFSTtIhAI0kKCD4FAkApS7SIQCNJCgg+BQJAKms+HBB8CgSABJPgQCASpIA6nAoEgLST4EAgEqVAXnw+BQJASEnwIBIJU4NW1dSm1FQgECSDBh0AgSAXN4VR6uwgEggSQ4EMgEKSClNoKBIK0kOBDIBCkgu5wKsGHQCCIDwk+BAJBKnC2g7MgAoFA0AoSfAgEglRwRfMhEAhSQoIPgUCQCuJwKhAI0kKCD4FAkAricCoQCNJCgg+BQJAKusOp+HwIBIL4kOBDIBCkgjicCgSCtJDgQyAQpIJoPgQCQVpI8CEQCFKhIcyHQCBICQk+BAJBKjQa4nAqEAjSQYIPgUCQCpJ2EQgEaSHBh0AgSAVJuwgEgrRIHHzcfvvtuPjii7FhwwY4joMbb7xR+/v09DTe8Y53YOPGjRgdHcWzn/1sXHfddVntr0Ag6BPoaRcptRUIBPGROPiYmZnB6aefjmuvvdb69yuvvBI33XQTvvCFL+CXv/wl3vOe9+Ad73gHvvnNb7a9swKBoH8gjeUEAkFaFJJ+YPPmzdi8eXPo3++44w5cfvnlOPfccwEAb33rW/GZz3wGP/7xj/GqV70q9Y4KBIL+Avf5qEtvF4FAkACZaz5e9KIX4Zvf/CZ27twJ13Vxyy234Ne//jUuuOAC6/sXFhYwNTWl/RMIBP0PVzQfAoEgJTIPPj71qU/h2c9+NjZu3IhSqYSLLroI1157Lc455xzr+7ds2YKJiQn1b9OmTVnvkkAg6AAarpTaCgSCdOhI8HHXXXfhm9/8Ju6991783d/9Ha644gp873vfs77/6quvxuTkpPq3Y8eOrHdJIBB0AHWmMRXmQyDwMFepY9/UfK93o++RWPMRhbm5OfzZn/0ZbrjhBrziFa8AAJx22mnYunUr/vf//t84//zzA58pl8sol8tZ7oZAIOgCOPPRkOBDIAAAvOnf7sbPdk7izj/9DaxaKnNbGDJlPqrVKqrVKnI5fbP5fB4NKcUTCIYKPOAQ5kMg8LDt6RlUag3sPDTX613payRmPqanp/HII4+o37dt24atW7di5cqVOOqoo/Cyl70M73//+zE6Ooqjjz4at912Gz7/+c/jE5/4RKY7LhAIegvd4VQWFwIB4FeBLdTkmYhC4uDjnnvuwXnnnad+v/LKKwEAl19+Oa6//np85StfwdVXX43LLrsMBw4cwNFHH42PfOQjeNvb3pbdXgsEgp5DHE4FgiBIfL1QleAjComDj3PPPVcrsTOxbt06fPazn21rpwQCQf9Dql0EgiAoHVmp13u8J/0N6e0iEAhSQTQfAkEQNWE+YkGCD4FAkAp16WorEATQEM1HLEjwIRAIUkEcTgWCIJTmoyZplyhI8CEQCFJB13zIKk8gcF1XVYEJ8xENCT4EAkEqcIdTSbsIBHr5eUWCj0hI8CEQCFJBql0EAh38ORDmIxoSfAgEglSQaheBQAcPyBeqovmIggQfAoEgFRpS7SIQaBDmIz4k+BAIBKmgOZzWJfgQCOquBB9xIcGHQCBIBdF8CAQ6GsJ8xIYEHwKBIBX03i4y0AoENS34EM1HFCT4EAgEqSCaD4FAhzAf8SHBh0AgSAU+0NYjmk0KBIsF/DkQn49oSPARgseemsa/3P4o5ipCnbXCHY8+jf/4yY5e74agy9A0HyI4FQik2iUBCr3egX7F33/vYXzrp7uwbmIUrzp9Q693p6/x/q/9DDsPzeFFz1iFjSvGer07gi6BO5yKz4dAAHDpk/h8REOYjxAcnq9q/wvCMdU8R9MLtR7viaCbkGoXgUCHlNrGhwQfIaDBtCGDakvQORKvh8UF6WorEOiQtEt8SPARAlrVyaDaGhTtN0R0uKhQF+ZDINDQ0ASnknaJggQfIaDBVAbV1qA8pwRqiwv8covPh0AgzEcSSPARArqJZEJtDZp4JEW1uKCV2sq1Fwgk+EgACT5CIMxHPLiuq1bAEqgtLjRE8yEQaNCCD6l2iYQEHyEg7aSIKKPB5xxhPhYX+OV2Xbn+AoFmMlYX5iMKEnyEoKGYD7mBosAjfXG5XFwwgw25/oLFDtNe3ZVnIhQSfIRANB/xINT74oVZ3SQpSsFiB38GXBeoCnMeCgk+QkADqwyo0eDnR2j3xQVzXJXgU7DYYbJ/0tk2HBJ8hEAEp/FQF+Zj0SLAfMgqT7DIYWbppblcOCT4CEFdTMZioSHMx6KFmc8Wrw/BYkeQ+ZBnIgwSfISgIcxHLPDzI4Ha4oL5bMizIljsMBdgEnyEQ4KPENREcBoLmuZDlN2LCuajIc+KYLHDDMBF8xEOCT5CIKW28aBpPiTnv6gQKLWV4EOwyGEG4KL5CEfi4OP222/HxRdfjA0bNsBxHNx4442B9/zyl7/Eq171KkxMTGDJkiV4/vOfj+3bt2exv12DaD7iQXw+Fi+k1FYg0GE+E5J2CUfi4GNmZgann346rr32WuvfH330UbzkJS/BSSedhFtvvRU/+9nP8IEPfAAjIyNt72w3QeZ0MqBGgxNDcq4WFyTtIhDoCKRdqhJ8hKGQ9AObN2/G5s2bQ//+53/+5/jN3/xNXHPNNeq1448/Pt3e9RCNFMyH67p4+xfuw9rxMj50ySmd2rW+grRVX7wQ5kOQBa7++s8ws1DHP7zhOXAcp9e70xaCzIdoPsKQqeaj0WjgO9/5Dp75zGfiwgsvxJo1a3DWWWdZUzP9DuXzkUDHsGdqHjf9fA8+f9cTi8ZWVwSnixfm9ZZSW0FSVOsNfPnHO/DNn+7CgZlKr3enbQQFp/JMhCHT4GPfvn2Ynp7GRz/6UVx00UX47//+b7zmNa/Ba1/7Wtx2223WzywsLGBqakr71w9QgtMEEypRbIvJVrchgtNFCzPWEOZDkBT8npkbgi6w5jMggtNwJE67RKHRHI0uueQSvPe97wUAPOc5z8Edd9yB6667Di972csCn9myZQs+9KEPZbkbmaCewl6dR7kLtTpKheEvJhLmY/HCDMxF8yFICi34qAx+8CFpl/jIdHZcvXo1CoUCnv3sZ2uvP+tZzwqtdrn66qsxOTmp/u3YsSPLXUqNNI3l+I22WOg2MRlbvDBTi8J8CJKCB7DDwXzovy+WeSANMmU+SqUSnv/85+Ohhx7SXv/1r3+No48+2vqZcrmMcrmc5W5kgnoKnw+d+VgcN51WaiuTz6KCeb0l7SZICq6pGwbmI2CvLtUuoUgcfExPT+ORRx5Rv2/btg1bt27FypUrcdRRR+H9738/Xv/61+Occ87Beeedh5tuugnf+ta3cOutt2a53x2H8vlIMKDy/N5iyfVJtcvihXm5Je0mSAo+fswOAfNhGu9VTCpEoJA4+Ljnnntw3nnnqd+vvPJKAMDll1+O66+/Hq95zWtw3XXXYcuWLXjXu96FE088Ef/v//0/vOQlL8lurzsM13VBz0QyzUfd+vMwoyHMx6JFsLGcXH9BMvDxY34ImA/zGVgYgoCqU0gcfJx77rkty0h///d/H7//+7+feqd6jbQ6Bk6xLRa6TdIuixcmxSytCARJMWyaD2ksFx/DX46RAmlTCYtS88HPldDuiwpmrCGaD0FS8PF1dgiYj4DmY5HMA2kgwYcFfFBNX+0y+A9SHPBzZUb9guGGOJwK2gUfP+aHgPkQk7H4kODDAh69JplQF7vgVHL+iwtBh1O5/oJk0NIuQ8B8BNMug39MnYIEHxbomg8ptY2CCE4XL+hyF/NePw65/oKk0NIuw8B8SNolNiT4sCDthGo6nC4GiOB08YKek2LeG0aE+RAkRWNImY9S85lYLIUHaSDBhwW11NUuTPOxSG46fn5EcLq4QBMHtRGQahdBUvAFy1BoPprPxEixGXwskkVoGkjwYUEjbbULM5RZLOYy2rmSaodFBRpoiflYJLe8IEMMXbVL8xkYK3kuFotF+5cGEnxYID4f8VEX5mPRgoiOUl6YD0E6DFtXW1qMjZXyAETzEQUJPixIq2NYjJqPtCyRYPDhGmkX0XwIkoIvWIYh7UJeN6MSfLSEBB8W8Am1loBL7kRX23rDxZMHZzPZVifQj4LTRsPFjgPtnzPXdfHE/pmWjr5xsOPAbN+cn6zgp126U+0yX61j9+RcR79D0F00hiztEmQ++u+YFmp13P3Yfty3/WBP90OCDwuyYD6yyvX99bd/gZd87Bbc/dj+TLaXNfox7XLNdx/CS6+5Bbc+tK+t7Xzhrifwso/fii/c9URb27n1oX146TW34Jrv/qqt7fQb/FLb7jAfb//CvXjJx27B9v39G4wLkkFLuwxB8EHHM9rHmo/90xW8/l/uwus/c2dP90OCDwsaKS3DKx3w+Xj0qWkAwCPN//sN/Sg4fax5rh5/eqat7dy//RAA4KG9h9vazkN7vM9ve6q9/ek3mKW2nWY+Hnt6BvWGiwd2Tnb0ewTdw7D1dqHjGSv2b9qFntNCrrfTvwQfFvBMS681HxTQ9OuqQDtXfcJ80DVrNxZ68pBH8U/N1draztR8VduvYYEqtSXmo8PBZ7X5LOw8JMzHsIBrlPt1jEsCCshV2qUPA6pqc9Au5Jye7ocEHxakr3bJ3ueDbpR+fTDTNuHrJKrN/Wi318zOg83goxk8pAUFL9U+OT9ZgQ6nWz4flWZwQ9dFMPgYOuZDpV0GgPnIS/DRd+CpBNeNP4l1wl6d/EL69cHsR3t1mgTbYWJq9Qb2TM0DAA7Pt8d8HFbMR/8NRO3AT7t4g1inNR+VJpu485AEH8OCxrBpPppjzmgz7VKpNzIRrGeJajOIz0vapf9gDqJxB9VOaD6qNe+7+1UJXuvD4IMernb2Z8/UvPr81FybzEczeKn2iSYmKzRMk7EOD7J0/p4U5mNowMePSr2RqLqwH2GmXVy3/577urFo6BUk+LDAnLTiTmJ6qW02wQKlXfq1Br4/mY/2gw9O7WfHfPTH+ckKgbRLpzUfzWdB0i7DA/OZmO/DNEUS0CNA1S5A/5XbVpsMbF40H/2HYKvweA/EYky79KPmo5ZF8MGo/aw0H8NmwlU3BacdPL5Gw1XbP7xQw2SbbJSgP2COtbOV9gL9XoMWY6NFf2rtN92Hz3xI2qXvkJ756EDw0dxOv6Zd+tHng6hbc2BLAr66nq3U26KDifkYdErZhOlw2sng0+yVJOzHcCDAfFQG+xmhhWo+n1NBeb95fRCDKMxHH8IUmKbRfGR1w0naJTkySbsYosZ2Ui+k+eiX85MVzBVUJ5mPqhl8iOh0KGAuEPqV4Y0Luk0LOQflAnW27a/gw/f5kOCj72Cu4ONXu3RC8+F9d78qwfsx7UITVTtMTFbBR73hYnqBBKf9NQi1C9PhtJPVPKZob2cftxwQxIc5Zgx82qU55uQdB+UiBR/9NXbTIkFKbfsQ5gMRZ0Xnuq6edsnI54Po5n5Nu/Qz89GOz4dJ66fVfUyzoKVfzk8W4OWDxULnS22F+RhOmM/E4DMf3vHkco5Ku/Rbh/OalNr2L0wqMM6kUa274B/LgmpzXbfv0y79yXxQ2iXd513XVZMb1eunDT745/qt5K4d8Gtd6oK9upnGlOBjOGCOtf06zsWFYj5yQLlPLdaJoSxK2qX/YE5acVZ0JrVWyYBqqzX8gKZfmY9+tldPKzh9erqChVoDjgM8Y81SAOkt1nnw0S/BWRbgh9KV4EMEp0MJc6zt13EuLhTz4fiaj/4TnFKAJMFH38HMXcfJZZs3WBbRLqea+5WO5OemXyZXUpyn3R9aVa9dNoKVS0oA/IqVpOBBS9yS7UFAQ0u7dD74kLTLcMIcW/tV2xYX9AzkNcFpfx2TlNr2MdIxH8Hgo11bXXI3Bfo5+OA/90vw4Wr/JwWtqo9cMYrx0SIAv2IlKXjQMkw+H1rw0Y1ql5ruHPn0dGXgKXrB8Gk+NMFpoT/TLlJq28cw0wdxunXSDeaw62lSxUnBP1+pNfpmcudo9KHmg5w20wpOqWvqkctHsWzEcypMzXxwwekQaT60tEsXfT5WLy1jSTMAEfZj8GE+EsPCfORyjnou+pf5kOCj72BOWnEGVbrBljJb3XZzfWbw0o+rAs1krE+Cj2qbjeU05mOkyXyk1HzwoKU6RGkXXXDavWqXUiGHI1eMAhDdxzDAHGv7cYxLApV26WPNR42lhnoJCT4sCDicxpjE6AajlTLQPt1WrXU2H3rTg7tx04N72toGPzf9klZot9SWVtSZMB9zi6DUtoXPx60P7cMN9z+pfj88X8U/fO9hfOhbP8eHvvVz3PnofvW3HQdmcd1tjwbONz1fxXwORy5vBh/CfHQEruviC3c9gXseP9Dx7zLH1oFnPlx/Yvd9PsLngb1T8/jnWx/BgZlKV/YP8J2WCz0utS20fsvig/lAxGM+vAs6UsyjVMihUmu0H3yYzEeGD+Z8tY53fvl+OHDw4IcuVBRhUvAJvh0786zglSc3S21T7s+eqXkAwIblI6AtpC21PWyU2rquC8fp7YojC/BnQmk+QtJK7/nqVkzOVXHOCUdg1dIyvvXT3fj77/1a/f3mX+zFj676DQDAP9/6KL784+1YNlLAZWcdrd6jmI+8g/XN4GP35Hy2ByUAADy8bxp/ceODeMaapfjelS/r6HcNm+aDhmxPcNrUfET4fHz2fx7Hdbc9ikqtgfec/8xu7KKYjPUzAvbqcTQfVZ8WVirnNh+kTqZdFqoNVOsuKvVGW9qUfku78F1Iuz8U5I2VChhvMh9ZlNqa+zfI4MdBueOw8314vgbX9csoKSBbs6wMAMoBlv9tZkE/3zztQt4r/UZnDwummk37ptvs5hwHgbTLgDMfDZbSUCZjEZoPGh+2PT3T+Z1rYmDTLrfffjsuvvhibNiwAY7j4MYbbwx979ve9jY4joNPfvKTbexi95GO+fBusDIPPtpmPjq3KqhmVCLbbyZjnC1Ky8TQdSsXckrzcXih/bSLuX+DDJfRy+SUaEu7ua4b6LVD98xRK8e01wH/mpmnqVL3ywOJaRmWc9lvoHGnG2lUc6ydHXTmw2U+H8XWmg9KgXRTv6QEp4PmcDozM4PTTz8d1157beT7brjhBtx1113YsGFD6p3rFYKN5VoPcv6ElVd0W9uCU+PzWfY9yIqx6Dd79SyOi857qZDD+Gh7zIcZtPTDOcoC/iDrN6iyBXv8cGkyo6ofSvXZ7iFzW1zzUepTId+wgIK6bqRR6drTgm1+iJiPOItQCvS6qV9SpbY9Trsk1nxs3rwZmzdvjnzPzp078c53vhPf/e538YpXvCL1zvUKZsQfZ8KggbBczJL50D+fpa8B33Y75le1Pgs+eIos7cKYB5K0ys5CcGru3yCDLrXjOIq+tR1bzcKw0T2jSnTd4DUzFwB0vxbzOVVdI8xHZ0DXrNaF80v3wrKRAhamK4Ov+eD26jF8Puge3js1j2q90RXjL5/5GLDgoxUajQbe9KY34f3vfz9OPvnklu9fWFjAwsKC+n1qairrXUqMNI3leNolq/puU4uRpfVwZswHnzj6QHCqT3bpBk9+LWkwmJqvpRKLmkHLsLicqhWe4yjmw3Yf8cM1nWdttuz1kDJpX/PhqGvSro+OwA5ajXdjLUHXeWm5gKenK0Nprx41D9TYud4zOY9NzVRkJ1Ed1sZyH/vYx1AoFPCud70r1vu3bNmCiYkJ9W/Tpk1Z71JipGkst8CoetVQqM1uhp0steV6knZW42YQ066ra7vQ9ifFrvDuxOViTpXa1htuqlWZ6YzaD+xQFmiwtItiPiyBVRTzQc+J7ZqZp0mlwjTNx3Ccy35DTWk+Oh/cURC7pOw9Z4PuWqsJTlXhQYTmg53jJ7uk+6AAf6iqXe699178wz/8A66//vrYK8Srr74ak5OT6t+OHTuy3KVUSGWvXmWaj4xWZubgmuWDmRXzYR5ir+fWKhcvptgZ3syvnM9jrJRXk2tS3YfrugHmo9rrE5QR6DByOUcNYq2ZDxKT+oEEbYuCVrpmwbSLLzilQd0MzgXZgCbEbpB0NH4sbQYfw5J20ZiPiHmAj/Hd0n2oUttBq3aJwg9/+EPs27cPRx11FAqFAgqFAp544gm8733vwzHHHGP9TLlcxvj4uPav1zCZjziTGAUa5UKOmcu0m3bRP58lJckj7nZU7ea56nVaoV5vL6ji+dlyMQfHcVIbjc03y5kB33Z/WCzWOb2cc8IdTm3VUKbmA/CDGbMihqAEp4WcClok7dIZ0LnuRhq1wdIuwPB0tfVMxloz4Fy31K2KF2K2eh18ZKr5eNOb3oTzzz9fe+3CCy/Em970JrzlLW/J8qs6ilSaj6ql1LbttIv+vVmuCmptTtJhn+21pEErIU4xeHJvFprkxkeKODRbTWw0RsFKzvFo5cPztaGxWHe1apfw3i5akEvmb0aFA72WzznqmplBrW8ylkOxIILTTsJnqDpvikf3gkq7DEnwUYjZ1bamMR+znd05+k5lMjZgDqfT09N45JFH1O/btm3D1q1bsXLlShx11FFYtWqV9v5isYh169bhxBNPbH9vu4SAvXqCUlvPZCybboadNBnjAVU7bEVAH9NHmo80aZcFpi3INVcGxHwk7WxLwcqykaJK3QyP5sP73/P5CGc++K1lMh+8sVWjZdqloT6jBKeSdukIappXDtBJaYASnI4MSdqFGEGtsVwE88EekK6lXfqkq23i4OOee+7Beeedp36/8sorAQCXX345rr/++sx2rJcIphLiC07LhXxmPgSdtFfXBpg2djMQqPU4rcDPWZpAiHt8EPzmcsmYDwpWlo0U1P0xLKt1uu6O42s+bMGent5raO8rGcwHAMZ86Nup1P3rIiZjnYUmRm80kM/lO/ZddC9Q2qXWcFGpNVK3e+g1VFDuOLH8njjz0T3BaTD47wUSBx/nnntuooqGxx9/POlX9BxB5iNJ8JGLRbfFgXnTZhl81DNiPtI04esksmI+eErA13wkZD6awYqXtqkE9m+QQQF63onPfNBnlOYj709qdYP5MM+T5vNREM1HJ8HHg05nCetG8AF47MegBh+a5iOWyZj/t92H5tFouIpx7RSqah+HrNR2GBDQfMTp7ULeEB00GcvWXr0zmo9eC04107M0mg/m8UEYH20yHwk1H8R8jI8WlJtgv3T+bRcNTfMRnlKK0nxogtMA8xEiOM37glNTEyXIBibz0UnQ9S4Xcuo+GuT+LqraJa7mgz0zlXoDT00vhL43K5CMoNfMhwQfFrTDfJTyzOejbc2HPkhny3xkU+1iTvC91lO263Dqe3z4q/K0zMdhpvmgPgpD7XBqufiNmNUu9JpvumQvtS1Jb5eOo5pRSjYOOFNADQMHWffBzffi+HyY93A3Ui++yZgEH30Hc0JN5PNRzGfW1ZZuzInmyrsfq13S9MHpJNp1OK1Y0i6pNR9NX5BxJjjt9fnJCirtknNaVLu4gZ/5yosKKZTQNLSxHNd8ONprgmxR6ybzwYKPkVIz+BgK5sO3V4+6T+lcjzTtGbohOuUVOb2EBB8WmBNqvGoXZq+elclYcyKktu7Z+nwEJ4U06G/mI33apZSB5sNnPgqqrG1omA/l84FIzYfNzK5W54FLM2Wjgg7vf1NXVuVpl4IwH51Eu+XqScCD2DEKPqrZNdDsJlzXNyjMs662UYtQuoePXrkEQHe8PnyTMdF89B3MBy7OGFdh1S7+TZdNqS1pDrJ0ONUbwrUjODW322OTMS44TTFu+k61WWg+qurzUbqIQQR3OKXgw3VtgbuN+fBXXmRQ5nezDX4O8J+FYt7xg3spte0IsmJF44Cb1am0S2Uwrys/V3EFp/RMHLPa6+nSDa8PqnQcKnv1YYE5oZqT8ydu/jV+9//crQ1+nfD5SJt2aTRcvPXz9+BD3/p56Ht4qW07q3Fzsonbhvupwwt49bX/g6/+ZHvq77ZBK7Vtq9rF13wQ85Q07UJMyfhIQU3Qw7Ja55MGzx1HdYSm54jek8/l1GfpEQtzOK1aS23bmxgf3nsYF3/qR/j+L/e2tZ1hQ63NZygJ6KvyOQcjXdR83P3Yflz8qR/h/u0HM9smv/c9wak/D4RViNJ9fcyqbJiPSq2B3/0/d+Pv/vuhlvspzEcfIqhj0H//0t1P4EePPI1f7PY78Ham1Nb7Xgo+4qZddk/N479/sRdfuOuJ0PfozEd2aZe4c+tPHj+ArTsO4as/ybaXT7s9a2zVLkvL3vmfWUh2Pen9S8oFpVMYFubDtVS7ABbHW3Z/1BS7QcGHR08DtrSL/n1U2VLM51DMqNT2B7/ahwd2TuJbP93V1naGDXp/pM5+Fy/ZJt1DN5rL3fTzPXhg5yT++xfZBZ78Xi8wkzEgPFBWaRcKPtrUfPx672H86JGn8fk7I8b+PjEZk+DDguCEqv9OQQDv9aFpPjIutaXgI671cEUZWoV3mdVFZd0XnNKxzbWZmgpsV0u7JD8um8nYaCndioxbgivmY0iCD5V2MZiPgFjbQuH7mg/fRbZuBCZhaRev2sVnkdrpoqyekyG5JlmBN+zrluA0l/Oda7uRuqV7MMvmhPye5Y3lgPCFKO3HMauaaZeDc23d0zRGTS/UQrfTLyZjEnxYwNsiA/rk7Lp+a3UuQKywEs3M7NWV4DRZ2kUrlQu5j3kqKc0krbaTUnBKD91cJVtxWb3RHmVsMxmjXHRSwa8yxmKpgnb0Nf0E3r1TYz6MFZ6tsRzXfKi0ixF0hPV2KRZyKDfNyVy3PSaJttlrV95+Q63NAD4JOAtWUKnJzl8Pui+z9N3hjzbXfAD2ucB1XfX9RzWDj5lKHZMJ07scNEbVG27oeCWltn0MujFLasLwb1Avf+f9zDUAms9HxszH+KhuPdwK/D1hGgPNSKiNhz2tyRi9L+v8Lj+WNAOnTfNBKvykdLBiUfLMC2NIJjpepaBrPvTrb612afi0b1Bwag8+fJMxRzWWA9pLvVCr816LpPsNfMzotCke1w51syKMFphZarB4oJ13HDhOdH8Xfm6XlYtYvbQMoD2vD16mHCaQ95kP0Xz0HeimoKoVPjjxi8uZD9XVtpiLVWIVBxUj7QLEm6wrMQRj7Wojwj4bd8Knc5x1TX+7WhZ+HQk87ZKEEuWW4CTuGhqHU1Zqy43Gogz6bNUuNP6ZrIgZD2hdbdmg2Y7LKX12WK5JVuhmtYsvPna0dFqnUetE8GEITgGgnA+fC/h5LuQdHLliFEB7wQdfIIVZA/Dgv5eQ4MMC1fjKwnzMVu2RpS44bW0uEwf0YIyV/GqJOKtvLWcbsorIzOfDZD5irlpU2iVr5qPN46LVMKdMSYVfb7iJrik51HrBx7DZq3v/U7v1MK8PO/PBWBOD+VABSojDKT+XQHvPGD1fw8JGZYVam6nLJGiwQLSbzrX0vVlee84GEmgRY7tPuZ9KIe9g43Iv+GhHdMpTLWHVeTV2znsJCT4sMHtP8Bt0znJxXde1drVt1+dDWUoXcol0B3F6M+jldOn302Q64poS+SsPN9PBRu/Wm4b5CApOKe0CAPMJPAh4eSjV1Ne6MLB2A+ZAawYRBI35MHq7FLjg1GgsZ1477nDqOL7XRzv3TlXSLlZUu8h86Nqh7rGDavzJ8LuUW6vDgg/S/1nmAr5ILOZyivlop9x2Lg7z0by+BUm79B9oYKUJiE+oNlqLP6ylQnaajwrTkYwmsB6O43WRNfMRRruHf87fxyxL67SVdkaaD77aTsLU6GmX4Sq15WkXAKHMTrTPhy9WbdVYjp9LwH822zEao4BmWK5JVmjXKycJuLi/2MUAXQlOO5B24fYZUXNBjT1DuZyDIxXzkd5obD6Emde/t2kyJsxH/0ExH7a0i0XQw8uosvT54ANukqZL/EYPi+yzolajzlUUqiFsUrvg202zoLX5fAC84iV+dQ4PHql9dTeU/N1AIO2ifEwMwanN54OYj7wTLLUlszHjNPFzCSATfQAvSRf46KrDKesCW1DXtPPXgyqcsvwuG/NRipgLzID6yEzSLv74NBXCfNTZ89dLSPBhAd2PNAHx1dycFll6F5dP9uVCll1tfYW/bz2ckPnosOaDPkqTQVzBaT3knLYLrdS2DZ+PQPCRwuvDLw91mMnYcFD83BwKiMt86LqOnOMETcaa/wd6u7BzCfgDdhaaD2E+dHSzt4tyOGVpl25oPvxS2+yrXXJc8xHB0NWYjglANmkXlhYO03xQwCXMRx9CCU4p7dJC88Gt1Xk+uhJhqxsHXDOQZPLjD281VPORzerG18fkA9uNAqc7M+3W2261i7qWee31JGkvgl8emgsVZA4qGmqg9X5PX+0SYq9ueOso/ZNiPtpnkqpq9TscAWFW6CbzwdMuJctir1Og48ry2nPxLCHK80mlP5oLEwo+Ds5WEzGsHHMx0i5cc9VLSPBhgVkHrTMf/k1Bmg+1Wm6+n5dptrMy45NXEto/Ts42s1Lb5iREEX7SUlsg4269xmSUVHRqMxkDkCjtReATprqXhoTibzChIOAPZFHBR6TPh+tq14p/jgcYZK1O1ycLwakwHzq6qfmwmdV1hflggvfMthlR7WJLu1D7DHp2xkeKqoN2WvaDmzaGCU7p/EqpbR+ibgpONZ8PRmsZmg+60Vo528UFr3ZJYnQVz2QsGyOhhgrUkq3s+fvi2sYn3S6QnDa2+XwAKZkPxlwNG/NBt08uRaktzznnmeCUXyt+2XgAbzIf7QhO6dmU4ENHVn2f4oAzH101Geuk4NQJpl1s1S4UhHObc9J9PJlS96ExHyFpFzEZ62PQxbFpPjjzML1QQ6Phsjbs3gRVYhe1nXLbKmM+RhJMfpUYtKmtCiEN6Nz4gVrctEtnNB/mYJJ08KSJrmymXRIyH/WGqz3kw1pqa1a7BJgPi+CU+wxwwWlYpZJWkkjBR1P7kYXmIyw1uVjRTebDr3wCiiqA7YLJWF2/F7MA7TZnFFRVls3no+4H4YSNbeo+eK8sG/PBLd2F+ehDmDoG/gBy5sF1gelKLUDVO6ypUFtpF675oLRLUs1HBwWnnCYvJqx24QNMpmkX4/uTWqzbfD4A3+sjLvPBr0Ex7wydyZhrUMxh9vG2IJc0VPlcDjTu1l1Xu1b8ZzqXOcf/HqX5aItZ1PdH4KGr1S4N/14oKDarC5oPt3Npl1xMnw9aiHAGQjEfGaRdbJoPfj1FcNqHUD4fVs2HPvlMzVVV2oVPWL7RWPqJ1S/Fcvy0S5xql1rrlYtmMpbyAeSr08TMR4eqXcxVU9LJPqzUdiQh88GDDy/t0r2Ond0AHZ7pcBpHcMqZD/45raEZ+5kH4YRMBKfNSU662urQmI9uNZZzmM9HF56RTghOTc8jAJG2C3S/F5nwc+OKZnfbDNIuNuaDP2NSatuHMB1O+UBortIPz9es5Zntdrat1RuqjLWU0OdD13OEVLtkwHzU22A+eMDTKZMxIHvBaVyWRhNJ5nKKUh4WfYFZapsPocytmg/GmvDGcprgVGM+gjlqn1lsP7gflmuSFbqp+eDGXN0UZSvxc5bVLjbBaYTJGN1/PAjwy23TGY21slfXgg+pdukdXNfFjgOzgXLYKM2HOVF6zEdQJ9Cuy6k2eeVzauUdZ/Jb4MFHWNrFQq26rovt+4PnIwycGqfjjbtSqnYo7WKuhOMMnjsOzKqBoGK5lkDyzra0HdI15DMyUNp1aK6lyHLv1Ly2n/WGd5/HxZMHZ1sOymapbajmo0WpbYH5w/D38hjGNBgDeNol/flcUCZj/F6sYd/h+dTb7BccnKmkbs3eVYdTNmEXuthYLm21y/RCDfc8fgD3PH4A256esW6TZzOiutr6mo9g2iUt8zEf0vhU7aPRzK6XWNTBxze27sJLr7kF//rDx7TXA/bqPEVgYT5ooOe0cLudbSuaZsCvdonFfNSCgYUJG/PxtXufxDkfvwXX3/F4rH1si/mIOKftIErwaMP92w/ipdfcgj+/4QEAjPkwql2SCH6BoHthMaQUNQke2XcYL/7YD/Der24Nfc+eyXm8+KM/wB99/h712t/+5y/x0mtuwR2PPN3yO+594gBe8rFb8KFv/SLyfcRStGwsx85/ve7CZUFGzmA+6i00H0Ut+MhOcMqvye/8690455pbcGi2knq7vUal1sD/7+9vw2/+ww9T9TfiC5NOa5S4K2ixi71dzLLvuHjtP/8PLr3uTlx63Z0473/fijsf3R/Yps58NJuMWk3Gmvd1Lsh87Du8kKqSi88Pc9V6IJDTmtmJ5qN3eOyp6eb/9gjWVj5qrtKn5qvYd3gBALB6aUm9XmozJ20KFkcTrLx1wWlY2oWvbryfH22eD/q/Ffhzm9RevWPVLoG0S/T7t+44BAB4aK93zEq/kw9Ju8RlPpheBwifnJPgsadm4LrAr/ZMhb5n+4FZ1Bqudk8/sq95nxsrNRsebX7usaej7wE6DEq7jJU8fwLTh6ZuTGSm4I1rPvi14sFHtOaj/eCDX5NHn5rGfLWBXYcGl/2Ymq/i6ekKdh6aw3yKFg/8nKYJXpKAB6K9YD6SpHhc11XPEjG9nP2ILLW12atbSl6Xjxab3wXMLCQ3GrPJAjh4gOQ4Enz0DDTomKsnX2tB1S7hbpyH52uqLIqiVsAfKNM+SMrdNO+5piZJuyQ3GfP+pwcxbnlwe4JT7p3SwVLbFswHXbvDc1W9O7HBfCQR/ALcndb7XBZNs2jfwno2AP555YMd/RznXlQliC0GZbPUdnzUCz6m5ozBzmAz+ESfz/n26g1XZz40k7GaHsgB7T9f3meDeX867kF2PeXXLmlK0zWuUecFp97/ecf3+eimvXqS76o1XLW/Lzh2ZeDztE2ezvAZ8HDmg7+/kM+phU/SRVmj4QbSO6buo1/KbAEJPgCE6wRsdr/EPCwf8yLUqbmqys8duXxMvY+i2bSaj4ox4CYp9dRMxkKrXfhA31wB1mniihl8WJTT/cd8tAg+mtduar6Kat1V5lZhPh+xBafN1FdJMR/tU8oq+IjI5dsCSPpcHBqXgpdW++lrPrzjW1b2nofDRnmfqfnQmY8c8/nQrxX/epvglLcwSAtadDRc/7vp+Ac5+OD7njSwjzKJ6wT4SrykAvTupV2SMNN8XFxaLjQ/H2SJ8rZS2xi9XQgjxXTBB2e5aH4ymQ8V8Ejw0VvQxa8YlJgZfNi62q5dNgLAm7RszEe7XTf9RlrePiSpdqlozEfrtIsKwpr/x+3GywcOs0FYK2iltp1kPloMnlRPPzVf085bsLGcN9jEHRCoCoOun/L5aIv5qDf/b4Reo7q6hv73VCzCyjAoNqDFeTMdThXzEULzej83QpmPuik41dIuQU2V31gu3UTluq4WuNQartZDpp2gpteIEsi3/GwKwXY70NIu1FiuTzUf/J5Y0gw++HPGj4UQKTgNaW1PKcyk4yJfGB2xtAwg6PXBy9x7jcUdfKhVjv2BU9UullX6mvHmxZ2rMeaDBx/tUYhktEPbSdvVNrTaxVJORxNj3IFXlUw6fr42rmdIp7raJrVXp2tXqTU0RiFM8xE7+DCuXyGh/bx9m/51adW3oVL3mxoq5iPGtaF7IHa1S3MMWzYSg/moh2s+THt1/j7zXPKf0z5fthW+9p0DzHzwa5c07WK6vXartwuvfOqGCzBnPuJW91HAX8w7ip3QmA+j/BxooflgDtYcaTpoA/7cMFrMY2LU/jzSfFDI937q7/0e9BB+2sWuE4iqdlnTZD52HprDdFMYxIOPdhtfcc0HkOyGrBoiPxtsinZF2ccMPhoq0ofWICwO2qGGo5Bk5TZbqeHAjF/V8PS0Jxwu5XPa6gUARktNKjSp5qN5/cIcQJNgIUbwwY+X3p9I82GUw4bBdDgdHwnRfBhBLgX8jtOsdmFCXP5efhuZ5xLw7dXTOpzaqgD4s5Kl82W3wQOnpBNYz5gPx+mJz4f5cxR4Gw1b8KvYwNhdbYMaEYAZGiYcF4nlGi3lVYM683mshbAtvUDi4OP222/HxRdfjA0bNsBxHNx4443qb9VqFVdddRVOPfVULFmyBBs2bMCb3/xm7Nq1K8t9zgz1EIqVJlWbdwU9zGubzMcvd3uVB6uWlFSAALRPC5sK/ySNzeI0jbMxH/SdSTUfedaRMk2pbdwKkqTbbbU/u4xa+qeaVUtmygUARovJ0i5m2ixpKbINXMcRpvuo2YKP5ufiTNT0LMRNuzgq7dLUQIXQvPQzLazpfqFxt2EEH5rg1DiXgN9BOnVwb/iD1OuuNmkPsuajHT2VedydLHvlGp98rstdbS09h1qBnqdSIWetZqxHMh+WtEuI5oP0fUlZq1nGfIQ+j8R8DGLwMTMzg9NPPx3XXntt4G+zs7O477778IEPfAD33Xcfvv71r+Ohhx7Cq171qkx2NmsQxWhSrIr5sEwYNPmvm/CYj/3NlTPXewDtd900Ff5jCSY/fqOHUZg1S4DiMx8xNR9MdJhLGHzwvG62XW3j08Zm/wRiPsxKFyB5V1t/tR7tAJoE/LqEMR98+/R+ur/jpBJqhvg4DCbFTGkXU/PRMFIptH2/J4wf4IdqPmr6uQR4cJ/ufC4Yzqi1hqtN2oOt+UjPKpoTfydLbXkAoFW7dNFeHYh/D/HWC6phHLtPeIdegu19BL+3i8GyFpMZGhLmGPMxHvI8+mxL75MehaQf2Lx5MzZv3mz928TEBG6++WbttX/6p3/CC17wAmzfvh1HHXVUur3sEML8/QPVLsyMiCb2NcvK2md4ygXIQPNhGCuNEO1frcN13cga7eSltrTaTab50NphJ2Y+0lPDUUjSWM50EXx62gskzUoXILnmY8HI59o8Y5KCXxdb0ygA1glUMR9JSm3jVrtQqW2T5o1b7eLbsvvva9VYTtN8qEE93fk00yq1RgOu6z9Tg6z54MeWuNolcF46GHywbedyrJdWl9Mucb+Pt9GwBb82wWkcnw/T5jyJrQKHCj6KPO1iMh/9k3ZJHHwkxeTkJBzHwfLly61/X1hYwMLCgvp9aircQClrqJp+YwCjSdWkynkkumZ8RPuMGXyU2s5J6/tAk5/rehMb3aD2z3L62P5g8dWF722QTPPBacakzEc7XgRxt9tqf8y21ZR2MTvaAmm62urXT5XaZqb5iJd28bxLmgxIjIna976IF3w4JvMRqfnwdRVmN9yotEvFQk+3G9ybz2Wt7qLBLvtiTbuYzFzSrtBJwLet26t3O/iIy3xYNB+WahdOZJSL4V1tbb1dACRys+aYs6RdwkzGem2tDnRYcDo/P4+rrroKb3zjGzE+Pm59z5YtWzAxMaH+bdq0qZO7pCGspt8UnNKAyW8GKmUimGmXUruDo6n5YMFGqwlQt1e3fz+vSqFBQBlUxTUZszEfKUpts2wsl2TwNJmPp6bDNR+8q20cdbx5/YoZp13MSZ6gBR/VhmaMFE9wGk/zQX9WgtPR1swHrygh2pcLlXXmw9+GeS75z+0+XwQv7cKC9gFOu1TbSrvED97bhcZ89KirLRC/tJd3L7dZKfgNE5k2KULzUbMwekAbaZeKn3ZRzEeIBivf46ZyQAeDj2q1it/+7d+G67r49Kc/Hfq+q6++GpOTk+rfjh07OrVLASifj0Ce0/vfrHbRSpmaJi6EsLRLasGp0UwrifNdHObD1tulmlDzQedJ82uIzXzoaZe45W4ttxsQnIa/l5gPetifjhCcjjEx8XyM4Cy02qUdwWkc5oMd8EKtbvX7iIJvOd5C86GqFLzfifkwPUgC1S71KOYjuH3AXpJI+o+02oyAzqvRiPXcDAJ44NSu4LSTwQe/xfLc56MLgV8q5kNVu+RY8Btk63gsobov29IuitEzK+so7ZLMXn2WpV3GQ0rf+6napSNpFwo8nnjiCfzgBz8IZT0AoFwuo1wuh/69k1D26iYF29AnDjIg4oKepaUCHMcvCQwITiOERnFg9gYBPOe7Sr3RMk1hM74xYat2MTu7tgKdp1yatIvx/ZV6w6q1SIpEaZcm8/HMdcvw0x2HGPMR3A+e5pqr1rXKJhtMh9pCBu6NuuYjXqmt5nabwGSslV+Lr/kgh1P/eTg8X0N5abM1gVFVwDva8s9Hm4xlLzg173Ez2BhkzUdUL6pW6CrzERCcNtmEDpf3mt8dlz2je6Jc9BeCfKzlHXoJUSZjfiAQ4vNRSXYPknB/LKrUVvl89D74yJz5oMDj4Ycfxve+9z2sWrUq66/IDLa0i+v6NPUIq3pouDrzkcs5ymIXADau8K3VgQxy0hZKjpzvWtFxsUptLUZkiX0+eDvsNkptAWA+4YMWd7thaZdKrYG9U17zsGevXwbAZz5smo98zlGvx1mRmILhQgZdbRe04KO15qNisBCxql2a72lVcUBfQ0FnLudgaSkocjODzGC1C7NX55UxluAjU82HZZIdlmoXfk6SO5wG01GdAmfXcjmHCU47e+5dI9CNy3K19vnQA3J6L+DrrzhqYcxHQnE7gd4/UmKaj4X+dThNzHxMT0/jkUceUb9v27YNW7duxcqVK7F+/XpceumluO+++/Dtb38b9Xode/bsAQCsXLkSpVIpbLM9gSm0BPRcMzWWA7wba5bl1ABgfKSIw/M1LCsXlKMcoW2TMVZTTohrNKY7nNq/P4r5oPx3q3Is2nQ+Tamt8cDPVmuYQDHk3fERlzbeMzmPhuud32NWLQHgswm2tAvgrSgqtUa8zsLkylnQ0y7tCBljaT60tEtD0+/EYj6a56vVdfQHWv+18dEiDi/UNFaGp09qrKKlYKZdTOaD7arqk2PtaptucrRpPmwVNoMITXDaZm+XjgpOm6eY7gUabxqud9+YRn+Zfa9xSHHZSF5qW7SM71wDR+Bl+ya7W1UsRIibctK0SyWYdgmajNHz13vNR+Lg45577sF5552nfr/yyisBAJdffjn+6q/+Ct/85jcBAM95znO0z91yyy0499xz0+9pB2Caa/HXAH2wqzdc30GueXMQtWWmXAA/mk1NC1tcHeOWYMVyONUmhaDIsBIr+PAnoHZKbYHsXE5VmXTeS1GF7c+Th2YBABuXjwYDR4vPB+Bd90OoxqJDTc1H1iZj8apdkms+avXgvWCDcjhlq7xllnLbAPNhaD5olWhar7cqtW03uDefy1q9YRW5DiI4o5DUwK+bJmPcJwjQUwHVRgPlXPtpWOv3GscU11dENxkLLiai7NXp83rwYddfpLVXp/lprJTXSt+5NYOtk26vkDj4OPfccyPFgVkJB7sBWuVVmpSY4zjaoMeDj1qjEWQ+mpOWKTYFMjAZs5QXxi331BtmhTAfloCLv1apNTDWgqjiaZek9urmaiMrrw8aLMuF6OCDNwMcD7BW9kHP72zbekViVmhkLTgN03zw87pQNTUfrb+bPu+63n0R1nqbrjP3m7GttjTmg10PWnnR7W0yH7acvLWxXJtdo9W+NVxd5DrAgtNKO8yHcdydNBkzu8AW2Wq8VndR7pARhDkmxGc+goJTfq5t9up88RimLQyrdpmLWXVIoGs9wkptGy4wU6kriUA/pV16z730EHz1betpYTIfcwbzMR7JfMRfmR2YqeCfb31EaRAAJlgs+DeJf1OGT36u64YyOYQGK78EgtUuQDzdB89xFhJOrqbfg22QbDRcfPZ/tuGnOw6Fbsd1XXzhrifw420HvO0aE5UZDN3z+AF8+Fu/wFd/4lVVHbl8VK3YCWZTOUKSFYkpGC4aTbN+vO0AvnDXE4mCdb2xXAzNR13XfMS5F/m9E1XxojQfSZkPumdMh9OG3ljOdf2FjCne5T+nZRYDK3zDXp3u//lqHf9y+6N49KnpVN8TB5NzVXz61kfx5MHZTLbHFxFRKcKbf7EX3/qp3vqiq8yHMQZozEeL6zq9UMNnbnsUT+yfUa/d/dh+fPHuJ1p/b0B7kYz54JqPik1wyp4Jx3FCRadh9uq+4DR9tUuZlQPz59E/572f+nu/Bz0Ej3jpZuc3Jh/saiz4IAaCjMaOW70ksG2b938YvvqTHbjmpodw3W2PBvanaEm7RNH+5mBh+37z4bM5vcbx+qgz5oOXTMYBTWw0Ydkm9Hu3H8SHvvULfPCbPw/dzi92T+EvbnwQf/r/ftbcrs982Pbnz254AP/+P9twzxMHAQDHHbFErdgJUWkXIJ6Iz58w7czHn379Z/iLGx/EI/viT2q65iNGqW3VSLskcDg1fzbhN5bzX7P1k+BMoq3aJc99PgJ6A32/bQ6n2fl8NKzjwXd/vgd/+5+/widu/nWq74mDG+57Eh+76Vf41Pcfaf3mGNAN/MKrot755fvw7q/crzVXNCtNumGvTotwvhpvNW7+5892Y8t//Qr/yM7Zn379Afz5DQ/i4b2Ho783ZWWTpvmIEpwarILy+jDGjbAUSLtdbcdKeTiOwzpN+/dAmKV7L9Bxh9N+htbFsuYCJaPZkeNNqmSORJEoTULv+o0TcOLaZbj0zI2BbScxQaLBetvTfhRvo5rjON/FEVyGlaOaeoFW4Pbq+YTVHPRdS8sFHJqtWpmPfVNe9clBNjiaoHN2YLaibZecBc1Aa7I5ab/+eZtw7BFL8MYXHKWcTQlhgtPRBA2fzOtHaQbaPxrww6pWbNB8PhZqVlGe6XCalPmoWdhAG+g6O1bmoxZ4H/0cdDj1/tYwmA96fz7n2E3GlMNkusnR/Fyt7mrHTt9J90tYsJcF6F7gz3870EzGQhYRc9W68qvZfmAWK5d4OVaTBYibRk0DsxeK0zQaqxrXwgZ6bg7O+mPD/map/FOHF3DC2mWhnw0yHzHTLlX/PrQFH/69rX+uXMjjMGoB5oPeH1rt0kZXW74dPl6Zz18vsbiDj3pwVcgHS1rR06BJjMNI8+KumxjB5S86xrrtJDlp2g9u922ajAHxVNDmoGqbcMKar1UttHMU6lrwob8WhUbDVf4oXnQ+Zw2oiC6MCrbonM1V6loJna0pIOCvqP7wpceqAco81laajzgrEvoe3yTOF+S6rqsGliS9Sfh+ui4wU6mp1Q1Bbyynaz7imYzpGo0w0Gnlg5iv+QhJu7iuSnUqnw8mVA4rk7bR037OPSPBacPVjp2ehSR9cdKC7ifTcTct+GQaxtLxiW3nwTk8Z9PywGeB7ghO+T1UyOVQrddbBgR0rfhxUDAVpocimONfXEdV5fNRyLPgl6VdQipJfKMx/Xvod/P9SVs5EIjlIobctp2B7mo7TDDz4wBf0XmRuKriqLO0S0RfFUKSnDQ9SDsPzfl5bsuAG4eOM7t1xmE+zK62QMLgw0kmOOUrM5V2sTxotLqJ6npLA/ZCraGda0qdmKWCKqhjq2hT89GK+YgzKAR9PvSmZXR+k0ye5uBlG2R1kzE97RJLcMquTVQgaTqcAtxi3S44dV3/vs7b0i6uPfiwBeK23hpJYJ5L7kHC/646AnfQ94Oe5z1T85l4XPBthKVdeFCy85CvNTErPzqadmGaMULBUkViA/2dzl2t7j//rdhEM9ZI7PNRzFmDXz+NFJJ2Scp8JPb58LZPQYc/X7C0CwVIfdDVtvd70ENoRjM1XfNh+hDUGg0/7dLC3RJIlpOm98xW6jg0W9VeswYfEZqPYLdOS/BhvOanXfiqufWNz0vl+Mq+5efYe8YjNB80ic1G2K9ztmiaTXo+86G/36YfKBfyWsBhMxkDkq1ITEtw/rDz/UwyeZrXxCY6NY2yNJ+POMwHY2KiVr2mwynAmsuFCE5pnwB/kgmzV/e+o/kZq8lYxoLTRkM7dgqSKE/fyeoXosXrDRd7mOg8LeJUu8wazAehF11tOfMR17+FAiw6Pj5+mM3UAp9NyXzomo+gvb+fRtI/5wtO7ZoPU3CauqutIQuwaQT7qavtog4+bDSrGY3TRWowe/WojrKEJDlp/sDTSt4PPpJVuwS7dbZOu3jtxHXaOTXzEWOw4t9DE5btQSP6vm5Q4hycquaDjmI+tJW3aw3qAGjltmHMx0iCFYlZ7cIfdr6fcel8fg7Il8RmNBal+YjFwlm6Hdtgq3ZRaRfOfBhBI+0PaYR8xiy4yjbTgfxZyKpxI6FWd7Vjp+eInoNOpl00FuJg+6kXs2+SDXMa8+F/p3mc3WA+9LRLTOaj+Vk6Dn48rfQ5AeYjZurT2tXW0tslIDgN6WwbZjJGi5yFWiPR+TfnJ5tG0Gc+JPjoKXipLQ3MvFma978vFJxlauJWSCI45YPekwf14KNsE5xGRMRxSuVsglPzfXGqXXR7dV1QGQUeoFD9uS03zSfpsGPWmI+FIPNhlnrSXGiW0/LUSzkkuLQJuMIQFJz6Dzvfz7grd77CWr3UEwdamQ8efFQbgWqXVqW9WrVLxIrQrFQAwPpJMOajbr+vAg6nFsFpwwg+bF1tG2464zaz4WNYtUua9FhSaPqLDHQfmpC+7lrHIP6dTx6c094PeGlnc1tZw9YLpWh5bm2gAIueRX48SZmPuCZjPGVrG9+VhiUk7RLUGTWD6hCTMQCYj9nkE9CrXQC7RjCsn0wv0Ps96CH0wcb72byBlH9FPehwGoUkja9szIdZqgnEW3kH8oqW1av5YHt26gY9HmO/uakOr1poBRo4cg4wVg4PqDh9bzvmybkqDrOJnL/f5vPBVylmaoWX20bZqwPxSm2VJbhRamvuZ+x8MxuEVi8tB7ZDiOpq68aYqLWePxHvdS0Th+onEcl8NLTP5VhaM8za2zyXgP5cpNFj2IJ0vatt95iPsBRIWpj7artfOXvKA56asejppL067SafrE0/nDDQczNvYz5aaT7SVrtYSm25OZ1ZvUMoh6Zd7MzHCBO8J0m98Man/H8r8yFpl97CbMIFBKkzv/GVG7i4UbDlBMPABwsafKyC0xgr7ziltqa1uesG99OsSbfBdyjUGaJW4KKnsaK3WrbZQHP63hZ8mAM1TXqFEN8RfoymyIszH2Gaj3RpF29bjuPvE5+c406cFTZpU1mkbYUXTLvYqd4wcJ+HqEE5qtQ2SvOh0i6OIThtWNIuSnzdPJcWh1P+9yQIuE3W3cC54/vbScHpfEgKJC0C7sGW8YLrAA7P19Q1o+tP93o7XZhbwZamKMTUfHDBKa8eA1qnXczbJW5gaXM4BVixQivBqcEm0+fMFEgu56impnErXqr1hjpnNKaOWjQf5HGSl7RLb2Gr6zepQG4OxRv3tEKSnHRVYz485bkSLFrSLlErb/OhtVGKNMjylaQZlcfSfGgmY95rcVZKvNxrtOR90FbRwgcRm2rfHKhpMtbs3i0VTY4TXJ3omo+QtEsKnw9+/QqW4CPpwFfK56wlrQTTIt+8rq0map35CH9vlOZjuulBAgQDCsV8GFoY014dgEqR2VjAYgI3TBtszEctkvno3CQcpr9IC/PYbMGy+TxRIE/ngFbfHfX5sKQp4mo+aAypNzxn2nbSLnFTS361S956/ykmJ8B8+BoO2zEULSmQJIaG5vtGmmOqWqxaql1s39lt9H4PeoioUltTcOqZjMVnPvycYBwmIFzzoTWWizH5JTEZ406e80ZUntReXTEfCY43n3Mi2Rw+iNgewp2GHTVpIAo5R5vUCFxs6hirk3Gu+cgg7WKzBPeDD552iRt8NCnfYs5q5kUwV+/mir11CSPXfMRJu/iv0X65LjDdnNzMycvUfHCfDzNwNQWn/FkgQ6o4x2RD8DlpaDoQOg/K56ODzEfmaRfjutmCD/MeVsFHQx8b2mmE2Ao25sNPZ7QSnPp/n680kqVdjE3HLW/mzT755K1S9mxc4whNu5DmoxBkIZLoywCfIck5/nOixivNZMy+j73Aog0+uPgQYKW2RrkUL7XtquZDiexs1S7hN2SwW2e45oOv8M1txqGZVXv0vKNWL3GYDzrHxXwOo6XwUltN82EpLzZXiVTCWsjntEmNYJvECHE0H0mcB22CYaKUealt3JQBBYflQs5qY06I8vkAWl9XzbExYdplpJhXQTexMkEtEVW7GA6nFuYjEHwYg3Q7LqemuVu1HsZ8NNMu3ap2YV4/aWFOprYJzHzeTK2ZYj66YjLmv+b7fLTSJvl/n6vW2yq1NcXHYeALgBxb4JjMh5l2UZ4gISlQm/gzqcW63/qjoJ7JEZvmQ0zGeo/gDWikXSgnzSYxs6ttFLjDaavBhA/4h2armFmoWalmWyRrIqxzovYaUasa82GmXWL4fGjMR/JSW858mA9Zo+FqVSGx0i4LTPNhMT2zGYwR4mg+KFCKl3YJanYU88GOK+7Eyd0VfW2FhfkwyqWD5X0t6Gyu+YiRdjGV/eMGKxNm8qaYD5YeM1kS+jWsAVdRVREk80PwPhNkCGuWQLWi0i7dYT4Wag08PR3eTiAOzInbNl6Y9zA9S3TNw0z6soTZ1RZgzEer4IPdm7OVmnY8yQWnMdlHtgDg+0r3iFqMhTIf5sIwyI4S0gYf3AYiyl5dTMZ6iKDttncjmF03KRLnjeWSaD74NsNg/n3noTm7yZjK4bVOu9D9H2UyxlflweAjftqFN5ZLYjJWZJoPk02YrtQ0ZipKcErnWqVd8iGC04iHPZbmI0ljOcv1o3uJp13iTpx84IvUfBgunWYQGTWJugb7EOlwqgzm9NfNfQsKTon21auA6o1gYzklOLUE4vz3JBb1BGI61XNSb1jbCyyoiSX+JJUELvMPovu4Xd2HGTTanp3AdyrNR1NwWui84NQcawFW7dIq7WIwH/MG8xG14EtrpMZ9PoCgxX9Ln48w5sMSCCTt7+IvjKM1gmIy1gcICDNrukDO9yHwzarMxj1R4Hm8uFbBhJ0H56yrvZEYNyRtazRCrV5j26Z7cD5Q7ZIg+HBYb5cE9ur5vIPRoj3tYk6sVs1Hc5A+ttlV2K924WkX9r0hK2jA9PlokXaJ1dvFEnzkKEjigtNklG+p0J7mI2qiDrjjRpqM6doogrlvAcGp6fPB0nXmY9JwvT44tkAOaM9oLPCcGOXmpuDUey37iXih1lBBNt3HTxpapqQwr5uNqSM2xPxOOsZuMh98IqRnJG61C+CNh/wYOUttgzlGJdZdGcyH2RHdXNuEdbWthvh8AD7LGjf4oOtJlS6A3SlVTMb6AOaqLix6pQdjvhosZYoCZz5aUeu0XUqDPMmYD5vJWJTzHX0X3bxWwSkTHdHDnirtwuzVkwhOfeYjF9ovxZxYzcFkrlJX9PQz1izVPsM1KLrPR5uajwTVLpVa8Pq1U2rLy/yiNB9a2qVq0XxEDLRxDOoItDA1gw9z30JLbW2N5SwmY/zzZjosiZGfCToP9JwEfT5cbX/5Z7IEv+/pPm5XdGrup73apa5/p5F2GWFBWadgK02NKyIOaD5ajB/a95o+RzHGLNd1A890ifbVWLiaYk4ab7Q+MExzaFsMjVKpbdK0SymYduHbqFsCvl5h0QYfJoUajF51zcf0gj/Qj5Ran7Z8zlEugXHLG49e6a1Cdh6cs1LNnHEJuykXmtuiQMXa1ZbRfXkVXKUQnHLmI4HglPYpn3OsFsBAkPkIE8gtKeWxbmIEgJ/O0NNAbEIJoe8BaN1hW5XapmY+LGmXuBNnhVG+0cyHnjpIknYJ0NER7w3zNKAgLpT5MDQffpAYfG/D1ffXDBqTeOmYqBrPSa2uW/hTl92Kxnx0IPho3kvFvIOjVo0ByCDtYlDrdpMxPfh4erqC+arfTVaZjHWh2sXsagvEMRnTmQ/zGKN0H2Ep9yjUGq7SOdH4UIyddgn6fPDvtLEQqdMuRb5YDbInUamebqP3e9AjhDW8CtirO/pqlZcyRcErBYxX8UL7csxqf/Cx6RNGIqpTCDTB0s1rZz786DdsgIqn+fD+z7HJPom9uiY4bbFyMf9OA/SRK0bVBMJNxnwhIzsmVTVhYT5GYwhOm/taqTUi9RC8T4691Da9z0e52ErzYQhOzTxzxHU1PWHilNqaCyjTYp22QTGK6XDKg0Rbw8MoY7gkFWUmKoHnpBG03a4b9vQdKLflOrIjl48CaJ/5oPNILJQ17dL83nUTI1jSfH74uEMTbLft1WNXu7D9mqvWA8cYZTRmLpDipNP4fUDBRJjgNGivHtR88P23Mh8RVYA28GoXfxtB9iSsHLgXWLzBh6n5CHGp81er3oTBS5lawS8FjBfFH7PKYz6+++Ae9X38xozjfKdy2RHMhyYUbR6fOUmZK+Yb7n8Sl/zTj7CLrcp4qZxN4BkGrjnhrqFcJGauXALBR3OA3rhiTG2Daz5spmc+8xG8fssS2KvT/nLMV+t4w7/ciU99/2FtMNNNxoKaD3NCc10XV3zxPvzZDQ9oryvNBzMZszEbmqmaTfNRb6BWb+Dyf/8xrrnpV9rfgkK88PtWmYyFmLVRRQ/dI6bXQTDtEpwUGkzvYTOGszX3+r93PYHX/PP/4MBMdMUIfUY9Jw17iwGep28VKLqui3d/5X68/2s/jXwfB/cO2riiGXxYmI/t+2dx0Sdvxws+8j284CPfw0e+84vQbdKxUSBoGyt4n6ojV/hBj1kJ106pLd3LV3/9AevfbaWpfk8mz9rg9Z+5E9fe8kjgszWD+TCfx6i0S5L7nMDvA9pHU3MUynxYfD74/ttSILxSZeuOQ3jlp36IOx/dH7p/6j5ixRA2jaAyGRPNR+8QVutt5u3o/6emFwDoZlStEDd/SX9/7tErUMrn1IC7ckkJRywra+9tJXo06eQozUcxH5/5+Pp9O/HTJyfxo0eeVq9paZcEzEeNMx9sQuffGWA+AmkXTyB35PJRdU54tYvd5yNccHrE0jLWjpdx3OolocEHt1U+aExuP981ibseO4D/e9cToakCe9pFP19PTS/gOw/sxpfu3q5XXzB3xaXsHpxZMIyL2PYq9UbgvFVqDTz61Axu+/VT+MJdT2h/s3V6DYNpxkeg+47KpOkeofNgCk4LLGg179WG6wcExVzQGM4mOP38HY/j/u2H8ONt4QM1/4x6TiwN2KoGc9TqOZ6aq+EbW3fha/c+aW36ZwNnPuhZtwVOP3zkKfxqz2HsO7yAfYcX8IW7todukyY2FXxEpF1Gi3msHffSlk8dXlDP5kgEcxoXT09X8J0HduPLP95uPR82jQRnPh7YOYm7tx3A/73zicBnzWqXQNo24vyn6e3CmWgaW4qG5og2E2A+KO1iNHkk2FgI5fxcreMbW3fiwZ1T+M8Hdofun63UdszCntCx5vvA4TT+TDpkCMv7hQlOt+9vTnbNVUIcmKVYYaAb4uhVY7jj6t/A3ql5AMCmlWPazQR4N9TB2Woo80FBlMplRzic5nNc82EEYwEmpNF8H6PwNMFpfOajzoIfPtEv1BrqeAOajxDmg6ddZprv4ekkq8mYJbgoFXL4/vvORd5xQpktx3Fw5PJRbHt6Bk8enMOmlWPqb7SSPDxfM1IFQZ+PGXYs5r3B88Lz1br6PBec5nMOSoUcKrVgcGEG1RTE0furdVd5pgSqW0JMvmywOZzS9wD+BKis/At5ADV1vDT45Zgw2GYypgRylpWaKTh1XVexBq3o6ooRfFQtaZ9KvaFdn1YlvXxle3i+prFpYfCZj4Ki523jBd1Tpx45gQd2TkYGQvQ3YsjsvV18xsVvCFhVn1XMRxvVLvx87Dw0h5PW6efDphsqsIDSf6aCgQQ//tlKUHBq88AhmNc5TurTL3X3x+OSsbgMS2mU8pa0C0vL2sYbrtc4OFtpuZ9mR1vArhvxu9oK89EzmAOvaixnlEvRjfTEgRkAUHnZOLDRwvZ98cWJq5eWcfKGCZy8YUKrwCCMtFBBK4fCCLU6b+UcXu0SzH8Dev6Yl8qpyT6W4NRf8RSYMFcbvJsr57DjVZqP5aOB0udCLmcVwIaVbBKWlgsty6hVXt6gxlVr72pd+bBw4SvtlwlzQOHnnR+zqbS3tcsGgqs4GriXlgvq+2gwCqz0zd8jgg+6zmFsRMWoyFJtxUlwmteZxUYjaK/ecHWWzETRSBkemq2q69CqIsmfZP0Vvnn8s5W67oLcYpKKYu7CwIWCYQ3I+HevWuo1Faw13FAvC3q+VPDRgvkYZ6Z1vuDUOy/tCE75+bDpWEw3acAvO63V/XYWM5V6QIDKx7V5Vu1C40WU5iNQ7RLjGBeM5w/gmiNX22542sUWfNjHIlUmW60HXK9tsDU9HWULUNPHSoKPHqIV85FXzId3inYd8tiIRMyHIUgKQ5JmP2GlqQRb2sUcpPiAHsZ8BBqSNY/Blj/M5RzWGj2+4JR6rNgGXRo8iBIOBB+M+TDZobC0i3I4bUPpHSYK5MHbgWYJsJlXta3eg8GHvx1+rrnPB+BfX9N23jz/dF0p+OCpGN4O3LYv9YjBLqzUlgfcNUvwERScNr/Lwnx43h/hAjnTZ4EHhK2qBOhe0Ktd7KyR+kzL4MP/zlYumwS6b8ZKBUbP1wPPrLm/QPizRouLKM2HxnwwAbPf1Za0F20EH+x5tulYrNUudE0bDcyxhmjc7RgIMh8U8NN4kaTUNhbzYXh8ABbBaXMzAYdTVe3C9EMtGAjOWpjW9zbYNB/8Z/XMq2oXCT56BlPZHxZ8mM6dRy4fQ1yYg2MYktwQYyGmXATTPAkIDiA86qbj4yV/QHD1RdvV0i62UtsYgxUvtQXsanAaPNYu8wYTvpKt1hvY00xNbVw+qg3ItF0b82HrNJsUSpx3SDeC4gP8/hlPH2SuamwTaFh6C9CvsemuGKb9CStR1JgPzqiw9ydxfgxT9vMKFH7uSwV9ALbZq9say0Wt1FTOvXlunmQBYSsXWiU4VQxhI3D808YE1ko4zgP4pJqPkWLeZxvc4LmvqP31M+Vh4wodB6VTrMwHm6z8tEtNHSMF9O0xHyztEsl8BCd0j/kIZ5JMnw8y2aLxIutSW8U8snHVTPuFlZ/b0mmtmA8a0/bPLODQbLXlftqYjyJzeqbr7T9PvZ/6e78HPULAZIyMYozyL3PQy1rz4bquHwXHCD5adbb1q138QSqMZuTMB00KS9gKWd+uG/hefq7SlNrSA2BTg9PgsWbcE+HxyWTP5DwarsdgrF5aDtjdF3JhglNfa5IWrdIuALC/yXyYDIttAjWbWvFgZNbCfNC58t0LjUE55PzTKrhSawQCOf+z0SwKh+9wqr/ORdbxmI9owaltdUwoGWlNfk1apl1q+nNSb7iBNBP39gHiMB+cuUuYdinltVV1WDdiHmiHpXPpvZHMB5us/F5BVd9kLINSW34MT1qYj4aR4gaYvboRJE8aaRR+r86zahcaL7I2GVuwsKZh1S4BzYeF2aXPhI359Hw/sm+afSZ8P23Mh+M4GDN0H3XRfPQeYfluU8Vv3kjJNB/NgThixaQ53cVJu7TUfOiCU8BCp7NgR1W7NCe3Jc3B2GQ+VNrFwnzwxnJA69VS1VjN2ro+kmBsjYX5oElmw/KRZvmxmXbJWYMhenjbSrussKdd+Hkh5sMUttqMfcx7g09gvCGYv/LS0y7mCj9ssuDMB/8MH9CC9uoRaZfmW838Nl8N8kFeCVGNa68LTo3vaAQDVe27DJ8Pfk0SC06NrrYAMG1UErXSblU05i5h2qWY1+7LMH+WsTJjNMOYj+Y5I8Gr2QuKB4ZjxYJmDKc0H5kITuNpPvg9RNe5Unc1PVMgBWYE6TQ+UNolUvNhNICL0jb5x9IM/oucpXG0fWmEiLBtmg8VfISM+aZ3Ef+MDTbmAwh2tuUGk71G7/egRwgyH9FpF0IawWnUiolPFrHSLs3gIKyzrbKNZhNykGb0Hz5T80GTVJgzJh/UbcyHeUw2kJaAPEZsD+dhpfnwVjJ89cb1HgACaRfe1ZYHQrT9MKozDuj67zo0r22bT+j7leajNfMR0Hyw7djSLjRB2dxWeWM485xQeW6VCfnM709mr26nmLnOyRZ8EGyN5eoG89JwXY2lM0H9kyoq7eKnwqLSLrxfzGiE4HTaCCBaC045cxeP+eDai1zO8UuSQ56/ciHfkmX0q13sYwUP5EdKOY35IBaWnsl2Sm214MOm+bCk7gohzIeZRjFNxuh6r2mWK8dJu5SNyqzIYzE62gLB8T2s/Nzq86GqwOxjkU34nlTzwX+fNdIuYjLWQ4SZjJm5bH6RVi0pxWoqR4jTe4L/Lc6kaGsWpG1P5Wz9bZkrNp5rNX0+aGUV1hOET1y2rrZAa4t1X2AbrvmgwZus0/lkwitdgOCDWsizxnJsV6JKbeNi3cQIco53Pp5uer8A+vV4OlRwmqzaRUu7MJ8PwH4f8ImCOx0CLJ1mpF34gBa0V0+TdvFXrrQ/jmPTv9D/LPgwvo6LUK2ajwjBaWRjMcY2cjO+YKVQ+GrbBv3+jcd80H7S9QyreKHnr8TYStu4wt11wzQf9CyRW7PqxzNXZcxHuGA9Lvhk+9ThhUBAaPP58LvaJtB8sLRLEsEpnfNYmg8W/BHU+N5km8PSLrautj7zES04te2DDcRumZ8zGVLpatsHsNX0A7plOKBfpCR6D4ANjhH+APwhihN8xDUZKxX8wCKY4/S1D2ZvF5/5sNO+evDh/Z9zHO08tWI+aiz4AexqcBq8yXhp1sZ8NMW/Ns0HzftaNUcGzEcxn8O65gDH89j8ehwIEZxaNR+xBae65mPMUvXEz/tSRs+X8n4ZZ8VIu1TSMh8haRcuAuWBvClMtTEfgd4uDd9kLFrzEQw+ojs/8yCNMR8G82JWWHRC8+HbYnv7UbKwgICfTi3mc5oo0wR/1imdYmvK6H2n59bMewWpEmQ2yaYlP8wAapfBfphjLcC72urVLmYahV+rqfmqOm7SfMQptVV2BHE0HxHMR9jClcDLzCmQa5X+sC1yo4Ik1dXWTLuEMB9S7dJDmBRveGM5/xQlSbkA9m6GJughstlH2xCW6ydUePChVhH2SUXvaqunXeoNPQdOA7Y97aJTja2oWr/UVk+70L7PV+tqUualtvTg8r4ugIX5yDnapOYfg796bAc23Qentvc3HSpNp9SkgtN5S9rF9Png7+HBAhccl5gza9UwJtMFpyZDFq1VAmyltkHBqcmMAcHGcg03eN/w16zBh2IWXcws1FRVABCt+eDPo28y5gc6xBpGlXdat5uC+SBdw6jBfIQJTov5HHMBDe4Pv4YUVJhjhcm2qFLb+ap6zjlzmjb1Yo57ZurFlnYpFvzAigeQ/Hxy5grwnzcgGfNBix4z6LTBLHXnP7eyV+efoXPCXaZtsDEfUYtYW1dbvh1eXg8MaLXL7bffjosvvhgbNmyA4zi48cYbtb+7rosPfvCDWL9+PUZHR3H++efj4Ycfzmp/M0OYyZhJBfIIMWnwYdrvRu1HHLEpwNu62x8u3g23ENLm3vf3Zw6nJDgt+5MWPSg8R25Lu5jMR0vBqVFqW6K0SzMAooHDcaDZy9METIMY9cIo5XMa/V/IOypo5II5mujbYT4Ae8WLrdolwHwk9PmwpUeC1S4s+GDbWsIGoXIhp7EEWrVLLRic+b+HX0e31Sqv3tCeJfPYbaXsprjRK7XV7xUO7v5qTmzRzId/nESj1xsNdbyUsgoEHy3TLv53xjUZMycNn6K3az6KhRy4l4oJfmzcZIynTky2ZRnTA800j5mnF9IGHwtG0GOKTq1pl5y/YOIBZJTwklodFHIOVi3xTNjmqvXQcdfvN5SA+bCajDU1Ry2qXUwXZ8BnspKkXaLmkdkQzYdarBLz0aLKpptIPArPzMzg9NNPx7XXXmv9+zXXXIN//Md/xHXXXYe7774bS5YswYUXXoj5+fm2dzZLhIkwa0b0ym+k5GkXXRBnQ9KbwY9k7dvkK6QwYRqnsv1SW+9zfNKi18w+CgSej+fRfkvBaUMPAkzB6RRz5RxjD9NspY5Gw2VpF+96OI6jaRy84/J+5oGQCsza0HwAduaDnxfSgsTx+Yh0OK3YmA/vfIxZBKc686EHH1yLoft88ODFrg2ywXc41V/3U40m82FngXxtTjDt4ibQfERVH5ngZnO+wNEPdOgZM30+WqZdLCZ5rUDP8Zip+QikXZrXP5/TJmgT/FmlTs31hqvt+7yhD1hSKqjg3e/twpiP1JqPeMyHzV69Une1IJmfz7D04Ggpr5hbIDwArCsX1/AgLuxYeFBmmozVXXvwoVUxVXXmI0naJarT+LwRUBJGjMVq1PPUbSTu7bJ582Zs3rzZ+jfXdfHJT34Sf/EXf4FLLrkEAPD5z38ea9euxY033og3vOEN7e1thuCeD1XmbtgwLo6m+UiZdonFfMRcjbd2OHXVdxdD0y7NY88FNR/lYh6FnINaw1U3u+kmSLBVBtnMosL20TcZ09XgNGiMjxRRyOdUs725qmezXKk3kHN8MSrgMQG0Ui3kcloJp/+9/qTTDkhrsjNE87EQEuTYqM6A5qManCS8beqaD2vfBlbFxMuPy8W8NlDqJbzhzEesrrahJmO6R4c52Kl7hlUlBZiPFj4fPMVD+pvxkQKm5muxmA+vsaJfAkzMxpKmXuZwIO0SfV/rJnkJ0y4BzYe+/6o1QMFh/U+C+0OLmZyjs5jzlYaaOFXapfmduZyDpeWCVqHDzbRSMx9m8HHQ1Hz4aVsC9/ng9yMPJMKYitFiHoV8DktKecxU6piaq2JlkwnRvtfVA6xYXW2NUncgmHahzZhsILk4L9T8XkE1Nk7bUC7k4DiIZe/vun6/prBqFwpylc3BsJXabtu2DXv27MH555+vXpuYmMBZZ52FO++80/qZhYUFTE1Naf+6Abrx6eIo6syIxttjPvyBOAytcn8m/JvJHtVbmY+QtIut2qWQcwJ556pl1QTojeW87UWXAKrPGaZqZrULrXKIDuYBF00y68ZHtICNukDSMURpPjrCfFgmO1NbwidgWqGZFueciZi1MR/F8FLbGjuvPM/sMR/+RB1mMmb6HUTR0W7IKo+zEXyVFdB85In58H5v2VjO5vPBBn+6FiesXQYgmvng9wHtBzcZI71MgPlIkHaJXWpr+DMk0XzYSkT55OKlXr33zrLxQqVd2ERFFS+EEXb/pNZ8NI+BUiGm0ZjN4ZSnisNKbcM0GqMqjeT7ltjgl9o29T4trivANB9WkzHXOJ5wfRKlolqZjDmOo8Z62l5Y8OG5CXs/m5oPkyHtJ+Yj0+Bjz549AIC1a9dqr69du1b9zcSWLVswMTGh/m3atCnLXQoFPaRE1wdd6rz38Yu0MYG1OhCv1NZfrWbDfGiCU7aq4yDascDtd5W9ei6Qd+aULc8fq5ytE1zFRoH7jNC+Av5gxZkPwOhzYHh8EMaY7TQ3GbPZq7ctOGWaDzoXtskuymSMPBgAfTDlzIe9sVzTXt1yH/CJmueZS4Uco5gjBKcJql18vY/+Op88wzRBAKt2ad4zrkVw6rrRvgS+p4jfzfaENUsBtEq7+KtOXrZKx0+TcjuC0/jMh54CsZWde9/tM6TFkOcaYJVszeOyMWQm2wIg0MSylEHwQePHcUcsARCP+VBi2oYeJMdlPgA/3RQm+vWrXUhwGiPtUtWDf8Di8xFirw4Er2sc4ScFDpuaY10Y8zbPSpJDmY9KrWUas9voOfdy9dVXY3JyUv3bsWNHV76XjK7oAQwTnNKqfmm5oG7quOD57zC0ioBNmKYxJnzBqcNWdcZAxix26T30/BXz3OgoqPng+WOT+SjEZj70FY+ZdqFBg843j95Njw8Cj/gLOUcNAHygysJkjH/39EJNlVTagsGoUlu+0qxa9hEIMRkz0y4Wt9JC3tFy01zzwbva0u+EZL1dvP/NrrY25iOy2oW9HnTiZYOl5fngg//OpsHYM5rBR5TPh8YisNJOOiZKuyQNPjR32mqjJVMC2IIPWiHbmQ+uU7FpUPx7IJwhsxlSLRvRxzbOmrSbdjlutXdN9kzNawGurTSVxp5a3dXSgzyQqBmaDYLJfITpboKltq2vk83nwxzfbQJagqnl4XYHYaD9O2b1Em0fTBCrVcw7gTGHX3/N0HIQq12isG7dOgDA3r17tdf37t2r/maiXC5jfHxc+9cNKJGSMpppUmdG9EoP4JHLRwMDbSuUIgYJQlrNx+RcFfc8fgB7p3Qhrz6w2tMu+qQQXJ3z7ppAkAKmSLtuMB+2firqM9U69kx6+xowGSvqAy6tGmkQ4X1MwpiPUbYi4YyOlfloM+0yWsozKtmb9Gwr7ahqFy34YOc3tKstaXIifD74qqaspV3yCBOcasZHDXPy1393XRfb98/Cdd1ADyT/mP0AtMoqVcyVVs64Z4Dgfdba4dQ7pgMzC9h+QA8+TIdVDls5Om8KR2kXk72g/Zuv1nHvEwdwz+MH8NCew4r9MnUa5ud3T84F3hPu82FoPljwGeXzYaZxbQwZ5f815sNIu2j9kQwtzqNPTeOex73jNwM0DnqeN64YRTHv6cH2HvaN+az26iw9GFrtwlxY+X2umA/mW2KDCj5YI79WbK3d58OodgmxVwf8MY6uY8UIEm2g4zlm1RL1WbrXDs9Xsb8pbA9zN+WvzVV0E718m+xvFsg0+Dj22GOxbt06fP/731evTU1N4e6778bZZ5+d5Ve1DdXbgOr8w0ptm5NzUr0HEK+rbVLHOdrf3ZPzuPS6O3HONbdoTptKcBqRduEdFc3v5ROXTXAK+ANmWBM+26D/h5+7By/+2A+w69CcOuZ8qObDGzRMzce8xnzoKTBe7cKZD13zkSzQi4Kp+0jKfCwt+xUGPDjlE3BUtcuIlfnwJ3tOD5cLOTVRV2p1K1sC+GW3FGObNO/1dzyOcz5+C/7jnh3MXt04ZjY4kz4ob1RDAf4kw1e9pjbKaywX/nzQKvnBnVPKVZaCD/79JqqcHTTSjoBf8RUox2/+/tb/ey9e9+k7cel1d+LCT96OG+7fCSDIVnDdx/b9s3jxR3+Ad3zpfu09vKstEFHtwhYVxSjNR02/x20MmektAgSZDx4w1tl5uP3XT+Hlf3cbLr3OO/5LP31HYB/MfR4t5bF+IqiTsjEfnIkyq11o4uULLB5A0dioHFtD0i40HvJnpJXXhyn4BiJ8PiyLVNM2Pw7zMdbUhR3bZD74vr/62v/Bef/7VsxWaqF9Xfhrc9WaJqwdyLTL9PQ0tm7diq1btwLwRKZbt27F9u3b4TgO3vOe9+Bv/uZv8M1vfhMPPPAA3vzmN2PDhg149atfnfGutwclOKW0S0je7jdOWoOzjl2JN73w6MTf4WsZwqNqyjfGnRBPXLsMFzx7LY5dvQSlpoL6V7sP+9uzlRGawQdbkdoEg2YwYK5IzbItmljCmA/XdXHf9oOoN1w8vn/GL7U10i70PTTokFpfS7uEMh8s7cI0H1Z79QyCj9VLPf+RQ7NVNBquXfMR8LbQV2m2hnq2tAtvLR9V7aJpPvL6IMnFcaFpF6OjqXkdH2522PzVnsOh1S62ssLIahdL2oU22Wih+Tj7uFV44XErcezqJTh29RL87guP0tJxoalJTbwZvAZhLRRo/x7Z6z1vpBmgzqMmw8mZj237Z9BwPdaA0Gi4inHxBadhmg8eMIVrFcwO2XbmIzhZcc1HKZ+Dw1xpOfNB9wAFaL/aczg0yOMT9kQzIJhhTImN+eBsAj8HNXauaiy9yJ97CuBoIRJ2/Sno4RVhcSuZStxe3XCwjky7kI5OldrqY6ANb3rh0XjxM1bhgpN9DWW17rEfjz41g6n5GvZMzsdkPuoa89EPwUfiUtt77rkH5513nvr9yiuvBABcfvnluP766/H//X//H2ZmZvDWt74Vhw4dwkte8hLcdNNNGBkZCdtkT6Bazxv+/jR+0A10zOol+Oofp2NtkjAfcatdCvkc/uXNzwMAXP7vP8Ztv34KOw/5DbUWuJI/Z18h+cxHcFIo5nNMmd2C+aBzZaSozFLbQ7NVNRDMVepq0AwrtaVKHro23FArVPPBgw822Vl9PjIIPngzrrD6ezO9w6/xaMlLhcxX9ZJCm88HnxhLKu3SbJceUu3CSyXLhRxKrAlbmOCUBuDRUt5q0kT7MzVXC+h9/GP0j5m+J++E+3zYgo9iziut5mXbtgF9YqyIr7w1+GyOFvNaszETOjsY3K7NqGm24p8P6qNxzglH4L9/sVfd2wHmY46LJBuB98yz1AoF2H7K0wg+GKMRVe2inu1cBPNh6QPCBdCKlbJoxog1eeVpG/Dtn+3CTPOZPP4In3Ei0LFywTNPJ5ljrffd3vvMSiPAe9ZGS3lfJ5fLaewFHU8rXZzZWA5orfswTf6ApIJTO5scpfW79MyNuPTMjbrTdM1FzvF/n5rnzEdwOvdNKXXNRz80lkscfJx77rmRjYYcx8GHP/xhfPjDH25rxzoNs/tnw/VuwDpjBdpF0bKyNWEKxJLApP69plJ+MBNqMsYEnzY63BwozFWBalJknCsl8jS+z/TDqBt5afPB9HtP6IPJ3sl5lWM2gw9ursNpfr56ryQM9KLgW1LXtIF9YrSIyabQLcpkbJS1UNcFp8FJgr+mmI9mabEWfLAqojDNx2ylpp8TrbGcHpCbzAddl8PzPgVuPibEptUbPsMSx+cD0NMhlXpT81H379W4GGsGT2EVLzwItQlhzaBxabmgBR90XKuWerqfect1AnTmg65xmIkcsU2tutpyzYfVXt2Y1GzaIOWGGaL5MK3v+ddw1uTIFaP49d5p7DwYEnywVKEtqLKlXejZ5HoN8m45PF/F2vER5tCsMx90rK1aUNiCj9bMR5PF4dUuxvgeVWrrO/9S2iU+453POcrzo1JvAGzzU3NVZhoX3BZvw8A1YUn1i51A7yWvPQJf5fHX6EGzRa9JUWLiqfD9SKb54KAJmOrnec+DEqOUg1UMwZw3oZgPaj6CaZdmOqC5WdOK3py0njT8MKrGhGJSzWYenAaTR5qU9eqlwe7C/PdCPsd6hmQvOAUY8zFXVWmoUiGH5WP+IB4UnLJVWilvnUQqlrQLnRfPptz7TFRXW7PUtlz0J6xJo+EZTxWY7pbmfUP7MzVfVWkX01DJO+6miLPmBx/BSd77Dk1wyhgJwGOt6PoleT5adn62VI74+54LXLelI35H4EbDN99byay8gSBboVVoNJ85m31+ueAvAkzxNYG7svqeLba0i38PAHZtkM0Nk2s+6PhtXjnUaXaslLe2GbDtM7f3N1MpgJl20XVqI8UcJprPFN27XPPBj4Eq3lrZEfB0T5gRowm7w6k+vkeVsZaNFhJJxn3HcTSWxbTxj6f5qMdiW7qJRRt80Op7lPlDeGYtyQe7MJi0nA1+IJD8Umw0mA8+GGnVLqbDqcVeneBNXHr5cRj97uc4vdfzFpEnYGM+9HNsVteYfQpoAKXcus1p1ky7KPMqLjitxV9ttAKtFA/P17TBXMudRzSW45oPPiDbVsY2pT2lXXhVh28wZTMZ834PdAe1OJyqEsSG/bofnvfZE9sKir6L3l+IYD74z/7g6H2+3kLzEYa4XjhcP0HgzB9hWVN7ZFYKrRjzgg+VdqnR+fM+b/OmsDUO5BOoevaMZ853OOWLiuC4wtkjwJ6CoPMyoqVdGPNBaRdb8MFSosS8PnnQT/tycLbApmUx3aTNnwHvPh9XpmHV5nH7bDE/hkCatgXz4d2X4ZVD2rGwFBKBe+d4FWDe6yabzN9r2hfEZbx9fYlewj01X2WaD0vahV3/KMO+XqA/9qIHsHVv5N4EthsoKeKYjFWZ/iIpzJUHH7BKhXDmg9+ENubDnBTNgdB0yzPLJoPMhz84zbHcIw1yvlmU9z3moEyTybanZ7zjtlQe8QG8kLOL5TrCfMxX1WpwtJjXVpCmsFULPkr5wMoJCJqMeU396oH95nTzvLoe/mqKr9B4zt28lrrmwww+7MzHJAtgoihm2q9czgmU9vFzQdfKFASnNUXyBcrRLsC81JYQxXyYHYEp+KDjpPuXmiHyQI/O+wIrl7RpL1r5fBTzDuvtEpwwzcWMLQVha0LG0y70WVuLgjmWslFtBg7amQ8l0syztIulN5SN+SDwZ4qqh/i5iEq7hDIfTJsR1SFYP5ZgtQtv8McvhY0NNFPZdJ3iGh7yucS08Y/DfMxX65omrB+waIMP37wop01+tjbPaRHVfZJQy0DzsWdy3jP/YjclX20GmuixAT0oBAyKw0KZj5iltmYDNlVqG2A+jLQLDSaGF4uN+dCrXez26rzKoV3w1Rjvq8BXkGZAyR/60aI97aIL8lxU677Kv2xZdQH+ZMJXU2GaDxM2kzE6l2Fpl0nWut4WEyjmg1n2RzEfdAuatHC94WosXVyoVEPFPqH47IC91DwQfJR9F2ReWUBmZIqhal47qoSaCnHlpPvQpr2wCzP9yY2nU+1dbfXA3m8sljztYjMpNDUfQHjahbcEsJUQ28Zac2IcKeZ8fVUzmOMOyfwYTMFpmOajxsa/OGM0wE3G7IJTPs5YmQ8jnZaU+dCqgLQGhjUWTAa3Rc7P2qKvD8SmwCIOPrjRFV+BmqmEdmCu6O37kV4EuWbZiGoCt3dqXls5OszSOmCvTkJRm+ajkAs8KOb+m8yHMhmzrJQAI+3CHgK/q62eDzVXZmZE3zL4YEJam7gyC8Gpr/nQc67cBTeqsdxoKW9lxkzdwFylbs0353JOYJDlgreAz0fIMesmY8QGthCcsnLJqLQLBU05S7VL3sp86PdFvYXPRxhsFR4cFfacmBQ099EgLC0Xm/vX0K61qS2hc+kHH0HNB3+fbcVasqQnzGqnKJ8Pk/mIX+0ST3DKn03FvIYxH8wYLyrtotmrG9djrFTQUpz8GAuGz8eImXap2JkvXhJrYx/tx2LTfPjjO9eW2dlAPZ2WtJs5/y5d81FlwWQw7TLSFKbPVuupAvlOYvEGH8zoqsgmgSzTLnFKbf0oPvmlyOccrF/ulTA/eXBOoyMB/8YO03wUc0G1f5FR9vSgmPvvC071cxVm525qPgLMh7HaI1tlWtXwvC4AHLki2GNnNCTtwktts0y7qAFxoaqthpeNRAhOQ6pduA+MLdCzUb6AXkYH6CK2MHt1E7beLrRd03jJNplHdZtVpbY5B+YYW9CYj2DqAzB7u8S/Zj7tHpZ28YOcAPORD1a7UKC5UNOZDxrsVbVLVQ8+NFfOevAaz1vSH7bGcjxVZlrChx0bHZdKu1iqXUZCmA9ajfvVcnadCmnO9rCFDwe3JLd52thKU81UpZ520TUfJUPzQdfDT7vZx129saYucA2DtattPjhvAHbW3Exlx/H50D7PGBpd8+EzH+Y4CfjnxHV9jxXRfPQY3OiqyCaBbNMuPlUWhnYVyL7uY9YPPgo0eNg1H1zEFxx8gz4fpvMkDUCBPjiWldLMQg2HGE0/x4RPdH7MgclcmY0lZD64kJaup0ldt4vxMObDMGviMEttbYLkAPNRrWvW2hzmqlZLJWpOjPnQgMvm80EdTU3mw7aSjEq7cIfTfMS5CLNob9XbJQwtmQ9iwApeSTb/+iJLwxK0tAu71ub30HW0aT5qlmvsp138id8UX9P3ErRUgU3zYfZ2sQhO7WmXYLpQtSiwMB8jxTyOWFpGKZ9Dw4VqncDBhdJh6ST+Pd5+G2kX9kyR4JSPmVrapbnK5zoHGzjjEsUiacdi62rLF62M+bDN7b6WR79XkjIfUZoPc5wE9O7EZFMgmo8egxtd8Qg2yqUuKeJ1tW0OhCmj0Y0rfNEX79bpbTOM+fAZklg+H5ZUABDeB4czH2Y+eLbautTWzIWbpk82wSlnPor5XCAQqhqrx3ahaz4488EEpwGTMf/3sVLeZ9xCersA3oTvp13szAddj3Cfj+CEStDs1Q3mgwet3I2TI8pQiQcfQW1Fjv1sZz54b5ckpe8j6ryEaD5U2iVv3ZdQwSlzhx0t5tVk55uMef8f0fT/0DQfLFCg9/lBtq7PAYx0mJFOjbRXN9hPW6mtTXBaKuSU+N4sta3ZNB/FPHI5BxuazKtN98GbIVrTLhYDOXNiHOPMhyq19dlim8PpaIu0i8Z8xNB8uK7PNuhdbf10Ibegjxac6mmXuGORWqAZwcfUXM3KoBG4ppGYONF89Bjc6IpfWLqHsvD58Lseht/YigIutMt8zAUEla1Nxiyaj1xwoAikXUyHU2I+cvqEDwTzwfOc+QikXXQfBZvmY1m5oKyaOfh7PD+M5qpNNf3KOPho7kPDBfY3+4p4mo/wtAsfZEdK+YAPTKMpMAV8Gny+atd8AHyFT7lwHnwwKr+YC+hPCLrPh/ezrdQ2zMXV9pzYSm3NYJ5Xv5jb4O60qapdVKmlffLhzAegX5diPniurMxHMa8YC9Pnw0+7sGoXSzm1zRbbZB0BXiKupzftglN9DDCdcF3XtWo+AD+gNt1nuZ7BT4l62zWNDgmNhquJNG3+JbZeKOYijD9TqtSWjd2cNaJ9alVq7Qc9/rFGLhAZa6ppPngfI7ZoiNR8qOAjWZWjCnQMzccUW/yMWJgPwD8fdP4k7dJj8NU3v7BZOpzyoCYMSjyV8obwa+19zQd9b6tSW5vDY7HgBPLOwa62erkYPcCK+WCD1ZMm81Gpa91OAZ1q5g+xjfkIa/BnVruYjeV05qP9a8tFnHsPe5TzWClvVA0EWSW+v6YmiN8nZFY2V2n4wr1icGCm9wCs1DZvczi1H3NFW2HrglN+34StIqPTLo3me2zMR3jahe7fOiu1TePzMR8y+Zglvfy6FPJO4FwtYyZjnJWje67S9F6g4M+adokUnLK0iyU9YZZa+zoFm+BU15ApJ1wmiqXH0xRy03EGTcb898yqffbeE2Y0xu/lMtc31YPBh175pKfBvFSmWWrrp5b4cx+sdrGPu/UGH/vDzyWBB95aYzm2uKDvchy7CNus6DPN4FqBp2j5M8tNxsYszAfgnw86f5J26TH4ispWMpWJvTozhglD0gjYxEb28JsGQ2HVLlWmerbR4WZbbxqs6a2+xgDN1/WVkpZ2Oaj3YtFMxgyfj2rd1Vp0k+U0HyRteg8gWO2SZ6tnfgxEXbcLx3HUSnHflBd8jBSjNR98oBlj1S6kqeGrQt/AKiLtYlDqnI7WNR+5wIqSrqVVcGrx+QjTT0S1uleltnkL88EnnJDmdA1XZ3Pigrs62lCp+8G3ue1iLlzzUTGZD3bPce8TYj6mF2rq/tNKbUO0TQC34WaCU8Mcz0+72DQf+hhAxlP0XZwNCDAfTYbB7Dis93bRxY1hXh/mhB3l82Frbsn3MWgyRqlqRwVB/HhI+1CpN0IqgnxdX5RbrDoWts/83tD6GDGWz4awrrZxA4Ewn4+puWifD/66pF36BNzoyr+wvr16t5gPX3jUHvOx69CcairnMx/23DBPOZlCQKu9evPBpMGJVn9mztYmOKUVEbU6n2clXzQZ8yZotFocKfrlslxItTGE+dBMxvJBkzGTus4CtFLcO7UAoLXmI4z5oMlogdmR04SnC05D0i5Gl2Gb5oNbSQP+tdS72hLzERSchon3bIEcpZOUyZgTdBLlefGAy27eDxx5WXhctGosZqYm+LNnq3bhaRdeicUNCifnKurn1U3mo+ECMxV9tQ6wBooVnUUAgmXntv2Nck42fT7MFARNVNwvhLBMpV3szAdPiQbSLofM4MP7HsfR04C6z4f3v6mRCAQfo+TzoacXi/mc5upJx8qrPmwBKBechrHDHLw0m2vkuLCdGNuwdH2A+Uio+eApfB4MTVdqqorFpvngr6u0SxY+EhmgP/aiB+DlnrZ67SyrXaIFp7r+ISnWT4zCcTzab29TcW6u6MyqBd6sy1btYrZ/pv0nrUXA56N5F1kFp013Uwo+vO6KRtqFDfZUGWMTkgHhaRee77TZq3N76qxAg+LeKT/tMhGh+eDnesTS28V3hMwx6rgeynyMGSt8ns4yu9qa+0P7qdurez+bnZ4B+0QeFqCXTObD0HzkHAQGcQ6b4DSNz0d4V1sjSDc1HxGCU55fdxzfa4Xu23zOwRLmXmt6UwD+czVn6Cf4PlkFpy3Sqfy9Ku1isGN+36Tgc0DpjZKhhaF95xP5qGI+QoIPVuniOEEROxDegl4L0lkq01btwlf79LP3nQjsM6GmpV30Y7TB1t6AUDQC7bBnIqijS3Zf87QVvzdcF3jqcHPxE5P5EJ+PHoNHz7Z67Uzs1Tl9HBKAtNPbBfAGpDXNlRbZj5srujDBqU0IWMzZutp6+0j0p9nbJWiv7m+PBqUTmsEHT7vwIIl242BzEOcDsqb5WB70+DDfo5XaUvBRa+8820CD4tPT3sNvpl1ad7XVg1PuJcA9PMJ8PsyqjjrLhZuaD3N/aD/56tm0V9cbigUH8bBHxCy1zRnpPfOeM7ejTMYaen4+Lkz/ExN+kzZdwOl9d7DaZVnTZKzecBWTYYqh6b6lydbveqxPmEB4A0X6vPcervnQUylREyY92xSomFbj3B7dhEq7GMxHw7CD5/u5kTEf3FOHe3zw/dF8PkLGWs2Mjz1TMxXPI4izBjbNh+M4Sv9gu291wanPeofB5vFBoHuFApSwRWug2oXG/ZiLoWJI2gXwx5/YzIcEH72Fznx4F4M3lstijuKD2Hytgf/zw8fw812T2nuS2uzaQKuPm3+5FwAT0tHKxQh8uMd/lM8HDSA0YJB7p2I+Qu3V/c/ta0blKu2idbX13u+tjGgF6dHXfGXGA5Ew5oM7UxbzuWDaxRAZZgEaFGnMHS3l1SoZ8FeQfB+9/70JzjzPPMjgK9ZW1S5U1cFt83lAVzZKKAGf+eCTQc0IPmoNN9CHhCNMO9Oq2iVK/+F93p/02mE+wjQfgbSLVmob1HyQjTrgpwVV36Gift/SJOOv1oNpFxKQzrIUDoGuVYX1gDF9XqImTLNbKi+15ZUuNjdM2mezsRwxLLw6hwKGdRMjyDnePtIkCATZApu9ehjLXDSYD/5MTS/UtJJyOnelgi6ej9L9cOaXs9M3PbgH3/nZ7sD7/ecyOLnTvTLHAm0b/ComvSw+rsWCmqOMxnKAPv7YQK//cvdhAJJ26Tm40VXRxnxkWGoLAN//5V78zXd+ib/59i+195gCsTQ47ghvYn/sKY/5oEqJOKW2toHf92nQqzBU2oV8PoxzpVYBzYdj9+QcXNcLJChomGUOp/yY6eEk4Z7Z72JJKY98zsHRK+3MBwCsWuIxQOMjRTUIuK5XXpiluymB6zsAbxLJ5xxV7TBulARTsEL7aZZi8yCD5+pnmzldkyo33St5tYvjOFi5pATH8a8bb2I1YdF8qLQLO/d0jW0ryLBVnmI+an6Ar3k5BMSvwQAY8CYnYnOSMJGtSi0XApM527e8Eyh7X1L2r/Ok0iTpzAe9ThPUshCRJOBPzMQM6YJT72cutjVt58O0XN5r+mKGX8v5aiPSDXPduOfZsXzUEzsrl2CzEZ7hqbNmmfe53cxoTJlyqeDDovlQzIe+H5yJGmumJ/3Ve01bsK1c4u3r6ub/BNP6noMHPXQvHp6v4p1fvg/v+sr9mi0+AMws2KvN+PFNN4PMMGbVLLVN2uqBs/OmFxAhjPlY3fSd2dNMD9usCnqBYPi7SMBLbZXgtJZ1tYu/jYf2eFHnIbOleQbNft53wTOxacUYKvU6ivkcXvfcjc3vD+aG6w1XldpZ7dXzOd8bwGhYZmo+TMHpuglvENp1yLvJSQG/YfmoanBUb7japESggIdy52NMSJbLOfjMm56HuWodK4xBhuOffucM7Jmax7qJERyc8QWAdeY5kKXglKdYAP/h/+fLnot9UwtqUCasmxjBP/3OGWqQ94WDZFLlrxb5BLqrOaivn9C3ZxpImSzBtb/zXOyfqajqCx54EYulC071ahfaZiFvX0GG3bJmqbZZahuV4wf8gbbeSMd8mFoYE8RGkJDU9PkwXSx5CosmJrOygu5bOsd+mqEZQHCTsRhpF3pfMZ+zCE5ptW6pdiE6v3lM/FrOVesqGDIDZwD4redtQj7n4KKT12nnpWYEoOYkt3ysiD1T89qkbeqUbM6tYW7SfAIfYed5rlrXNGPFvIMNy0fxqTeeoczOCDZbeQJffFE64/H9s+p87jgwi5M3TKj37570xjF6bm37+sQBb+G3bqIceA8/D3ReqD/SspF4gQCvjAvz3AljPt718hOwfmIUCzV9fug1Fm3wwSsDuJgnS8Gp43jbrtQbeHy/d3OaUSuVx7ZDha2fGMW7zz8h8LqN+eB5YltjuUIu2LCM9tHUfJiBGrd6B3yPjyOXj1pX03wFTIPToWbVgGmY85ITVoccvY/nHbNS/cxXynXmUJit5kMfOGigfD7bDxOvPG2D+tkPenVRbMlIu6hyZSPlZFZ1mKves45bpb3fpvngExh9njMsdO/Qd+Qcn+YNYwcD/iYB5sNIu4TQ7g3X7oLZCiMR+X7ADyDM0lLaN56HJw1HMe+gWndVxYXZd4juW5pk+EoVMO3Vw9MuPPBZqNaxtFwIpAyjekaZadx8zqve8TxKamr/zcAZ8IKxN599jPrdLFe3deEFEHAgBfzAk1b8tp41YYLToqH5UN854z0PJhN08ekbYCIq9aY1lmt+9xPN8RnwFk08+DDtArR9bd47jz89G/oeIFjtQuk7WxBog2avHuJfEsZ8rJ8YxbteHpwfeo1Fm3apMoMs3lZZ2TlnJMqhm3Nb8+Y083U1lv7JGr7PR5DqBIj5CIoig/4RpPnwmY8Gc/2jSchUvj/ZfGg3rhj1ynojVry+5oNWlu3dmnyCazSC1HUW4B1sAXsePQpmNRTvAsqFgjtVEKennNTqzuztEnLvasFH81pq3VMNzQfgT5r0HZRSAsKfEfMc53KOdq0DgtOwapeUzEcrzQcxH0rjwJ6BomFFb4p1zbSgWe2i9DXGZMvZx0DahU3mObYYomuzYFD0Uc3QTHt1vo/zjPkYjzHpmYsXW5rI25aeYuL7TOfDpvkIG2vNtAv/ztlKLZZHRlTahWvVCkbwAAQrd9TzZ9Gb0X3xWFPsHyaI5z4f3j99TG0F7hkVZt0QFnz0KxZt8MGNrijHW6n5vV2yUgQrWu9pYj70GydpvXcS2EzG+ErXNBkrNrUCXKzlun7Kgj8os2xgp22YVst8xcAV6ObnAP/hnJwLVrukAZ/g6lzz0QHBKSHpw2+6Pmqaj+a2nppeUOckwHyEdrW1HyNf0ds0H4r5YMI6k3Jfy6jnVtUuBI/5yGm/c4TR7g2X+XwkSrvoaUMTtOo07cQBL11R1IIPnW0wNR9jIZoPs5JJMw2r66W25n1jsgSmXimqt0vNEmT7gWwjwPpEwawYCzOzMrvOAsFGbDb/EsVAhGh+gKC2Zr5a98fMCLFmVOqNt5an79o16QccpmHakxHMR8kY38ME8cq+oNbQuh0vLccb5+h+qoRoPsjLZ5CwaIMPbnSlCU7drJkPXQ29YDwMJlWeJWibdUPzof5u0OG0r/Sgu673sNAgyIVK0+wByhnBx8HZKmYWair9Qq+bqRR+zCrtMqsP7mnBUwL1RncEp2E51zCYq2O+WqTjf2TfNADv3JsDlan5aNUBtpXg1C//84NS2iYFm1zH0srngxAotTX2L8h8+JVKpiFdHHCHVjM1YVt16vbqOU0gawYftLoPVrs0NR8hqRGN+VANFJtlu8Z9Y3p9VI2UYVQzNFuXbM4amKxPFMxSW1tDOgCs94o/Jij9UlFPuyzU6qqKx6yWI3DPI/M8z1Uavk4ugvmI6mxLx1NgaRfWESKU+aAmnhxmtUto2oU96yrlUi7EDqptaRc+Hts62vY7Fm/wwVZUWmvk5liVheYDCK60TebDFIhlCVvahVZLOSc4KdDPmkit4q80Rgq+OJfboNMDND5SVIPazkNzgXSBOWjx71aC02buvN2HiT/UjYabWF0eB+bqMXHwETAZ81eLtHqnCgLboGZ6OJglzCZ0wakefHgVQf5ET9uoGqv0teN+2iWs1DZoKx9d7RLKfDTa6+0CBGl326pTK7U1vDT8ag1iY5rf0byXKaBWmo+iIThtnlPdZMzbJ6omC2M+fJ+dpncHBTaW55qg0rjsmHiQarI+UaDrUjOZD2N/fc1HhODUUsUT5iatOZxS8FHyAyg/7RI+fZHzqS3twjsl2xhnHnw0Gi4LPsLTLoQwB2YuJN7fFMPH1XsAuoDZb2Doi+8HLeUCLOLggxtdKfqbpV2ycoEzV4GVul+/7/3eeeZDF5zqK0kb88EDslku8GJCyBkefLDJgybJHQdmsbtZ9ULMhxlQ6MFHcxCfCTqcpgG/fDWt2qWDzEfKtAudX79tt9+unWCjc01tQ53pmGzQBae+a6fLGrh57/MH5bqR79c0H6Fpl2Bahe+T+bmgFsif6NNoPri+yFz5qpU/W3VqJmM5nbmglbt5TCrtUtTvW5MpoeCtajAftbqfuw8EH4yiBxC4d33DqXjMB9cGpWI+6B6wCGQBrvngglPdGI+Pg3Sfh4mJbawNP4aaCsaimI8mI2ErtWVjvG3c5WmXp2cWUKk1kHP8aj4O0yQsnPnwzxk5ksbVewD6/VRRwYf/LIZ1tO1nLNrgg68S/ZJH10+7ZMR8mIOW65oVBq3FU2nhm4wFKxro+8yOngSf5mS9RfK+EJIzH3whS5H//dsPeWWaOQdrmxOWmUrhgw4NTlSClpRFMOE4vslWw3V96jpLe3Vj9ZiUrQmajPmrRfNc2QY108+i1URtMxmj7+cBKqUeAP9epRXk0nIBS5rfG+rzYZzjfE7PRwd8PozAhG5DrattgueD256bk4+tysD0+QCYVsFIoxDGjBU53bemQFUJThlLUak1NC2Cea+HdZUmbVpUG/iqhRXg2qA0mg+z4smc6FTvFWupbVMDY5QQA0GfIIKN+eDsTZyOsFEW+1qpreW+2j9TUfcNBSJrx0esC5eSEeSRx5IJ/j1kxpaE+eApWmLE+EJA0i4DhDCTsayZD9sNywVDNYNSzRJmbwb+s9kMDgjaGgN62oWb/UyHMB+UF/3xtgMAvNWCMjzSOs86Gm0f1rG1HXDBHE2i5QzPsxl82Ho/RCGQdmE+H6bg1kbnmsxHK/1QKST4qNZdTRBZYIOyKTYcKxXUZNPK4ZSQz+kTfMDh1IH2N98gzq92SZoGDbNYp9U5n3xt7J/PfNiDD1sTM4D5fBiCU95DZ4EFH44TvG/CukqX8npgY+9qS2kXy0KCMR+x0i4G89Ey7cI1H4aRG5/o6bhCe7uoscm/Z3lZuW9PEMV8hKddNOaDl/sXclhW9tPG/P8wRoPfFxtXjIY+E7y/zdPEfMT0+AD0+2nBwnxI2mWAQA90QPORob06YBc4ak2jWlDl7cDWejvYVyUXeD+gq8W5/wQNtlxwygcPeki37jik/c63aX4GsFiHZxDJ+112O5N24bbPo8V86MATBm6ZDOiukOZgYg0+EjIf/F7kHiXVWkO7R4r5oObDLwvNqckmVFtiKbXNW9gFgt50ztGuW9rqs7By2ymLyRYP1sK0HuZzbKYDCGbahe67Ktd81OpapYt53yjNh9HYUTEfEb1dqsbzDej3SRJ/ibBS27C0i675CPYjMiteWpmM8XPDx6M4/bCiyq35c8LvxSOXj6r05pPNhphhHjsEfl+EBSgEOhdPTXuajzRpF95YjjMf7Qr0e4FFG3xwo6sSmwSytFcH7A+I3k+jc5qPvMUPwBQl2lZ9gEFzMu8AGgSowZbj6Ctgekhp0OUPrdl5lsO0Ls6S+WiwUlvTOrvd7ZNoMQ3taRpRcWMmc3s2/wBygaWqDr9nj/1eoom13BQO0yWo1huaEJmvCOsG5c4bfYXFA+ZEXTBWmFG9XfI5HnwEmbq4CKPdbYJLXXRNwQOdKyqdtTMfQbGonmYgxsOsdpkLmcj5NswOqCVjwWB1OI2odpmr1BU7ESvtYvRHouocc6Iz+9gAXL+kMwuAPza0slcftTSX5L2hogJS8gmyBR+8opEvuI5cMRrwKkrCfIQFKATS8pDmI43g1Kt2aaZdlg522mVROpxyOrcQ0tslM8GpNe0SrD7piMmYZYWkmA+L2M6WJ56r1LTBL9Ce2QjSzId0I/tdS7sY5yWQdsngYeJpl044nAKecHN6oZZq5eEPKN75jdR8WAa2ESZK5d2CW2k+6NwW8zks1LyVVE7dD80JTt07us/HaKmgBs1wh1OD+XBaOJzy4MNxFOvIhbBJNVGt0i665iPIfKi0CzEZLGjV0gEm82Gkacg63+ztQufTdt+Ymo8F495N6vNB+zhdqal0aSzmg1Jv1FgupDonjuYD4M3VogWn/n3KFkPsesZhPqK8XvhzogUPy0fVPhLj8WQL5kP/fHjfKcC/Z0jzkSTtwo0wKXhbvUyqXQYOpteFJjjNnPkIbkdvl53cxyAubIJTon9pYNGZj5C0Cxv8VNqlOYiZHg3mQ8p/H4tgPsJo7XZgYz6y1tbQwJsmWDJFiYqqLua07Y0W81hhEbKV8j57wbU5YYEzp7Pp84DOfFBQ6nc0bZbasnw/HXO4w2kwhx+l+eDPWj7PmA+u+Uj4fLRKu/CVvy441dMsJSONQtsmts+8T0vG56u23i51P/iwrVjDNB+mHsVa7WJJ444aK24gZvBhMB9zFd1a3tzW9EJNpcnMrrb8ZzquMD0P3T/83I6x62kLsEyMGClJDj7GF4zgI8B8RBiMAbrgtDXzoQcfiZgPNlbQuT1iqV99k8VirdtYlMGHqexXpWs1v7dLVtUneipDj/y9fekg82FQ5/xnKim0+Xx4+0oPr18SWGS231RqawYRq5aUtN4gfDWgMx+d13zkGX2v2JsMq10AfwBJQ3sGfT78AImfqyNDhGyO42grPC6itoGOnc4tZ17MKomice/wydJnPuzHZQZ4+ZyjVasEfD4M5oOCj4bb2jI+DMpkKg7zkQ8+AwHmQ2MSWDoglPnQNTM681EPFW/y7/TTLrp4k/a3atN82Kpdmt+xb2pBbd/WHt4EnYuA4DRE8+G6Hrvi7XuE5qPm2Q2Q40BQcEr3afA88yA7UnAaEnw2zIUn++6NK0c1l2bXdSMNxgCT+Wil+dCDwLSltnRfrFhSBA0Lo8XBS2JI8JFztBVgPSQaTwsuXFs/4d2cCxbNR0fs1Q3qHEBgdZy3rPoAfzKdrdQ01sCsdjHPk+N4nSYJfDUwqjEfLdIuGTAftDLvlOAU8AfedGmXptbI1HwU85oQOmpQ07U50SyBWTnABzS/941+X1SNiWdE03y0FrbS/kRXu7CUBhOn8t4uiTUf7P7laKX58KtVms9tUQ/UvG0HnxNCoNTW4vPBS23taRdT80HPXzMwal5f19UXFoC9eo7Oxd5mS/W4kx49P2bqzdznkWJefR8Fd3TcWvBR9FfvfL/DfD54fyfbfR61YDMN+Ah8LMzlTOZjTGM+pub8NFUo88GOL8xgjGAGlWk0Hwust8tIMa+qc0xfoEFA5ntcr9fxgQ98AMceeyxGR0dx/PHH46//+q81Y61eg9uNF3KONgn4IqhsNR9Hrhi1dnaME8Wnha3U1tS08CCgZFktTS/U1AqllA9Wu9jOE39QeRv4aOajA5oPtYLunOaDBpA0wRJvFgUEXSFpm1F0Lg06s4z5CLuXzLRLkd33ZhDsl9o20y6so+myFsGHrdTWFJVy5AzmgzZbZw6n6atddHZgSjEfLPhg+6sEp2a1i+XZAIITsVkd45uM8WqXhrWjrdqGYki991RqRoUau76m14ff1ZalXYzgI+6kx58fwN6Fl0BNFim489MuTPOR99MudVcPAjjM+9T7zibDV637otqIVJzZeoDQcA3mwxScNp+1vVPzqhP5qiWl0PGI9rWUz2kCUBvMoDyZ5sPbT27uWC7k1H08iJqPzLmaj33sY/j0pz+Nz33uczj55JNxzz334C1veQsmJibwrne9K+uvSwVOV2omY7WGsk/OivmgbR+5fFQNfJrPh6U0LivQCslmMsbdTAl8wKKHl7fJLhaC1S62FSmtAI5YVtYGZ/4AB0ttO6f54D0+sk5v0SoyVbVLQHCqU9VjpTwm56qRzAdVvMxX661NxgpURWCszmsNNRIUTOaj7mpunGPFvJpowsb+YPCR056nKOaD91VpuK5fhZM2+DCZD6X5aGUyRv/rwRhgr8IgmBoR32RMr3axdbQlqBWy0ZTO1HyY2/V+D97ntI9TCTw+AF8XRmNGWFdbwAvmnp6u+MGH4fMB6G3lecYo0FiueT3GLOd5rlKP19slJPioGYwLd3peu6yMnOMxjpVaA/c+cRBAdPBPx7d++UjLe9Qc4xKZjDWv+bQWfHj6q52H5rR7clCQ+Yx3xx134JJLLsErXvEKHHPMMbj00ktxwQUX4Mc//nHWX5UafDXlMH//h/dN++mEjJgPGvA3rhhVBlf0YDbaWNnFgVmnz3+2pl3YbGJ26wR0kzEyEbOtfmmyNCdN02SMw8xBZ1E6RofTqcZyQDbMB1numyI92mYUnatVAbRYEZppF11wamiB8r7mY54xdZz5CAvQS0Y5s8l8mNdeczjN6SvutM9HWFfTwxbmwya6jjIZ4+kA0wzOZEps9vXc58OWdjGrQqrGRM7PRa3ewO2/fgqv/NQP8eDOSWsjvjCBaCsEBKcRqaJxo9y2lc8HZz7Cql30hUtO7UMtRgo1LO3Cr4PX28X77nXjnhliLueocevj330IQHTakz7fSu8BBMe4JJoP1e6i4pvTFfNOW+NPr5F58PGiF70I3//+9/HrX/8aAPDTn/4UP/rRj7B582br+xcWFjA1NaX96zRM3cOxq5egVMipG3PFWFFzj2sHJ60bBwA87+iVLPJvqthZ+N8Jnw9bSR63SgfCq13oZubBRyHn4NkbvOOh1fqJ65YGvvfMo1cCAJ5/zArt9UjNh+HzkYVpjp526YyT7KlHTgAAnrV+PPFnzRWsWZ74rA3jKOQcPGfT8tBtkNX5zEKtZdrlxHXLtH3lqQHTH4JbeM8yT5dyIYdnrx9HPufgGWuWtTwuwGM+HFZuG/T5YD87vvNtww3vfNoKNLAfmKlqr/uaD7vJGN2X9Nye2PzfrHax/QzYNR9mVUrLtEuI5oOzlRT3VeoNfPtnu/Dgzil862e7FEtiYzEJcSc9XqoOtEq76OW2vEOzf1ws7WIEARwnNe9TGmsAX1A5V4lX7TLKgk+e8jcrHY9fsxT5nKONVfQzBVtnHq2PYxzPXOvt6/OOWRn6HoI5xqVhPgilvPdMnXrkBBzHf7YHCZlzNX/6p3+KqakpnHTSScjn86jX6/jIRz6Cyy67zPr+LVu24EMf+lDWuxEJczW1dnwEd139cuye9JTNm1aOZVa69LsvPBoXnrwORywr478e3A2AUbFsUOqsvbr/PaZi3VZmyP9Og3Wp4N3sL3/WWvzoqvMwOVeFAwcnrA0GH2cfvwo/+fPzsWpJSXs9ruYj5yS3KreBC07NATwrXHTKevzkz8/XOkzGBb/mlVqDmYx5r//D65+DqUtqWLkkfNt+U69qS7fcl55wBO75C/+6+KkBFzlHZ034xDNf8f0dHMfBM9YsxU/+/HzNol07LlNw6vhBR73Z78f2d0AXnOqaj2TXzRcOzmqvH1YOp3bBKZ2Td738GbjshUepRQi/HznbMVKyB9E8sDN1GVxwGl3tYtirNxklx3FQzOWUVoeCgp0H56ysgMnOjMdlPozgIypVZBqNVYxA2tt/nnYJZz42n7peu0/5d3ppl+j7nL+fWivQudOCnpyD448I3stbXnsafv8lx6LecDFazOPY1UtCv+fcE9cE9jUM5piWyF7d+Cxt6y9e8Sy8/dzjM1ssdxOZBx//8R//gS9+8Yv40pe+hJNPPhlbt27Fe97zHmzYsAGXX3554P1XX301rrzySvX71NQUNm3alPVuafANxvwLunJJKXKQbwdkg2uuaHjw0QnBqdmZFAj2Z9CYD+4NQMFHc7DmE+XGFWPYGL4YAKBb/5rbBKJ9PtJYldugmA9uMpZx2gWwH2sc8GP2Suh8nw/Auz9b3ZO8r0Y9hmcMH6R4OahfYqqnHWoN1zpRRu2XTXDq7ZeDCoLVOPz3vNEQMG21iyqZNNqjUwM4TfPBu9rm/QleP1f+PnImoZTPqaAK4KW5/rm19WCZnA3v3hxoLGdZ6RfyDip1bwyh1MKOg3NKsxbG1ADxJ72CEbwTgzNmKes0Ldatmg8WfGiCU8ulNSdTnkajT8axVwe8gIX2w5bGM+/lfM5RzFccxJ34efDBW1XEgalVoyos8z4dJGQefLz//e/Hn/7pn+INb3gDAODUU0/FE088gS1btliDj3K5jHK5uyfPz4tmP+FHIZDL5WmXTmo+2OBnGgXZVn1AMO2ShVBT13yYkbxdmNoO1MpNMxnr7jWPgmcl7qUXeM8GaiAWB5zuriacqEvNc16pNQJBB793KO0S97rY0i58m0GHU/6z31iuVve9IJI+H8R87D40j3rDRT7nYKbiV26F2quHTGg6k+CfB+qgO6262uqaj0qtYfXjODTn9fewCQVLxiKF2tNrwYcqhfZZlO3N6gzvOPhCIh3dz5lDrp0x2R6+TQruqFInzOfDN/oKb1DIQRO17tEU/rli3ivvpuB5At715tbq3QYf4+KyTwSTGc+CGe41Mj+C2dlZ5MyVTT6PhuUB7BX8HhjdvQEDDn8sCMpipW/CZq8+16TQSagYVu0SDD7av1U4/RuVdsk8+Ohg2qVdcLdKW568FTjd3cpkzATvlGmWaPJS26gUgX274cwHAM1wDDBKbXOOYqx4p13zM62wdnxETT77DnslplTtwUvGvf0KTuomuL26eX/y35Xmg1Uy0XPOn7VDivkIXuugyVjQII93tqXrc3CWicN5h2oz7RJT88GZDzJryzn2FHEY88EnXJvmI246zXbvFVt8dtQiOq73aOEJ6GNckpQLEBy3JPiw4OKLL8ZHPvIRfOc738Hjjz+OG264AZ/4xCfwmte8JuuvSg2bIrwbMOnUTnp8AP7xNVzf2W+22lzFMtqOBkVbPwjKJ2dRJcIHkKiutlkpt3nJZsUygPcDVFWERfMRB3zQrxlC6lbgJmNmvwxiK6qM1o/PfJjMhr7NKM0HbyzHtRJJJ4t8zsG6pscMWWQftpTZAmbaxX7uSyFpF0C/XwNdbWsN8DJv+jsF9aYeAwj6fNhaA/BrZ7MQty0kCHEnPm5z74tNC9aFUrjmgzEfFpOxuENwqZAL3AOtxk06bm40F9ZJtxvg5yKJ2BSwCE5jONT2OzJPu3zqU5/CBz7wAfzJn/wJ9u3bhw0bNuCP//iP8cEPfjDrr0oN3lSum6A8XUDF3qEgiE9CtYaLUs5RKxizvb0pBAzrWdEOOF0bfJjCc9Rpwbuj2qjrfkCpkAMWKO1CVHX84+eDflLPGN7TiHqQKO2HhXKPe10K+ZxKJwH+QE/bNqsb+H2acxw1IXEzvjSl70cuH8WTB+ew89Acngffs2aZMflqzEcLa3ogWO2hBx+WMmbW0sBxvOefmI+RFNUufD+r9UagnNg7pvBnOXapreUeCNMpxKl2oXTiAmtjkSQIGC3mVVoHaH2fK4t9znxQarIH6Vd+DyUpswUsmo8+W0SlQebBx7Jly/DJT34Sn/zkJ7PedGZIukLMCr7Dn2481AkRJKDfsLVGAyXkrIOImhwszIe/rWzTLlEmY51Ju3TOzK0d0P7MM9voJOwMH/STijO11XlR7wni26s3EjMftG26z80S24DPRwzmI81K9cgVo8A2vzOpYj6MyVezV4+h+TAnc35e/IZ0PKXlM5we+1PzNR8RPh/BrrZBhqbWcAPMh5nGHTFSO2lKbf0qOfv5oYBuat5rLlexsDVl1tsqjZP0SMkMPuIxH5RqpmMBesV8+Nc6KfPhOF4bEJtt/aBi8I8gBczmat1CWAldp/KPJvMB2Gv16fu5GNNc3RUL7e/jCHtgAiZjxfDBPS38xnKd62rbLui8Thu2yXGhql1Y2iUuo6f7fOg+KMpkrJ6c+eDbAYLBh7nqNBvL0e/tMh8bjQ6lU5YyW3PbrazpAUvwETPtUsjn1N/nm6Jzu8+HfZywCk4taRczwCZRLCEV80HjRkgDM2UyNlfVtDply7lZqNV95iPBdTXZ2lY6OVt/H7O9RDfBx7ikmg9AD7bKGY2RvUR/jcRdQtryvXbB7YWBzjaVA/TgKsoimSYDznyY9GoW+1jI5wKTG6ET1S7K4ZRVu2QRRGUJOq8zC/4EkkbzMTlXU2mOuFomXXBqNxnjK+tEzEchGHwUQpgPLe2S80svK4yhTCPI5h1KAV+PEKX5CDt3ur16hODUcETlgtNSPhfLTC9McMrvC3p+uODUdjy2fUxTaqscWUPuAZ+Bq2mNM23VLp7mw3stadrF3Lc475+zpV16LDhNynwA+jPVb4uoNBj8I0iB3lW72HO5ndqPHHNCpGO2tcVWk0KESC2rm91mbgYYaZeM2kPz7qims2u/gPZnesFbledzTiAwiwKZIx2arajXEqddmC7BNBmrpah2AVowH8YEH552aW+iOHK51wZdMR9NkeeycrjmI4zKL0dokrS0S57SLvzc+s+5qeex+3zoJal1i5aH9nO2Ug/0d7EtFNIwH1xw6t8DYWkX8pupKsYm5xgpLe7zkSbtwo4hzmJozKb5oFLbHqdd0jAfthTWIGPwjyAF+sbnowv7QeyHaZFsqzzhTImpws+qSoS+N9JkLKP20DmWdjGbc/UL6LgPszLQJKBBn09AcUttVTlozWXOmI72P2c+kvTb4QxTwQg+onw+co7ucGp7f1xw5sN13XjMRxzNR4jglAeO/P2kOfA6aOvbt51Trvnguhe+8qXtUypJOx7L+aJ9zjnAkphNyOi8aGmXkM8S81GpNZSwl1yRCda0S4IggJ+rOPc4BSuzFc589GbhCbQnOAX0e0o0HwMKc5XXLQR8PhqdnxBNozEbhU7ngT+Q5s2d1T4q5sN4+As539kybIBLCt1krD9Lbem80sSYdEWztBw8V7FNxhTzUVelyH5X2yCtn4T54PdLTgma9SDE31+dJYmqhkmC9c1S27lqHQdnq6GaD81kLMznI0bwUQ6hxakDdJFpPsK2xbezUKtr+oliPrifdN+E7SuBJu6l5UJstoEH763ugaWlgmJZ908vNI9Dfy9PJ6VJfevtGeIzH3raxft/0EptAdMtVjQfA4meldqG2Kt3MvgosBUsEKL5UGkXNmHkdJFaVq3ofeYjKIqj85NFUznvO/zAy0Zd9wPovM4YDplxUcjnVHM5tc24mg8L80HXpchWvbMt8v3WbVvTLs0gN+Dz4f9csAQfaZmPkWJeWd/vPDjHWsqbzEeQUTARJTilSa6sMRP+PlPAX2A+H3wfTXBtGBfdFnPB/aQKnrFS3po+Nb8nyYq7wFjT2YguvIA3XlAg/PS0lwI0j5VEktznI0nwwe+/YozP+dUufvBBC77eaD7aS7sUIxaHg4jBP4IU6FWpbbdNxgA+AXvfNWtlPoLVLuZ7smY+bOeeBt2sfT54zjerICor0Hn17bmTHzufUBwnfh5d6z/S0JkhVWrLfCTGUjIfZrolyHwwwSnz+fD/nv7e4w3mlOYjhPnIOeFjQok7nBrnYUQxH2Y1hvczMR+FXC5wfaO62rquP3EW8452XWnMoBTHknIB65ePNN8brvkwjz0KSrDNmI+o1BtNqE81HWVNFo8zH6mqXRIyHxSs8OCDzJ57Xe2SSnAqaZfBR1IzpqwQqHbpQsmvos+b32WjT/3JwaCEeQOtjG52GrxsQQCtlpNoC6JAxzVf8weffku7lE3NR4r94wNZkntJb/uul33zpoTzKapd+HEEBaf6tQ+zVye0o4ki3ceTnPkYtZfaRk1ovN+OeX/S7/yYyZcB8Cc/s9qlkHOsYxCfWOi+MN9HzyoxH6PFvAq0bOeL9jFJT5E8E5xGdbQl0H1IzIepXyqxdBLv7RIX2oIpxiKCyoJ52qWXzAc/H2k0H7YmfYOMwT+CFLD1WugGfJMxw+ejg6txJRyM0Hz4g28485FVlciIEudZBt2smQ8KPtjKp9veLq0Q0HykGFQ4hZvknrb5fARMxuqtKXcbbPoE0+lU7TMLNnI5J8DctPOcktfHkwfn1ERtrjqVyDbie7iA1kw/jVrSLoD/zMzytEuEdsT8HKDrRbT3NPdniqVdqLonK+ajoKXe9LYMNvjMRwvNR7Wh2j0k0nxoaZfWzwkJ1zXmIwXjkhUyZT6GwOcjc4fTfkWt3sDD+6axd2reVzx33eejqfkwq126IThtNDR6nZsF2Xq7ADA0HxmlXUKqXQB/sEqiLYgCTWq08ilYJrZeg87rnimvHDRV8MFWUUkCWW6EpcTPRoqEN5ZLIgTWBKdGcBsotTVMxrISnAI+8/HL3VM4OOOtyM18u9KiRNzjUZoPlXYx0gzFpnW+SrsYzEfYRJ7L+W6WFDCFMR+Udhkp5tWxWjUfxHyMxr+GmuC0WbETxXzQth97ehqALe3CSohTlLxq41EMvx56/67JOdzz+AE8c90yX3Daa81HGuZjyNIuiyb4mF6oYfM//BAA8KebTwLQ2UnfBqX5qJPgtPNt3jUb5pC22LbyQKAzwceSMqVdgtsjG+gk2oIo0ABDx91vYlPAZx8e3DkFIJ3mg6+ikgTUfv8Rv6Mu3QtWk7GUPh+muZg5OZqN5bJMu2xsTsh3bzugXjMnYL+8OCrt4gtxzfdR6ap57Wi7SreR030+oibycoGCDyrBNs5J8/fDC37ahY7VdhxLVNolneB0rhqf+fjJ4wfVMZjHBFCw22a1Swzmg4Llux47gEuvuxNHrRzDn/2mN/b3otqFxjfH8aqDkoKzif2WPk6DRRN8TIwWsaSUx0yljif2zwLoAfOhaMdm2qULJb/0wM4s1NQgmHP0yeF3zzoK4yMFvODYlfpnLT0r2sVrztiIx56awYWnrA387U0vPBrf/tlunHXcSssnk4NWVXsmPRp41dJSJtvNEq997pF4cOckFmoN5HMOfuesoxJvQ0+7pNN8EFVO5yjPHDT3NgWEq5fFP3+2UtvXP/8ozFcbOOeEI7T3moJTc15oZ5X6wuNW4aUnrFb9XZ6zabnSRhBOXLsMFzx7Lc44akXodjauGMUlz9mATSvGAn970fGr8OJnrMKlZ27UXjfda81ql6iJfNXSEg4v1NR+m89fUWk+vKBgrJTHy09ag7OPW4U3vGBTYHsXn74BP31yEq8+48jQ7zTBBad7p7z7Y/XScuj7Lz1zI36xe0rdy5eddbT2d15CTPfbyiXx76mkPh8vfeZqvOCYldh7eB5P7J/F9gOz6lr0gvlYNz6C15xxJNaOj6RiYIdN87Fogg/HcXDkilH8eu80ntg/A6CHJmM1nfnopOaDVnlT8zXNKIib//zW8zbht54XHLA0wWlG+/iCY1fiq398tvVvr3/+UXj985NPvmGg+W/HAS/YNCedfsCLjl+Nm95zTlvb0ASnidIufkXL001vBtJIUPplar6qOrAmOX98oKTn7KJT1uGiU9YF3qsLTqOrYZJirFTA//2DsyLfU8jn8C9vfl7kexzHwT+84Qzr31YsKeGLf/jCwOt0Dog1KOZzhpleePBx5IpRPL5/Fo8/PaM+q+8zVbv43XFXLS3jy28N7gcAnLZxOf4j5LkLA2c+yKKeUjs2vOgZ0fcysT4NF2oM3hixPRMjCZmPNctG8B9vOxuNhovj//w/4brAwaYTcC+CD8dx8Pevf07qz+vVLoOv+Rj88CkBaPBUzEcPfT5c3m+kg+kAEpgdnq+2bIttohOltt0EDTDbKfhIMNANEnj+OI3gdKHawK5D+uRC26FnZXykkEisaNN8hKGgBR9O4Bh64UaZBUzBqWkyFsV80Fi1LST4MIXKWaUqOegr56t1xX61E8BzDQgdV5LtJa12IeRyDpY1PUgokO5F8NEuhk3zMfhHkAA0sO6a9AbarjucsoevWne7Yq9OlPzUXI15fMQ7bi34GMCb3dR8bOxD5iML6MxH/OtEg9neqXnMVxtwHGD9hK4boGflSEu6IXLbBT2giILZ2yWYdhm8ew/wz+Hsgi945ivWqJJyqlxRwUfAcdjX5ADZNWPkoPM+U6nDdb0Jb3UbqUs+eT72VDP4SLAgGGtjMUSBcy+Zj3ahV7sM5jPBMfhHkAD0QDeF1j0zGQO8vKdyOO3gxE4T0+H5qqrVD2uLbaITgtNuwhSVDS3zkbLUlu67/c0qkDXLygGTMXpWkq54be3fw8D3Oe9kKzjtJZR7bUi1SxQDSfcqXZug4DRcHJ4VAs/P8tFU3YUJVMUDcOYjflCrN5ZLth/jqgFjk/nogeC0XfAKH+47M6gYvBmlDZiTT7fdLnnkv2Apb+wE/FbX1ZZtsU10wmSsmzDp/iQD3SAhbbWLGVDyAMN8NpLk5gH9Xm9VTqk1lrP1dhnAiQJgmg/mUsrPS5y0i7ktgjlmdIL5MAmnLIJ3U/eWZJtJe7twkLnaIDMfPOAQ5mPAYD7Q3aZzHcfRHr5u+HyMK+ajhtmENtm6ydjgPayLhvlI6fNhGsfx1Ir5bCRmPiyC0zBoaRcnW5OxXqJoaD4KOZ35iEq7mMFeUHDaeebDTEtnIdjm7G8+52DtsvDqGRPcZybpgs1Puwyu5oMzH6L5GDCYD3Qv6Fyt1r0b1S5K81FNbJM98GkX4/pSl9NhQ9pS21IhSKsTzGcjaeCWRHCqpV2GUnDarHYp6JqPKAZy3cSIZj0eVu1C6ArzkXHwsW58JNHCqy3mY5QEp4PMfEi1y8DiiKVl3fyoB4OaX/FS96tdOsjA0EN3eL4WyyKZox2BVz+AT3pHLCtn1i233zA+km5FGEi7sADDfDaSTjzElMUJ8AP26hn6fPQSJvNRzOnVLlHaq2I+h7XjfrAc6JPSC+YjA+aQ24In3d5oQp8PjvFhE5wK8zFYyOUc1fkR6C3zsVBt+CZjHQyCiG6cmq9irtraIplj4Ett2aTWjx4fWSFtqa15TXk1kLmdtMxHHDOlVvbqAys4bT7rNfac6z4f0c8Uv2dNzYd5TjpS7WIRnLYLHjQlrT5rZzyiAH2+2rvGcu2CH/MgavBMDP4RJIRGLfdgQuVtpWtd8PkYVz4fNWtH2yhwpmAQI20+qQ2r3gPwrk0ci3AT5gDGzxHfzkgxh1UJnCj5tmMxHzmT+RgOzYfJTng+H8xevcVzqF+PHlS7mOxXJsyHv9+JmY+EJmMcpkfNIIqYh83hdPCPICGi8trdAG8rrUptO8p8NB1O56qYo7RLzFXSoKdd+AAzrB4fgCdkpiCzHebjyBDmY0OKEkvadpxB3hScBjQfA+rzYWpqPJ8PznxEl7zr1Ud2nw9/W51lPvI5B+vG29dM8eNPyqTkcz5zlLzUVj/Xg6gj4qL/YehqO5hPdRvQ8to9aavs3TSVWqMrvV2Ikp+p1DG9kEzzMdpGXX0/gI/Xw8x8AH6QmeQ68ZX58rEilpS5doTR4wkNxvi2zdWzDbrDKYZO88F/j9PVlhDGRAHBMaMjzAc770nFoWHgzE+aZ1J1xU44HpnMR5Juuv0C0XwMOPhAmu9x2qVao7RL55kPAKqZU9xVkmbqM4A3e16bQIc7+KAgMxnzwZgh4/zw7aTJ9VNZYBzmQ692ycExmssNrObDwlboXW2jnyk+VgU0H91gPjqQtuTHkSaoVcFHwgWb2c13EANaup8cZ3CfCY7Bm1HahEZl9lJwWqsrk7FOak+K+Zx6YKkzZZpqFzN/PQjQmI8hNRgjUJCZ5F7iVuZmgBEVmMQBGSLFEpw6OvMBBCtgBhE2bw5NcNrCaVgTnLaodonrWpwE/LRnlbbkK/Y0pe80JiVdsPFFGDCYwQfdO+VCri2n2X7B4M0obYIPpL24AbVqF6X56OxloAdv75TXHCpNtcsgqqv5pDbsaRda2SVZETmO77hpBmdtMx9JSm254LR5zfi1G9RVnq1CRdd8tEi7RGg+zCBzJGa/piRwmP4mq+eHjj9t6Tt9JnG1y+jgC07pmIfB4wNYhMEHN+/ppc9Hpc7s1Tu8H/TgUdv0dJqPwbtVaOCcGC1iaTn7lWE/IY3gFPBX0ObkwmntNBMPpeni5Nb5rUX7n7O8NmgwXYGTdLUFvOCEqoyKpnjVTLt0SIBIk3RWpeo0/qXdHgVsSdniAPMxgBo2EjAPg94DWITBBzfv6YWK3sZ8dHo/6MFr6lvjBx9tmPr0A9SqbYgrXQhKcJrwXqIgwTxHfHJLc/4oqIkT4Jtdbc3XBpX5sLmSxu1qS6DAL1C22wXBKYDsmY+iPdiNi8zSLoPMfAxBXxdgEQYfAHD8EUsBeCviboOX2lKX2U6nNEyxVZxBD/AGvGUjBeRzDpaVu3+u2gUd93FHLOnxnnQe65r584mxZNdpefMZON44R0vK3nVfUsprTpuxt9vcD/Pes8GWdtHLPAdzmLJVuxTzDpY2z62ZCrAhbKziQV0pn+uYboxKVI9dnc0ztGLMY3KOT7k9YoKSjt3lQh4jbNIexICWzt3KsWSeO/2K4eaiQ/ChS07GXY/tx4uOX9X17+bVLrsOeRqMTvccMaP+uF1tHcfBZ950Jg7P1xJPav2Ai05Zh7+ePxnnnrim17vScfz28zehVMhh8ynrE33u7377dDyxfxYnrF2mvT4xWsS1v/NcjI8WUqU9nr1+HB+/9DQ8a/14y/damQ/2nYPoyQBYOtHmHTiOg39505mYXqjFmkD/14Un4oyjluOVp20wtqWbwHUK//Q7z8XeqflUlSk2/N6LjsHKJSVc8pwNrd9swfsuOBFnHrMSF568LvFnl40UMV/1Us+DKGI+ecM4rrn0NJy8ofUzNQjoSPCxc+dOXHXVVfiv//ovzM7O4hnPeAY++9nP4nnPe14nvi4xjj9iqVpRdBvk83F4vqY0GJ1OC5grrLjMBwC86PjVWe9O1zBSzONNZx/T693oCsZHinhzimM946gVOOOoFda/XXRK8gGe4DgOfut5m2K9Vyu1VYJT+98HCWaqhNKrL3pG/GfqyOWj1uvK0w5jLczK2sHzj1mZ6fZWLCnh8hcdk/rzm1aO4U0vPDrVZ8dHCspuYBCZD8dx8Nsxn6lBQOZ37cGDB/HiF78Y5513Hv7rv/4LRxxxBB5++GGsWGEf4BYbiPl47OkZAF4gsLzDrILJfHQqPywQpIFpr26+NogTBdBaJNoOuE6sEx4fwwhuNDaIzMewIfPg42Mf+xg2bdqEz372s+q1Y489NuuvGVjQauixp6YBeCubTtdsm3l3CT4E/QRboOFYUjGDBpvmI7tt++dkWLs1Zw3OAA9qQDtMyDxZ+M1vfhPPe97z8Fu/9VtYs2YNzjjjDPzrv/5r6PsXFhYwNTWl/RtmkFJ556E5AN3xnxg3mQ9ZKQn6CDZDMU1wOoCVCUBngw8uME2SRl3M4AzwINqrDxsyDz4ee+wxfPrTn8YJJ5yA7373u3j729+Od73rXfjc5z5nff+WLVswMTGh/m3aNDw5LRuo1M5tlr12owzU1HzISknQT8hZNB+aDmRIBKdZrrb5toTJjAfOAA8qmzZMyDz4aDQaeO5zn4u//du/xRlnnIG3vvWt+KM/+iNcd9111vdfffXVmJycVP927NiR9S71FUyDmG4wHzziL+adgTQMEwwv9N4u3v/D0Nsl4M2R4XPHAxtZTMQDZ4AH9Z4aJmQ+C61fvx7Pfvaztdee9axnYfv27db3l8tljI+Pa/+GGeZqqCvMB4v4ZZUk6DdoaRcb8zEkPh/ZCk55tYs803HAGWARnPYemT/VL37xi/HQQw9pr/3617/G0UenK48aNpi+/FnVz0eBP3Si9xD0G2xW6sPhcGrYq2cYRHHNhywo4mGZMB99hcyDj/e+972466678Ld/+7d45JFH8KUvfQn/8i//giuuuCLrrxpImGmXbrR65w+dDFSCfoNNcDoMPh+dZD54YCMLinjgDLAITnuPzIOP5z//+bjhhhvw5S9/Gaeccgr++q//Gp/85Cdx2WWXZf1VAwnuy1/K53DE0nLHv1NLu3TQkEggSAObydgw+HyYC41Mq13E5yMxNOZjQEXMw4SOzESvfOUr8cpXvrITmx548LTL+uUjXck9jpXyyOcc1BsuRoekKZFgeOA4DhzHqwCzpV2GhfnIsjmjxnwImxkLmuZDmI+eQ2aiLoMLTrvVbdVxHBX1yypJ0I8oGEHHUAQfZqlthsyH4zjqnEnwEQ+cAe5FR3OBDrkCXUa5B8EH4FOOo0VJuwj6DxRsEB1uE6EOGkymI+v0EZ0rWVDEA0+7iNtA7yGXoMvQgo8uiE0JFPXLQCXoR5jplrxW7TKYw1Q5rz9rWfvrUPWMMB/xwNMug1q+PUyQK9BllNlA0RvmQy65oP9gCk0119NBZT5YY7mck/1xEPMhPh/xsKSUV1VUwnz0HnIJugzuetgL5qOT7bcFgrQwe7oMh8+H/6xnqfcwtzkiwUcseNo3bxwUwWnvIcFHl8FLbTcu77zBGIEeOrFiFvQjfMaj+TsXnA5oWSQPmoodCKBoISNpl/ggBnhQU3nDBLkCXcaSUgGbVo5iw8QI1i8f6dr3nrZxAgDwrPXLuvadAkFcnLh2GZaU8iogH4beLo7jqAChE8zHieuWoVzI4bgjlmS+7WHFaRsnUMw7OGZ19xZ+AjuEg+8y8jkHN737HDhO9gK0KFz+omPwm6euxxHLOm9qJhAkxed+/wWYq9QxMeYxdPkh0HwAXml9pd7I1OOD8Jk3nYmZhRqWj5Uy3/aw4h/fcAam5mtYuUTOWa8hwUcPsKTcm9MugYegX1Eq5DQPHN3hdHAJWgo6OnEMxXxOAo+EKORzEnj0CQb3qRYIBEMLRzMZ6+GOtAliN3nli0AgkOBDIBD0IXiWYpA9GVTwMcDHIBB0AvJECASCvsMwlNoCvqmgNDITCHRI8CEQCPoOw2AyBvjMxyDrVgSCTkCeCIFA0HfIDUGpLeBrPTpR7SIQDDIk+BAIBH2HYSm1VZqPQVbNCgQdgDwRAoGg75AbgsZyAEu7CPMhEGgY3KdaIBAMLXJDYK8O+IJTYT4EAh3yRAgEgr6DlnYZ4CZgvuB0cI9BIOgEJPgQCAR9B0fz+RjciVs5nArzIRBokCdCIBD0HfJD4vPhC04H9xgEgk5Agg+BQNB30NIuAzxxl6TaRSCwQp4IgUDQd3CGhPmgZnmDXLEjEHQC8kQIBIK+AycKBlvzIWkXgcAGCT4EAkHfQXw+BILhxuA+1QKBYGjBg48BJj5U2kU0HwKBjkKvd0AgEAhMUKqlkHM0/ceg4ZWnrcf92w/iVadv6PWuCAR9BQk+BAJB34HYjtwg0x4ATjlyAl/947N7vRsCQd9BuECBQNB3yDHmQyAQDB8k+BAIBH0H0nwMcqWLQCAIhwQfAoGg70AOp8J8CATDiY4HHx/96EfhOA7e8573dPqrBALBkIDSLvkBLrMVCATh6OiT/ZOf/ASf+cxncNppp3XyawQCwZCBCA9hPgSC4UTHgo/p6Wlcdtll+Nd//VesWLGiU18jEAiGEHnRfAgEQ42OBR9XXHEFXvGKV+D888/v1FcIBIIhhap2EWdQgWAo0RGfj6985Su477778JOf/KTlexcWFrCwsKB+n5qa6sQuCQSCAYJUuwgEw43MmY8dO3bg3e9+N774xS9iZGSk5fu3bNmCiYkJ9W/Tpk1Z75JAIBgwUMyRH2B3U4FAEI7Mg497770X+/btw3Of+1wUCgUUCgXcdttt+Md//EcUCgXU63Xt/VdffTUmJyfVvx07dmS9SwKBYMCQzwnzIRAMMzJPu7z85S/HAw88oL32lre8BSeddBKuuuoq5PN57W/lchnlcjnr3RAIBAMMSruI5kMgGE5kHnwsW7YMp5xyivbakiVLsGrVqsDrAoFAYINKu4jPh0AwlJAnWyAQ9B3y0ttFIBhqdKWr7a233tqNrxEIBEMCR6pdBIKhhjAfAoGg7yDMh0Aw3JDgQyAQ9B3E4VQgGG5I8CEQCPoO46OF5v/FHu+JQCDoBLqi+RAIBIIkOO+kNfibV5+Cc044ote7IhAIOgAJPgQCQd+hXMjjd194dK93QyAQdAiSdhEIBAKBQNBVSPAhEAgEAoGgq5DgQyAQCAQCQVchwYdAIBAIBIKuQoIPgUAgEAgEXYUEHwKBQCAQCLoKCT4EAoFAIBB0FRJ8CAQCgUAg6Cok+BAIBAKBQNBVSPAhEAgEAoGgq5DgQyAQCAQCQVchwYdAIBAIBIKuQoIPgUAgEAgEXUXfdbV1XRcAMDU11eM9EQgEAoFAEBc0b9M8HoW+Cz4OHz4MANi0aVOP90QgEAgEAkFSHD58GBMTE5Hvcdw4IUoX0Wg0sGvXLixbtgyO42S67ampKWzatAk7duzA+Ph4ptvuFwz7MQ778QFyjMOAYT8+QI5xGJD18bmui8OHD2PDhg3I5aJVHX3HfORyOWzcuLGj3zE+Pj6UNxLHsB/jsB8fIMc4DBj24wPkGIcBWR5fK8aDIIJTgUAgEAgEXYUEHwKBQCAQCLqKRRV8lMtl/OVf/iXK5XKvd6VjGPZjHPbjA+QYhwHDfnyAHOMwoJfH13eCU4FAIBAIBMONRcV8CAQCgUAg6D0k+BAIBAKBQNBVSPAhEAgEAoGgq5DgQyAQCAQCQVexqIKPa6+9FscccwxGRkZw1lln4cc//nGvdykVtmzZguc///lYtmwZ1qxZg1e/+tV46KGHtPece+65cBxH+/e2t72tR3ucHH/1V38V2P+TTjpJ/X1+fh5XXHEFVq1ahaVLl+J1r3sd9u7d28M9ToZjjjkmcHyO4+CKK64AMJjX7/bbb8fFF1+MDRs2wHEc3HjjjdrfXdfFBz/4Qaxfvx6jo6M4//zz8fDDD2vvOXDgAC677DKMj49j+fLl+IM/+ANMT0938SiiEXWM1WoVV111FU499VQsWbIEGzZswJvf/Gbs2rVL24bt2n/0ox/t8pHY0eoa/t7v/V5g3y+66CLtPYN8DQFYn0vHcfDxj39cvaefr2Gc+SHO+Ll9+3a84hWvwNjYGNasWYP3v//9qNVqme3nogk+vvrVr+LKK6/EX/7lX+K+++7D6aefjgsvvBD79u3r9a4lxm233YYrrrgCd911F26++WZUq1VccMEFmJmZ0d73R3/0R9i9e7f6d8011/Roj9Ph5JNP1vb/Rz/6kfrbe9/7XnzrW9/C1772Ndx2223YtWsXXvva1/Zwb5PhJz/5iXZsN998MwDgt37rt9R7Bu36zczM4PTTT8e1115r/fs111yDf/zHf8R1112Hu+++G0uWLMGFF16I+fl59Z7LLrsMP//5z3HzzTfj29/+Nm6//Xa89a1v7dYhtETUMc7OzuK+++7DBz7wAdx33334+te/joceegivetWrAu/98Ic/rF3bd77znd3Y/ZZodQ0B4KKLLtL2/ctf/rL290G+hgC0Y9u9ezf+/d//HY7j4HWve532vn69hnHmh1bjZ71exyte8QpUKhXccccd+NznPofrr78eH/zgB7PbUXeR4AUveIF7xRVXqN/r9bq7YcMGd8uWLT3cq2ywb98+F4B72223qdde9rKXue9+97t7t1Nt4i//8i/d008/3fq3Q4cOucVi0f3a176mXvvlL3/pAnDvvPPOLu1htnj3u9/tHn/88W6j0XBdd/CvHwD3hhtuUL83Gg133bp17sc//nH12qFDh9xyuex++ctfdl3XdX/xi1+4ANyf/OQn6j3/9V//5TqO4+7cubNr+x4X5jHa8OMf/9gF4D7xxBPqtaOPPtr9+7//+87uXAawHd/ll1/uXnLJJaGfGcZreMkll7i/8Ru/ob02KNfQdYPzQ5zx8z//8z/dXC7n7tmzR73n05/+tDs+Pu4uLCxksl+LgvmoVCq49957cf7556vXcrkczj//fNx555093LNsMDk5CQBYuXKl9voXv/hFrF69GqeccgquvvpqzM7O9mL3UuPhhx/Ghg0bcNxxx+Gyyy7D9u3bAQD33nsvqtWqdj1POukkHHXUUQN5PSuVCr7whS/g93//97VmioN+/Ti2bduGPXv2aNdsYmICZ511lrpmd955J5YvX47nPe956j3nn38+crkc7r777q7vcxaYnJyE4zhYvny59vpHP/pRrFq1CmeccQY+/vGPZ0pndxq33nor1qxZgxNPPBFvf/vbsX//fvW3YbuGe/fuxXe+8x38wR/8QeBvg3INzfkhzvh555134tRTT8XatWvVey688EJMTU3h5z//eSb71XeN5TqBp59+GvV6XTuRALB27Vr86le/6tFeZYNGo4H3vOc9ePGLX4xTTjlFvf47v/M7OProo7Fhwwb87Gc/w1VXXYWHHnoIX//613u4t/Fx1lln4frrr8eJJ56I3bt340Mf+hBe+tKX4sEHH8SePXtQKpUCA/ratWuxZ8+e3uxwG7jxxhtx6NAh/N7v/Z56bdCvnwm6LrZnkP62Z88erFmzRvt7oVDAypUrB/K6zs/P46qrrsIb3/hGrWnXu971Ljz3uc/FypUrcccdd+Dqq6/G7t278YlPfKKHexsPF110EV772tfi2GOPxaOPPoo/+7M/w+bNm3HnnXcin88P3TX83Oc+h2XLlgVSuoNyDW3zQ5zxc8+ePdZnlf6WBRZF8DHMuOKKK/Dggw9qeggAWo711FNPxfr16/Hyl78cjz76KI4//vhu72ZibN68Wf182mmn4ayzzsLRRx+N//iP/8Do6GgP9yx7/Nu//Rs2b96MDRs2qNcG/fotdlSrVfz2b/82XNfFpz/9ae1vV155pfr5tNNOQ6lUwh//8R9jy5YtfW/j/YY3vEH9fOqpp+K0007D8ccfj1tvvRUvf/nLe7hnncG///u/47LLLsPIyIj2+qBcw7D5oR+wKNIuq1evRj6fD6h59+7di3Xr1vVor9rHO97xDnz729/GLbfcgo0bN0a+96yzzgIAPPLII93YtcyxfPlyPPOZz8QjjzyCdevWoVKp4NChQ9p7BvF6PvHEE/je976HP/zDP4x836BfP7ouUc/gunXrAgLwWq2GAwcODNR1pcDjiSeewM0339yyVflZZ52FWq2Gxx9/vDs7mCGOO+44rF69Wt2Xw3INAeCHP/whHnrooZbPJtCf1zBsfogzfq5bt876rNLfssCiCD5KpRLOPPNMfP/731evNRoNfP/738fZZ5/dwz1LB9d18Y53vAM33HADfvCDH+DYY49t+ZmtW7cCANavX9/hvesMpqen8eijj2L9+vU488wzUSwWtev50EMPYfv27QN3PT/72c9izZo1eMUrXhH5vkG/fsceeyzWrVunXbOpqSncfffd6pqdffbZOHToEO699171nh/84AdoNBoq+Op3UODx8MMP43vf+x5WrVrV8jNbt25FLpcLpCsGAU8++ST279+v7sthuIaEf/u3f8OZZ56J008/veV7++katpof4oyfZ599Nh544AEtkKRA+tnPfnZmO7oo8JWvfMUtl8vu9ddf7/7iF79w3/rWt7rLly/X1LyDgre//e3uxMSEe+utt7q7d+9W/2ZnZ13Xdd1HHnnE/fCHP+zec8897rZt29xvfOMb7nHHHeeec845Pd7z+Hjf+97n3nrrre62bdvc//mf/3HPP/98d/Xq1e6+fftc13Xdt73tbe5RRx3l/uAHP3Dvuece9+yzz3bPPvvsHu91MtTrdfeoo45yr7rqKu31Qb1+hw8fdu+//373/vvvdwG4n/jEJ9z7779fVXp89KMfdZcvX+5+4xvfcH/2s5+5l1xyiXvssce6c3NzahsXXXSRe8YZZ7h33323+6Mf/cg94YQT3De+8Y29OqQAoo6xUqm4r3rVq9yNGze6W7du1Z5NqhC444473L//+793t27d6j766KPuF77wBfeII45w3/zmN/f4yDxEHd/hw4fd//W//pd75513utu2bXO/973vuc997nPdE044wZ2fn1fbGORrSJicnHTHxsbcT3/604HP9/s1bDU/uG7r8bNWq7mnnHKKe8EFF7hbt251b7rpJveII45wr7766sz2c9EEH67rup/61Kfco446yi2VSu4LXvAC96677ur1LqUCAOu/z372s67ruu727dvdc845x125cqVbLpfdZzzjGe773/9+d3Jysrc7ngCvf/3r3fXr17ulUsk98sgj3de//vXuI488ov4+Nzfn/smf/Im7YsUKd2xszH3Na17j7t69u4d7nBzf/e53XQDuQw89pL0+qNfvlltusd6Xl19+ueu6XrntBz7wAXft2rVuuVx2X/7ylweOff/+/e4b3/hGd+nSpe74+Lj7lre8xT18+HAPjsaOqGPctm1b6LN5yy23uK7ruvfee6971llnuRMTE+7IyIj7rGc9y/3bv/1bbfLuJaKOb3Z21r3gggvcI444wi0Wi+7RRx/t/tEf/VFgATfI15Dwmc98xh0dHXUPHToU+Hy/X8NW84Prxhs/H3/8cXfz5s3u6Oiou3r1avd973ufW61WM9tPp7mzAoFAIBAIBF3BotB8CAQCgUAg6B9I8CEQCAQCgaCrkOBDIBAIBAJBVyHBh0AgEAgEgq5Cgg+BQCAQCARdhQQfAoFAIBAIugoJPgQCgUAgEHQVEnwIBAKBQCDoKiT4EAgEAoFA0FVI8CEQCAQCgaCrkOBDIBAIBAJBVyHBh0AgEAgEgq7i/w+dUFR8r521fwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3032753467559814, 2.302574872970581, 2.3025147914886475, 2.3026864528656006, 2.3027560710906982, 2.3025150299072266, 2.3014299869537354, 2.3025708198547363, 2.3027079105377197, 2.3025777339935303, 2.302640914916992, 2.302563190460205, 2.30230450630188, 2.3027172088623047, 2.3026137351989746, 2.3026421070098877, 2.3037302494049072, 2.3025076389312744, 2.3023762702941895, 2.302522659301758, 2.3025574684143066, 2.3026485443115234, 2.302464723587036, 2.302577495574951, 2.302706241607666, 2.3023550510406494, 2.302419424057007, 2.302518606185913, 2.302744150161743, 2.3025803565979004, 2.3025527000427246, 2.3025546073913574, 2.302583694458008, 2.3025848865509033, 2.3026673793792725, 2.302584171295166, 2.302582263946533, 2.3025848865509033, 2.3025505542755127, 2.302647352218628, 2.3025689125061035, 2.3025708198547363, 2.302480697631836, 2.3026022911071777, 2.3025853633880615, 2.3025853633880615, 2.3026044368743896, 2.3025784492492676, 2.3024728298187256, 2.3027398586273193, 2.302595376968384, 2.3025550842285156, 2.3025858402252197, 2.302656412124634, 2.3024680614471436, 2.3025989532470703, 2.302628993988037, 2.3025832176208496, 2.302581548690796, 2.302520275115967, 2.3025856018066406, 2.302600383758545, 2.302051305770874, 2.3025238513946533, 2.3025386333465576, 2.302581787109375, 2.302797794342041, 2.302582263946533, 2.302584409713745, 2.302584409713745, 2.3025076389312744, 2.3026084899902344, 2.302564859390259, 2.302593231201172, 2.3026020526885986, 2.3026187419891357, 2.302589178085327, 2.3025810718536377, 2.3025848865509033, 2.3025779724121094, 2.302591323852539, 2.3025975227355957, 2.3025810718536377, 2.302598476409912, 2.3025779724121094, 2.302635908126831, 2.3025619983673096, 2.3025870323181152, 2.302544116973877, 2.302572011947632, 2.302671194076538, 2.3027026653289795, 2.3025851249694824, 2.3025858402252197, 2.3025851249694824, 2.3025882244110107, 2.3025667667388916, 2.3025856018066406, 2.302583694458008, 2.3026123046875, 2.3025834560394287, 2.302582263946533, 2.302581787109375, 2.30259108543396, 2.3025877475738525, 2.302572727203369, 2.302354574203491, 2.302582025527954, 2.302689790725708, 2.3026204109191895, 2.3025667667388916, 2.3025856018066406, 2.3026137351989746, 2.3025262355804443, 2.3025834560394287, 2.302581310272217, 2.302591323852539, 2.302581787109375, 2.302610397338867, 2.3025896549224854, 2.302584409713745, 2.302565336227417, 2.3025805950164795, 2.3025858402252197, 2.302593946456909, 2.30259108543396, 2.3025858402252197, 2.3026251792907715, 2.3025882244110107, 2.3025851249694824, 2.3025872707366943, 2.3025805950164795, 2.302600383758545, 2.3026046752929688, 2.3025870323181152, 2.302579402923584, 2.3025925159454346, 2.3025763034820557, 2.302607297897339, 2.302565813064575, 2.3025848865509033, 2.302607774734497, 2.302572011947632, 2.3025929927825928, 2.302588701248169, 2.3025972843170166, 2.302551031112671, 2.3025858402252197, 2.3025989532470703, 2.3025858402252197, 2.302600860595703, 2.3025851249694824, 2.3026061058044434, 2.302586078643799, 2.3025834560394287, 2.302588701248169, 2.302607774734497, 2.3025472164154053, 2.3025777339935303, 2.302567720413208, 2.302595376968384, 2.3025524616241455, 2.3025853633880615, 2.3025898933410645, 2.3025856018066406, 2.302558422088623, 2.3025851249694824, 2.3026092052459717, 2.3025875091552734, 2.3025965690612793, 2.3023478984832764, 2.302581548690796, 2.302584171295166, 2.302586317062378, 2.302582025527954, 2.3025875091552734, 2.3025851249694824, 2.3025851249694824, 2.3025801181793213, 2.3025853633880615, 2.302586078643799, 2.3025753498077393, 2.3025851249694824, 2.302586793899536, 2.302579879760742, 2.3025875091552734, 2.302581787109375, 2.302577495574951, 2.3025858402252197, 2.302544355392456, 2.302584409713745, 2.302593231201172, 2.302581548690796, 2.3025624752044678, 2.3026461601257324, 2.302593231201172, 2.3025856018066406, 2.3025381565093994, 2.3025856018066406, 2.302572727203369]\n",
      "[7.142857142857143, 6.25, 12.5, 8.035714285714286, 8.035714285714286, 16.964285714285715, 9.821428571428571, 10.714285714285714, 13.392857142857142, 11.607142857142858, 12.5, 16.071428571428573, 12.5, 8.035714285714286, 8.928571428571429, 5.357142857142857, 6.25, 11.607142857142858, 10.714285714285714, 10.714285714285714, 15.178571428571429, 12.5, 9.821428571428571, 9.821428571428571, 8.928571428571429, 8.928571428571429, 13.392857142857142, 7.142857142857143, 5.357142857142857, 8.035714285714286, 14.285714285714286, 7.142857142857143, 12.5, 8.928571428571429, 6.25, 10.714285714285714, 8.035714285714286, 8.035714285714286, 16.964285714285715, 8.928571428571429, 8.035714285714286, 8.928571428571429, 9.821428571428571, 7.142857142857143, 13.392857142857142, 10.714285714285714, 7.142857142857143, 9.821428571428571, 11.607142857142858, 8.928571428571429, 9.821428571428571, 10.714285714285714, 11.607142857142858, 8.928571428571429, 15.178571428571429, 6.25, 7.142857142857143, 11.607142857142858, 11.607142857142858, 12.5, 10.714285714285714, 14.285714285714286, 15.178571428571429, 13.392857142857142, 10.714285714285714, 9.821428571428571, 8.035714285714286, 10.714285714285714, 8.928571428571429, 13.392857142857142, 15.178571428571429, 8.928571428571429, 11.607142857142858, 7.142857142857143, 7.142857142857143, 10.714285714285714, 8.035714285714286, 8.928571428571429, 12.5, 10.714285714285714, 8.035714285714286, 6.25, 12.5, 8.928571428571429, 12.5, 8.035714285714286, 10.714285714285714, 6.25, 7.142857142857143, 12.5, 6.25, 7.142857142857143, 9.821428571428571, 8.035714285714286, 19.642857142857142, 12.5, 10.714285714285714, 6.25, 14.285714285714286, 7.142857142857143, 14.285714285714286, 14.285714285714286, 5.357142857142857, 14.285714285714286, 3.5714285714285716, 10.714285714285714, 15.178571428571429, 14.285714285714286, 9.821428571428571, 9.821428571428571, 10.714285714285714, 8.035714285714286, 7.142857142857143, 7.142857142857143, 8.928571428571429, 13.392857142857142, 7.142857142857143, 12.5, 8.035714285714286, 11.607142857142858, 7.142857142857143, 9.821428571428571, 9.821428571428571, 7.142857142857143, 10.714285714285714, 8.928571428571429, 4.464285714285714, 9.821428571428571, 6.25, 8.928571428571429, 11.607142857142858, 10.714285714285714, 7.142857142857143, 6.25, 10.714285714285714, 10.714285714285714, 5.357142857142857, 8.035714285714286, 7.142857142857143, 12.5, 9.821428571428571, 7.142857142857143, 8.928571428571429, 11.607142857142858, 10.714285714285714, 8.928571428571429, 14.285714285714286, 6.25, 7.142857142857143, 9.821428571428571, 9.821428571428571, 8.928571428571429, 7.142857142857143, 7.142857142857143, 10.714285714285714, 9.821428571428571, 6.25, 7.142857142857143, 16.071428571428573, 13.392857142857142, 8.035714285714286, 10.714285714285714, 8.928571428571429, 6.25, 11.607142857142858, 8.928571428571429, 11.607142857142858, 9.821428571428571, 7.142857142857143, 7.142857142857143, 5.357142857142857, 13.392857142857142, 8.035714285714286, 8.928571428571429, 8.035714285714286, 8.035714285714286, 8.928571428571429, 12.5, 12.5, 8.035714285714286, 8.928571428571429, 17.857142857142858, 14.285714285714286, 10.714285714285714, 7.142857142857143, 8.928571428571429, 14.285714285714286, 13.392857142857142, 12.5, 9.821428571428571, 10.714285714285714, 6.25, 9.821428571428571, 8.035714285714286, 10.714285714285714, 13.392857142857142, 11.607142857142858, 8.928571428571429, 8.928571428571429, 15.178571428571429]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [0.841748058795929, 0.5383376479148865, 0.37141960859298706, 0.2189747840166092, 0.2170722633600235, 0.2683789134025574, 0.1937561184167862, 0.2995546758174896, 0.13230514526367188, 0.12556131184101105, 0.08791607618331909, 0.13517722487449646, 0.1180429607629776, 0.2700677216053009, 0.23012836277484894, 0.11778731644153595, 0.08971132338047028, 0.0745047926902771, 0.044976893812417984, 0.030214795842766762, 0.14274518191814423, 0.16257527470588684, 0.13489486277103424, 0.22497442364692688, 0.04410076141357422, 0.0439407117664814, 0.0999048724770546, 0.09295899420976639, 0.05333646386861801, 0.042801376432180405, 0.0852958932518959, 0.035196453332901, 0.09896297752857208, 0.09667126089334488, 0.11132311820983887, 0.07094293087720871, 0.11317868530750275, 0.17386971414089203, 0.04825839400291443, 0.1526862233877182, 0.12213451415300369, 0.0335562527179718, 0.14572270214557648, 0.14732243120670319, 0.08901072293519974, 0.10628568381071091, 0.1219853013753891, 0.04227989539504051, 0.1546023041009903, 0.07231778651475906, 0.08872615545988083, 0.06031284108757973, 0.11893129348754883, 0.07610543072223663, 0.05435555428266525, 0.03299633413553238, 0.06796611100435257, 0.09908641129732132, 0.1245361715555191, 0.13339823484420776, 0.044910043478012085, 0.039106521755456924, 0.08405368030071259, 0.03416334092617035, 0.18436889350414276, 0.06167331337928772, 0.05363277718424797, 0.03776988759636879, 0.010305949486792088, 0.08863425254821777, 0.11051689833402634, 0.03690870478749275, 0.021718373522162437, 0.08610344678163528, 0.08286675065755844, 0.05776119977235794, 0.09465332329273224, 0.032651614397764206, 0.07205092906951904, 0.0745658427476883, 0.08170061558485031, 0.10555801540613174, 0.016445361077785492, 0.12694816291332245, 0.11931197345256805, 0.08286337554454803, 0.07604096084833145, 0.04736681655049324, 0.07517056912183762, 0.13407494127750397, 0.02461135759949684, 0.026882896199822426, 0.050736844539642334, 0.03605273738503456, 0.056351643055677414, 0.09767205268144608, 0.07290007919073105, 0.08676333725452423, 0.0794496163725853, 0.04368472844362259, 0.050167299807071686, 0.04737326130270958, 0.05501176789402962, 0.08879045397043228, 0.01769072189927101, 0.11385718733072281, 0.045953329652547836, 0.057710688561201096, 0.03719104081392288, 0.07977698743343353, 0.02595260553061962, 0.1046842560172081, 0.06301649659872055, 0.02800893224775791, 0.024529291316866875, 0.020508909597992897, 0.14025148749351501, 0.05224132165312767, 0.02634393982589245, 0.03067580796778202, 0.010352589190006256, 0.030206164345145226, 0.09297139197587967, 0.1973668485879898, 0.11294060945510864, 0.10930002480745316, 0.0792819932103157, 0.11282505095005035, 0.06902279704809189, 0.034222979098558426, 0.01758032664656639, 0.20883719623088837, 0.0871180072426796, 0.021445829421281815, 0.058817390352487564, 0.11408091336488724, 0.04319537431001663, 0.028295835480093956, 0.009734376333653927, 0.0865861177444458, 0.013264675624668598, 0.03975219279527664, 0.03132316842675209, 0.07329122722148895, 0.031415101140737534, 0.057007454335689545, 0.07466187328100204, 0.03515228256583214, 0.01828647591173649, 0.034930113703012466, 0.04921986907720566, 0.05617351084947586, 0.025701504200696945, 0.07073844969272614, 0.0677885115146637, 0.0442965142428875, 0.08668070286512375, 0.01085565984249115, 0.10640285909175873, 0.042185988277196884, 0.045891039073467255, 0.010602300986647606, 0.07824820280075073, 0.029184645041823387, 0.1528889238834381, 0.0852082297205925, 0.01046351995319128, 0.26733046770095825, 0.008088228292763233, 0.1218838021159172, 0.06059052422642708, 0.17010393738746643, 0.09900021553039551, 0.027551589533686638, 0.009467942640185356, 0.0559978224337101, 0.015254249796271324, 0.06907999515533447, 0.026691734790802002, 0.09885875135660172, 0.01129892561584711, 0.03152812644839287, 0.08123517781496048, 0.04274165257811546, 0.03844240680336952, 0.06572488695383072, 0.10163140296936035, 0.020722707733511925, 0.016591958701610565, 0.10138952732086182, 0.10918857157230377, 0.028943251818418503, 0.04512939602136612, 0.040990330278873444, 0.04000023752450943, 0.045494887977838516, 0.011356256902217865, 0.05481533333659172, 0.013076278381049633, 0.04331720620393753]\n",
    "# acc_list_epoch_ = [71.42857142857143, 83.03571428571429, 84.82142857142857, 95.53571428571429, 91.07142857142857, 91.96428571428571, 93.75, 91.96428571428571, 96.42857142857143, 94.64285714285714, 98.21428571428571, 93.75, 96.42857142857143, 92.85714285714286, 94.64285714285714, 96.42857142857143, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 95.53571428571429, 95.53571428571429, 97.32142857142857, 91.96428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 97.32142857142857, 98.21428571428571, 95.53571428571429, 98.21428571428571, 96.42857142857143, 96.42857142857143, 95.53571428571429, 98.21428571428571, 95.53571428571429, 97.32142857142857, 99.10714285714286, 93.75, 95.53571428571429, 98.21428571428571, 94.64285714285714, 95.53571428571429, 97.32142857142857, 95.53571428571429, 94.64285714285714, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 98.21428571428571, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 96.42857142857143, 98.21428571428571, 98.21428571428571, 95.53571428571429, 99.10714285714286, 94.64285714285714, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 97.32142857142857, 95.53571428571429, 98.21428571428571, 100.0, 97.32142857142857, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 96.42857142857143, 99.10714285714286, 98.21428571428571, 94.64285714285714, 97.32142857142857, 96.42857142857143, 98.21428571428571, 95.53571428571429, 93.75, 100.0, 99.10714285714286, 98.21428571428571, 99.10714285714286, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 99.10714285714286, 95.53571428571429, 98.21428571428571, 96.42857142857143, 98.21428571428571, 98.21428571428571, 99.10714285714286, 97.32142857142857, 97.32142857142857, 98.21428571428571, 99.10714285714286, 99.10714285714286, 93.75, 97.32142857142857, 99.10714285714286, 98.21428571428571, 100.0, 99.10714285714286, 95.53571428571429, 91.07142857142857, 95.53571428571429, 95.53571428571429, 95.53571428571429, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 94.64285714285714, 98.21428571428571, 100.0, 98.21428571428571, 97.32142857142857, 98.21428571428571, 98.21428571428571, 100.0, 96.42857142857143, 100.0, 98.21428571428571, 98.21428571428571, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 99.10714285714286, 95.53571428571429, 98.21428571428571, 99.10714285714286, 98.21428571428571, 100.0, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 96.42857142857143, 99.10714285714286, 96.42857142857143, 97.32142857142857, 100.0, 91.96428571428571, 100.0, 96.42857142857143, 97.32142857142857, 91.96428571428571, 97.32142857142857, 99.10714285714286, 100.0, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 96.42857142857143, 100.0, 99.10714285714286, 99.10714285714286, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 100.0, 100.0, 95.53571428571429, 94.64285714285714, 99.10714285714286, 97.32142857142857, 98.21428571428571, 98.21428571428571, 98.21428571428571, 100.0, 98.21428571428571, 100.0, 99.10714285714286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 10.20%\n",
      "Loss on the train set: 2.30\n",
      "Accuracy on the test set: 10.67%\n",
      "Loss on the test set: 2.30\n",
      "Generalization error: -1.335144e-05\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
