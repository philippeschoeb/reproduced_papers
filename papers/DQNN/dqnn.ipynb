{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce67047",
   "metadata": {},
   "source": [
    "# Distributed Quantum Neural Networks on Distributed Photonic Quantum Computing (DQNN) with MerLin\n",
    "\n",
    "This implementation is based on prior work by [Chen *et al.*](https://arxiv.org/pdf/2505.08474v1) and their [repository](https://github.com/Louisanity/PhotonicQuantumTrain).\n",
    "\n",
    "This notebook will demonstrate the Quantum Train framework with:\n",
    "- A brief introduction to the concepts.\n",
    "- A tutorial on how to run a simple classification task with the MNIST dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad833d79",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "\n",
    "Parler de MPS, LE PROCESS\n",
    "\n",
    "The Photonic Quantum Train algorithm leverages the efficient expressivity of photons to represent an exponentionnaly large number of photons. Indeed in the example that will follow, only 17 photons are necessary to generate the 6690 parameters used in a complete CNN model. The full pipeline can be represented by this figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fbaf1d",
   "metadata": {},
   "source": [
    "![](images/md1.png)\n",
    "Source: K.-C. Chen, C.-Y. Liu, Y. Shang, F. Burt, and K. K. Leung, “Distributed Quantum Neural Networks on Distributed Photonic Quantum Computing,” May 13, 2025, arXiv: arXiv:2505.08474. doi: 10.48550/arXiv.2505.08474.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5834d04d",
   "metadata": {},
   "source": [
    "We can observe here that 2 boson sampler are used to generate probabilities of a 13 photon system. This probability distribution of $2^13$ elements is then processed by a quantum layer represented by an MPS. The MPS has 14 sites and an output dimension of 1. The role of this layer is to take the distribution and then process it into a list of classical parameters to assign to the CNN model on the right. The user can also change the bond dimension $\\chi$. Changing this hyperparameter directly controls the experessablity of the MPS layer. A higher bond dimension guves a higher expressability but also much more parameters to optimize.\n",
    "\n",
    "NOTE: In this notebook the ADAM optimizer will be used for the boson samplers and for the MPS layer since it is faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e072c2",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "The tutorial below decorticates the `run_default_exp` function in the [/papers.DQNN.lib/default_exp.py](/reproduced_papers/papers/DQNN/papers.DQNN.lib/default_exp.py) file. It is also possible to run this experiment simply by running this line. \n",
    " >``python3 papers.DQNN.lib/runner.py --exp_to_run DEFAULT``\n",
    "\n",
    " Other experiments are available. See the [README](/reproduced_papers/papers/DQNN/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f2bf0",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(__file__)))\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from papers.DQNN.lib.photonic_qt_utils import (\n",
    "    setup_session,\n",
    "    create_boson_samplers,\n",
    "    calculate_qubits,\n",
    ")\n",
    "from papers.DQNN.lib.model import PhotonicQuantumTrain, train_quantum_model, evaluate_model\n",
    "from papers.DQNN.lib.classical_utils import create_datasets, train_classical_cnn\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25401180",
   "metadata": {},
   "source": [
    "## 3. Load the data\n",
    "\n",
    "The partial MNIST set used in the paper and experiments can be accessed easily using this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22793353",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, train_loader, val_loader, batch_size = create_datasets()\n",
    "\n",
    "\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80165d",
   "metadata": {},
   "source": [
    "## 4. Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce60e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the two boson samplers to use\n",
    "bs_1, bs_2 = create_boson_samplers()\n",
    "\n",
    "#Calculates the number of qubits needed to generate all of the parameters of the CNN.\n",
    "#The nw_list_normal is a list which gives a template on how many parameters need to \n",
    "#be generated fp the classical CNN model.\n",
    "n_qubit, nw_list_normal = calculate_qubits()\n",
    "\n",
    "#Define the bond dimension of the MPS, by default we recommand 7\n",
    "bond_dim=7\n",
    "\n",
    "qt_model = PhotonicQuantumTrain(n_qubit, bond_dim=bond_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb8fc8",
   "metadata": {},
   "source": [
    "# 5. Run the CNN model by itself for comparaison\n",
    "\n",
    "To do so, the function below can be called. This function generates, trains, and prints the accuracy of the classical model. It returns it at the end for future uses. It is the same CNN structure that will be optimized by the quantum train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be527de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_classical_cnn(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    classical_epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4df62c",
   "metadata": {},
   "source": [
    "## 6. Train the Quantum Train\n",
    "\n",
    "To train the model the function below can be called. Here is a description of all of the parameters:\n",
    "\n",
    "- `qt_model` : PhotonicQuantumTrain\n",
    "    Model to train.\n",
    "- `train_loader` : DataLoader\n",
    "    Loader for standard training batches.\n",
    "- `train_loader_qnn` : DataLoader\n",
    "    Loader for QNN parameter training batches.\n",
    "- `bs_1` : BosonSampler\n",
    "    First boson sampler providing a quantum layer.\n",
    "- `bs_2` : BosonSampler\n",
    "    Second boson sampler providing a quantum layer.\n",
    "- `n_qubit` : int\n",
    "    Number of qubits used to generate the quantum states.\n",
    "- `nw_list_normal` : List[float]\n",
    "    Indices of network weights to keep from the generated probabilities.\n",
    "- `num_training_rounds` : int\n",
    "    Number of training rounds.\n",
    "- `num_epochs` : int\n",
    "    Number of epochs per training round for the MPS mapping network.\n",
    "- `num_qnn_train_step` : int, optional\n",
    "    Number of optimization steps for the QNN parameters. Default is 12. If the COBYLA optimizer is to be used, 1000 is the suggested value.\n",
    "- `qu_train_with_cobyla` : bool, optional\n",
    "    Whether to use COBYLA for QNN optimization. Default is False.\n",
    "\n",
    "The updated model, the updated parameters of the boson samplers, the loss and accuracy values per training round are returned. The parameters of the model are already updated, the returned parameters are just jere for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qt_model,qnn_parameters, loss_list_epoch, acc_list_epoch = train_quantum_model(\n",
    "        qt_model=qt_model,\n",
    "        train_loader=train_loader,\n",
    "        train_loader_qnn=train_loader_qnn,\n",
    "        bs_1=bs_1,\n",
    "        bs_2=bs_2,\n",
    "        n_qubit=n_qubit,\n",
    "        nw_list_normal=nw_list_normal,\n",
    "        num_training_rounds=30,\n",
    "        num_epochs=5,\n",
    "        qu_train_with_cobyla=False,\n",
    "        num_qnn_train_step=12,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce9f22f",
   "metadata": {},
   "source": [
    "# 7. Use the model as you want!\n",
    "\n",
    "A simple function who prints and returns  the performance for a test set is also available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc,loss,gen_error=evaluate_model(\n",
    "        qt_model, train_loader, val_loader, bs_1, bs_2, n_qubit, nw_list_normal\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69413583",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Other experiments are available in this repository. In order to run them and this one in just a terminal line, make sur the checkout the [README](/reproduced_papers/papers/DQNN/README.md)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quandela_1_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
