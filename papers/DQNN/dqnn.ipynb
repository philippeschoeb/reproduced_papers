{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce67047",
   "metadata": {},
   "source": [
    "# Distributed Quantum Neural Networks on Distributed Photonic Quantum Computing (DQNN) with MerLin\n",
    "\n",
    "This implementation is based on prior work by [Chen *et al.*](https://arxiv.org/pdf/2505.08474v1) and their [repository](https://github.com/Louisanity/PhotonicQuantumTrain).\n",
    "\n",
    "This notebook will demonstrate the Quantum Train framework with:\n",
    "- A brief introduction to the concepts.\n",
    "- A tutorial on how to run a simple classification task with the MNIST dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad833d79",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "The Photonic Quantum Train algorithm leverages the efficient expressivity of photons to represent an exponentially large number of photons. Indeed in the example that will follow, only 8 photons are necessary to generate the 6690 parameters used in a complete CNN model. The full pipeline can be represented by this figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fbaf1d",
   "metadata": {},
   "source": [
    "![](images/md1.png)\n",
    "\n",
    "Source: K.-C. Chen, C.-Y. Liu, Y. Shang, F. Burt, and K. K. Leung, “Distributed Quantum Neural Networks on Distributed Photonic Quantum Computing,” May 13, 2025, arXiv: arXiv:2505.08474. doi: 10.48550/arXiv.2505.08474.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5834d04d",
   "metadata": {},
   "source": [
    "We can observe here that 2 boson sampler are used to generate probabilities of a 13 photon system. This probability distribution of $2^13$ elements is then processed by a quantum layer represented by an MPS. The MPS has 14 sites and an output dimension of 1. The role of this layer is to take the distribution and then process it into a list of classical parameters to assign to the CNN model on the right. The user can also change the bond dimension $\\chi$. Changing this hyperparameter directly controls the expressability of the MPS layer. A higher bond dimension gives a higher expressability but also much more parameters to optimize.\n",
    "\n",
    "NOTE: In this notebook the ADAM optimizer will be used for the boson samplers and for the MPS layer since it is faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e072c2",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "The tutorial below decorticates the `run_default_exp` function in the [/papers/DQNN/lib/default_exp.py](lib/default_exp.py) file. It is also possible to run this experiment simply by running this line. \n",
    " >``python3 papers.DQNN.lib/runner.py --exp_to_run DEFAULT``\n",
    "\n",
    " Other experiments are available. See the [README](README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f2bf0",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc1c344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "REPO_ROOT = Path.cwd().resolve().parents[1]\n",
    "sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from papers.DQNN.lib.classical_utils import train_classical_cnn\n",
    "from papers.DQNN.lib.model import (\n",
    "    PhotonicQuantumTrain,\n",
    "    evaluate_model,\n",
    "    train_quantum_model,\n",
    ")\n",
    "from papers.DQNN.lib.photonic_qt_utils import (\n",
    "    calculate_qubits,\n",
    "    create_boson_samplers,\n",
    ")\n",
    "from papers.DQNN.utils.utils import create_datasets\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25401180",
   "metadata": {},
   "source": [
    "## 3. Load the data\n",
    "\n",
    "The partial MNIST set used in the paper and experiments can be accessed easily using this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22793353",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, train_loader, val_loader = create_datasets()\n",
    "\n",
    "\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80165d",
   "metadata": {},
   "source": [
    "## 4. Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86ce60e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n",
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n",
      "# of NN parameters for quantum circuit:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "# Create the two boson samplers to use\n",
    "bs_1, bs_2 = create_boson_samplers()\n",
    "\n",
    "# Calculates the number of qubits needed to generate all of the parameters of the CNN.\n",
    "# The nw_list_normal is a list which gives a template on how many parameters will be\n",
    "# generated by the quantum process.\n",
    "n_qubit, nw_list_normal = calculate_qubits()\n",
    "\n",
    "# Define the bond dimension of the MPS. By default, we recommand 7\n",
    "bond_dim = 7\n",
    "\n",
    "qt_model = PhotonicQuantumTrain(n_qubit, bond_dim=bond_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb8fc8",
   "metadata": {},
   "source": [
    "# 5. Run the CNN model by itself for comparaison\n",
    "\n",
    "To do so, the function below can be called. This function generates, trains, and prints the accuracy of the classical model. It returns it at the end for future uses. It is the same CNN structure that will be optimized by the quantum train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be527de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n",
      "Accuracy on the test set: 91.83%\n"
     ]
    }
   ],
   "source": [
    "model = train_classical_cnn(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4df62c",
   "metadata": {},
   "source": [
    "## 6. Train the Quantum Train\n",
    "\n",
    "To train the model the function below can be called. Here is a description of all of the parameters:\n",
    "\n",
    "- `qt_model` : PhotonicQuantumTrain\n",
    "    Model to train.\n",
    "- `train_loader` : DataLoader\n",
    "    Loader for standard training batches.\n",
    "- `train_loader_qnn` : DataLoader\n",
    "    Loader for QNN parameter training batches.\n",
    "- `bs_1` : BosonSampler\n",
    "    First boson sampler providing a quantum layer.\n",
    "- `bs_2` : BosonSampler\n",
    "    Second boson sampler providing a quantum layer.\n",
    "- `n_qubit` : int\n",
    "    Number of qubits used to generate the quantum states.\n",
    "- `nw_list_normal` : List[float]\n",
    "    Indices of network weights to keep from the generated probabilities.\n",
    "- `num_training_rounds` : int\n",
    "    Number of training rounds.\n",
    "- `num_epochs` : int\n",
    "    Number of epochs per training round for the MPS mapping network.\n",
    "- `num_qnn_train_step` : int, optional\n",
    "    Number of optimization steps for the QNN parameters. Default is 12. If the COBYLA optimizer is to be used, 1000 is the suggested value.\n",
    "- `qu_train_with_cobyla` : bool, optional\n",
    "    Whether to use COBYLA for QNN optimization. Default is False.\n",
    "\n",
    "The updated model, the updated parameters of the boson samplers, the loss and accuracy values per training round are returned. The parameters of the model are already updated, the returned parameters are just jere for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b74485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---- QNN parameters of shape (171,) \n",
      " ----\n",
      "# of trainable parameter in Mapping model:  1519\n",
      "# of trainable parameter in QNN model:  171\n",
      "# of trainable parameter in full model:  1690\n",
      "-----------------------\n",
      "Training round [1/15], Epoch [1/5], Step [47/47], Loss: 1.3797, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [1/15], Epoch [2/5], Step [47/47], Loss: 1.1450, batch time: 0.03, accuracy:  60.71%\n",
      "Training round [1/15], Epoch [3/5], Step [47/47], Loss: 0.7803, batch time: 0.04, accuracy:  69.64%\n",
      "Training round [1/15], Epoch [4/5], Step [47/47], Loss: 0.8698, batch time: 0.04, accuracy:  75.00%\n",
      "Training round [1/15], Epoch [5/5], Step [47/47], Loss: 0.8178, batch time: 0.04, accuracy:  72.32%\n",
      "Training round [1/15], Q-Epoch [1/12], Step [3/6], Loss: 0.7375, batch time: 0.08, accuracy:  76.40%\n",
      "Training round [1/15], Q-Epoch [1/12], Step [6/6], Loss: 0.7205, batch time: 0.08, accuracy:  76.40%\n",
      "Training round [1/15], Q-Epoch [2/12], Step [3/6], Loss: 0.7512, batch time: 0.08, accuracy:  76.50%\n",
      "Training round [1/15], Q-Epoch [2/12], Step [6/6], Loss: 0.8061, batch time: 0.08, accuracy:  73.30%\n",
      "Training round [1/15], Q-Epoch [3/12], Step [3/6], Loss: 0.7623, batch time: 0.08, accuracy:  75.90%\n",
      "Training round [1/15], Q-Epoch [3/12], Step [6/6], Loss: 0.7742, batch time: 0.08, accuracy:  74.90%\n",
      "Training round [1/15], Q-Epoch [4/12], Step [3/6], Loss: 0.7212, batch time: 0.08, accuracy:  77.30%\n",
      "Training round [1/15], Q-Epoch [4/12], Step [6/6], Loss: 0.7531, batch time: 0.09, accuracy:  75.70%\n",
      "Training round [1/15], Q-Epoch [5/12], Step [3/6], Loss: 0.7376, batch time: 0.08, accuracy:  77.60%\n",
      "Training round [1/15], Q-Epoch [5/12], Step [6/6], Loss: 0.7326, batch time: 0.08, accuracy:  77.30%\n",
      "Training round [1/15], Q-Epoch [6/12], Step [3/6], Loss: 0.7054, batch time: 0.08, accuracy:  76.40%\n",
      "Training round [1/15], Q-Epoch [6/12], Step [6/6], Loss: 0.6825, batch time: 0.08, accuracy:  77.40%\n",
      "Training round [1/15], Q-Epoch [7/12], Step [3/6], Loss: 0.7178, batch time: 0.08, accuracy:  77.10%\n",
      "Training round [1/15], Q-Epoch [7/12], Step [6/6], Loss: 0.7713, batch time: 0.08, accuracy:  76.30%\n",
      "Training round [1/15], Q-Epoch [8/12], Step [3/6], Loss: 0.7760, batch time: 0.08, accuracy:  76.50%\n",
      "Training round [1/15], Q-Epoch [8/12], Step [6/6], Loss: 0.7394, batch time: 0.07, accuracy:  76.80%\n",
      "Training round [1/15], Q-Epoch [9/12], Step [3/6], Loss: 0.7846, batch time: 0.08, accuracy:  75.60%\n",
      "Training round [1/15], Q-Epoch [9/12], Step [6/6], Loss: 0.7184, batch time: 0.08, accuracy:  76.40%\n",
      "Training round [1/15], Q-Epoch [10/12], Step [3/6], Loss: 0.7301, batch time: 0.08, accuracy:  75.70%\n",
      "Training round [1/15], Q-Epoch [10/12], Step [6/6], Loss: 0.7584, batch time: 0.08, accuracy:  75.20%\n",
      "Training round [1/15], Q-Epoch [11/12], Step [3/6], Loss: 0.8102, batch time: 0.08, accuracy:  74.40%\n",
      "Training round [1/15], Q-Epoch [11/12], Step [6/6], Loss: 0.8012, batch time: 0.08, accuracy:  75.30%\n",
      "Training round [1/15], Q-Epoch [12/12], Step [3/6], Loss: 0.8228, batch time: 0.08, accuracy:  74.50%\n",
      "Training round [1/15], Q-Epoch [12/12], Step [6/6], Loss: 0.7714, batch time: 0.08, accuracy:  76.60%\n",
      "-----------------------\n",
      "Training round [2/15], Epoch [1/5], Step [47/47], Loss: 0.6888, batch time: 0.04, accuracy:  75.89%\n",
      "Training round [2/15], Epoch [2/5], Step [47/47], Loss: 0.6378, batch time: 0.03, accuracy:  84.82%\n",
      "Training round [2/15], Epoch [3/5], Step [47/47], Loss: 0.5356, batch time: 0.04, accuracy:  78.57%\n",
      "Training round [2/15], Epoch [4/5], Step [47/47], Loss: 0.7393, batch time: 0.03, accuracy:  75.89%\n",
      "Training round [2/15], Epoch [5/5], Step [47/47], Loss: 0.3915, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [2/15], Q-Epoch [1/12], Step [3/6], Loss: 0.7286, batch time: 0.08, accuracy:  78.90%\n",
      "Training round [2/15], Q-Epoch [1/12], Step [6/6], Loss: 0.6227, batch time: 0.08, accuracy:  82.60%\n",
      "Training round [2/15], Q-Epoch [2/12], Step [3/6], Loss: 0.6874, batch time: 0.08, accuracy:  78.90%\n",
      "Training round [2/15], Q-Epoch [2/12], Step [6/6], Loss: 0.6671, batch time: 0.08, accuracy:  79.60%\n",
      "Training round [2/15], Q-Epoch [3/12], Step [3/6], Loss: 0.6775, batch time: 0.08, accuracy:  77.30%\n",
      "Training round [2/15], Q-Epoch [3/12], Step [6/6], Loss: 0.5998, batch time: 0.08, accuracy:  82.00%\n",
      "Training round [2/15], Q-Epoch [4/12], Step [3/6], Loss: 0.6439, batch time: 0.08, accuracy:  80.90%\n",
      "Training round [2/15], Q-Epoch [4/12], Step [6/6], Loss: 0.6547, batch time: 0.08, accuracy:  80.20%\n",
      "Training round [2/15], Q-Epoch [5/12], Step [3/6], Loss: 0.6517, batch time: 0.08, accuracy:  79.90%\n",
      "Training round [2/15], Q-Epoch [5/12], Step [6/6], Loss: 0.6052, batch time: 0.08, accuracy:  81.40%\n",
      "Training round [2/15], Q-Epoch [6/12], Step [3/6], Loss: 0.6093, batch time: 0.08, accuracy:  80.10%\n",
      "Training round [2/15], Q-Epoch [6/12], Step [6/6], Loss: 0.6087, batch time: 0.08, accuracy:  82.30%\n",
      "Training round [2/15], Q-Epoch [7/12], Step [3/6], Loss: 0.6015, batch time: 0.08, accuracy:  82.10%\n",
      "Training round [2/15], Q-Epoch [7/12], Step [6/6], Loss: 0.6626, batch time: 0.08, accuracy:  80.10%\n",
      "Training round [2/15], Q-Epoch [8/12], Step [3/6], Loss: 0.6634, batch time: 0.08, accuracy:  79.70%\n",
      "Training round [2/15], Q-Epoch [8/12], Step [6/6], Loss: 0.6366, batch time: 0.08, accuracy:  80.20%\n",
      "Training round [2/15], Q-Epoch [9/12], Step [3/6], Loss: 0.6574, batch time: 0.08, accuracy:  79.30%\n",
      "Training round [2/15], Q-Epoch [9/12], Step [6/6], Loss: 0.6252, batch time: 0.08, accuracy:  81.20%\n",
      "Training round [2/15], Q-Epoch [10/12], Step [3/6], Loss: 0.6241, batch time: 0.08, accuracy:  82.10%\n",
      "Training round [2/15], Q-Epoch [10/12], Step [6/6], Loss: 0.6142, batch time: 0.08, accuracy:  79.80%\n",
      "Training round [2/15], Q-Epoch [11/12], Step [3/6], Loss: 0.6948, batch time: 0.12, accuracy:  78.30%\n",
      "Training round [2/15], Q-Epoch [11/12], Step [6/6], Loss: 0.5966, batch time: 0.08, accuracy:  81.70%\n",
      "Training round [2/15], Q-Epoch [12/12], Step [3/6], Loss: 0.5985, batch time: 0.08, accuracy:  81.20%\n",
      "Training round [2/15], Q-Epoch [12/12], Step [6/6], Loss: 0.5742, batch time: 0.08, accuracy:  81.80%\n",
      "-----------------------\n",
      "Training round [3/15], Epoch [1/5], Step [47/47], Loss: 0.5431, batch time: 0.03, accuracy:  84.82%\n",
      "Training round [3/15], Epoch [2/5], Step [47/47], Loss: 0.5832, batch time: 0.04, accuracy:  80.36%\n",
      "Training round [3/15], Epoch [3/5], Step [47/47], Loss: 0.4661, batch time: 0.03, accuracy:  79.46%\n",
      "Training round [3/15], Epoch [4/5], Step [47/47], Loss: 0.6726, batch time: 0.04, accuracy:  83.93%\n",
      "Training round [3/15], Epoch [5/5], Step [47/47], Loss: 0.3875, batch time: 0.04, accuracy:  86.61%\n",
      "Training round [3/15], Q-Epoch [1/12], Step [3/6], Loss: 0.5092, batch time: 0.08, accuracy:  83.80%\n",
      "Training round [3/15], Q-Epoch [1/12], Step [6/6], Loss: 0.5200, batch time: 0.08, accuracy:  82.40%\n",
      "Training round [3/15], Q-Epoch [2/12], Step [3/6], Loss: 0.5529, batch time: 0.08, accuracy:  83.30%\n",
      "Training round [3/15], Q-Epoch [2/12], Step [6/6], Loss: 0.5128, batch time: 0.08, accuracy:  84.60%\n",
      "Training round [3/15], Q-Epoch [3/12], Step [3/6], Loss: 0.5712, batch time: 0.08, accuracy:  83.10%\n",
      "Training round [3/15], Q-Epoch [3/12], Step [6/6], Loss: 0.4784, batch time: 0.08, accuracy:  86.60%\n",
      "Training round [3/15], Q-Epoch [4/12], Step [3/6], Loss: 0.5056, batch time: 0.08, accuracy:  83.70%\n",
      "Training round [3/15], Q-Epoch [4/12], Step [6/6], Loss: 0.5228, batch time: 0.08, accuracy:  85.20%\n",
      "Training round [3/15], Q-Epoch [5/12], Step [3/6], Loss: 0.5232, batch time: 0.08, accuracy:  83.70%\n",
      "Training round [3/15], Q-Epoch [5/12], Step [6/6], Loss: 0.5376, batch time: 0.08, accuracy:  84.60%\n",
      "Training round [3/15], Q-Epoch [6/12], Step [3/6], Loss: 0.4888, batch time: 0.08, accuracy:  85.30%\n",
      "Training round [3/15], Q-Epoch [6/12], Step [6/6], Loss: 0.5505, batch time: 0.08, accuracy:  83.00%\n",
      "Training round [3/15], Q-Epoch [7/12], Step [3/6], Loss: 0.5673, batch time: 0.08, accuracy:  84.20%\n",
      "Training round [3/15], Q-Epoch [7/12], Step [6/6], Loss: 0.5399, batch time: 0.08, accuracy:  84.60%\n",
      "Training round [3/15], Q-Epoch [8/12], Step [3/6], Loss: 0.6206, batch time: 0.08, accuracy:  81.80%\n",
      "Training round [3/15], Q-Epoch [8/12], Step [6/6], Loss: 0.4977, batch time: 0.08, accuracy:  85.20%\n",
      "Training round [3/15], Q-Epoch [9/12], Step [3/6], Loss: 0.5769, batch time: 0.08, accuracy:  81.70%\n",
      "Training round [3/15], Q-Epoch [9/12], Step [6/6], Loss: 0.5062, batch time: 0.08, accuracy:  84.20%\n",
      "Training round [3/15], Q-Epoch [10/12], Step [3/6], Loss: 0.5946, batch time: 0.08, accuracy:  82.20%\n",
      "Training round [3/15], Q-Epoch [10/12], Step [6/6], Loss: 0.5415, batch time: 0.08, accuracy:  84.30%\n",
      "Training round [3/15], Q-Epoch [11/12], Step [3/6], Loss: 0.5140, batch time: 0.08, accuracy:  83.80%\n",
      "Training round [3/15], Q-Epoch [11/12], Step [6/6], Loss: 0.5177, batch time: 0.08, accuracy:  84.70%\n",
      "Training round [3/15], Q-Epoch [12/12], Step [3/6], Loss: 0.5313, batch time: 0.09, accuracy:  83.00%\n",
      "Training round [3/15], Q-Epoch [12/12], Step [6/6], Loss: 0.4687, batch time: 0.08, accuracy:  85.50%\n",
      "-----------------------\n",
      "Training round [4/15], Epoch [1/5], Step [47/47], Loss: 0.5116, batch time: 0.03, accuracy:  83.93%\n",
      "Training round [4/15], Epoch [2/5], Step [47/47], Loss: 0.5130, batch time: 0.04, accuracy:  82.14%\n",
      "Training round [4/15], Epoch [3/5], Step [47/47], Loss: 0.2635, batch time: 0.04, accuracy:  91.96%\n",
      "Training round [4/15], Epoch [4/5], Step [47/47], Loss: 0.4333, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [4/15], Epoch [5/5], Step [47/47], Loss: 0.4965, batch time: 0.04, accuracy:  81.25%\n",
      "Training round [4/15], Q-Epoch [1/12], Step [3/6], Loss: 0.4310, batch time: 0.08, accuracy:  87.10%\n",
      "Training round [4/15], Q-Epoch [1/12], Step [6/6], Loss: 0.5056, batch time: 0.08, accuracy:  86.00%\n",
      "Training round [4/15], Q-Epoch [2/12], Step [3/6], Loss: 0.4469, batch time: 0.07, accuracy:  86.50%\n",
      "Training round [4/15], Q-Epoch [2/12], Step [6/6], Loss: 0.4995, batch time: 0.08, accuracy:  85.30%\n",
      "Training round [4/15], Q-Epoch [3/12], Step [3/6], Loss: 0.4580, batch time: 0.11, accuracy:  87.30%\n",
      "Training round [4/15], Q-Epoch [3/12], Step [6/6], Loss: 0.4041, batch time: 0.09, accuracy:  87.80%\n",
      "Training round [4/15], Q-Epoch [4/12], Step [3/6], Loss: 0.5418, batch time: 0.08, accuracy:  84.70%\n",
      "Training round [4/15], Q-Epoch [4/12], Step [6/6], Loss: 0.4604, batch time: 0.09, accuracy:  87.20%\n",
      "Training round [4/15], Q-Epoch [5/12], Step [3/6], Loss: 0.4255, batch time: 0.09, accuracy:  86.90%\n",
      "Training round [4/15], Q-Epoch [5/12], Step [6/6], Loss: 0.4399, batch time: 0.08, accuracy:  87.80%\n",
      "Training round [4/15], Q-Epoch [6/12], Step [3/6], Loss: 0.4397, batch time: 0.08, accuracy:  87.80%\n",
      "Training round [4/15], Q-Epoch [6/12], Step [6/6], Loss: 0.4518, batch time: 0.08, accuracy:  87.70%\n",
      "Training round [4/15], Q-Epoch [7/12], Step [3/6], Loss: 0.3898, batch time: 0.08, accuracy:  87.10%\n",
      "Training round [4/15], Q-Epoch [7/12], Step [6/6], Loss: 0.4518, batch time: 0.07, accuracy:  88.60%\n",
      "Training round [4/15], Q-Epoch [8/12], Step [3/6], Loss: 0.5255, batch time: 0.08, accuracy:  85.10%\n",
      "Training round [4/15], Q-Epoch [8/12], Step [6/6], Loss: 0.3720, batch time: 0.08, accuracy:  89.70%\n",
      "Training round [4/15], Q-Epoch [9/12], Step [3/6], Loss: 0.4738, batch time: 0.08, accuracy:  86.00%\n",
      "Training round [4/15], Q-Epoch [9/12], Step [6/6], Loss: 0.4061, batch time: 0.08, accuracy:  87.50%\n",
      "Training round [4/15], Q-Epoch [10/12], Step [3/6], Loss: 0.4181, batch time: 0.08, accuracy:  87.20%\n",
      "Training round [4/15], Q-Epoch [10/12], Step [6/6], Loss: 0.5421, batch time: 0.08, accuracy:  86.10%\n",
      "Training round [4/15], Q-Epoch [11/12], Step [3/6], Loss: 0.5275, batch time: 0.08, accuracy:  86.70%\n",
      "Training round [4/15], Q-Epoch [11/12], Step [6/6], Loss: 0.3859, batch time: 0.08, accuracy:  88.60%\n",
      "Training round [4/15], Q-Epoch [12/12], Step [3/6], Loss: 0.4852, batch time: 0.08, accuracy:  86.30%\n",
      "Training round [4/15], Q-Epoch [12/12], Step [6/6], Loss: 0.3852, batch time: 0.08, accuracy:  88.60%\n",
      "-----------------------\n",
      "Training round [5/15], Epoch [1/5], Step [47/47], Loss: 0.3484, batch time: 0.03, accuracy:  86.61%\n",
      "Training round [5/15], Epoch [2/5], Step [47/47], Loss: 0.2744, batch time: 0.04, accuracy:  92.86%\n",
      "Training round [5/15], Epoch [3/5], Step [47/47], Loss: 0.2791, batch time: 0.03, accuracy:  89.29%\n",
      "Training round [5/15], Epoch [4/5], Step [47/47], Loss: 0.5439, batch time: 0.03, accuracy:  80.36%\n",
      "Training round [5/15], Epoch [5/5], Step [47/47], Loss: 0.3849, batch time: 0.04, accuracy:  89.29%\n",
      "Training round [5/15], Q-Epoch [1/12], Step [3/6], Loss: 0.4237, batch time: 0.08, accuracy:  87.70%\n",
      "Training round [5/15], Q-Epoch [1/12], Step [6/6], Loss: 0.3420, batch time: 0.08, accuracy:  90.50%\n",
      "Training round [5/15], Q-Epoch [2/12], Step [3/6], Loss: 0.4233, batch time: 0.08, accuracy:  88.00%\n",
      "Training round [5/15], Q-Epoch [2/12], Step [6/6], Loss: 0.3718, batch time: 0.08, accuracy:  89.50%\n",
      "Training round [5/15], Q-Epoch [3/12], Step [3/6], Loss: 0.4441, batch time: 0.07, accuracy:  87.00%\n",
      "Training round [5/15], Q-Epoch [3/12], Step [6/6], Loss: 0.3889, batch time: 0.08, accuracy:  89.70%\n",
      "Training round [5/15], Q-Epoch [4/12], Step [3/6], Loss: 0.3869, batch time: 0.08, accuracy:  89.10%\n",
      "Training round [5/15], Q-Epoch [4/12], Step [6/6], Loss: 0.3407, batch time: 0.08, accuracy:  90.60%\n",
      "Training round [5/15], Q-Epoch [5/12], Step [3/6], Loss: 0.4296, batch time: 0.08, accuracy:  89.10%\n",
      "Training round [5/15], Q-Epoch [5/12], Step [6/6], Loss: 0.4136, batch time: 0.08, accuracy:  87.00%\n",
      "Training round [5/15], Q-Epoch [6/12], Step [3/6], Loss: 0.4014, batch time: 0.13, accuracy:  88.40%\n",
      "Training round [5/15], Q-Epoch [6/12], Step [6/6], Loss: 0.4174, batch time: 0.08, accuracy:  87.10%\n",
      "Training round [5/15], Q-Epoch [7/12], Step [3/6], Loss: 0.4509, batch time: 0.08, accuracy:  87.80%\n",
      "Training round [5/15], Q-Epoch [7/12], Step [6/6], Loss: 0.3970, batch time: 0.08, accuracy:  88.20%\n",
      "Training round [5/15], Q-Epoch [8/12], Step [3/6], Loss: 0.3941, batch time: 0.08, accuracy:  89.00%\n",
      "Training round [5/15], Q-Epoch [8/12], Step [6/6], Loss: 0.4257, batch time: 0.08, accuracy:  86.50%\n",
      "Training round [5/15], Q-Epoch [9/12], Step [3/6], Loss: 0.4009, batch time: 0.08, accuracy:  88.90%\n",
      "Training round [5/15], Q-Epoch [9/12], Step [6/6], Loss: 0.3944, batch time: 0.08, accuracy:  89.60%\n",
      "Training round [5/15], Q-Epoch [10/12], Step [3/6], Loss: 0.4265, batch time: 0.07, accuracy:  87.60%\n",
      "Training round [5/15], Q-Epoch [10/12], Step [6/6], Loss: 0.4181, batch time: 0.08, accuracy:  88.60%\n",
      "Training round [5/15], Q-Epoch [11/12], Step [3/6], Loss: 0.3861, batch time: 0.08, accuracy:  89.50%\n",
      "Training round [5/15], Q-Epoch [11/12], Step [6/6], Loss: 0.4378, batch time: 0.08, accuracy:  86.20%\n",
      "Training round [5/15], Q-Epoch [12/12], Step [3/6], Loss: 0.3830, batch time: 0.08, accuracy:  89.20%\n",
      "Training round [5/15], Q-Epoch [12/12], Step [6/6], Loss: 0.4068, batch time: 0.08, accuracy:  88.40%\n",
      "-----------------------\n",
      "Training round [6/15], Epoch [1/5], Step [47/47], Loss: 0.3961, batch time: 0.04, accuracy:  84.82%\n",
      "Training round [6/15], Epoch [2/5], Step [47/47], Loss: 0.4380, batch time: 0.04, accuracy:  86.61%\n",
      "Training round [6/15], Epoch [3/5], Step [47/47], Loss: 0.3803, batch time: 0.04, accuracy:  91.96%\n",
      "Training round [6/15], Epoch [4/5], Step [47/47], Loss: 0.3865, batch time: 0.04, accuracy:  91.07%\n",
      "Training round [6/15], Epoch [5/5], Step [47/47], Loss: 0.3315, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [6/15], Q-Epoch [1/12], Step [3/6], Loss: 0.3228, batch time: 0.08, accuracy:  90.50%\n",
      "Training round [6/15], Q-Epoch [1/12], Step [6/6], Loss: 0.3930, batch time: 0.08, accuracy:  88.40%\n",
      "Training round [6/15], Q-Epoch [2/12], Step [3/6], Loss: 0.3511, batch time: 0.08, accuracy:  89.20%\n",
      "Training round [6/15], Q-Epoch [2/12], Step [6/6], Loss: 0.3022, batch time: 0.08, accuracy:  91.20%\n",
      "Training round [6/15], Q-Epoch [3/12], Step [3/6], Loss: 0.3536, batch time: 0.11, accuracy:  89.40%\n",
      "Training round [6/15], Q-Epoch [3/12], Step [6/6], Loss: 0.3860, batch time: 0.08, accuracy:  88.20%\n",
      "Training round [6/15], Q-Epoch [4/12], Step [3/6], Loss: 0.3424, batch time: 0.08, accuracy:  90.10%\n",
      "Training round [6/15], Q-Epoch [4/12], Step [6/6], Loss: 0.3333, batch time: 0.08, accuracy:  90.80%\n",
      "Training round [6/15], Q-Epoch [5/12], Step [3/6], Loss: 0.3517, batch time: 0.08, accuracy:  89.70%\n",
      "Training round [6/15], Q-Epoch [5/12], Step [6/6], Loss: 0.3287, batch time: 0.08, accuracy:  90.10%\n",
      "Training round [6/15], Q-Epoch [6/12], Step [3/6], Loss: 0.3240, batch time: 0.08, accuracy:  91.40%\n",
      "Training round [6/15], Q-Epoch [6/12], Step [6/6], Loss: 0.3280, batch time: 0.08, accuracy:  89.80%\n",
      "Training round [6/15], Q-Epoch [7/12], Step [3/6], Loss: 0.4024, batch time: 0.08, accuracy:  88.50%\n",
      "Training round [6/15], Q-Epoch [7/12], Step [6/6], Loss: 0.3603, batch time: 0.08, accuracy:  89.10%\n",
      "Training round [6/15], Q-Epoch [8/12], Step [3/6], Loss: 0.3786, batch time: 0.08, accuracy:  87.90%\n",
      "Training round [6/15], Q-Epoch [8/12], Step [6/6], Loss: 0.3270, batch time: 0.08, accuracy:  91.20%\n",
      "Training round [6/15], Q-Epoch [9/12], Step [3/6], Loss: 0.3669, batch time: 0.08, accuracy:  89.50%\n",
      "Training round [6/15], Q-Epoch [9/12], Step [6/6], Loss: 0.3514, batch time: 0.08, accuracy:  89.10%\n",
      "Training round [6/15], Q-Epoch [10/12], Step [3/6], Loss: 0.3340, batch time: 0.08, accuracy:  89.80%\n",
      "Training round [6/15], Q-Epoch [10/12], Step [6/6], Loss: 0.3731, batch time: 0.08, accuracy:  89.70%\n",
      "Training round [6/15], Q-Epoch [11/12], Step [3/6], Loss: 0.3515, batch time: 0.08, accuracy:  90.00%\n",
      "Training round [6/15], Q-Epoch [11/12], Step [6/6], Loss: 0.3118, batch time: 0.08, accuracy:  91.00%\n",
      "Training round [6/15], Q-Epoch [12/12], Step [3/6], Loss: 0.3116, batch time: 0.08, accuracy:  90.80%\n",
      "Training round [6/15], Q-Epoch [12/12], Step [6/6], Loss: 0.3536, batch time: 0.08, accuracy:  89.60%\n",
      "-----------------------\n",
      "Training round [7/15], Epoch [1/5], Step [47/47], Loss: 0.3784, batch time: 0.04, accuracy:  92.86%\n",
      "Training round [7/15], Epoch [2/5], Step [47/47], Loss: 0.2925, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [7/15], Epoch [3/5], Step [47/47], Loss: 0.3415, batch time: 0.04, accuracy:  90.18%\n",
      "Training round [7/15], Epoch [4/5], Step [47/47], Loss: 0.3762, batch time: 0.04, accuracy:  89.29%\n",
      "Training round [7/15], Epoch [5/5], Step [47/47], Loss: 0.3733, batch time: 0.03, accuracy:  89.29%\n",
      "Training round [7/15], Q-Epoch [1/12], Step [3/6], Loss: 0.3031, batch time: 0.07, accuracy:  92.40%\n",
      "Training round [7/15], Q-Epoch [1/12], Step [6/6], Loss: 0.3478, batch time: 0.08, accuracy:  89.20%\n",
      "Training round [7/15], Q-Epoch [2/12], Step [3/6], Loss: 0.2746, batch time: 0.10, accuracy:  91.00%\n",
      "Training round [7/15], Q-Epoch [2/12], Step [6/6], Loss: 0.3488, batch time: 0.08, accuracy:  90.00%\n",
      "Training round [7/15], Q-Epoch [3/12], Step [3/6], Loss: 0.3016, batch time: 0.08, accuracy:  91.30%\n",
      "Training round [7/15], Q-Epoch [3/12], Step [6/6], Loss: 0.3384, batch time: 0.08, accuracy:  90.20%\n",
      "Training round [7/15], Q-Epoch [4/12], Step [3/6], Loss: 0.3269, batch time: 0.08, accuracy:  91.40%\n",
      "Training round [7/15], Q-Epoch [4/12], Step [6/6], Loss: 0.2855, batch time: 0.08, accuracy:  91.30%\n",
      "Training round [7/15], Q-Epoch [5/12], Step [3/6], Loss: 0.3232, batch time: 0.08, accuracy:  90.40%\n",
      "Training round [7/15], Q-Epoch [5/12], Step [6/6], Loss: 0.3246, batch time: 0.08, accuracy:  91.30%\n",
      "Training round [7/15], Q-Epoch [6/12], Step [3/6], Loss: 0.2661, batch time: 0.08, accuracy:  92.20%\n",
      "Training round [7/15], Q-Epoch [6/12], Step [6/6], Loss: 0.3285, batch time: 0.08, accuracy:  90.70%\n",
      "Training round [7/15], Q-Epoch [7/12], Step [3/6], Loss: 0.3202, batch time: 0.08, accuracy:  90.70%\n",
      "Training round [7/15], Q-Epoch [7/12], Step [6/6], Loss: 0.3232, batch time: 0.08, accuracy:  90.40%\n",
      "Training round [7/15], Q-Epoch [8/12], Step [3/6], Loss: 0.2814, batch time: 0.08, accuracy:  90.90%\n",
      "Training round [7/15], Q-Epoch [8/12], Step [6/6], Loss: 0.3032, batch time: 0.07, accuracy:  91.80%\n",
      "Training round [7/15], Q-Epoch [9/12], Step [3/6], Loss: 0.2823, batch time: 0.08, accuracy:  91.00%\n",
      "Training round [7/15], Q-Epoch [9/12], Step [6/6], Loss: 0.3066, batch time: 0.08, accuracy:  90.70%\n",
      "Training round [7/15], Q-Epoch [10/12], Step [3/6], Loss: 0.3524, batch time: 0.08, accuracy:  89.00%\n",
      "Training round [7/15], Q-Epoch [10/12], Step [6/6], Loss: 0.3277, batch time: 0.08, accuracy:  90.60%\n",
      "Training round [7/15], Q-Epoch [11/12], Step [3/6], Loss: 0.3496, batch time: 0.07, accuracy:  90.30%\n",
      "Training round [7/15], Q-Epoch [11/12], Step [6/6], Loss: 0.3387, batch time: 0.08, accuracy:  90.20%\n",
      "Training round [7/15], Q-Epoch [12/12], Step [3/6], Loss: 0.3498, batch time: 0.08, accuracy:  89.60%\n",
      "Training round [7/15], Q-Epoch [12/12], Step [6/6], Loss: 0.3398, batch time: 0.08, accuracy:  90.30%\n",
      "-----------------------\n",
      "Training round [8/15], Epoch [1/5], Step [47/47], Loss: 0.2607, batch time: 0.04, accuracy:  91.96%\n",
      "Training round [8/15], Epoch [2/5], Step [47/47], Loss: 0.2887, batch time: 0.04, accuracy:  90.18%\n",
      "Training round [8/15], Epoch [3/5], Step [47/47], Loss: 0.4540, batch time: 0.04, accuracy:  89.29%\n",
      "Training round [8/15], Epoch [4/5], Step [47/47], Loss: 0.3145, batch time: 0.04, accuracy:  91.07%\n",
      "Training round [8/15], Epoch [5/5], Step [47/47], Loss: 0.2377, batch time: 0.04, accuracy:  91.96%\n",
      "Training round [8/15], Q-Epoch [1/12], Step [3/6], Loss: 0.3096, batch time: 0.08, accuracy:  91.60%\n",
      "Training round [8/15], Q-Epoch [1/12], Step [6/6], Loss: 0.2988, batch time: 0.08, accuracy:  89.20%\n",
      "Training round [8/15], Q-Epoch [2/12], Step [3/6], Loss: 0.3326, batch time: 0.08, accuracy:  91.10%\n",
      "Training round [8/15], Q-Epoch [2/12], Step [6/6], Loss: 0.3578, batch time: 0.08, accuracy:  88.60%\n",
      "Training round [8/15], Q-Epoch [3/12], Step [3/6], Loss: 0.2955, batch time: 0.08, accuracy:  92.70%\n",
      "Training round [8/15], Q-Epoch [3/12], Step [6/6], Loss: 0.2929, batch time: 0.08, accuracy:  90.60%\n",
      "Training round [8/15], Q-Epoch [4/12], Step [3/6], Loss: 0.3272, batch time: 0.08, accuracy:  90.00%\n",
      "Training round [8/15], Q-Epoch [4/12], Step [6/6], Loss: 0.3434, batch time: 0.08, accuracy:  89.30%\n",
      "Training round [8/15], Q-Epoch [5/12], Step [3/6], Loss: 0.3417, batch time: 0.08, accuracy:  89.30%\n",
      "Training round [8/15], Q-Epoch [5/12], Step [6/6], Loss: 0.3025, batch time: 0.08, accuracy:  90.70%\n",
      "Training round [8/15], Q-Epoch [6/12], Step [3/6], Loss: 0.3254, batch time: 0.08, accuracy:  89.10%\n",
      "Training round [8/15], Q-Epoch [6/12], Step [6/6], Loss: 0.3087, batch time: 0.08, accuracy:  90.20%\n",
      "Training round [8/15], Q-Epoch [7/12], Step [3/6], Loss: 0.3029, batch time: 0.08, accuracy:  90.50%\n",
      "Training round [8/15], Q-Epoch [7/12], Step [6/6], Loss: 0.3192, batch time: 0.08, accuracy:  89.80%\n",
      "Training round [8/15], Q-Epoch [8/12], Step [3/6], Loss: 0.3201, batch time: 0.08, accuracy:  89.10%\n",
      "Training round [8/15], Q-Epoch [8/12], Step [6/6], Loss: 0.2918, batch time: 0.09, accuracy:  90.70%\n",
      "Training round [8/15], Q-Epoch [9/12], Step [3/6], Loss: 0.3163, batch time: 0.08, accuracy:  90.80%\n",
      "Training round [8/15], Q-Epoch [9/12], Step [6/6], Loss: 0.2800, batch time: 0.09, accuracy:  91.60%\n",
      "Training round [8/15], Q-Epoch [10/12], Step [3/6], Loss: 0.3038, batch time: 0.08, accuracy:  90.60%\n",
      "Training round [8/15], Q-Epoch [10/12], Step [6/6], Loss: 0.3154, batch time: 0.08, accuracy:  90.30%\n",
      "Training round [8/15], Q-Epoch [11/12], Step [3/6], Loss: 0.3403, batch time: 0.08, accuracy:  90.70%\n",
      "Training round [8/15], Q-Epoch [11/12], Step [6/6], Loss: 0.3241, batch time: 0.08, accuracy:  89.50%\n",
      "Training round [8/15], Q-Epoch [12/12], Step [3/6], Loss: 0.3116, batch time: 0.08, accuracy:  91.20%\n",
      "Training round [8/15], Q-Epoch [12/12], Step [6/6], Loss: 0.3048, batch time: 0.08, accuracy:  89.60%\n",
      "-----------------------\n",
      "Training round [9/15], Epoch [1/5], Step [47/47], Loss: 0.2036, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [9/15], Epoch [2/5], Step [47/47], Loss: 0.3998, batch time: 0.04, accuracy:  88.39%\n",
      "Training round [9/15], Epoch [3/5], Step [47/47], Loss: 0.2877, batch time: 0.04, accuracy:  90.18%\n",
      "Training round [9/15], Epoch [4/5], Step [47/47], Loss: 0.2229, batch time: 0.03, accuracy:  91.96%\n",
      "Training round [9/15], Epoch [5/5], Step [47/47], Loss: 0.2762, batch time: 0.04, accuracy:  91.07%\n",
      "Training round [9/15], Q-Epoch [1/12], Step [3/6], Loss: 0.3552, batch time: 0.08, accuracy:  88.60%\n",
      "Training round [9/15], Q-Epoch [1/12], Step [6/6], Loss: 0.3415, batch time: 0.08, accuracy:  89.20%\n",
      "Training round [9/15], Q-Epoch [2/12], Step [3/6], Loss: 0.3381, batch time: 0.08, accuracy:  88.90%\n",
      "Training round [9/15], Q-Epoch [2/12], Step [6/6], Loss: 0.3171, batch time: 0.08, accuracy:  90.60%\n",
      "Training round [9/15], Q-Epoch [3/12], Step [3/6], Loss: 0.3237, batch time: 0.08, accuracy:  89.10%\n",
      "Training round [9/15], Q-Epoch [3/12], Step [6/6], Loss: 0.3555, batch time: 0.08, accuracy:  88.70%\n",
      "Training round [9/15], Q-Epoch [4/12], Step [3/6], Loss: 0.3551, batch time: 0.08, accuracy:  88.30%\n",
      "Training round [9/15], Q-Epoch [4/12], Step [6/6], Loss: 0.3166, batch time: 0.08, accuracy:  90.40%\n",
      "Training round [9/15], Q-Epoch [5/12], Step [3/6], Loss: 0.2825, batch time: 0.08, accuracy:  91.30%\n",
      "Training round [9/15], Q-Epoch [5/12], Step [6/6], Loss: 0.3522, batch time: 0.08, accuracy:  89.90%\n",
      "Training round [9/15], Q-Epoch [6/12], Step [3/6], Loss: 0.3008, batch time: 0.08, accuracy:  89.80%\n",
      "Training round [9/15], Q-Epoch [6/12], Step [6/6], Loss: 0.3415, batch time: 0.08, accuracy:  90.40%\n",
      "Training round [9/15], Q-Epoch [7/12], Step [3/6], Loss: 0.2746, batch time: 0.08, accuracy:  92.20%\n",
      "Training round [9/15], Q-Epoch [7/12], Step [6/6], Loss: 0.3099, batch time: 0.08, accuracy:  90.40%\n",
      "Training round [9/15], Q-Epoch [8/12], Step [3/6], Loss: 0.2892, batch time: 0.11, accuracy:  90.90%\n",
      "Training round [9/15], Q-Epoch [8/12], Step [6/6], Loss: 0.3657, batch time: 0.08, accuracy:  89.30%\n",
      "Training round [9/15], Q-Epoch [9/12], Step [3/6], Loss: 0.3190, batch time: 0.08, accuracy:  90.60%\n",
      "Training round [9/15], Q-Epoch [9/12], Step [6/6], Loss: 0.3304, batch time: 0.08, accuracy:  89.40%\n",
      "Training round [9/15], Q-Epoch [10/12], Step [3/6], Loss: 0.3435, batch time: 0.08, accuracy:  89.60%\n",
      "Training round [9/15], Q-Epoch [10/12], Step [6/6], Loss: 0.3507, batch time: 0.08, accuracy:  88.90%\n",
      "Training round [9/15], Q-Epoch [11/12], Step [3/6], Loss: 0.2836, batch time: 0.08, accuracy:  90.60%\n",
      "Training round [9/15], Q-Epoch [11/12], Step [6/6], Loss: 0.3716, batch time: 0.08, accuracy:  88.20%\n",
      "Training round [9/15], Q-Epoch [12/12], Step [3/6], Loss: 0.3171, batch time: 0.13, accuracy:  89.70%\n",
      "Training round [9/15], Q-Epoch [12/12], Step [6/6], Loss: 0.3176, batch time: 0.08, accuracy:  90.30%\n",
      "-----------------------\n",
      "Training round [10/15], Epoch [1/5], Step [47/47], Loss: 0.3522, batch time: 0.04, accuracy:  91.07%\n",
      "Training round [10/15], Epoch [2/5], Step [47/47], Loss: 0.2448, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [10/15], Epoch [3/5], Step [47/47], Loss: 0.2842, batch time: 0.04, accuracy:  91.96%\n",
      "Training round [10/15], Epoch [4/5], Step [47/47], Loss: 0.2314, batch time: 0.03, accuracy:  92.86%\n",
      "Training round [10/15], Epoch [5/5], Step [47/47], Loss: 0.2079, batch time: 0.03, accuracy:  91.07%\n",
      "Training round [10/15], Q-Epoch [1/12], Step [3/6], Loss: 0.2491, batch time: 0.08, accuracy:  92.70%\n",
      "Training round [10/15], Q-Epoch [1/12], Step [6/6], Loss: 0.2566, batch time: 0.08, accuracy:  92.50%\n",
      "Training round [10/15], Q-Epoch [2/12], Step [3/6], Loss: 0.2967, batch time: 0.08, accuracy:  92.70%\n",
      "Training round [10/15], Q-Epoch [2/12], Step [6/6], Loss: 0.2896, batch time: 0.08, accuracy:  90.00%\n",
      "Training round [10/15], Q-Epoch [3/12], Step [3/6], Loss: 0.2470, batch time: 0.08, accuracy:  93.10%\n",
      "Training round [10/15], Q-Epoch [3/12], Step [6/6], Loss: 0.2431, batch time: 0.08, accuracy:  92.50%\n",
      "Training round [10/15], Q-Epoch [4/12], Step [3/6], Loss: 0.2905, batch time: 0.08, accuracy:  92.00%\n",
      "Training round [10/15], Q-Epoch [4/12], Step [6/6], Loss: 0.2198, batch time: 0.08, accuracy:  93.40%\n",
      "Training round [10/15], Q-Epoch [5/12], Step [3/6], Loss: 0.2799, batch time: 0.08, accuracy:  91.50%\n",
      "Training round [10/15], Q-Epoch [5/12], Step [6/6], Loss: 0.2350, batch time: 0.08, accuracy:  93.00%\n",
      "Training round [10/15], Q-Epoch [6/12], Step [3/6], Loss: 0.2624, batch time: 0.08, accuracy:  92.10%\n",
      "Training round [10/15], Q-Epoch [6/12], Step [6/6], Loss: 0.2330, batch time: 0.08, accuracy:  93.00%\n",
      "Training round [10/15], Q-Epoch [7/12], Step [3/6], Loss: 0.2758, batch time: 0.08, accuracy:  92.60%\n",
      "Training round [10/15], Q-Epoch [7/12], Step [6/6], Loss: 0.2814, batch time: 0.09, accuracy:  91.40%\n",
      "Training round [10/15], Q-Epoch [8/12], Step [3/6], Loss: 0.2346, batch time: 0.08, accuracy:  92.60%\n",
      "Training round [10/15], Q-Epoch [8/12], Step [6/6], Loss: 0.2661, batch time: 0.18, accuracy:  91.80%\n",
      "Training round [10/15], Q-Epoch [9/12], Step [3/6], Loss: 0.2040, batch time: 0.08, accuracy:  93.50%\n",
      "Training round [10/15], Q-Epoch [9/12], Step [6/6], Loss: 0.2485, batch time: 0.07, accuracy:  93.10%\n",
      "Training round [10/15], Q-Epoch [10/12], Step [3/6], Loss: 0.2630, batch time: 0.07, accuracy:  92.40%\n",
      "Training round [10/15], Q-Epoch [10/12], Step [6/6], Loss: 0.2570, batch time: 0.08, accuracy:  91.60%\n",
      "Training round [10/15], Q-Epoch [11/12], Step [3/6], Loss: 0.2457, batch time: 0.07, accuracy:  93.30%\n",
      "Training round [10/15], Q-Epoch [11/12], Step [6/6], Loss: 0.2800, batch time: 0.07, accuracy:  90.70%\n",
      "Training round [10/15], Q-Epoch [12/12], Step [3/6], Loss: 0.2460, batch time: 0.07, accuracy:  91.60%\n",
      "Training round [10/15], Q-Epoch [12/12], Step [6/6], Loss: 0.2903, batch time: 0.07, accuracy:  91.70%\n",
      "-----------------------\n",
      "Training round [11/15], Epoch [1/5], Step [47/47], Loss: 0.2778, batch time: 0.04, accuracy:  92.86%\n",
      "Training round [11/15], Epoch [2/5], Step [47/47], Loss: 0.3294, batch time: 0.04, accuracy:  91.07%\n",
      "Training round [11/15], Epoch [3/5], Step [47/47], Loss: 0.3876, batch time: 0.04, accuracy:  85.71%\n",
      "Training round [11/15], Epoch [4/5], Step [47/47], Loss: 0.2364, batch time: 0.03, accuracy:  92.86%\n",
      "Training round [11/15], Epoch [5/5], Step [47/47], Loss: 0.1789, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [11/15], Q-Epoch [1/12], Step [3/6], Loss: 0.2304, batch time: 0.08, accuracy:  93.40%\n",
      "Training round [11/15], Q-Epoch [1/12], Step [6/6], Loss: 0.2769, batch time: 0.08, accuracy:  91.50%\n",
      "Training round [11/15], Q-Epoch [2/12], Step [3/6], Loss: 0.2282, batch time: 0.08, accuracy:  93.00%\n",
      "Training round [11/15], Q-Epoch [2/12], Step [6/6], Loss: 0.1889, batch time: 0.08, accuracy:  93.80%\n",
      "Training round [11/15], Q-Epoch [3/12], Step [3/6], Loss: 0.1955, batch time: 0.08, accuracy:  93.90%\n",
      "Training round [11/15], Q-Epoch [3/12], Step [6/6], Loss: 0.2448, batch time: 0.08, accuracy:  92.50%\n",
      "Training round [11/15], Q-Epoch [4/12], Step [3/6], Loss: 0.2145, batch time: 0.18, accuracy:  92.60%\n",
      "Training round [11/15], Q-Epoch [4/12], Step [6/6], Loss: 0.2778, batch time: 0.08, accuracy:  91.60%\n",
      "Training round [11/15], Q-Epoch [5/12], Step [3/6], Loss: 0.1658, batch time: 0.08, accuracy:  94.60%\n",
      "Training round [11/15], Q-Epoch [5/12], Step [6/6], Loss: 0.2637, batch time: 0.08, accuracy:  91.60%\n",
      "Training round [11/15], Q-Epoch [6/12], Step [3/6], Loss: 0.2462, batch time: 0.08, accuracy:  92.60%\n",
      "Training round [11/15], Q-Epoch [6/12], Step [6/6], Loss: 0.2399, batch time: 0.08, accuracy:  92.70%\n",
      "Training round [11/15], Q-Epoch [7/12], Step [3/6], Loss: 0.2303, batch time: 0.08, accuracy:  92.70%\n",
      "Training round [11/15], Q-Epoch [7/12], Step [6/6], Loss: 0.2534, batch time: 0.08, accuracy:  91.90%\n",
      "Training round [11/15], Q-Epoch [8/12], Step [3/6], Loss: 0.1923, batch time: 0.08, accuracy:  93.70%\n",
      "Training round [11/15], Q-Epoch [8/12], Step [6/6], Loss: 0.2134, batch time: 0.08, accuracy:  93.00%\n",
      "Training round [11/15], Q-Epoch [9/12], Step [3/6], Loss: 0.2488, batch time: 0.08, accuracy:  91.80%\n",
      "Training round [11/15], Q-Epoch [9/12], Step [6/6], Loss: 0.2151, batch time: 0.07, accuracy:  93.70%\n",
      "Training round [11/15], Q-Epoch [10/12], Step [3/6], Loss: 0.2136, batch time: 0.08, accuracy:  93.60%\n",
      "Training round [11/15], Q-Epoch [10/12], Step [6/6], Loss: 0.2546, batch time: 0.08, accuracy:  91.50%\n",
      "Training round [11/15], Q-Epoch [11/12], Step [3/6], Loss: 0.2070, batch time: 0.07, accuracy:  93.70%\n",
      "Training round [11/15], Q-Epoch [11/12], Step [6/6], Loss: 0.2308, batch time: 0.08, accuracy:  92.10%\n",
      "Training round [11/15], Q-Epoch [12/12], Step [3/6], Loss: 0.2636, batch time: 0.08, accuracy:  92.30%\n",
      "Training round [11/15], Q-Epoch [12/12], Step [6/6], Loss: 0.1937, batch time: 0.08, accuracy:  94.00%\n",
      "-----------------------\n",
      "Training round [12/15], Epoch [1/5], Step [47/47], Loss: 0.4095, batch time: 0.04, accuracy:  88.39%\n",
      "Training round [12/15], Epoch [2/5], Step [47/47], Loss: 0.2473, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [12/15], Epoch [3/5], Step [47/47], Loss: 0.1903, batch time: 0.04, accuracy:  94.64%\n",
      "Training round [12/15], Epoch [4/5], Step [47/47], Loss: 0.1927, batch time: 0.04, accuracy:  92.86%\n",
      "Training round [12/15], Epoch [5/5], Step [47/47], Loss: 0.1651, batch time: 0.04, accuracy:  95.54%\n",
      "Training round [12/15], Q-Epoch [1/12], Step [3/6], Loss: 0.2455, batch time: 0.08, accuracy:  91.80%\n",
      "Training round [12/15], Q-Epoch [1/12], Step [6/6], Loss: 0.2557, batch time: 0.08, accuracy:  92.50%\n",
      "Training round [12/15], Q-Epoch [2/12], Step [3/6], Loss: 0.2564, batch time: 0.08, accuracy:  92.50%\n",
      "Training round [12/15], Q-Epoch [2/12], Step [6/6], Loss: 0.2227, batch time: 0.08, accuracy:  91.50%\n",
      "Training round [12/15], Q-Epoch [3/12], Step [3/6], Loss: 0.2221, batch time: 0.08, accuracy:  93.20%\n",
      "Training round [12/15], Q-Epoch [3/12], Step [6/6], Loss: 0.2193, batch time: 0.08, accuracy:  93.80%\n",
      "Training round [12/15], Q-Epoch [4/12], Step [3/6], Loss: 0.2369, batch time: 0.08, accuracy:  91.80%\n",
      "Training round [12/15], Q-Epoch [4/12], Step [6/6], Loss: 0.2311, batch time: 0.08, accuracy:  92.80%\n",
      "Training round [12/15], Q-Epoch [5/12], Step [3/6], Loss: 0.2225, batch time: 0.08, accuracy:  93.20%\n",
      "Training round [12/15], Q-Epoch [5/12], Step [6/6], Loss: 0.2279, batch time: 0.08, accuracy:  92.40%\n",
      "Training round [12/15], Q-Epoch [6/12], Step [3/6], Loss: 0.2569, batch time: 0.08, accuracy:  92.30%\n",
      "Training round [12/15], Q-Epoch [6/12], Step [6/6], Loss: 0.2494, batch time: 0.12, accuracy:  93.00%\n",
      "Training round [12/15], Q-Epoch [7/12], Step [3/6], Loss: 0.2093, batch time: 0.08, accuracy:  93.20%\n",
      "Training round [12/15], Q-Epoch [7/12], Step [6/6], Loss: 0.2327, batch time: 0.08, accuracy:  92.10%\n",
      "Training round [12/15], Q-Epoch [8/12], Step [3/6], Loss: 0.2217, batch time: 0.08, accuracy:  93.30%\n",
      "Training round [12/15], Q-Epoch [8/12], Step [6/6], Loss: 0.2626, batch time: 0.08, accuracy:  92.00%\n",
      "Training round [12/15], Q-Epoch [9/12], Step [3/6], Loss: 0.2430, batch time: 0.08, accuracy:  92.80%\n",
      "Training round [12/15], Q-Epoch [9/12], Step [6/6], Loss: 0.2561, batch time: 0.08, accuracy:  91.10%\n",
      "Training round [12/15], Q-Epoch [10/12], Step [3/6], Loss: 0.2461, batch time: 0.08, accuracy:  92.10%\n",
      "Training round [12/15], Q-Epoch [10/12], Step [6/6], Loss: 0.1938, batch time: 0.08, accuracy:  93.60%\n",
      "Training round [12/15], Q-Epoch [11/12], Step [3/6], Loss: 0.2144, batch time: 0.14, accuracy:  93.00%\n",
      "Training round [12/15], Q-Epoch [11/12], Step [6/6], Loss: 0.2529, batch time: 0.08, accuracy:  91.60%\n",
      "Training round [12/15], Q-Epoch [12/12], Step [3/6], Loss: 0.2414, batch time: 0.09, accuracy:  92.40%\n",
      "Training round [12/15], Q-Epoch [12/12], Step [6/6], Loss: 0.2432, batch time: 0.08, accuracy:  92.40%\n",
      "-----------------------\n",
      "Training round [13/15], Epoch [1/5], Step [47/47], Loss: 0.2312, batch time: 0.03, accuracy:  92.86%\n",
      "Training round [13/15], Epoch [2/5], Step [47/47], Loss: 0.2830, batch time: 0.04, accuracy:  90.18%\n",
      "Training round [13/15], Epoch [3/5], Step [47/47], Loss: 0.2084, batch time: 0.04, accuracy:  90.18%\n",
      "Training round [13/15], Epoch [4/5], Step [47/47], Loss: 0.2436, batch time: 0.07, accuracy:  91.07%\n",
      "Training round [13/15], Epoch [5/5], Step [47/47], Loss: 0.4857, batch time: 0.04, accuracy:  88.39%\n",
      "Training round [13/15], Q-Epoch [1/12], Step [3/6], Loss: 0.2485, batch time: 0.08, accuracy:  92.20%\n",
      "Training round [13/15], Q-Epoch [1/12], Step [6/6], Loss: 0.2412, batch time: 0.08, accuracy:  92.60%\n",
      "Training round [13/15], Q-Epoch [2/12], Step [3/6], Loss: 0.2509, batch time: 0.08, accuracy:  92.40%\n",
      "Training round [13/15], Q-Epoch [2/12], Step [6/6], Loss: 0.1961, batch time: 0.08, accuracy:  94.40%\n",
      "Training round [13/15], Q-Epoch [3/12], Step [3/6], Loss: 0.2341, batch time: 0.08, accuracy:  92.80%\n",
      "Training round [13/15], Q-Epoch [3/12], Step [6/6], Loss: 0.2401, batch time: 0.07, accuracy:  93.10%\n",
      "Training round [13/15], Q-Epoch [4/12], Step [3/6], Loss: 0.1968, batch time: 0.08, accuracy:  93.60%\n",
      "Training round [13/15], Q-Epoch [4/12], Step [6/6], Loss: 0.2070, batch time: 0.08, accuracy:  93.60%\n",
      "Training round [13/15], Q-Epoch [5/12], Step [3/6], Loss: 0.2294, batch time: 0.08, accuracy:  92.80%\n",
      "Training round [13/15], Q-Epoch [5/12], Step [6/6], Loss: 0.2361, batch time: 0.08, accuracy:  92.10%\n",
      "Training round [13/15], Q-Epoch [6/12], Step [3/6], Loss: 0.2243, batch time: 0.08, accuracy:  93.30%\n",
      "Training round [13/15], Q-Epoch [6/12], Step [6/6], Loss: 0.1991, batch time: 0.08, accuracy:  94.30%\n",
      "Training round [13/15], Q-Epoch [7/12], Step [3/6], Loss: 0.2444, batch time: 0.08, accuracy:  92.50%\n",
      "Training round [13/15], Q-Epoch [7/12], Step [6/6], Loss: 0.2136, batch time: 0.08, accuracy:  93.80%\n",
      "Training round [13/15], Q-Epoch [8/12], Step [3/6], Loss: 0.2283, batch time: 0.08, accuracy:  92.80%\n",
      "Training round [13/15], Q-Epoch [8/12], Step [6/6], Loss: 0.2025, batch time: 0.08, accuracy:  94.20%\n",
      "Training round [13/15], Q-Epoch [9/12], Step [3/6], Loss: 0.2118, batch time: 0.08, accuracy:  93.80%\n",
      "Training round [13/15], Q-Epoch [9/12], Step [6/6], Loss: 0.1807, batch time: 0.08, accuracy:  94.60%\n",
      "Training round [13/15], Q-Epoch [10/12], Step [3/6], Loss: 0.2517, batch time: 0.08, accuracy:  92.70%\n",
      "Training round [13/15], Q-Epoch [10/12], Step [6/6], Loss: 0.1985, batch time: 0.08, accuracy:  93.70%\n",
      "Training round [13/15], Q-Epoch [11/12], Step [3/6], Loss: 0.1996, batch time: 0.08, accuracy:  93.70%\n",
      "Training round [13/15], Q-Epoch [11/12], Step [6/6], Loss: 0.2058, batch time: 0.08, accuracy:  92.70%\n",
      "Training round [13/15], Q-Epoch [12/12], Step [3/6], Loss: 0.2497, batch time: 0.08, accuracy:  92.20%\n",
      "Training round [13/15], Q-Epoch [12/12], Step [6/6], Loss: 0.2556, batch time: 0.08, accuracy:  91.70%\n",
      "-----------------------\n",
      "Training round [14/15], Epoch [1/5], Step [47/47], Loss: 0.1592, batch time: 0.04, accuracy:  95.54%\n",
      "Training round [14/15], Epoch [2/5], Step [47/47], Loss: 0.3019, batch time: 0.03, accuracy:  91.07%\n",
      "Training round [14/15], Epoch [3/5], Step [47/47], Loss: 0.2792, batch time: 0.04, accuracy:  91.96%\n",
      "Training round [14/15], Epoch [4/5], Step [47/47], Loss: 0.3750, batch time: 0.03, accuracy:  92.86%\n",
      "Training round [14/15], Epoch [5/5], Step [47/47], Loss: 0.3186, batch time: 0.03, accuracy:  94.64%\n",
      "Training round [14/15], Q-Epoch [1/12], Step [3/6], Loss: 0.2272, batch time: 0.08, accuracy:  93.70%\n",
      "Training round [14/15], Q-Epoch [1/12], Step [6/6], Loss: 0.2044, batch time: 0.08, accuracy:  93.50%\n",
      "Training round [14/15], Q-Epoch [2/12], Step [3/6], Loss: 0.2254, batch time: 0.08, accuracy:  93.30%\n",
      "Training round [14/15], Q-Epoch [2/12], Step [6/6], Loss: 0.2095, batch time: 0.08, accuracy:  93.90%\n",
      "Training round [14/15], Q-Epoch [3/12], Step [3/6], Loss: 0.2359, batch time: 0.13, accuracy:  93.00%\n",
      "Training round [14/15], Q-Epoch [3/12], Step [6/6], Loss: 0.2076, batch time: 0.08, accuracy:  93.50%\n",
      "Training round [14/15], Q-Epoch [4/12], Step [3/6], Loss: 0.2087, batch time: 0.08, accuracy:  94.60%\n",
      "Training round [14/15], Q-Epoch [4/12], Step [6/6], Loss: 0.1722, batch time: 0.10, accuracy:  94.90%\n",
      "Training round [14/15], Q-Epoch [5/12], Step [3/6], Loss: 0.2118, batch time: 0.08, accuracy:  93.60%\n",
      "Training round [14/15], Q-Epoch [5/12], Step [6/6], Loss: 0.2245, batch time: 0.08, accuracy:  93.70%\n",
      "Training round [14/15], Q-Epoch [6/12], Step [3/6], Loss: 0.1833, batch time: 0.08, accuracy:  94.20%\n",
      "Training round [14/15], Q-Epoch [6/12], Step [6/6], Loss: 0.1900, batch time: 0.08, accuracy:  94.70%\n",
      "Training round [14/15], Q-Epoch [7/12], Step [3/6], Loss: 0.1713, batch time: 0.08, accuracy:  94.80%\n",
      "Training round [14/15], Q-Epoch [7/12], Step [6/6], Loss: 0.2217, batch time: 0.08, accuracy:  92.90%\n",
      "Training round [14/15], Q-Epoch [8/12], Step [3/6], Loss: 0.2210, batch time: 0.08, accuracy:  93.50%\n",
      "Training round [14/15], Q-Epoch [8/12], Step [6/6], Loss: 0.1988, batch time: 0.08, accuracy:  93.90%\n",
      "Training round [14/15], Q-Epoch [9/12], Step [3/6], Loss: 0.2153, batch time: 0.08, accuracy:  93.60%\n",
      "Training round [14/15], Q-Epoch [9/12], Step [6/6], Loss: 0.2295, batch time: 0.09, accuracy:  92.10%\n",
      "Training round [14/15], Q-Epoch [10/12], Step [3/6], Loss: 0.1848, batch time: 0.08, accuracy:  94.30%\n",
      "Training round [14/15], Q-Epoch [10/12], Step [6/6], Loss: 0.2075, batch time: 0.09, accuracy:  93.10%\n",
      "Training round [14/15], Q-Epoch [11/12], Step [3/6], Loss: 0.2067, batch time: 0.08, accuracy:  93.50%\n",
      "Training round [14/15], Q-Epoch [11/12], Step [6/6], Loss: 0.2233, batch time: 0.09, accuracy:  93.50%\n",
      "Training round [14/15], Q-Epoch [12/12], Step [3/6], Loss: 0.2241, batch time: 0.08, accuracy:  92.60%\n",
      "Training round [14/15], Q-Epoch [12/12], Step [6/6], Loss: 0.2046, batch time: 0.08, accuracy:  93.40%\n",
      "-----------------------\n",
      "Training round [15/15], Epoch [1/5], Step [47/47], Loss: 0.3233, batch time: 0.04, accuracy:  89.29%\n",
      "Training round [15/15], Epoch [2/5], Step [47/47], Loss: 0.3215, batch time: 0.04, accuracy:  89.29%\n",
      "Training round [15/15], Epoch [3/5], Step [47/47], Loss: 0.2069, batch time: 0.04, accuracy:  94.64%\n",
      "Training round [15/15], Epoch [4/5], Step [47/47], Loss: 0.2028, batch time: 0.04, accuracy:  92.86%\n",
      "Training round [15/15], Epoch [5/5], Step [47/47], Loss: 0.4348, batch time: 0.04, accuracy:  88.39%\n",
      "Training round [15/15], Q-Epoch [1/12], Step [3/6], Loss: 0.2067, batch time: 0.08, accuracy:  93.10%\n",
      "Training round [15/15], Q-Epoch [1/12], Step [6/6], Loss: 0.1881, batch time: 0.08, accuracy:  93.90%\n",
      "Training round [15/15], Q-Epoch [2/12], Step [3/6], Loss: 0.2171, batch time: 0.08, accuracy:  93.00%\n",
      "Training round [15/15], Q-Epoch [2/12], Step [6/6], Loss: 0.2359, batch time: 0.08, accuracy:  93.30%\n",
      "Training round [15/15], Q-Epoch [3/12], Step [3/6], Loss: 0.1942, batch time: 0.08, accuracy:  94.30%\n",
      "Training round [15/15], Q-Epoch [3/12], Step [6/6], Loss: 0.2125, batch time: 0.08, accuracy:  94.00%\n",
      "Training round [15/15], Q-Epoch [4/12], Step [3/6], Loss: 0.1864, batch time: 0.08, accuracy:  94.70%\n",
      "Training round [15/15], Q-Epoch [4/12], Step [6/6], Loss: 0.1608, batch time: 0.08, accuracy:  94.40%\n",
      "Training round [15/15], Q-Epoch [5/12], Step [3/6], Loss: 0.2131, batch time: 0.08, accuracy:  94.50%\n",
      "Training round [15/15], Q-Epoch [5/12], Step [6/6], Loss: 0.2121, batch time: 0.08, accuracy:  93.30%\n",
      "Training round [15/15], Q-Epoch [6/12], Step [3/6], Loss: 0.2127, batch time: 0.08, accuracy:  94.20%\n",
      "Training round [15/15], Q-Epoch [6/12], Step [6/6], Loss: 0.1905, batch time: 0.08, accuracy:  94.00%\n",
      "Training round [15/15], Q-Epoch [7/12], Step [3/6], Loss: 0.2268, batch time: 0.08, accuracy:  93.30%\n",
      "Training round [15/15], Q-Epoch [7/12], Step [6/6], Loss: 0.2046, batch time: 0.08, accuracy:  93.50%\n",
      "Training round [15/15], Q-Epoch [8/12], Step [3/6], Loss: 0.2065, batch time: 0.08, accuracy:  93.00%\n",
      "Training round [15/15], Q-Epoch [8/12], Step [6/6], Loss: 0.2085, batch time: 0.08, accuracy:  93.40%\n",
      "Training round [15/15], Q-Epoch [9/12], Step [3/6], Loss: 0.1807, batch time: 0.07, accuracy:  94.50%\n",
      "Training round [15/15], Q-Epoch [9/12], Step [6/6], Loss: 0.2132, batch time: 0.08, accuracy:  93.00%\n",
      "Training round [15/15], Q-Epoch [10/12], Step [3/6], Loss: 0.1818, batch time: 0.13, accuracy:  94.50%\n",
      "Training round [15/15], Q-Epoch [10/12], Step [6/6], Loss: 0.1907, batch time: 0.08, accuracy:  93.80%\n",
      "Training round [15/15], Q-Epoch [11/12], Step [3/6], Loss: 0.2291, batch time: 0.08, accuracy:  92.80%\n",
      "Training round [15/15], Q-Epoch [11/12], Step [6/6], Loss: 0.1961, batch time: 0.08, accuracy:  94.00%\n",
      "Training round [15/15], Q-Epoch [12/12], Step [3/6], Loss: 0.2188, batch time: 0.08, accuracy:  93.80%\n",
      "Training round [15/15], Q-Epoch [12/12], Step [6/6], Loss: 0.1790, batch time: 0.08, accuracy:  94.10%\n"
     ]
    }
   ],
   "source": [
    "qt_model, qnn_parameters, loss_list_epoch, acc_list_epoch = train_quantum_model(\n",
    "    qt_model=qt_model,\n",
    "    train_loader=train_loader,\n",
    "    train_loader_qnn=train_loader_qnn,\n",
    "    bs_1=bs_1,\n",
    "    bs_2=bs_2,\n",
    "    n_qubit=n_qubit,\n",
    "    nw_list_normal=nw_list_normal,\n",
    "    num_training_rounds=15,\n",
    "    num_epochs=5,\n",
    "    qu_train_with_cobyla=False,\n",
    "    num_qnn_train_step=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce9f22f",
   "metadata": {},
   "source": [
    "# 7. Use the model as you want!\n",
    "\n",
    "A simple function who prints and returns the performance for a test set is also available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8b2bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 93.93%\n",
      "Loss on the train set: 0.20\n",
      "Accuracy on the test set: 94.00%\n",
      "Loss on the test set: 0.27\n",
      "Generalization error: 0.07287425\n"
     ]
    }
   ],
   "source": [
    "acc, loss, gen_error = evaluate_model(\n",
    "    qt_model, train_loader, val_loader, bs_1, bs_2, n_qubit, nw_list_normal\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69413583",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Other experiments are available in this repository. In order to run them and this one in just a terminal line, make sur the checkout the [README](README.md)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quandela_1_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
